{"./":{"url":"./","title":"Introduction","keywords":"","body":"1. My Notebook1.1. Gitbook Cli1. My Notebook All my stuff 1.1. Gitbook Cli cd folder npm install -g gitbook-cli gitbook init gitbook build # 生成在当前目录的默认文件夹 _book里面 gitbook build ./out # 生成在当前目录的默认文件夹 指定的 out 里面 gitbook serve # localhost:4000 配置文件，不必须 { \"title\": \"前端规范\", \"description\": \"前端规范 简介\", \"language\": \"zh-hans\", \"plugins\": [ \"-lunr\", \"-search\", \"search-plus\", //支持中文搜索 上面 search 是默认的 “-” 是去掉的意思 \"splitter\", // 这个侧边可以拉伸 \"tbfed-pagefooter\", //这个是底部加 信息 下面可以看到具体的配置 \"expandable-chapters-small\" //使左侧的章节目录可以折叠 ], \"pluginsConfig\": { \"theme-default\": { \"showLevel\": true }, \"tbfed-pagefooter\": { \"copyright\": \"Copyright &copy xxxxx\", \"modify_label\": \"该文件修订时间：\", \"modify_format\": \"YYYY-MM-DD HH:mm:ss\" } }, \"links\": { \"gitbook\": false, \"sharing\": { \"google\": false, \"facebook\": false, \"twitter\": false, \"all\": false } } } 参考资料：http://gitbook.zhangjikai.com/plugins.html Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/":{"url":"CSS/","title":"CSS","keywords":"","body":"1. TOC1. TOC animation code_reset code_清除浮动 css3各种图形 interview_BFC interview_css动画硬件加速 interview_css变量 interview_css模块化 interview_flex interview_requestAnimationFrame interview_retina屏幕css interview_元素显示隐藏的几种方案 interview_垂直水平居中 interview_布局 sass transform transition Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"CSS/animation.html":{"url":"CSS/animation.html","title":"animation","keywords":"","body":"1. 动画1.1. 定义关键帧1.2. 施加动画1.3. 动画调速1.4. 延迟、重复、方向、结束状态1.5. 速记写法1.6. 暂停动画1. 动画 与 Transition 不同，CSS3 动画不需要触发就能开始。虽然仍可以向 :hover 状态添加一个动画，在鼠标移上时播放。但也可以让动画在页面加载后就开始。 动画的基础是一组关键帧。可以认为 Transition 只支持两个关键帧，而动画支持多个关键帧。 1.1. 定义关键帧 @keyframes animationName { from { /* list CSS properties here */ } to { /* list CSS properties here */ } } @keyframes 不是一个 CSS 属性，它是一个规则（rule）。(其他 CSS 规则如 @import @media。) 至少得有两个关键帧。可以使用关键字 from 和 to 创建开始帧的结束帧。例如，让元素渐现的动画： @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } } 可以使用百分比创建多个帧。关键字 from 和 to 可以用 0% 和 100% 代替。 @keyframes backgroundGlow { from { background-color: yellow; } 50% { background-color: blue; } to { background-color: red; } } 每个帧内可以放多个属性： @keyframes growAndGlow { from { background-color: yellow; } 50% { transform: scale(1.5); background-color: blue; } to { transform: scale(3); background-color: red; } } 若多个百分比使用同一组属性（帧）则可以造成暂停的效果。例如下面的例子，从 25% 到 75%（即一半的时间）一直停在蓝色上： @keyframes glow { from { background-color: yellow; } 25%, 75% { background-color: blue; } to { background-color: red; } } 如果多个时刻的关键帧相同，可以将它们列在一起。例如，20% 的时候蓝色，40% 的时候橙色，60% 的时候再回到蓝色…… @keyframes glow { from { background-color: yellow; } 20%, 60% { background-color: blue; } 40%, 80% { background-color: orange; } to { background-color: red; } } 1.2. 施加动画 对元素施加动画，在页面加载后立即指定动画。利用这点可以实现介绍性的动画。 还可以对伪类施加（:hover、:active、:target、:focus）。或者施加到一个 CSS 类上，然后通过 Javascript 动态的将 CSS 类应用到某个元素上。 CSS3 提供了一些动画相关的属性，控制动画播放的方式和时间。最少需要指定动画名和持续时间： @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } } .announcement { animation-name: fadeIn; animation-duration: 1s; } 将动画名放在引号内，不是必须的，但可以防止与 CSS 关键字冲突。 可以同时施加多个动画，如 fadeIn 和 blink；指定不同的持续时间： animation-name: fadeIn, blink; animation-duration: 1s, 3s; 与 transitions 一样，时间单位可以是秒（s）或毫秒（ms）。 1.3. 动画调速 通过 animation-timing-function 控制动画速度。可以使用 cubic-Bezier 曲线，或内建的关键字（linear, ease, ease-in, ease-out, ease-in-out）。 调速函数可以控制整个动画或特定帧。 .announcement { animation-name: fadeIn; animation-duration: 1s; animation-timing-function: ease-out; } 控制帧速度： @keyframes growAndGlow { from { background-color: yellow; animation-timing-function: cubic-bezier(1, .03, 1, .115); } 50% { transform: scale(1.5); background-color: blue; animation-timing-function: linear; } to { transform: scale(3); background-color: red; } } 1.4. 延迟、重复、方向、结束状态 利用 animation-delay 延迟动画开始： .announcement { animation-name: fadeIn; animation-duration: 1s; animation-delay: 1s; } 控制动画播放次数： animation-iteration-count: 10; animation-iteration-count: infinite 会导致动画持续播放。 若动画播放超过一次，默认下一次动画开始时会重头播放。如果想让动画正一次，反一次，利用 animation-direction: alternate。（默认是 normal） 动画完成后（如果动画持续多次，指多次重复都结束后，即“最后的最后”），默认元素回到动画开始前的状态。例如若动画放大按钮，动画结束后，按钮默认缩小的原来的状态。如果要让元素停在动画结束的状态，设置属性 animation-fill-mode: forwards。 1.5. 速记写法 animation 属性组合了以下属性：animation-name, animation-duration, animation-timing-function, animation-iteration-count, animation-direction, animation-delay, animation-fill-mode。 .fade { animation-name: fadeOut; animation-duration: 2s; animation-timing-function: ease-in-out; animation-iteration-count: 2; animation-direction: alternate; animation-delay: 5s; animation-fill-mode: forwards; } 可以简写成： .fade { animation: fadeOut 2s ease-in-out 2 alternate 5s forwards; } 若要对元素施加多个动画，只需要逗号分隔多个列表。如施加 fadeOut 和 glow： .fade { animation: fadeOut 2s ease-in-out 2 alternate 5s forwards, glow 5s; } 1.6. 暂停动画 属性 animation-play-state 控制动画的重放。它接收两个关键字 running 或 paused。后者暂停动画。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/code_reset.html":{"url":"CSS/code_reset.html","title":"code_reset","keywords":"","body":"1. css reset 重置1.1. 如何修改 chrome 记住密码后自动填充表单的黄色背景 ？1.2. 让页面里的字体变清晰，变细用CSS怎么做？1. css reset 重置 1.1. 如何修改 chrome 记住密码后自动填充表单的黄色背景 ？ input:-webkit-autofill, textarea:-webkit-autofill, select:-webkit-autofill { background-color: rgb(250, 255, 189); /* #FAFFBD; */ background-image: none; color: rgb(0, 0, 0); } 1.2. 让页面里的字体变清晰，变细用CSS怎么做？ -webkit-font-smoothing: antialiased; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/code_清除浮动.html":{"url":"CSS/code_清除浮动.html","title":"code_清除浮动","keywords":"","body":"1. 清除浮动，触发 BFC1. 清除浮动，触发 BFC .clear{zoom:1;} .clear:after{content:\"\"; display:block;clear:both;} /*给浮动元素的父级加 */ /* other methods 1.给父级也加浮动 2.给父级加display:inline-block 3.在浮动元素下加 .clear{ height:0px;font-size:0;clear:both;} 4.在浮动元素下加 5.给浮动元素的父级overflow:hidden 并且zoom:1; */ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/css3各种图形.html":{"url":"CSS/css3各种图形.html","title":"css3各种图形","keywords":"","body":"1. css3 实现的各种常用图形1. css3 实现的各种常用图形 http://www.jqhtml.com/8045.html Square Rectangle Circle oval Triangle Up Triangle Down Triangle Left Triangle Right Triangle Top Left Triangle Top Right Triangle Bottom Left Triangle Bottom Right Curved Tail Arrow Trapezoid Parallelogram Star (6-points) Star (5-points) Pentagon Hexagon Octagon Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_BFC.html":{"url":"CSS/interview_BFC.html","title":"interview_BFC","keywords":"","body":"1. 边距重叠解决方案(BFC -- block format context 块级格式化上下文)1.1. 原理，渲染规则1.2. 如何创建 BFC1.3. 使用场景1. 边距重叠解决方案(BFC -- block format context 块级格式化上下文) 边距重叠包含父子、兄弟 \b父子关系，子元素高度 100px，margin-top 10px，这时容器高度也是 100px，如果想让容器高度也是 110px，需要创建 BFC，常见是给容器加上 overflow hidden 1.1. 原理，渲染规则 BFC 内部的盒会在垂直方向一个接一个排列（可以看作BFC中有一个的常规流），他们相互影响，可能会发生 margin collapse BFC 在页面上是一个独立的容器，外面元素和里面的元素不会相互影响。 BFC 的区域不会与浮动元素重叠（清除浮动原理） 计算 BFC 高度时浮动元素也会参与计算 1.2. 如何创建 BFC float 不为 none position 不为 relative or static display 设为 inline-block, table-cell, table overflow hidden/auto (不是 visible 就行) 1.3. 使用场景 可以包含浮动元素，清除浮动用 不被浮动元素覆盖 阻止元素的 margin 垂直方向重叠 清除浮动，其背后原理就是浮动元素也参与计算 CSS盒模型 html * { margin: 0; padding: 0; } #sec { background: #f00; /* overflow: hidden; */ } .child { height: 100px; margin-top: 10px; background: yellow } #margin { background: pink; overflow: hidden; } #margin>p { margin: 5px auto 25px; background: red; } 如果是3个p并列，他们margin重叠。解决办法，在其中一个 p 套上 div，让他BFC，此时margin会相加 2 2 3 #layout .left { float: left; width: 100px; height: 100px; background: pink; } #layout .right { height: 110px; background: #ccc; overflow: auto; } #float { background: red; overflow: auto; /*float: left;*/ } #float .float { float: left; font-size: 30px; } 我是浮动元素 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_css动画硬件加速.html":{"url":"CSS/interview_css动画硬件加速.html","title":"interview_css动画硬件加速","keywords":"","body":"1. 用 CSS 开启硬件加速来提高网站性能1.1. 硬件加速是非规范的1.1.1. GPU 合成代价1.1.2. 创建复合层1.1.3. 硬件加速的优缺点1.1.4. 性能优化技巧1.2. 使用硬件加速的注意事项1.3. 总结1.3.1. reference1. 用 CSS 开启硬件加速来提高网站性能 只允许改变 transform、opacity，其它属性不要动，避免重新计算布局(reflow) 对动画元素应用 transform: translate3d(0, 0, 0)、will-change: transform 等，开启硬件加速 动画元素尽量用 fixed、absolute 定位方式，避免 reflow 对动画元素应用高一点的 z-index，减少复合层数量 1.1. 硬件加速是非规范的 很多情况下，开启硬件加速确实能带来明显的性能提升，但是，这部分内容是非规范的，W3C并没有相关规范说明其中细节，所以通过一些技巧（例如transform: translate3d(0, 0, 0)）开启硬件加速是规范之外的行为，可能得到性能提升，也可能带来严重的性能问题。 1.1.1. GPU 合成代价 GPU是独立的一部分，有自己的处理器、内存核数据处理模型，那么意味着通过 CPU 在内存里创建的图像数据无法直接与 GPU 共享，需要打包发送给GPU，GPU 收到后才能执行我们期望的一系列操作，这个过程需要时间，而打包数据需要内存。 需要的内存取决于： 复合层的数量 复合层的大小 如果复合层太多太大，内存会被迅速消耗，然后掉帧（卡顿、闪烁）现象，甚至浏览器/应用崩溃也就很合理了。 1.1.2. 创建复合层 浏览器在一些情况下会创建复合层，例如： 显示复合层： 3D transforms: translate3d, translateZ and so on; , and elements; animation of transform and opacity via Element.animate(); animation of transform and opacity via СSS transitions and animations; position: fixed; will-change; 隐式复合层： 位于复合层之上的元素会被创建复合层（B 的 z-index 大于 A，对 A 做动画，B 也会被塞进独立的复合层） 很容易理解，A 在动画过程中可能会与 B 产生重叠，被 B 遮住，那么 GPU 需要每帧对 A 图层做动画，然后再与 B 图层合成，才能得到正确结果，所以 B 无论如何都要被塞进复合层，连同 A 一起交给 GPU 隐式创建复合层主要出于重叠考虑，如果浏览器不确定会不会发生重叠，那么就要把不确定的东西都塞进复合层，所以，从这个角度看，高 z-index 原则是有道理的 1.1.3. 硬件加速的优缺点 优点： 动画非常流畅，能达到 60fps 动画执行过程在独立线程里，不受计算密集的JS任务影响 缺点： 把元素塞进复合层时需要额外重绘，有时很慢（可能需要整页重绘） 复合层数据传递给 GPU 有额外时耗，取决于复合层的数量和大小，这在中低端设备可能会导致闪烁 每个复合层都要消耗一部分内存，移动设备上内存很贵，过多占用会导致浏览器/应用崩溃 存在隐式复合层的问题，不注意的话内存飙升 文字模糊，元素有时会变形 1.1.4. 性能优化技巧 尽量避免隐式复合层 复合层直接影响repaint、内存消耗：动画开始时创建复合层、结束时删除复合层，都会引起repaint，而动画开始时必须把图层数据发送给GPU，内存消耗集中在这里。两条建议： 给动画元素应用高z-index，最好直接作为body的子元素，对于嵌套很深的动画元素，可以复制一个到body下，仅用于实现动画效果 给动画元素应用will-change，浏览器会提前把这些元素塞进复合层，可以让动画开始/结束时更流畅些，但不能滥用，在不需要的时候赶紧去掉，减少内存消耗 只改变 transform 和 opacity 减少复合层的大小：减小width、height，减少传递给GPU的数据，由 GPU 做scale放大展示，视觉效果无差异（多用于纯色背景元素，对不太重要的图片也可以进行5%到10%的宽高压缩），例如： #a, #b { will-change: transform; background-color: #f00; } #a { width: 100px; height: 100px; } #b { width: 10px; height: 10px; transform: scale(10); } 最终显示的两个红色块在视觉上没有差异，但减小了90%的内存消耗 考虑对子元素动画与容器动画 容器动画可能存在不必要的内存消耗，比如子元素之间的空隙，也会被当做有效数据发送给GPU，如果对各个子元素分别应用动画，就能避免这部分的内存消耗 例如 12道太阳光线旋转，转容器就把容器整张图都发送给GPU，单独转12道光线就去掉了光线之间的11条空隙，能够节省一半内存 早早关注复合层的数量和大小 从一开始就关注复合层，尤其是隐式创建的复合层，避免后期优化影响布局 复合层的大小比数量影响更大，但浏览器会做一些优化操作，把几个复合层整合成一个，叫 Layer Squashing，但有时一个大复合层比几个小复合层消耗的内存更多，有必要的话可以手动去掉这种优化： 不要滥用硬件加速 没事不要乱加transform: translateZ(0)、will-change: transform等强制开启硬件加速的属性，GPU 合成存在缺点和不足，而且是非标准的行为，最好情况能带来显著性能提升，最坏情况可能会让浏览器崩溃 CSS animations, transforms 以及 transitions 不会自动开启GPU加速，而是由浏览器的缓慢的软件渲染引擎来执行。当浏览器检测到页面中某个 DOM元素应用了某些 CSS 规则时就会开启，最显著的特征的元素的 3D 变换。 虽然我们可能不想对元素应用3D变换，可我们一样可以开启3D引擎。例如我们可以用 transform: translateZ(0); 来开启硬件加速 。 .cube { transform: translateZ(0); /* Or */ transform: rotateZ(360deg); /* Other transform properties here */ } 在 Chrome and Safari 中，当我们使用 CSS transform 或者 animation 时可能会有页面闪烁的效果，下面的代码可以修复此情况： .cube { backface-visibility: hidden; perspective: 1000; /* Other transform properties here */ } 在webkit内核的浏览器中，另一个行之有效的方法是 cube { transform: translate3d(0, 0, 0); /* Other transform properties here */ } 原生的移动端应用(Native mobile applications)总是可以很好的运用GPU，这是为什么它比网页应用(Web apps)表现更好的原因。硬件加速在移动端尤其有用，因为它可以有效的减少资源的利用。 在使用动画的时候不要用 top, left, 使用 transform: translate. Render tree 的元素被分到图层中，图层被 GPU 形成渲染文理。transform 属性不会触发浏览器的 repaint，而 left 和 top 则会一直触发 repaint. 1.2. 使用硬件加速的注意事项 不能让每个元素都启用硬件加速，这样会暂用很大的内存，使页面会有很强的卡顿感。 GPU渲染会影响字体的抗锯齿效果。这是因为 GPU 和 CPU 具有不同的渲染机制，即使最终硬件加速停止了，文本还是会在动画期间显示得很模糊。 1.3. 总结 使用 GPU 可以优化动画效果 GPU 渲染动会达到 60fps 使用对 GPU 友好的 CSS 属性 理解强制触发硬件加速的 transform 技巧 如果仅仅为了开启硬件加速而随便乱用，那是不明智的。小心使用这些方法，如果通过你的测试，结果确是提高了性能，你才可以使用这些方法。使用GPU可能会导致严重的性能问题，因为它增加了内存的使用，而且它会减少移动端设备的电池寿命。 1.3.1. reference http://www.ayqy.net/blog/css%E5%8A%A8%E7%94%BB%E4%B8%8Egpu/ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_css变量.html":{"url":"CSS/interview_css变量.html","title":"interview_css变量","keywords":"","body":"1. CSS 变量教程1.1. 一、变量的声明1.2. 二、var() 函数1.3. 三、变量值的类型1.4. 四、作用域1.5. 五、响应式布局1.6. 六、兼容性处理1.7. 七、JavaScript 操作1. CSS 变量教程 1.1. 一、变量的声明 声明变量的时候，变量名前面要加两根连词线（--）。 body { --foo: #7F583F; --bar: #F7EFD2; } 上面代码中，body 选择器里面声明了两个变量：--foo 和 --bar。 它们与 color、font-size 等正式属性没有什么不同，只是没有默认含义。所以 CSS 变量（CSS variable）又叫做\"CSS 自定义属性\"（CSS custom properties）。因为变量与自定义的 CSS 属性其实是一回事。 你可能会问，为什么选择两根连词线（--）表示变量？因为$foo被 Sass 用掉了，@foo被 Less 用掉了。为了不产生冲突，官方的 CSS 变量就改用两根连词线了。 各种值都可以放入 CSS 变量。 :root{ --main-color: #4d4e53; --main-bg: rgb(255, 255, 255); --logo-border-color: rebeccapurple; --header-height: 68px; --content-padding: 10px 20px; --base-line-height: 1.428571429; --transition-duration: .35s; --external-link: \"external link\"; --margin-top: calc(2vh + 20px); } 变量名大小写敏感，--header-color和--Header-Color是两个不同变量。 1.2. 二、var() 函数 var() 函数用于读取变量。 a { color: var(--foo); text-decoration-color: var(--bar); } var() 函数还可以使用第二个参数，表示变量的默认值。如果该变量不存在，就会使用这个默认值。 color: var(--foo, #7F583F); 第二个参数不处理内部的逗号或空格，都视作参数的一部分。 var(--font-stack, \"Roboto\", \"Helvetica\"); var(--pad, 10px 15px 20px); var() 函数还可以用在变量的声明。 :root { --primary-color: red; --logo-text: var(--primary-color); } 注意，变量值只能用作属性值，不能用作属性名。 .foo { --side: margin-top; /* 无效 */ var(--side): 20px; } 上面代码中，变量 --side 用作属性名，这是无效的。 1.3. 三、变量值的类型 如果变量值是一个字符串，可以与其他字符串拼接。 --bar: 'hello'; --foo: var(--bar)' world'; 利用这一点，可以 debug（例子）。 body:after { content: '--screen-category : 'var(--screen-category); } 如果变量值是数值，不能与数值单位直接连用。 .foo { --gap: 20; /* 无效 */ margin-top: var(--gap)px; } 上面代码中，数值与单位直接写在一起，这是无效的。必须使用calc()函数，将它们连接。 .foo { --gap: 20; margin-top: calc(var(--gap) * 1px); } 如果变量值带有单位，就不能写成字符串。 /* 无效 */ .foo { --foo: '20px'; font-size: var(--foo); } /* 有效 */ .foo { --foo: 20px; font-size: var(--foo); } 1.4. 四、作用域 同一个 CSS 变量，可以在多个选择器内声明。读取的时候，优先级最高的声明生效。这与 CSS 的\"层叠\"（cascade）规则是一致的。 下面是一个例子。 :root { --color: blue; } div { --color: green; } #alert { --color: red; } * { color: var(--color); } 蓝色 绿色 红色 上面代码中，三个选择器都声明了--color变量。不同元素读取这个变量的时候，会采用优先级最高的规则，因此三段文字的颜色是不一样的。 这就是说，变量的作用域就是它所在的选择器的有效范围。 body { --foo: #7F583F; } .content { --bar: #F7EFD2; } 上面代码中，变量--foo的作用域是body选择器的生效范围，--bar的作用域是.content选择器的生效范围。 由于这个原因，全局的变量通常放在根元素:root里面，确保任何选择器都可以读取它们。 :root { --main-color: #06c; } 1.5. 五、响应式布局 CSS 是动态的，页面的任何变化，都会导致采用的规则变化。 利用这个特点，可以在响应式布局的media命令里面声明变量，使得不同的屏幕宽度有不同的变量值。 body { --primary: #7F583F; --secondary: #F7EFD2; } a { color: var(--primary); text-decoration-color: var(--secondary); } @media screen and (min-width: 768px) { body { --primary: #F7EFD2; --secondary: #7F583F; } } 1.6. 六、兼容性处理 对于不支持 CSS 变量的浏览器，可以采用下面的写法。 a { color: #7F583F; color: var(--primary); } 也可以使用@support命令进行检测。 @supports ( (--a: 0)) { /* supported */ } @supports ( not (--a: 0)) { /* not supported */ } 1.7. 七、JavaScript 操作 JavaScript 也可以检测浏览器是否支持 CSS 变量。 const isSupported = window.CSS && window.CSS.supports && window.CSS.supports('--a', 0); if (isSupported) { /* supported */ } else { /* not supported */ } JavaScript 操作 CSS 变量的写法如下。 // 设置变量 document.body.style.setProperty('--primary', '#7F583F'); // 读取变量 document.body.style.getPropertyValue('--primary').trim(); // '#7F583F' // 删除变量 document.body.style.removeProperty('--primary'); 这意味着，JavaScript 可以将任意值存入样式表。下面是一个监听事件的例子，事件信息被存入 CSS 变量。 const docStyle = document.documentElement.style; document.addEventListener('mousemove', (e) => { docStyle.setProperty('--mouse-x', e.clientX); docStyle.setProperty('--mouse-y', e.clientY); }); 那些对 CSS 无用的信息，也可以放入 CSS 变量。 --foo: if(x > 5) this.width = 10; 上面代码中，--foo 的值在 CSS 里面是无效语句，但是可以被 JavaScript 读取。这意味着，可以把样式设置写在 CSS 变量中，让 JavaScript 读取。 所以，CSS 变量提供了 JavaScript 与 CSS 通信的一种途径。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_css模块化.html":{"url":"CSS/interview_css模块化.html","title":"interview_css模块化","keywords":"","body":"1. css 模块化1.1. style 标签位置，由于 scoped 不再被支持，淘汰1.2. css @import 语法，和 scss less @import 一个思路，模块化思想第一步1.2.1. link 与 @import 的区别1.3. 实际项目解决方法，模块化思路 ✅1.3.1. CSS Modules1.3.2. 在生产环境中使用1.3.3. 多个 class1.4. reference1. css 模块化 ​下面说的是多页面非 SPA，在模块化开发的过程中，每一个模块都是一个独立的小系统，有自己的 html, js, css。js 模块化很方便移植。但是css 的引入却是个问题。问题在于一个页面要使用这个模块，要么在头部用 link 标签引入对应的 css 文件，要么直接把模块的 css 放在全局 css进行打包；前者属于有的放矢，有效的保证了资源的利用，但是需要人工引入，不方便；后者直接放在全局，虽然实现了方便性，但也对于不需要此模块的页面增加了负担，也增加了css样式相互影响的风险。 几种 css 模块化实践: 1.1. style 标签位置，由于 scoped 不再被支持，淘汰 html 页面样式文件的引入主要有三种方式： 直接通过 style 属性写在 html 标签内，也就是行内样式 引入外部 css 文件的形式，也即外联样式 通过 标签嵌入到 标签内，就是嵌入式 另一种方案：==就是在 标签中放置 标签，隔离其他区域的样式==。然而现在连 firefox 55 版本后默认都不支持了，虽然可以开启。 W3C 关于 style 标签放置位置的规范，html5 中 块元素都可以包裹 style 标签。 scoped: style加入此属性后，这些属性只会在当前包裹它的元素及其子元素内生效，如果没有此属性，则会在全局生效。 如此一来，我们不仅实现了模块的移植便利，还很好的控制了模块的css作用范围，再也不用担心选择器冲突导致的各种样式混乱啦。 1.2. css @import 语法，和 scss less @import 一个思路，模块化思想第一步 首先我们知道 @import 很少用，有些缺点： @import 的文件是额外请求的，所以页面加载的时候会有一小会儿的裸体（FOUC flash of unstyled content, 样式没加载进来），要等这些模块一个一个加载 请求数太多，页面性能不佳，对服务器压力也会相对大一些。 不同的浏览器以及不同的书写形式可能会有不同的加载顺序。 1.2.1. link 与 @import 的区别 link 是 HTML方式， @import 是CSS方式 link 最大限度支持并行下载，@import 过多嵌套导致串行下载，出现 FOUC @import 必须在样式规则之前，可以在css文件中引用其他文件 总体来说：link 优于 @import /*xxx 页面入口样式文件 style.css*/ @import './css/base.css';/*页面基础样式*/ @import './css/index.css'; @import './css/header.css'; @import './css/footer.css'; 这样模块化避免大家修改一个或者几个大的 css。未来想换个 footer，把原先的 comment 掉，添加新的就好。还方面后续再换回来。删除某个模块也方便。 最好的办法就是把模块打包！这和js模块化一样的，模块化开发，然后上线之前打包，线上完美使用。 CSS Combo：CSS模块打包利器 首先安装 css combo：npm install -g css-combo 进入你所在的入口文件（本例为style.css）目录，输入：csscombo style.css style.combo.css 这样就会把 style.css 文件打包成 style.combo.css 文件 把所有的模块 import 都放在入口文件的最开始，方便管理。 less, scss 和 css combo 解决的不是一类问题，less 更多的是把 css 编程化，css combo 只专注 css 模块打包。 不管用上面 css @import 还是 sass、less 通过 @import ，只能部分解决的 css 模块化的问题。 由于 css 是全局的，在被引入的文件和当前文件出现重名的情况下，前者样式就会被后者覆盖。在引入一些公用组件，或者多人协作开发同一页面的时候，就需要考虑样式会不会被覆盖，这很麻烦。 // file A .name { color: red } // file B @import \"A.scss\"; .name { color: green } css 全局样式的特点，导致 css 难以维护，所以需要一种 css \"局部\"样式的解决方案。也就是彻底的 css 模块化，@import 进来的 css 模块不能影响覆盖其他模块。 1.3. 实际项目解决方法，模块化思路 ✅ 所有模块都有一个唯一的 id，模块内的所有样式的选择器前都会加上所在模块的 id，这样就避免了模块间的 css 样式到处跑了。或者通过在每个 class 名后带一个独一无二 hash 值，这样就不有存在全局命名冲突的问题了。这样就相当于伪造了\"局部\"样式。 // 原始样式 styles.css .title { color: red; } // 原始模板 demo.html import styles from 'styles.css'; Hello World // 编译后的 styles.css .title_3zyde { color: red; } // 编译后的 demo.html Hello World 1.3.1. CSS Modules 实现上面的效果需要借助 Webpack, Browserify 等 CSS Modules 允许使用 :global(.className) 的语法，声明一个全局规则。凡是这样声明的 class，都不会被编译成哈希字符串。 /* App.css 加入一个全局 class */ .title { color: red; } :global(.title) { color: green; } 限制： You have to use camelCase CSS class names. You have to use styles object whenever constructing a className. Mixing CSS Modules and global CSS classes is cumbersome. Reference to an undefined CSS Module resolves to undefined without a warning. webpack 1.x 与 CSS Modules webpack 自带的 css-loader 组件，自带了 CSS Modules，通过简单的配置即可使用。 { test: /\\.css$/, loader: \"css?modules&localIdentName=[name]__[local]--[hash:base64:5]\" } 命名规范是从 BEM 扩展而来。 Block: 对应模块名 [name] Element: 对应节点名 [local] Modifier: 对应节点状态 [hash:base64:5] 使用 和 -- 是为了区块内单词的分割节点区分开来。最终 class 名为 `stylestitle--3zyde`。 1.3.2. 在生产环境中使用 在实际生产中，结合 sass 使用会更加便利。以下是结合 sass 使用的 webpack 的配置文件。 { test: /\\.scss$/, loader: \"style!css?modules&importLoaders=1&localIdentName=[name]__[local]--[hash:base64:5]!sass?sourceMap=true&sourceMapContents=true\" } 通常除了局部样式，还需要全局样式，比如 base.scss 等基础文件。将公用样式文件和组件样式文件分别放入到两个不同的目标下: . ├── app │ ├── styles # 公用样式 │ │ ├── app.scss │ │ └── base.scss │ │ │ └── components # 组件 ├── Component.jsx # 组件模板 └── Component.scss # 组件样式 然后通过 webpack 配置，将在 app/styles 文件夹的外的(exclude) scss 文件\"局部\"化。 { test: /\\.scss$/, exclude: path.resolve(__dirname, 'app/styles'), loader: \"style!css?modules&importLoaders=1&localIdentName=[name]__[local]--[hash:base64:5]!sass?sourceMap=true&sourceMapContents=true\" }, { test: /\\.scss$/, include: path.resolve(__dirname, 'app/styles'), loader: \"style!css?sass?sourceMap=true&sourceMapContents=true\" } 1.3.3. 多个 class 有时候，一个元素有多个 class 名，可以通过 join(\" \") 或字符串模版的方式来给元素添加多个 class 名。 // join-react.jsx Hello World // stringTemp-react.jsx Hello World 如果只写一个 class 就能把样式定义好，那么最好把所有样式写在一个 class 中。如果我们使用了多个 class 定义样式，通常会带一些一些逻辑判断。这个时候写起来就会麻烦不少。 引入 classnames 即可以解决给元素写多个 class 名的问题，也可以解决写逻辑判断的麻烦问题。 classNames('foo', 'bar'); // => 'foo bar' classNames('foo', { bar: true }); // => 'foo bar' classNames({ 'foo-bar': true }); // => 'foo-bar' classNames({ 'foo-bar': false }); // => '' classNames({ foo: true }, { bar: true }); // => 'foo bar' classNames({ foo: true, bar: true }); // => 'foo bar' // lots of arguments of various types classNames('foo', { bar: true, duck: false }, 'baz', { quux: true }); // => 'foo bar baz quux' // other falsy values are just ignored classNames(null, false, 'bar', undefined, 0, 1, { baz: null }, ''); // => 'bar 1' 引入 CSS Modules 的样式模块，每个 class 每次都要写 styles.xxx 也是很麻烦，在《深入React技术栈》提到了 react-css-modules 的库，来减少代码的书写，感兴趣的同学可以研究下。 1.4. reference https://github.com/css-modules/css-modules https://github.com/ruanyf/css-modules-demos https://github.com/gajus/react-css-modules (css-modules 限制) https://github.com/gajus/babel-plugin-react-css-modules Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_flex.html":{"url":"CSS/interview_flex.html","title":"interview_flex","keywords":"","body":"1. Flex box1.1. flex 多列1.2. 居中1.3. flex container1.3.1. justify-content1.3.2. align-items1.3.3. align-content (多行才起作用，即 flex-wrap: wrap/wrap-reverse 配合使用)1.3.4. flex-direction1.3.5. flex-wrap1.4. flex items1.4.1. flex1.4.2. align-self1.4.3. order1.4.4. flex-grow1.4.5. flex-basis1.4.6. flex-shrink1.5. reference1. Flex box 学习：http://flexboxfroggy.com/#zh-cn 1.1. flex 多列 .container { display: flex; } .initial { flex: initial; width: 200px; min-width: 100px; } .none { flex: none; width: 200px; } .flex1 { flex: 1; } .flex2 { flex: 2; } 1.2. 居中 .vertical-container { height: 300px; display: flex; align-items: center; justify-content: center; } 1.3. flex container .container { display: flex; /* or inline-flex */ flex-direction: row | row-reverse | column | column-reverse; flex-wrap: nowrap | wrap | wrap-reverse; flex-flow: || ; justify-content: flex-start | flex-end | 'center' | 'space-between' | space-around | 'space-evenly'; align-items: flex-start | flex-end | center | baseline | stretch; align-content: flex-start | flex-end | center | space-between | space-around | stretch; } 1.3.1. justify-content justify-content: flex-start | flex-end | center | space-between | space-around | space-evenly; justify-content 中使用多的有 center, space-between, space-evenly flex-start (default): items are packed toward the start line flex-end: items are packed toward to end line center: items are centered along the line space-between: items are evenly distributed in the line; first item is on the start line, last item on the end line `space-around: items are evenly distributed in the line with equal space around them. Note that visually the spaces aren't equal, since all the items have equal space on both sides. The first item will have one unit of space against the container edge, but two units of space between the next item because that next item has its own spacing that applies. space-evenly: items are distributed so that the spacing between any two items (and the space to the edges) is equal. 1.3.2. align-items This defines the default behavior for how flex items are laid out along the cross axis on the current line. .container { align-items: flex-start | flex-end | center | baseline | stretch; } flex-start: cross-start margin edge of the items is placed on the cross-start line flex-end: cross-end margin edge of the items is placed on the cross-end line center: items are centered in the cross-axis baseline: items are aligned such as their baselines align stretch (default): stretch to fill the container (still respect min-width/max-width) 1.3.3. align-content (多行才起作用，即 flex-wrap: wrap/wrap-reverse 配合使用) 多行之间的间隔、分配方式 This aligns a flex container's lines within when there is extra space in the cross-axis, similar to how justify-content aligns individual items within the main-axis. Note: this property has no effect when there is only one line of flex items. .container { align-content: flex-start | flex-end | center | space-between | space-around | stretch; } flex-start: lines packed to the start of the container flex-end: lines packed to the end of the container center: lines packed to the center of the container space-between: lines evenly distributed; the first line is at the start of the container while the last one is at the end space-around: lines evenly distributed with equal space around each line stretch (default): lines stretch to take up the remaining space 1.3.4. flex-direction 1.3.5. flex-wrap 1.4. flex items 1.4.1. flex This is the shorthand for flex-grow, flex-shrink and flex-basis combined. The second and third parameters (flex-shrink and flex-basis) are optional. Default is 0 1 auto. 只设置一个参数是\b比例 flex-grow .item { flex: none | [ ? || ] } 1.4.2. align-self This allows the default alignment (or the one specified by align-items) to be overridden for individual flex items. Please see the align-items explanation to understand the available values. .item { align-self: auto | flex-start | flex-end | center | baseline | stretch; } Note that float, clear and vertical-align have no effect on a flex item. 1.4.3. order .item { order: ; } 1.4.4. flex-grow 每个 item 占用比例 .item { flex-grow: ; /* default 0 */ } 1.4.5. flex-basis This defines the default size of an element before the remaining space is distributed. It can be a length (e.g. 20%, 5rem, etc.) or a keyword. The auto keyword means \"look at my width or height property\" (which was temporarily done by the main-size keyword until deprecated). The content keyword means \"size it based on the item's content\" - this keyword isn't well supported yet, so it's hard to test and harder to know what its brethren max-content, min-content, and fit-content do. .item { flex-basis: | auto; /* default auto */ } If set to 0, the extra space around content isn't factored in. If set to auto, the extra space is distributed based on its flex-grow value. 1.4.6. flex-shrink This defines the ability for a flex item to shrink if necessary. .item { flex-shrink: ; /* default 1 */ } Negative numbers are invalid. 1.5. reference http://www.jqhtml.com/6319.html Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_requestAnimationFrame.html":{"url":"CSS/interview_requestAnimationFrame.html","title":"interview_requestAnimationFrame","keywords":"","body":"1. requestAnimationFrame 为何性能好？为何不用 setTimeout1.1. 内部原理1.2. requestAnimationFrame 优于 setTimeout/setInterval 的地方1. requestAnimationFrame 为何性能好？为何不用 setTimeout 国庆北京高速，最多每 16.7s 通过一辆车，结果，突然插入一批 setTimeout 的军车，强行要 10s 通过。显然，这是超负荷的，要想顺利进行，只能让第三辆车直接消失（正如显示绘制第三帧的丢失）。然，这是不现实的，于是就有了会堵车！ 同样的，显示器16.7ms刷新间隔之前发生了其他绘制请求(setTimeout)，导致所有第三帧丢失，继而导致动画断续显示（堵车的感觉），这就是过度绘制带来的问题。不仅如此，这种计时器频率的降低也会对电池使用寿命造成负面影响，并会降低其他应用的性能。 这也是为何 setTimeout 的定时器值推荐最小使用 16.7ms 的原因（16.7 = 1000 / 60, 即每秒60帧）。 而 requestAnimationFrame 就是为了这个而出现的。我所做的事情很简单，跟着浏览器的绘制走，如果浏览设备绘制间隔是16.7ms，那我就这个间隔绘制；如果浏览设备绘制间隔是 10ms, 我就 10ms 绘制。这样就不会存在过度绘制的问题，动画不会掉帧。 1.1. 内部原理 浏览器每次要重绘，就会通知 requestAnimationFrame，在同样的时间间隔里进行动画。 如果有多个 requestAnimationFrame 动画，浏览器只要通知一次就可以了。而 setTimeout 貌似是多个独立绘制 页面最小化了，或者被Tab切换关灯了。页面是不会重绘的，自然，requestAnimationFrame 动画不会执行。页面绘制全部停止，资源高效利用。 1.2. requestAnimationFrame 优于 setTimeout/setInterval 的地方 在于它是由浏览器专门为动画提供的API，在运行时浏览器会自动优化方法的调用，并且如果页面不是激活状态下的话，动画会自动暂停，有效节省了CPU开销。 requestAnimationFrame 会把每一帧中的所有 DOM 操作集中起来，在一次重绘或回流中就完成，并且重绘或回流的时间间隔紧紧跟随浏览器的刷新频率，一般来说，这个频率为每秒 60 帧。 在隐藏或不可见的元素中，requestAnimationFrame 将不会进行重绘或回流，这当然就意味着更少的的cpu，gpu和内存使用量。 (function() { var lastTime = 0; var vendors = ['webkit', 'moz']; for (var x = 0; x Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_retina屏幕css.html":{"url":"CSS/interview_retina屏幕css.html","title":"interview_retina屏幕css","keywords":"","body":"1. Have you ever worked with retina graphics? If so, when and what techniques did you use?1. Have you ever worked with retina graphics? If so, when and what techniques did you use? On retina devices the websites are not broken. They just look vague and pixels start appearing as low resolution images. So the only way to correct is to resize the images by following one of the techniques below: Using alternate high resolution pixels (图片是 css 宽高的2倍) Suppose we have an image of 200px by 400px (CSS pixels) and we want to display it properly in a retina display, we can upload an alternate image of size 400px by 800px in our server and render them whenever the webpage is opened in a retina device. #element { background-image: url('hires.png'); } @media only screen and (min-device-pixel-ratio: 2) { #element { background-image: url('hires@2x.png'); } } @media only screen and (min-device-pixel-ratio: 3) { #element { background-image: url('hires@3x.png'); } } Using JavaScript to replace all the images with double sized image. 弊端是 retina 屏幕会把1倍图片、2倍图片都下载，速度慢。 // 检测屏幕像素比 $(document).ready(function() { if (window.devicePixelRatio > 1) { var lowResolutionImages = $('img'); images.each(function(i) { var lowResolution = $(this).attr('src'); var highResolution = lowResolution.replace('.', '@2x.'); $(this).attr('src', highResolution); }); } }); Using @face-fonts instead of images icon(✅) Image fonts will automatically resize themselves on the high resolution devices just like normal fonts do. Using SVG images instead of Bitmap images(✅) Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_元素显示隐藏的几种方案.html":{"url":"CSS/interview_元素显示隐藏的几种方案.html","title":"interview_元素显示隐藏的几种方案","keywords":"","body":"1. 元素显示与隐藏的方案1. 元素显示与隐藏的方案 /* 首选 */ .hidden{ position: absolute; top: -9999em; } .hidden{ position: absolute; visibility: hidden; } .hidden{ display: none; } 对于 position，如果元素之前没有过 position 属性那就没问题，如果之前就是 absolute、relative 尽量不用 对于 display，需要判断之前元素是 inline-block or block 要想让屏幕阅读器等辅助设备也能明白显示和隐藏，只能用 position top 方法 （可用性隐藏）。但如果被隐藏元素是 a, input，这样的隐藏方式会在用户点击 tab 时产生扰乱，&#x1F41F; 和 &#x1F43B; 不可得兼。 使用 absolute 隐藏是会产生重绘 repaint 而不会产生强烈的回流 reflow。而使用 display:none 不仅会重绘，还会产生回流（DOM 节点删除增加），DOM影响范围越广，回流越强烈。所以，就 JavaScript 交互的呈现性能上来讲，使用 absolute 隐藏是要优于 display 相关隐藏的。(reflow --> repaint) 方案1 对应的 js dom.style.position = \"static\"; // or dom.classList.remove('hidden'); //better 方案2 对应的 js dom.style.position = \"static\"; dom.style.visibility = \"visible\"; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_垂直水平居中.html":{"url":"CSS/interview_垂直水平居中.html","title":"interview_垂直水平居中","keywords":"","body":"1. 盒子垂直水平居中1.1. 水平居中1. 盒子垂直水平居中 /* 方法一 absolute transform/margin */ div { position: absolute; width: 500px; height: 300px; top: 50%; left: 50%; transform: translate(-50%, -50%); /* 外边距为自身宽高的一半 margin: -150px 0 0 -250px; */ background-color: pink; } /** 方法二 flex **/ .container { display: flex; align-items: center; /* 垂直居中 */ justify-content: center; /* 水平居中 */ } .container div { width: 100px; height: 100px; background-color: pink; } /** 方法三 absolute top right bottom left = 0 **/ div { position: absolute; width: 300px; height: 300px; margin: auto; top: 0; left: 0; bottom: 0; right: 0; background-color: pink; } 对于文字使用 line-height === height 方式 span 和 文字 垂直对齐，vertical-align: middle 1.1. 水平居中 http://blog.jobbole.com/46574/ 给div设置一个宽度，然后添加 margin: 0 auto 属性 div { width: 200px; margin: 0 auto; } 面试说：对于文字，span 等 inline 元素，使用 text-align center，块级如果已知容器和孩子宽高，也可以通过 padding 挤出空间 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/interview_布局.html":{"url":"CSS/interview_布局.html","title":"interview_布局","keywords":"","body":"1. 常见网站布局1.1. 已知高度的三列布局，左右宽度固定，中间自适应。(float, absolute, flex, table, grid)1.2. 三栏垂直分布，上下固定，移动端常见1.3. 两行，头固定，下面自适应高度1.4. 两列，左侧固定宽，右侧自适应宽度1. 常见网站布局 1.1. 已知高度的三列布局，左右宽度固定，中间自适应。(float, absolute, flex, table, grid) Layout html * { padding: 0; margin: 0; } .layout article div { min-height: 100px; } 高度如果未知，flex 和 table 可以继续用。不改变代码情况下grid内容超出 .layout.float .left { float: left; width: 300px; background: red; } .layout.float .center { background: yellow; } .layout.float .right { float: right; width: 300px; background: blue; } 三栏布局 浮动解决方案 兼容性比较好，但脱离了文档流，需要清除浮动 1.这是三栏布局的浮动解决方案； 2.这是三栏布局的浮动解决方案； 3.这是三栏布局的浮动解决方案； 4.这是三栏布局的浮动解决方案； 5.这是三栏布局的浮动解决方案； 6.这是三栏布局的浮动解决方案； .layout.absolute .left-center-right>div { position: absolute; } .layout.absolute .left { left: 0; width: 300px; background: red; } .layout.absolute .center { left: 300px; right: 300px; background: yellow; } .layout.absolute .right { right: 0; width: 300px; background: blue; } 三栏布局 绝对定位解决方案 快捷，但也脱离了文档流，导致里面的布局也会脱离文档流，整个布局并不实用。 1.这是三栏布局的浮动解决方案； 2.这是三栏布局的浮动解决方案； 3.这是三栏布局的浮动解决方案； 4.这是三栏布局的浮动解决方案； 5.这是三栏布局的浮动解决方案； 6.这是三栏布局的浮动解决方案； .layout.flexbox { margin-top: 110px; } .layout.flexbox .left-center-right { display: flex; } .layout.flexbox .left { width: 300px; background: red; } .layout.flexbox .center { flex: 1; background: yellow; } .layout.flexbox .right { width: 300px; background: blue; } 三栏布局 flexbox解决方案 解决float and absolute shortcomings 当中间文字过多时，两侧高度会同中间div高度保持一致 1.这是三栏布局的浮动解决方案； 2.这是三栏布局的浮动解决方案； 3.这是三栏布局的浮动解决方案； 4.这是三栏布局的浮动解决方案； 5.这是三栏布局的浮动解决方案； 6.这是三栏布局的浮动解决方案； .layout.table .left-center-right { width: 100%; height: 100px; display: table; } .layout.table .left-center-right>div { display: table-cell; } .layout.table .left { width: 300px; background: red; } .layout.table .center { background: yellow; } .layout.table .right { width: 300px; background: blue; } 三栏布局 表格布局解决方案 历史上评价不高，兼容性好 当中间文字过多时，两侧高度会同中间div高度保持一致 1.这是三栏布局的浮动解决方案； 2.这是三栏布局的浮动解决方案； 3.这是三栏布局的浮动解决方案； 4.这是三栏布局的浮动解决方案； 5.这是三栏布局的浮动解决方案； 6.这是三栏布局的浮动解决方案； .layout.grid .left-center-right { width: 100%; display: grid; grid-template-rows: 100px; grid-template-columns: 300px auto 300px; } .layout.grid .left-center-right>div {} .layout.grid .left { width: 300px; background: red; } .layout.grid .center { background: yellow; } .layout.grid .right { background: blue; } 三栏布局 网格布局解决方案 可以做复杂事情，新解决方案，兼容性不好 1.这是三栏布局的浮动解决方案； 2.这是三栏布局的浮动解决方案； 3.这是三栏布局的浮动解决方案； 4.这是三栏布局的浮动解决方案； 5.这是三栏布局的浮动解决方案； 6.这是三栏布局的浮动解决方案； 1.2. 三栏垂直分布，上下固定，移动端常见 Document html * { margin: 0; padding: 0; } html, body { height: 100%; } /* position fixed header, footer { height: 100px; width: 100%; background: #ccc; position: fixed; } header { top: 0 } footer { bottom: 0 } section { height: calc(100% - 200px); background: yellow; padding: 100px 0; } */ /*flex 布局*/ body { display: flex; justify-content: flex-start; flex-direction: column; } header, footer { background: #ccc; height: 100px; } section { background: yellow; flex: 1; } 移动端常见，我是导航 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 我是页面底部 1.3. 两行，头固定，下面自适应高度 Document html, body { height: 100%; } body { display: flex; flex-direction: column; } header { /* height: 100px; */ flex-basis: 100px; background: #ccc; } section{ flex: 1; background: #312; } 移动端常见，我是导航 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 中间部分，自适应高度 1.4. 两列，左侧固定宽，右侧自适应宽度 Document html, body { height: 100%; } body { display: flex; } aside { flex-basis: 100px; background: #ccc; } section { flex: 1; } 侧边栏固定 自适应宽度 自适应宽度 自适应宽度 自适应宽度 自适应宽度 自适应宽度 自适应宽度 自适应宽度 自适应宽度 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/sass.html":{"url":"CSS/sass.html","title":"sass","keywords":"","body":"1. scss vs sass1.1. 编译1.1.1. 编译方法1.1.2. 编译结果1.2. 常用基本语法1.3. 1. 变量1.4. 2. 嵌套1.4.1. 2.1 选择器嵌套1.4.2. 2.2 属性嵌套1.5. 3. 代码重用之继承1.6. 4. 代码重用之Mixin混合器1.7. 5. 颜色函数1.8. 6. @import引入1.8.1. 原生的CSS导入1.8.2. 一. Sass/Scss、Less是什么?1.8.3. 二. Sass/Scss 与 Less 区别1.8.4. 三. 总结1. scss vs sass Sass有两种后缀名文件：.sass和.scss。在同一个项目中，两种格式文件可以共存（不建议，最好统一为一种格式），但二者有各自的特点： sass 后缀的文件：使用类 Ruby 的语法，格式为空格缩进式，没有花括号，靠换行区分不同属性，格式要求比较严格。 scss 后缀的文件：是 Sass3 引入的新语法，基本写法与CSS大致相同，所以对于专门做前端的同学来说，.scss后缀的文件是不二选择。 1.1. 编译 1.1.1. 编译方法 Sass 编译方式大概有三种：通过命令行编译（基础方法）、GUI可视化图形同居编译及自动化编译。 命令行编译 单文件转换命令： sass style.scss style.css #把名为 style 的 Sass 文件转换为 CSS文件。 单文件监听命令（添加--watch命令）： sass --watch style.scss:style.css #`--watch`参数加上之后，可以监测style这个文件的变化，更新保存之后自动编译。 多文件（文件夹）监听命令 sass --watch sass/main:dist/css #监视 sass 目录下 main 文件夹中的所有 Sass文件，并自动编译为CSS文件之后，放到dist/css目录下。 逆向操作，css 文件转换为 sass/scs s文件 sass-convert style.css style.sass sass-convert style.css style.scss GUI编译工具 推荐国人自己开发的Koala工具，有中文版，上手也很简单。戳这里看教程 自动化编译 这里有很多途径实现。可以通过 webstorm、Sublime等编辑器的相关插件实现，也可以借助 Gulp 等自动化构建工具来配置。 Sass其他命令 sass -h 运行命令行帮助文档，可以获得所有的配置选项 sass –style 指定编译后的css代码格式，后面可跟4种参数：nested，expanded，compact，compressed sass –sourcemap 表示开启 sourcemap 调试。开启之后，会生成一个后缀名为.css.map的文件。不过现在基本都会默认生成此文件。 1.1.2. 编译结果 像上面提到的，通过给命令--style后面添加不同的参数，会生成不同样式的css代码，这其实没有太多好说，但大家有没有想过一个问题，Sass 文件中的注释会被编译到 CSS 文件中么？这就要看--style命令后面是什么参数了，默认是nested（嵌套式），而expanded（展开式）是CSS代码常见的格式。 --Sass中的注释有3种：-- //我是单行注释 不会出现在编译之后任何格式的CSS文件中。 /-我是多行注释-/ 只会出现在编译之后代码格式为 expanded 的CSS文件中。 /-!我是强制注释-/ 会出现在任何代码格式的CSS文件中。 1.2. 常用基本语法 1.3. 1. 变量 变量是Sass中最基本的语法。凡是css属性的标准值（比如说 1px 或者 bold）可存在的地方，都可以替换为变量。之后，如果你需要一个不同的值，只需要改变这个变量的值，则所有引用此变量的地方生成的值都会随之改变。 通过 --$-* 符号来定义，通过变量名称实现多处重复引用。 $box-color: red; //定义变量 ul{ color: $box-color; //引用 } li{ background-color: $box-color; //引用 } //编译后 ul { color: red; } li { background-color: red; } 另外，变量的值也可以引用其他变量： $highlight-color: #F90; $highlight-border: 1px solid $highlight-color; .selected { border: $highlight-border; } //编译后 .selected { border: 1px solid #F90; } 1.4. 2. 嵌套 Sass支持选择器及属性嵌套，可以避免代码的重复书写。 1.4.1. 2.1 选择器嵌套 div { h1 { color: #333; } p { margin-bottom: 1.4px; a { color: #999; } } } /* 编译后 -/ div h1 { color: #333; } div p { margin-bottom: 1.4px; } div p a { color: #999; } 大多数情况下上面那种简单的嵌套都没问题。但如果你想要在嵌套的选择器里边应用一个类似于：hover的伪类，就需要用到 --&-* 这个连接父选择器的标识符。 div { p { margin-bottom: 1.4px; &:hover { color: #999; } } } //编译后： div p { margin-bottom: 1.4px; } div p:hover { color: #999; } 1.4.2. 2.2 属性嵌套 示例1： div { border: { style: solid; width: 1px; color: #ccc; } } //编译后 div { border-style: solid; border-width: 1px; border-color: #ccc; } 示例2： div { border: 1px solid #ccc { left: 0px; right: 0px; } } //编译后 div { border: 1px solid #ccc; border-left: 0px; border-right: 0px; } 1.5. 3. 代码重用之继承 使用选择器的继承，要使用关键词@extend，后面紧跟需要继承的选择器。 .class1 { border: 1px solid #333; } .class2 { @extend .class1; background-color: #999; } //编译后 .class1, .class2 { border: 1px solid #333; } .class2 { background-color: #999; } 如上示例，.class2不仅会继承.class1自身的所有样式，也会继承任何跟.class1有关的组合选择器样式，如下： .class1 { border: 1px solid #333; } .class1 a { color: red; } .class2 { @extend .class1; } //编译后： .class1, .class2 { border: 1px solid #333; } .class1 a, .class2 a { color: red; } 1.6. 4. 代码重用之Mixin混合器 sass中使用@mixin声明混合，可以传递参数，参数名以$符号开始，多个参数以逗号分开，也可以给参数设置默认值。声明的@mixin通过@include + mixin 名称来调用。 无参数mixin声明及调用： @mixin mixName { float: left; margin-left: 10px; } div { @include mixName; } //编译后： div { float: left; margin-left: 10px; } 带参数mixin声明及调用 可以不给参数值直接写参数，如果给了值的话，就是参数的默认值，在调用的时候传入其他值就会把默认值覆盖掉。 @mixin left($value: 10px) { float: left; margin-left: $value; } div { @include left(66px); } //编译后： div { float: left; margin-left: 66px; } 带多组数值参数的mixin声明及调用 如果一个参数可以有多组值，如box-shadow、transition等，那么参数则需要在变量后加三个点表示，如$variables…。 @mixin mixName($shadow...) { box-shadow:$shadow; } .box{ @include mixName(0 2px 2px rgba(0,0,0,.3),0 3px 3px rgba(0,0,0,.3),0 4px 4px rgba(0,0,0,.3)); } //编译后： .box { box-shadow: 0 2px 2px rgba(0, 0, 0, 0.3), 0 3px 3px rgba(0, 0, 0, 0.3), 0 4px 4px rgba(0, 0, 0, 0.3); } 下面是一个实际应用中关于CSS3浏览器兼容的mixin使用示例： @mixin transition($transition){ -webkit-transition: $transition; -moz-transition: $transition; -ms-transition: $transition; -o-transition: $transition; transition: $transition; } @mixin opacity($opacity) { opacity: $opacity; filter: alpha(opacity = $opacity * 100); } div { width: 100px; height: 100px; @include transition(all 0.5s); @include opacity(0.5); } ul { width: 50px; height: 50px; @include transition(all 1s); @include opacity(1); } //编译后 div { width: 100px; height: 100px; -webkit-transition: all 0.5s; -moz-transition: all 0.5s; -ms-transition: all 0.5s; -o-transition: all 0.5s; transition: all 0.5s; opacity: 0.5; filter: alpha(opacity=50); } ul { width: 50px; height: 50px; -webkit-transition: all 1s; -moz-transition: all 1s; -ms-transition: all 1s; -o-transition: all 1s; transition: all 1s; opacity: 1; filter: alpha(opacity=100); } 1.7. 5. 颜色函数 Sass中集成了大量的颜色函数，让变换颜色更加简单直接。 $box-color: red; ul { color: $box-color; } li { background-color: darken($box-color,30%); } //编译后： ul { color: red; } li { background-color: #660000; } 其他颜色函数 lighten(#cc3, 10%) // #d6d65c grayscale(#cc3) // #808080 complement(#cc3) // #33c 1.8. 6. @import引入 CSS 中原本就有不常用的@import语法，但是有两个弊端： 引入语句一定要卸载代码最前面才会生效； 影响性能。如果 A 文件要引入 B 文件，当浏览器读到 A 文件时会再去下载 B，阻塞进程。 而Sass中的@import会在生成CSS文件时就把引入的所有文件先导入进来，也就是所有相关的样式会被编译到同一个CSS文件中，无需发起额外的请求。 当然，Sass的@import也支持导入远程的CSS文件。那效果跟普通CSS导入样式文件一样，导入的css文件不会合并到编译后的文件中，而是以@import方式存在。 一般来说基础的文件命名需要以’_’ 开头，如 _partial.scss。这种文件在导入的时候可以不写下划线及后缀，可写成@import “partial”。但是倒入CSS文件的话，就需要“文件名+后缀”了。 @import 'partial'; //导入名为“_partial.scss”的文件 @import 'toolbar.css'; //导入名toolbar.css”的文件 { margin: 0; padding: 0; } 1.8.1. 原生的CSS导入 下列三种情况下会生成原生的CSS@import： 被导入文件的名字以. css 结尾； 被导入文件的名字是一个URL地址（例如http://www.sass.hk/css/css.css ），由此可用谷歌字体API提供的相应服务； 被导入文件的名字是 CSS 的 url() 值。 也就是说，你不能用 Sass的 @import 直接导入一个原始的CSS文件，因为 sass 会认为你想用 CSS 原生的 @import。但是，因为 sass 的语法完全兼容 css，所以你可以把原始的css文件改名为.scss后缀，即可直接导入了。 1.8.2. 一. Sass/Scss、Less是什么? 参考网站：http://www.sasschina.com/guide Sass (Syntactically Awesome Stylesheets)是一种动态样式语言，Sass语法属于缩排语法，比css比多出好些功能(如变量、嵌套、运算,混入(Mixin)、继承、颜色处理，函数等)，更容易阅读。 Sass 与 Scss是什么关系? Sass的缩排语法，对于写惯 css 前端的 web 开发者来说很不直观，也不能将 css 代码加入到 Sass里面，因此sass语法进行了改良，Sass 3就变成了Scss(sassy css)。与原来的语法兼容，只是用{}取代了原来的缩进。 Less也是一种动态样式语言。对CSS赋予了动态语言的特性，如变量，继承，运算， 函数. Less 既可以在客户端上运行 (支持IE 6+, Webkit, Firefox)，也可在服务端运行 (借助 Node.js)。 1.8.3. 二. Sass/Scss 与 Less 区别 编译环境不一样 Sass 的安装需要 Ruby 环境，是在服务端处理的，而 Less 是需要引入 less.js 来处理 Less 代码输出 css 到浏览器，也可以在开发环节使用Less，然后编译成css文件，直接放到项目中，也有 Less.app、SimpleLess、CodeKit.app这样的工具，也有在线编译地址。 变量符不一样，Less是@，而Scss是$ 变量插值方式不同 在两种语言中，变量都可以以一定的方式插入到字符串中去，这个特性极为有用，但两种语言的插入方式不同，具体请看下例： //sass 中 $direction: left; .myPadding{ padding-#{$direction}: 20px; } //less中 @direction: left; .myPadding{ padding-@{direction}: 20px; } //编译后的css代码是相同的，如下： .myPadding{ padding-left: 20px; } 输出设置，Less 没有输出设置，Sass 提供4中输出选项：nested, compact, compressed 和 expanded。 输出样式的风格可以有四种选择，默认为nested nested：嵌套缩进的css代码 expanded：展开的多行css代码 compact：简洁格式的css代码 compressed：压缩后的css代码 Sass支持条件语句，可以使用if{} else{}, for{}循环等等。而Less不支持。 @if lightness($color) > 30% { } @else { } @for $i from 1 to 10 { .border-#{$i} { border: #{$i}px solid blue; } } 引用外部CSS文件 scss引用的外部文件命名必须以_开头, 如下例所示: 其中_test1.scss、_test2.scss、_test3.scss 文件分别设置的h1 h2 h3。文件名如果以下划线_开头的话，Sass会认为该文件是一个引用文件，不会将其编译为css文件 // 源代码： @import \"_test1.scss\"; @import \"_test2.scss\"; @import \"_test3.scss\"; // 编译后： h1 { font-size: 17px; } h2 { font-size: 17px; } h3 { font-size: 17px; } Less 引用外部文件和css中的@import没什么差异。 Sass 和 Less 的工具库不同 Sass 有工具库Compass, 简单说，Sass 和 Compass 的关系有点像 Javascript 和 jQuery 的关系, Compass 是 Sass 的工具库。在它的基础上，封装了一系列有用的模块和模板，补充强化了Sass的功能。bootstrap v4 Less 有UI组件库 Bootstrap v3 1.8.4. 三. 总结 不管是 Sass 还是 Less，都可以视为一种基于 CSS 之上的高级语言，其目的是使得 CSS 开发更灵活和更强大，Sass 的功能比 Less 强大，基本可以说是一种真正的编程语言了，Less 则相对清晰明了，易于上手，对编译环境要求比较宽松。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/transform.html":{"url":"CSS/transform.html","title":"transform","keywords":"","body":"1. CSS 动画：transform1.1. 2D 变换1.1.1. 原点1.1.2. 旋转1.1.3. 缩放1.1.4. 平移1.1.5. 斜切（Skew）1.1.6. 组合 Transform1. CSS 动画：transform 1.1. 2D 变换 有四个主要的变换函数：translate, rotate, scale, skew。这些函数通过组合进 matrix 变换函数。 1.1.1. 原点 用 transform-origin 改变变换的原点。默认在中心。其取值与 background-position 类似。两个值分别表示水平和垂直偏移。可以使用关键字（top, center, bottom, left, right）和数值，位置可以位于元素之外。 例如，原点放在左上角，可以表述为等价的三种形式： transform-origin: left top; transform-origin: 0 0; // 像素 transform-origin: 0% 0%; 1.1.2. 旋转 旋转图片。可以是浮点数。正负值分别表示顺时针和逆时针变换。 单位： deg： 360度，如 rotate(90deg)。 grad：用于简化计算：一圈算 400 grad。如 rotate(100grad)。 rad： 一圈 2π。如 rotate(1.57rad)。 turn：表示一圈。如 rotate(.25turn)。 注意问题： 页面上的其他内容的布局不受变换影响。因此可能出现交叠。 DOM 不受影响。被变换的元素的属性值（如 offsetWidth）保持不变。 CSS transform 本质上对变换元素进行相对定位；元素原来位置保持不动。 如果 overflow 设为 scroll 或 auto，因变换导致的溢出会导致滚动条出现。 其他 CSS 规则在变换前施加，特效会随着旋转。 值总是要带单位，即使是 0。 若需要绕右上角转到，需要设置 transform-origin： img.tilt { width: 300px; height: 300px; float: left; transform-origin: right top; transform: rotate(−10deg); } 1.1.3. 缩放 scale 函数的参数是乘数。如 scale(2) 长宽放大2倍。scale(.5) 长宽缩小一倍。 利用负值可以反转图像。例如左右反转： 水平和垂直方向可以独立缩放，例如： transform: scale(.5, 2); 或者使用独立的函数：scaleX 用于水平缩放、scaleY 用于垂直缩放。 1.1.4. 平移 translate(x, y) 沿水平和垂直方向移动元素。translateX() 沿水平移动；translateY() 垂直移动。 transform: translate(50px, -4em); 1.1.5. 斜切（Skew） transform: skewX(21deg) 设置元素的左右两边相对垂线偏移 21 度，即整个元素向右斜切。 拉伸也有两个独立的函数：skewX 和 skewY。 1.1.6. 组合 Transform 两种组合方式：transform 属性中空格分隔多个函数；或作为 matrix 属性的值。 空格分隔的多个transform属性值： transform: translate(50px, -4em) rotate(15deg); matrix 属性的写法略。 注意，写多个 transform 属性不会组合变换！最后一个变换声明会覆盖前面的。 transform: translate(50px, -4em); transform: rotate(15deg); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"CSS/transition.html":{"url":"CSS/transition.html","title":"transition","keywords":"","body":"1. Transition1.1. 延时1.2. Easing 函数1.2.1. Transition 速记1. Transition CSS Transition 是最简单形式的动画：从一个可视状态变换到另一个可视状态。如果需要更多状态，需要使用关键帧动画。 例子：鼠标以上后，图片旋转。 img:hover { transform: rotate(7.5deg); transition: 2s all; } 值顺序不重要。可以是 2s all 或 all 2s。若时间需要精确到毫秒，可以使用小数加秒 transition: 2.35s all; 的形式，或毫秒形式 transition: 2350ms all;。 当鼠标移出时，元素立即回到了其初始状态。但有时你期望恢复初始状态也有平滑的动画。方法是将 :hover 中 transition 声明移到默认样式中，:hover 中只保留 transform。背后的原理是，将一个属性放入默认样式，不管进出状态，transition 都生效。 如果在动画过程中鼠标移出或移入，transition 会被打断，会平滑的反转。这个特性非常好！ transition 中可以只指定时间：transition: 2s;。 一般会把 transition 放入默认样式（如 .navButto）而不是最终样式（如 .navButton:hover）。==但对于下拉菜单，下列也可以缓慢动画，但收起最好非常快的完成，为此，可以在默认样式中使用 transition-delay: 5s;，但在最终样式（:hover）覆盖：transition-delay: 0;。== 不是所有的 CSS 属性都可以参与动画。可以参与的属性包括颜色和尺寸类的： transform color, background-color, border-color, opacity border-width, font-size, height, width letter-spacing, line-height, word-spacing margin, padding 定位属性，top, left, right, bottom You can find a complete list at www.w3.org/TR/css3-transitions/#animatable-properties. 只要 CSS 属性改变都可以触发 transition，包括通过 Javascript 改变 CSS 属性。 transition 包含四个控制属性，分别控制参与动画的属性、动画时间、动画类型、延迟时间（可选）。 transition-property 指定参与动画的属性。多个属性逗号风格。值 all 表示动画所有改变的 CSS 属性。 transition-duration 属性指定动画时间。单位可以是秒或毫秒。 每个属性的动画时间可以不同。为此，需要对应使用 transition-duration 和 transition-property（逗号分隔），如： transition-property: color, background-color, border-color; transition-duration: .25s, .75s, 2s; 1.1. 延时 延迟时间直接加到 transition 后面： transition: 2s 4s; 延迟不仅对动画开始有效，对动画反转回到起点也有效。例如上面的代码，动画会延迟 4 秒后开始；结束后会延迟 4 秒后再回到起始状态。（注意，鼠标在图片上停留至少4秒动画才会开始。） transition-delay: .5s; 有时不想让所有属性都延时触发，可以为每个属性分别指定延时： transition-property: color, background-color, border-color; transition-duration: 1s, 1s, .5s; transition-delay: 0, 0, 1s; 在某些浏览器中左右移动的动画可能不够流畅。使用 translateX 替代 left，会更流畅，适合移动绝对或相对定位的元素。 img { width: 300px; height: 300px; float: left; transition-property: opacity, translateX; transition-duration: 2s, 4s; } img:hover { opacity: .2; transform: translateX(60px); } 1.2. Easing 函数 CSS3动画默认使用 ease。可以使用其他缓动，如 linear： transition: 2s transform linear; 独立的属性是 transition-timing-function。改属性可以取五个值：linear, ease, ease-in, ease-out, ease-in-out. 若不指定该属性，默认使用 ease。 要观看这些缓动函数的区别，参见：www.the-art-of-web.com/css/timing-function/。 transition-timing-function 属性还接受 cubic-bezier 值。The Bezier curve plots the progress of the animation over time. By adjusting two control points you can control how the line curves: the steeper the line, the faster the animation, the flatter the line, the slower. transition-timing-function: cubic-bezier(.20, .96, .74, .07); Cubic Bezier 曲线最好通过工具创建盒测试。参见：https://matthewlein.com/tools/ceaser 可以对不同的属性施加不同的缓动函数。 1.2.1. Transition 速记 四个属性 transition-property transition-duration transition-timing-function transition-duration 可以合并成一个 transition 属性。空格分隔，分别列出要动画的属性、时常、缓动函数、延时： transition: all 1s ease-in .5s; 缓动函数和延时可不设 transition: all 1s; transition: background-color 1s; 属性位置只能填 all 或单个CSS属性。如果要动画多个属性，需要每个属性一个完整配置，逗号分隔。 transition: color 1s, background-color 1s, border-color .5s 1s; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"DotNet/":{"url":"DotNet/","title":"DotNet","keywords":"","body":"1. TOC1. TOC async_await DotNetCore_Fundamentals log4net_redis ORM Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"DotNet/async_await.html":{"url":"DotNet/async_await.html","title":"async_await","keywords":"","body":"1. async and await1. async and await 需要完善异步操作，如多线程委托写法 using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading; using System.Threading.Tasks; namespace AsyncProgramming { class Program { static void Main(string[] args) { #region 同步 //Console.WriteLine(\"start\"); ////模拟延迟操作 //Thread.Sleep(3000); //Console.WriteLine(\"end\"); //Console.ReadKey(); #endregion #region .net 4.0 //Console.WriteLine(\"main start\"); //step 1 ////模拟延迟操作，耗时操作交给新线程 //Thread thread = new Thread(() => //{ // Console.WriteLine(\"child thread starts\"); //step 3 // //子线程处理 // Thread.Sleep(3000); // Console.WriteLine(\"child thread end\"); //step 4 //}); //thread.Start(); //Console.WriteLine(\"main end\"); //step 2 //Console.ReadKey(); #endregion #region .net 4.5 Console.WriteLine(\"main start... threadId: \" + Thread.CurrentThread.ManagedThreadId); //step 1 //模拟延迟操作，耗时操作交给新线程 Do(); Console.WriteLine(\"main end... threadId: \" + Thread.CurrentThread.ManagedThreadId); //step 3 Console.ReadKey(); #endregion } async static void Do() { Console.WriteLine(\"child thread starts... threadId: \" + Thread.CurrentThread.ManagedThreadId); //step 2 await Task.Delay(3000); //await 要求方法必须异步方法 async //await后代码都会交给新线程执行。 Console.WriteLine(\"child thread end... threadId: \" + Thread.CurrentThread.ManagedThreadId); //step 4 } } } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"DotNet/DotNetCore_Fundamentals.html":{"url":"DotNet/DotNetCore_Fundamentals.html","title":"DotNetCore_Fundamentals","keywords":"","body":"1. .Net Core Fundamentals (.net core v1.1.2)1.1. Get Started1.2. Adding a Configuration Source1.3. Features of Asp.net core1.4. Startup.cs -- Entry point1.5. Request Pipeline & Middleware1.6. ViewComponents VS PartialView1.7. MVC cons and pros1.8. Web Api in .Net Core1. .Net Core Fundamentals (.net core v1.1.2) 1.1. Get Started Follow Official website: https://docs.microsoft.com/en-us/aspnet/core/getting-started 1.2. Adding a Configuration Source Asp.net core no longer uses web.config as configuration file. Instead, appsettings.json is used for this purpose. 1.3. Features of Asp.net core Modular version of .NET Framework supports different environments cross-platform better performance Dependency Injection (Loose coupling, less code changes, better testability) 1.4. Startup.cs -- Entry point ConfigureServices is used to add services to the container, and to configure those services, Dependency Injection! AddTransient: Every request creates an instance. 每次请求都创建一个新的实例. always different; a new instance is provided to every controller and every service. AddScoped: the same within a request, but different across different requests. 相同请求得到同一个实例，常用注册Repository。不同请求实例不同 AddSingleton: the same for every object and every request Configure is used to specify how an ASP.NET application will respond to individual HTTP requests. Use middleware to configure the HTTP request pipeline 1.5. Request Pipeline & Middleware Request --> Middleware --> Middleware --> ... --> Response 1.6. ViewComponents VS PartialView ViewComponent is a upgrade of PartialView. Partial View: Usually contains only html code and the model which has to be the one passed in calling page. Render PartialView in Parent View: @Html.Partial(\"partialview\", model) ViewComponent: Contains logic! It has a Invoke method which will be called and render its ViewComponent using System.Collections.Generic; using Aspnetcore.Pieshop.Webapp.Models; using Aspnetcore.Pieshop.Webapp.ViewModels; using Microsoft.AspNetCore.Mvc; namespace Aspnetcore.Pieshop.Webapp.ViewComponents { public class ShoppingCartSummaryViewComponent : ViewComponent { private readonly ShoppingCart _shoppingCart; public ShoppingCartSummaryViewComponent(ShoppingCart shoppingCart) { _shoppingCart = shoppingCart; } public IViewComponentResult Invoke() { var items = _shoppingCart.GetShoppingCartItems(); _shoppingCart.ShoppingCartItems = items; var shoppingCartViewModel = new ShoppingCartViewModel { ShoppingCart = _shoppingCart, ShoppingCartTotal = _shoppingCart.GetShoppingCartTotal() }; return View(shoppingCartViewModel); } } } Parent View which called the ViewComponent: // Maybe in _Layout.cshtml @await Component.InvokeAsync(\"ShoppingCartSummary\") 1.7. MVC cons and pros pros: Separation of Concerns testability reuse cons: View may change too fast and Model cannot keep pace with View. Usually have to create ViewModels for View. This is painful as application get larger and larger. 1.8. Web Api in .Net Core Post: Use POST for creating a resource 201 Created Header: content-type Validation Data annotations ModelState Put/Patch: Use PUT for full updates, PATCH for partial updates JsonPatch standard 204 NoContent or 200 Ok Delete: DELETE is for deleting resources 204 NoContent Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"DotNet/helpers/":{"url":"DotNet/helpers/","title":"DotNet/helpers","keywords":"","body":"1. TOC1. TOC PinyinHelper Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"DotNet/helpers/PinyinHelper.html":{"url":"DotNet/helpers/PinyinHelper.html","title":"PinyinHelper","keywords":"","body":"1. PinyinHelper1. PinyinHelper ChineseChar cc = new ChineseChar(string text); var pinyin = cc.Pinyins; foreach(string s in pinyin) { Console.Write(s); } // 获得中文首字母 string txt = textBox1.Text; foreach(char c in txt) { ChineseChar cc = new ChineseChar(c); string pinyin = cc.Pinyins[0]; //多音字中第一个拼音 char firstLetter = pinyin[0]; textBox2.Text += firstLetter; } // 中国人 => ZGR public static string GetPinyinFirstLetter(string str) { StringBuilder pinyin = new StringBuilder(); foreach(var s in str) { ChineseChar cc = new ChineseChar(s); pinyin.Append(cc.Pinyins[0][0]); //Pinyins[0]多音字第一个音（zhong1）,[0][0]第一个音首字母 } return pinyin.ToString(); } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"DotNet/log4net_redis.html":{"url":"DotNet/log4net_redis.html","title":"log4net_redis","keywords":"","body":"1. 文件并发(日志处理)--队列--Redis+Log4Net1.1. 方式一：使用队列1.2. 方式二：使用 Redis 与 Log4Net 完成分布式日志记录1. 文件并发(日志处理)--队列--Redis+Log4Net 多线程操作同一个文件时会出现并发问题。解决的一个办法就是给文件加锁(lock)，但是这样的话，一个线程操作文件时，其它的都得等待，这样的话性能非常差。另外一个解决方案，就是先将数据放在队列中，然后开启一个线程，负责从队列中取出数据，再写到文件中。 在这之前，有必要先了解下Redis，关于Redis的介绍可以参考我的这篇博文：ASP.NET Redis 开发 Redis工具和所需资料代码全下载，地址：http://pan.baidu.com/s/155F6A 下面我们讲解一个实际项目中应用的案例，关于日志的处理.这里是使用ASP.NET MVC项目作为Demo。 1.1. 方式一：使用队列 思路：把所有产生的日志信息存放到一个队列里面，然后通过新建一个线程，不断的从这个队列里面读取异常信息，然后往日志里面写。也就是所谓的生产者、消费者模式。 1. 新建一个类MyErrorAttribute using System.Web.Mvc; public class MyErrorAttribute: HandleErrorAttribute { public static Queue ExceptionQueue = new Queue (); public override void OnException(ExceptionContext filterContext) { ExceptionQueue.Enqueue(filterContext.Exception); filterContext.HttpContext.Response.Redirect(\"~/Error.html\"); base.OnException(filterContext); } } 2. 在FilterConfig类中进行如下修改： public class FilterConfig { public static void RegisterGlobalFilters(GlobalFilterCollection filters){ //filters.Add(new HandleErrorAttribute()); filters.Add(new MyErrorAttribute()); } string filePath = Server.MapPath(\"~/Logs/\"); ThreadPool.QueueUserWorkItem(o => { while (true) { if (MyErrorAttribute.ExceptionQueue.Count > 0) { Exception ex = MyErrorAttribute.ExceptionQueue.Dequeue(); if (ex != null) { string fileName = filePath + DateTime.Now.ToString(\"yyyy-MM-dd\") + \".txt\"; File.AppendAllText(fileName, ex.Message); } else { Thread.Sleep(50); } } else { Thread.Sleep(50); } } }); } 1.2. 方式二：使用 Redis 与 Log4Net 完成分布式日志记录 在程序最开始加入log4net.Config.XmlConfigurator.Configure() 在要打印日志的地方LogManager.GetLogger(typeof(Program)).Debug(“信息”); 。通过LogManager.GetLogger传递要记录的日志类类名获得这个类的 ILog（这样在日志文件中就能看到这条日志是哪个类输出的了），然后调用Debug方法输出消息。因为一个类内部不止一个地方要打印日志，所以一般把ILog声明为一个 static 字段。 Private static ILog logger = LogManager.GetLogger(typeof(Test)) 输出错误信息用ILog.Error方法，第二个参数可以传递Exception对象。log.Error(\"错误\"+ex)，log.Error(\"错误\",ex) Appender：可以将日志输出到不同的地方，不同的输出目标对应不同的 Appender：RollingFileAppender（滚动文件）、AdoNetAppender（数据库）、SmtpAppender （邮件）等。 level（级别）：标识这条日志信息的重要级别None>Fatal>ERROR>WARN>DEBUG>INFO>ALL，设定一个Level，那么低于这个Level的日志是不会被写到Appender中的. Log4Net 还可以设定多个 Appender，可以实现同时将日志记录到文件、数据、发送邮件等；可以设定不同的 Appender 的不同的 Level，可以实现普通级别都记录到文件，Error以上级别发送邮件；可以实现对不同的类设定不同的Appender；还可以自定义Appender，这样可以自己实现将Error信息发短信等. 配置Log4Net，在Web.config中添加如下配置： ServiceStack.dll、ServiceStack.Interfaces.dll、ServiceStack.ServiceInterface.dll、log4net.dll的引用，然后新建一个类MyErrorAttribute using System.Web.Mvc; using ServiceStack.Redis; public static IRedisClientsManager clientsManager = new PooledRedisClientManager(new string[] { \"127.0.0.1:6379\" }); public static IRedisClient redisClient = clientsManager.GetClient(); public override void OnException(ExceptionContext filterContext) { redisClient.EnqueueItemOnList(\"errorMsg\", filterContext.Exception.ToString()); filterContext.HttpContext.Response.Redirect(\"~/Error.html\"); base.OnException(filterContext); } 在FilterConfig类中进行如下修改： public class FilterConfig { public static void RegisterGlobalFilters(GlobalFilterCollection filters) { //filters.Add(new HandleErrorAttribute()); //filters.Add(new MyErrorAttribute()); filters.Add(new MyExceptionAttribute()); } } 在 Gobal.asax.cs 中的 Application_Start 事件里添加如下代码： log4net.Config.XmlConfigurator.Configure(); //获取Log4Net配置信息 ThreadPool.QueueUserWorkItem(o => { while (true) { if (MyExceptionAttribute.redisClient.GetListCount(\"errorMsg\") > 0) { string msg = MyExceptionAttribute.redisClient.DequeueItemFromList(\"errorMsg\"); if (!string.IsNullOrEmpty(msg)) { ILog logger = LogManager.GetLogger(\"testError\"); logger.Error(msg); //将异常信息写入Log4Net中 } else { Thread.Sleep(50); } } else { Thread.Sleep(50); } } }); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"DotNet/ORM.html":{"url":"DotNet/ORM.html","title":"ORM","keywords":"","body":"1. ORM1.1. 常见1.2. 互联网产品不用 EF1. ORM 开发人员不需要写 sql 语句操作数据库。 1.1. 常见 Entity Framework/ NHibernate / Dapper / Petapoco / MyBatis.net / CYQData / MonoSql 1.2. 互联网产品不用 EF 执行效率相对纯 sqlDataReader 低 EF 对项目侵入性较高 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Git/":{"url":"Git/","title":"Git","keywords":"","body":"1. TOC1. TOC Git查看、删除、重命名远程分支和tag todo Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Git/Git查看、删除、重命名远程分支和tag.html":{"url":"Git/Git查看、删除、重命名远程分支和tag.html","title":"Git查看、删除、重命名远程分支和tag","keywords":"","body":"1. Git查看、删除、重命名远程分支和tag1.1. 1. 查看远程分支1.2. 2. 删除远程分支和tag1.3. 3. 删除不存在对应远程分支的本地分支1.4. 4. 重命名远程分支1.5. 5. 把本地tag推送到远程1.6. 6. 获取远程tag1.7. git tag — 标签相关操作1.7.1. 列出标签1.7.2. 打标签1.7.3. 切换到标签1.7.4. 删除标签1.7.5. 给指定的commit打标签1.7.6. 标签发布1. Git查看、删除、重命名远程分支和tag 1.1. 1. 查看远程分支 加上-a参数可以查看远程分支，远程分支会用红色表示出来（如果你开了颜色支持的话）： git branch -a master remote tungway v1.52 * zrong remotes/origin/master remotes/origin/tungway remotes/origin/v1.52 remotes/origin/zrong 1.2. 2. 删除远程分支和tag git branch -D gh-pages 删除本地分支 在Git v1.7.0 之后，可以使用这种语法删除远程分支： git push origin --delete 删除tag这么用： git push origin --delete tag 否则，可以使用这种语法，推送一个空分支到远程分支，其实就相当于删除远程分支： git push origin : 这是删除tag的方法，推送一个空 tag 到远程 tag： git tag -d git push origin :refs/tags/ 两种语法作用完全相同。 1.3. 3. 删除不存在对应远程分支的本地分支 假设这样一种情况： 我创建了本地分支b1并pull到远程分支 origin/b1； 其他人在本地使用 fetch 或 pull 创建了本地的b1分支； 我删除了 origin/b1 远程分支； 其他人再次执行 fetch 或者 pull 并不会删除这个他们本地的 b1 分支，运行 git branch -a 也不能看出这个branch被删除了，如何处理？ 使用下面的代码查看b1的状态： git remote show origin * remote origin Fetch URL: git@github.com:xxx/xxx.git Push URL: git@github.com:xxx/xxx.git HEAD branch: master Remote branches: master tracked refs/remotes/origin/b1 stale (use 'git remote prune' to remove) Local branch configured for 'git pull': master merges with remote master Local ref configured for 'git push': master pushes to master (up to date) 这时候能够看到b1是stale的，使用 git remote prune origin 可以将其从本地版本库中去除。 更简单的方法是使用这个命令，它在fetch之后删除掉没有与远程分支对应的本地分支： git fetch -p 1.4. 4. 重命名远程分支 在git中重命名远程分支，其实就是先删除远程分支，然后重命名本地分支，再重新提交一个远程分支。 例如下面的例子中，我需要把 devel 分支重命名为 develop 分支： $ git branch -av * devel 752bb84 Merge pull request #158 from Gwill/devel master 53b27b8 Merge pull request #138 from tdlrobin/master zrong 2ae98d8 modify CCFileUtils, export getFileData remotes/origin/HEAD -> origin/master remotes/origin/add_build_script d4a8c4f Merge branch 'master' into add_build_script remotes/origin/devel 752bb84 Merge pull request #158 from Gwill/devel remotes/origin/devel_qt51 62208f1 update .gitignore remotes/origin/master 53b27b8 Merge pull request #138 from tdlrobin/master remotes/origin/zrong 2ae98d8 modify CCFileUtils, export getFileData 删除远程分支： git push --delete origin devel To git@github.com:zrong/quick-cocos2d-x.git - [deleted] devel 重命名本地分支： git branch -m devel develop 推送本地分支： git push origin develop 然而，在 github 上操作的时候，我在删除远程分支时碰到这个错误： git push --delete origin devel remote: error: refusing to delete the current branch: refs/heads/devel To git@github.com:zrong/quick-cocos2d-x.git ! [remote rejected] devel (deletion of the current branch prohibited) error: failed to push some refs to 'git@github.com:zrong/quick-cocos2d-x.git' 这是由于在 github 中，devel 是项目的默认分支。要解决此问题，这样操作： 进入 github 中该项目的 Settings 页面； 设置 Default Branch 为其他的分支（例如 master）； 重新执行删除远程分支命令。 1.5. 5. 把本地tag推送到远程 git push --tags 1.6. 6. 获取远程tag git fetch origin tag 1.7. git tag — 标签相关操作 1.7.1. 列出标签 git tag # 在控制台打印出当前仓库的所有标签 git tag -l 'v0.1.*' # 搜索符合模式的标签 1.7.2. 打标签 git标签分为两种类型：轻量标签和附注标签。轻量标签是指向提交对象的引用，附注标签则是仓库中的一个独立对象。建议使用附注标签。 git tag v0.1.2-light # 创建轻量标签 git tag -a v0.1.2 -m '0.1.2版本' # 创建附注标签 创建轻量标签不需要传递参数，直接指定标签名称即可。 创建附注标签时，参数 a 即 annotated 的缩写，指定标签类型，后附标签名。参数m指定标签说明，说明信息会保存在标签对象中。 1.7.3. 切换到标签 与切换分支命令相同，用git checkout [tagname] 查看标签信息，用git show命令可以查看标签的版本信息： git show v0.1.2 1.7.4. 删除标签 误打或需要修改标签时，需要先将标签删除，再打新标签。 git tag -d v0.1.2 # 删除标签 参数 d 即 delete 的缩写，意为删除其后指定的标签。 1.7.5. 给指定的commit打标签 打标签不必要在head之上，也可在之前的版本上打，这需要你知道某个提交对象的校验和（通过git log获取）。 git tag -a v0.1.1 9fbc3d0 1.7.6. 标签发布 通常的git push不会将标签对象提交到git服务器，我们需要进行显式的操作： git push origin v0.1.2 # 将v0.1.2标签提交到git服务器 git push origin –tags # 将本地所有标签一次性提交到git服务器 注意：如果想看之前某个标签状态下的文件，可以这样操作 git tag # 查看当前分支下的标签 git checkout v0.21 # 此时会指向打v0.21标签时的代码状态，（但现在处于一个空的分支上） cat test.txt # 查看某个文件 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Git/todo.html":{"url":"Git/todo.html","title":"todo","keywords":"","body":" git 教程简明 git 教程 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"HighChart/":{"url":"HighChart/","title":"HighChart","keywords":"","body":"1. TOC1. TOC highChart_config highChart_demo highChart_draggable Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"HighChart/highChart_config.html":{"url":"HighChart/highChart_config.html","title":"highChart_config","keywords":"","body":"1. HighChart config1. HighChart config export const config = { title: '', legend: { enabled: false }, colors: [ // '#7373FF', // push it to first when needing to display myProduct: purple(myproduct) '#ffd669', // yellow '#F5896C', // red '#72C284', // green '#f15c80', '#e4d354', '#8d4653', '#91e8e1' ], chart: { height: 260, width: 600, style: { fontFamily: '.PingFang SC', color: '#d8d9d8' } }, yAxis: { allowDecimals: false, title: { text: '' }, min: 0, max: 5, tickInterval: 1, // gridLineDashStyle: 'longdash', // minorGridLineColor: '#f5f5f5', // gridLineWidth: 2, gridLineColor: '#f5f5f5', labels: { style: { color: '#a6a6a6' } } }, credits: { enabled: false }, animation: false, plotOptions: { series: { point: { events: { // drag: function(e) { // // Returning false stops the drag and drops. Example: // if (e.y > 100) { // this.y = 100 // return false // } // }, // drop: function(e) { // console.log(e) // console.log(this) // // 更新用户数据到state // } }, pointWidth: 18, //stacking: 'percent', dataLabels: { enabled: true, inside: true, align: 'right', color: '#fff' } } // stickyTracking: false }, spline: { marker: { radius: 6, lineColor: '#666666', lineWidth: 1 } }, line: { cursor: 'ns-resize' } }, tooltip: { yDecimals: 2 } }; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"HighChart/highChart_demo.html":{"url":"HighChart/highChart_demo.html","title":"highChart_demo","keywords":"","body":"1. HighChart Demo1. HighChart Demo import React, { Component } from 'react'; import PropTypes from 'prop-types'; import uid from 'uid'; import { config } from '../chartConfig'; import Chart from '../../common/chart/Chart.jsx'; import highChartsDragabled from 'highcharts-draggable-points'; import { MY_PRODUCT_ID, MY_PRODUCT_COLOR } from '../const'; import update from 'immutability-helper'; class ChanpinjiazhilianJiazhiquxian extends Component { constructor(props) { super(props); } render() { const { products } = this.props; const colors = config.colors; // const products = [ // { // id: MY_PRODUCT_ID, // name: MY_PRODUCT_NAME, // analysis: [ // { id: 1, key: 'time', value: 5, category: 'delete' }, // { id: 2, key: 'space', value: 4, category: 'creativity' }, // { id: 3, key: 'cost', value: 2, category: 'add' } // ] // }, // { // id: '34dsaffda', // name: 'iphone 5', // analysis: [ // { id: 1, key: 'time', value: 5, category: 'delete' }, // { id: 2, key: 'space', value: 4, category: 'creativity' }, // { id: 3, key: 'cost', value: 2, category: 'add' } // ] // }, // { // id: 'dfasfdfsa', // name: 'huawei mate', // analysis: [ // { id: 1, key: 'time', value: 5, category: 'delete' }, // { id: 2, key: 'space', value: 4, category: 'creativity' }, // { id: 3, key: 'cost', value: 2, category: 'add' } // ] // } // ] const keys = products[0].analysis.map((p) => p.key); const chartData = { xAxis: { categories: keys, lineColor: '#f5f5f5', // lineWidth: 3, tickWidth: 0, // gridLineColor: '#197F07', // gridLineWidth: 3, // minorGridLineColor: '#f5f5f5', labels: { style: { color: '#a6a6a6' } }, plotBands: [ // { // color: 'orange', // Color value // from: 0.97, // Start of the plot band // to: 1.03 // End of the plot band // } ] }, series: [] }; products.forEach((product, i) => { const values = product.analysis.map((a, index) => { chartData.xAxis.plotBands.push({ color: '#fcfcfc', // Color value from: index - 0.03, // Start of the plot band to: index + 0.03 // End of the plot band }); return { analysisId: a.analysisId, yaosu: a.key, y: a.value, productId: product.id, productName: product.name }; }); let seriesSettings = { name: product.name, data: values, type: 'line', // draggableX: true, draggableY: true, dragMaxY: 5, dragMinY: 0, minPointLength: 1, lineWidth: 1, marker: { enabled: true, symbol: 'circle', radius: 6 } }; if (product.id === MY_PRODUCT_ID) { seriesSettings.dashStyle = 'Solid'; } else { seriesSettings.dashStyle = 'longdash'; } chartData.series.push(seriesSettings); }); config.colors[myProductIndex] = MY_PRODUCT_COLOR; const chartConfig = { ...config, ...chartData }; let chartChangeset = []; config.chart.width = 800; config.plotOptions.series.point.events = { drag: function(e) { const { productId } = this; if (productId !== MY_PRODUCT_ID) return false; // 禁用非 我的产品拖动 // Returning false stops the drag and drops if (e.y > 5) { this.y = 5; return false; } }, drop: function() { this.y = Math.round(this.y); // this.update(this.y) const { productId, analysisId, y } = this; chartChangeset.push({ productId, analysisId, y }); } }; const buildUpdateOperation = (source, operationArr) => { let result = {}; // source: copy products // operationArr: [ { id: '111', analysisId: 1, value: 99 }, { id: '111', analysisId: 3, value: 99 }, { id: '222', analysisId: 3, value: 99 } ] operationArr.forEach((c) => { const targetIndex = source.findIndex((x) => x.id === c.productId); const target = source.find((x) => x.id === c.productId); const targetAnalysisIndex = target.analysis.findIndex((x) => x.analysisId === c.analysisId); const targetAnalysis = target.analysis.find((x) => x.analysisId === c.analysisId); if (result[targetIndex]) { result[targetIndex].analysis[targetAnalysisIndex] = { $merge: { value: c.y } }; } else { result[targetIndex] = { analysis: { [targetAnalysisIndex]: { $merge: { value: c.y } } } }; } }); /** * { * 1: { * analysis: { * 0: { $merge: { value: 99 }}, * 2: { $merge: { value: 99 }} * } * }, * 2: { * analysis: { * 2: { $merge: { value: 99 }} * } * } * } */ return result; }; const saveData = (step) => { const operation = buildUpdateOperation(products, chartChangeset); var result = update(products, operation); saveAnliFun(result, () => { setCurrentStep.call(this, step + 1); }); }; return ( {products.map((p, index) => ( {p.name} ))} ); } } export default ChanpinjiazhilianJiazhiquxian; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"HighChart/highChart_draggable.html":{"url":"HighChart/highChart_draggable.html","title":"highChart_draggable","keywords":"","body":"1. HighChart Draggable1. HighChart Draggable // // // var chart = new Highcharts.Chart({ chart: { renderTo: 'container', animation: false }, title: { text: 'Highcharts draggable points demo' }, xAxis: { categories: ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] }, yAxis: { allowDecimals: false, title: { text: '' }, min: 0, max: 5, tickInterval: 1, gridLineColor: '#f5f5f5', labels: { style: { color: '#a6a6a6' } } }, plotOptions: { series: { point: { events: { drag: function (e) { // Returning false stops the drag and drops. Example: /* if (e.newY > 300) { this.y = 300; return false; } */ e.y = Math.round(e.y); $('#drag').html( 'Dragging ' + this.series.name + ', ' + this.category + ' to ' + Highcharts.numberFormat(e.y, 2) + '' ); }, drop: function (e) { // this.update(Math.round(this.y)); this.update(Math.round(e.y)); $('#drop').html( 'In ' + this.series.name + ', ' + this.category + ' was set to ' + Highcharts.numberFormat(this.y, 2) + '' ); } } }, stickyTracking: false }, column: { stacking: 'normal' }, line: { cursor: 'ns-resize' } }, tooltip: { yDecimals: 2 }, series: [{ data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], draggableY: true, dragMinY: 0, dragMaxY: 5, minPointLength: 1 }] }); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/":{"url":"Interview/","title":"Interview","keywords":"","body":"1. TOC1. TOC design_pattern hash碰撞 IaaS-PaaS-SaaS的区别 nodejs_interview oop shift_operator sql to learn 代理 代码优化 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/algorithm/":{"url":"Interview/algorithm/","title":"Interview/algorithm","keywords":"","body":"1. TOC1. TOC array_vs_linkedList 算法 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/algorithm/array_vs_linkedList.html":{"url":"Interview/algorithm/array_vs_linkedList.html","title":"array_vs_linkedList","keywords":"","body":"1. Array vs Linked list1. Array vs Linked list Array Linked List Cost of accessing an element O(1) O(n) Storage feature Continuous block Separate Memory requirement Fixed size (some may unused); May not be available as a large block; Good for small type, int. No unused memory; but extra memory for pointer variables; Usually available for multiple small blocks; Good for storing complex type (16 bytes), Node type (4 byte), totally 20 for one whole (complex)(pointerNode) -> Cost of inserting an element At beginning: o(n), shifting all elements by 1 index; At end: o(1); Avg: o(n) At beginning: o(1); At end: o(n); Avg: o(n) Ease of use Easy hard Dynamic list: first allocating a fixed size array in memory. When adding extra elements which above the size, it creates a double size array in new memory address and copies original array to new array, so this is costing. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/algorithm/算法.html":{"url":"Interview/algorithm/算法.html","title":"算法","keywords":"","body":"1. 算法1. 算法 https://juejin.im/entry/58759e79128fe1006b48cdfd https://segmentfault.com/a/1190000009857470 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/amazon/":{"url":"Interview/amazon/","title":"Interview/amazon","keywords":"","body":"1. TOC1. TOC leadership_principles online_assessment prep system_design Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/amazon/leadership_principles.html":{"url":"Interview/amazon/leadership_principles.html","title":"leadership_principles","keywords":"","body":"1. Amazon leadership principles1. Amazon leadership principles Customer Obsession real-time chat UPMC mapQuest Leaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. Although leaders pay attention to competitors, they obsess over customers. Ownership Ub tahoe: instead of a beautiful dropdownList, accordion, implement a reusable plugin, although the layout stays ugly for a while, long-term, easy to maintain, more efficient to use in future. in SNH, SMS message, angular issue, other teams, they ask for help and I help Leaders are owners. They think long term and don’t sacrifice long-term value for short-term results. They act on behalf of the entire company, beyond just their own team. They never say “that’s not my job\". Invent and Simplify Unity xml T4 log4net + redis/queue Leaders expect and require innovation and invention from their teams and always find ways to simplify. They are externally aware, look for new ideas from everywhere, and are not limited by “not invented here\". As we do new things, we accept that we may be misunderstood for long periods of time. Are Right, A Lot performance UnitOfWork, Cache reusable dropdown plugin Leaders are right a lot. They have strong judgment and good instincts. They seek diverse perspectives and work to disconfirm their beliefs. Learn and Be Curious how memcache achieve distribute cache? how to use nosql to improve db performance instead of too many joins? Leaders are never done learning and always seek to improve themselves. They are curious about new possibilities and act to explore them. Hire and Develop the Best no hire experience, but in Tahoe, I ES2015, naming convention, coding style to coach others help new employees (Vishal) with angular Leaders raise the performance bar with every hire and promotion. They recognize exceptional talent, and willingly move them throughout the organization. Leaders develop leaders and take seriously their role in coaching others. We work on behalf of our people to invent mechanisms for development like Career Choice. Insist on the Highest Standards UPMC mapQuest, based on customer feedback performance Cache, best user experience Leaders have relentlessly high standards - many people may think these standards are unreasonably high. Leaders are continually raising the bar and driving their teams to deliver high quality products, services and processes. Leaders ensure that defects do not get sent down the line and that problems are fixed so they stay fixed. Think Big instead of single beautiful dropdownList, create reusable, maintainable plugin create a jquery-like helper library, helperClass Thinking small is a self-fulfilling prophecy. Leaders create and communicate a bold direction that inspires results. They think differently and look around corners for ways to serve customers. Bias for Action UPMC chart.js, open-source to create charts instead of microsoft server-generated images Speed matters in business. Many decisions and actions are reversible and do not need extensive study. We value calculated risk taking. Frugality find open source chart plugin -- chart.js Accomplish more with less. Constraints breed resourcefulness, self-sufficiency and invention. There are no extra points for growing headcount, budget size or fixed expense. Earn Trust admit mistake when SPA layout changes, an anchor raises error when peers ask, offer help as much as I can Leaders listen attentively, speak candidly, and treat others respectfully. They are vocally self-critical, even when doing so is awkward or embarrassing. Leaders do not believe their or their team’s body odor smells of perfume. They benchmark themselves and their teams against the best. Dive Deep real-time chat, discuss with peers about database design log4net + redis Leaders operate at all levels, stay connected to the details, audit frequently, and are skeptical when metrics and anecdote differ. No task is beneath them. Have Backbone; Disagree and Commit Jay decides ui and func Leaders are obligated to respectfully challenge decisions when they disagree, even when doing so is uncomfortable or exhausting. Leaders have conviction and are tenacious. They do not compromise for the sake of social cohesion. Once a decision is determined, they commit wholly. Deliver Results UPMC mapQuest result satisfied customer log4net + redis, has setbacks/obstacles, but carry on Leaders focus on the key inputs for their business and deliver them with the right quality and in a timely fashion. Despite setbacks, they rise to the occasion and never settle. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/amazon/online_assessment.html":{"url":"Interview/amazon/online_assessment.html","title":"online_assessment","keywords":"","body":"1. Given a movie, find similar movies1.1. balanced Parenthesis1. Given a movie, find similar movies using System; using System.Linq; using System.Collections.Generic; namespace MyCollections { public class Movie { private readonly int movieId; private readonly float rating; private List similarMovies; // Similarity is bidirectional public Movie(int movieId, float rating) { this.movieId = movieId; this.rating = rating; similarMovies = new List(); } public int getId() { return movieId; } public float getRating() { return rating; } public float Rating { get { return rating; } } public int Id { get { return movieId; } } public void addSimilarMovie(Movie movie) { similarMovies.Add(movie); movie.similarMovies.Add(this); } public List getSimilarMovies() { return similarMovies; } /* * Implement a function to return top rated movies in the network of movies * reachable from the current movie * eg: A(Rating 1.2) * / \\ * B(2.4) C(3.6) * \\ / * D(4.8) * In the above example edges represent similarity and the number is rating. * getMovieRecommendations(A,2)should return C and D (sorting order doesn't matter so it can also return D and C) * getMovieRecommendations(A,4) should return A, B, C, D (it can also return these in any order eg: B,C,D,A) * getMovieRecommendations(A,1) should return D. Note distance from A to D doesn't matter, return the highest rated. * * @param movie * @param numTopRatedSimilarMovies: number of movies we want to return * @return List of top rated similar movies */ public static IList getMovieRecommendations(Movie movie, int numTopRatedSimilarMovies) { if (movie == null) { throw new ArgumentNullException(\"movie\"); } HashSet moviesInNetwork = new HashSet(new MovieComparer()); // Flatten the network in a HashSet // Two problems with my implementation: // 1. It's recursive so it won't work for very large networks (as demonstrated in the sample Program below) // 2. It's O(n^2), worst case when every single movie is related to every other movies (n*(n-1)), not so good... GetDistinctMovies(movie, moviesInNetwork); // Order the movies by rating value (descending) and take the number of movies we want to return. // Orderby is a quicksort O(nlog(n)) // I cannot make any assumption concerning the numTopRatedSimilarMovies range so I didn't try to optimize anything here. return (from m in moviesInNetwork orderby m.Rating descending select m).Take(numTopRatedSimilarMovies).ToList(); } private static void GetDistinctMovies(Movie movie, HashSet knownMovies) { // Contains method is O(1) for HashSet if (knownMovies.Contains(movie)) return; // Add method is O(1) for HashSet knownMovies.Add(movie); foreach (var similarMovie in movie.getSimilarMovies()) { GetDistinctMovies(similarMovie, knownMovies); } } /// /// Movie comparer, used in the HashSet constructor. I assumed movie Ids are unique. /// private class MovieComparer : IEqualityComparer { public bool Equals(Movie m1, Movie m2) { return m1.Id == m2.Id; } public int GetHashCode(Movie movie) { return movie.Id; } } } public class Program { public static void Main() { try { Movie.getMovieRecommendations(null, 10); } catch (ArgumentNullException ex) { Console.WriteLine(ex.Message); } var A = new Movie(0, 1.2f); var B = new Movie(1, 2.4f); var C = new Movie(2, 3.6f); A.addSimilarMovie(B); A.addSimilarMovie(C); //B.addSimilarMovie (C); var D = new Movie(3, 4.8f); D.addSimilarMovie(B); D.addSimilarMovie(C); //D.addSimilarMovie (A); ShowRecommentations(A, 2); ShowRecommentations(A, 4); ShowRecommentations(A, 1); Console.WriteLine(\"Now with a very **deep** network\"); Random rating = new Random(); var movieId = 0; var X = new Movie(movieId, (float)rating.NextDouble() * 5); var currentMovie = X; while (movieId 1.1. balanced Parenthesis Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/amazon/prep.html":{"url":"Interview/amazon/prep.html","title":"prep","keywords":"","body":"1. Amazon seattle1. Amazon seattle Interviewer 1: Coding & Algorithms & Data Structures Interviewer 2: Coding & Problem Solving Interviewer 3: Problem Solving & Design (logical & maintainable/software) Interviewer 4: Architecture & System Design – This interview will test your understanding of distributed systems, concurrency/multi-threading, etc. Asking clarifying questions and gathering requirements is KEY for this interview. Please use this link to prepare https://www.hackerrank.com/domains/distributed-systems/client-server/page:1 namespace TcpEchoServer { public class TcpEchoServer { public static void Main() { Console.WriteLine(\"Starting echo server...\"); int port = 1234; TcpListener listener = new TcpListener(IPAddress.Loopback, port); listener.Start(); TcpClient client = listener.AcceptTcpClient(); NetworkStream stream = client.GetStream(); StreamWriter writer = new StreamWriter(stream, Encoding.ASCII) { AutoFlush = true }; StreamReader reader = new StreamReader(stream, Encoding.ASCII); while (true) { string inputLine = \"\"; while (inputLine != null) { inputLine = reader.ReadLine(); writer.WriteLine(\"Echoing string: \" + inputLine); Console.WriteLine(\"Echoing string: \" + inputLine); } Console.WriteLine(\"Server saw disconnect from client.\"); } } } } namespace TcpEchoClient { class TcpEchoClient { public static void Main(string[] args) { Console.WriteLine(\"Starting echo client...\"); int port = 1234; TcpClient client = new TcpClient(\"localhost\", port); NetworkStream stream = client.GetStream(); StreamReader reader = new StreamReader(stream); StreamWriter writer = new StreamWriter(stream) { AutoFlush = true }; while (true) { Console.Write(\"Enter text to send: \"); string lineToSend = Console.ReadLine(); Console.WriteLine(\"Sending to server: \" + lineToSend); writer.WriteLine(lineToSend); string lineReceived = reader.ReadLine(); Console.WriteLine(\"Received from server: \" + lineReceived); } } } } [x] Google Amazon parking lot example design [x] https://www.careercup.com/page?pid=trees-and-graphs-interview-questions Google “solve boggle board algorithm” [x] Understand the difference between breadth and depth, when to use each one etc. [x] http://codercareer.blogspot.com/p/binary-tree-interview-questions.html [x] Google “binary search questions” https://www.hackerrank.com/challenges/tree-height-of-a-binary-tree https://www.hackerrank.com/challenges/tree-level-order-traversal https://www.hackerrank.com/challenges/balanced-brackets https://www.hackerrank.com/challenges/contacts https://www.hackerrank.com/challenges/find-the-running-median https://www.hackerrank.com/challenges/swap-nodes-algo Please also review: https://www.hiredintech.com/classrooms/system-design/lesson/52 Leadership Principles – The principles are an important aspect who we are at Amazon and the culture we maintain. As you review the 14 principles be prepared to answer a question about your work delivering on a project, challenges you might have faced, problems you had to work through, meeting a deadline, etc. You will be expected to walk us through various example in your life in which you exhibited the leadership principles. You can use this link in preparing for the questions to expect. https://careerservices.wayne.edu/behavioralinterviewinfo.pdf Design Pattern SOA Distributed system: https://www.hackerrank.com/domains/distributed-systems/client-server/page:1 microService sharding large scale map-reduce, SOA, loading balance DNS lookups, TCP/IP 一道是anagrams, 另一道是group anagram的变形, 最后问了一下 hashmap 出现 collision 会发生什么。leetcode 49和242原题. hashmap 的题目说出来 hashCode, bucket, linkedList, key-value pair基本就可以了. 关注一亩三分地微博： Warald Onsite面经: 第一轮: First Common Ancestor of two nodes in a graph. 第二轮: Given two strings and a dictionary, only one character can be changed at a time, the changed string must also be found in the dictionary. Write a function to decide if it is possible that the 1st string can be changed to the 2nd string. using ctci.Contracts; using System; namespace Chapter01 { public class Q1_05_One_Away_A : IQuestion { public static bool OneEditReplace(String s1, String s2) { bool foundDifference = false; for (int i = 0; i 1) { return false; } /* Get shorter and longer string.*/ String s1 = first.Length 第三轮: Two sum, multiple pairs. 第四轮: System design. 跪的妥妥的. 10000 cameras, 100 hours of video each. 30 fps. Police need to input a plate number and find the path of a suspicious vehicle. (Estimate the size of the video, e.g., blueray disc is 2 hours and 20 GB. No need to scan all of the videos. Estimate the time that a vehicle can be seen between 2 traffic cameras, e.g., 0.3 miles and 30 miles per hour, then select 1 out of 100). Web client, load balancer, servers, db. 第五轮: 纯粹Behavior questions,要结合工作中实际的例子说明. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/amazon/system_design.html":{"url":"Interview/amazon/system_design.html","title":"system_design","keywords":"","body":"1. tiny url1. tiny url how long is the original url length? 30 => 120 bytes => db storage how long is the shortened url length? less than 10 => we can use 2nd method since long id 2132132132123 returns a string \"DTiRtHL\" with length 7. One Simple Solution could be Hashing. Use a hash function to convert long string to short string. In hashing, that may be collisions (2 long urls map to same short url) and we need a unique short url for every long url so that we can access long url back. A Better Solution is to use the integer id stored in database and convert the integer to character string that is at most 6 characters long. This problem can basically seen as a base conversion problem where we have a 10 digit input number and we want to convert it into a 6 character long string. using System; using System.Text; public class TinyURL { static string ALPHABET_MAP = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"; static int BASE = ALPHABET_MAP.Length; //62 public static string Encode(long index) { StringBuilder sb = new StringBuilder(); while (index > 0) { sb.Append(ALPHABET_MAP[(int)(index % BASE)]); index /= BASE; } char[] arr = sb.ToString().ToCharArray(); //Array.Reverse(arr); return new string(arr); } public static long Decode(string str) { long num = 0; // if using reverse, use this for loop //for (int i = 0, len = str.Length; i = 0; i--) { num = num * BASE + ALPHABET_MAP.IndexOf(str[i]); } return num; } public static void Main(string[] args) { Console.WriteLine($\"Encoding for {int.MaxValue} is {Encode(int.MaxValue)}\"); //6 digit Console.WriteLine($\"Decoding for bLMuvc is {Decode(\"bLMuvc\")}\"); //6 digit Console.WriteLine($\"Encoding for 123 is {Encode(123)}\"); Console.WriteLine(\"Decoding for 9b is \" + Decode(\"9b\")); } } reducing the response time of the server by using a distributed system to share the load based on geography by using a central server but many caching servers at various geographical locations reducing the storage space database design backup and failover security issues prevent people from creating links to handling old/obsolete urls while creating the url we can say to the user that it will be deleted if the url is never used for more than say 3 years may be allow the user to login and delete unused ones user friendly things browser plugins to speed up creating links (youtube sharing has an option to create short urls) giving report to user about the usage statistics mobile app to create urls quickly 10000 cameras, 100 hours of video each. 30 fps. Police need to input a plate number and find the path of a suspicious vehicle. (Estimate the size of the video, e.g., blueray disc is 2 hours and 20 GB. No need to scan all of the videos. Estimate the time that a vehicle can be seen between 2 traffic cameras, e.g., 0.3 miles and 30 miles per hour, then select 1 out of 100). Web client, load balancer, servers, db. Assuming each camera captures 640 x 480 p video & all data stored in a raw format, its easy to do calculation that per camera storage requirement is around 10 GB of data per hour. The given spec matches. So we are good. 30 miles per hour of speed == 0.5 miles per sec. Since cameras are placed at 0.3 mile, a moving vehicle will always be captured every sec by a new camera. Db Design - Either cameras are doing OCR to figure out numbers at camera level, or the video is being stored on a central server where OCR is being done. For every frame, if a vehicle is identified, the number plate, timestamp & camera id is stored. I will index the DB on number plate. So for a given number, query can be done such that all rows with the number plate can be fetched ordered by timestamp. This way, the path of the number plate can be easily traced. Design a kind of kindle fire application where we can subscribe news channel and read the news from all publishers as a digital format how many articles are created per day => estimate db storage subject: news, sports, movie channels, observer: vipUser, regularUser message: Article vipUser can subscribe all channels while regularUser can subscribe most 5. Design a kindle app for mobile device and think about the large scale service that would support content distribution for it and how you would design it features: read txt, epub formats in device sync: add these documents to cloud sign in, read repositories from cloud categorize books, news, docs for cloud all documents discover and push books to user based on search result, payment history search a book and read 1st chapter to trial, buy books help: ask an issue, feedback share book to facebook reading editor: font, theme, process, bookmark, table of content others: resolution for different mobiles You have a cluster with 100 machines that need time to be synced. The central time server can only handle 10 requests at a time. How will you set this up? Way 1: divide the cluster into groups of 10 and the central time server syncs with 1st group, then 2nd. pros: easy to maintain grouping grouping map can be stored on central time server cons: if central server fails, may need to do resyncing if one or more of the servers in a group fail to sync or take too long then the other servers will be kept waiting Way 2: create 10 groups and assign masters in groups, those masters sync with the central server and they in turn push out to slaves in the group. Way 3: central server have a list of unsynced, syncing and synced servers. the central server can start with a random 10 servers and change their state from to be unsynced to syncing and update the lists. When a server finished syncing, its state is changed to synced and added to the synced list. Next, a new server can be synced if space is available. pros: servers don't constantly wait unnecessarily a priority can be assigned to certain servers if dependencies exist can retry on sync errors cons: if central server fails, need to redo syncing. To combat this each server can store their state, so when the central server comes back online, it can poll the cluster to see what needs to be done and recreate its lists How will you design the backend of product recommender system on amazon.com Depending upon what he is searching on Relating that searched Item to what he Purchased in the history Respecting User preference on Public Review of the Product Products that People who bought the same product along with the product searched by the current User. Best Brand Products that matches the searched product. Sort according to the best discount on the product searched Product which offers Free Shipping Coming to the Design The search itself can arrange the matched items in a tree/Graph structure. When the user traversing down a path, user is exploring more and more since the system should never be able to say that it can no longer search your product. Check the movie online assessment Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/angular1/":{"url":"Interview/angular1/","title":"Interview/angular1","keywords":"","body":"1. TOC1. TOC Angular1 ng-model-options Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/angular1/Angular1.html":{"url":"Interview/angular1/Angular1.html","title":"Angular1","keywords":"","body":"1. Most comes from dotnetTricks1.1. Routing1.1.1. How angular is compiled1.1.2. How Data binding happens (apply, digest, watch)1.1.3. Digest life cycle1.1.4. How to handles exception automatically?1.1.5. $watch, $watchGroup, $watchCollection1.1.6. Difference between $observe and $watch1.1.7. $parse and $eval1.1.8. Isolate scope1.1.9. How Angular service return a promise?1.1.10. Interceptor? What are common uses of it?1. Most comes from dotnetTricks Service, Factory, Provider Factory allows you to add some logic before creating the object. It returns the created object. app.factory('myFactory',function(){ var obj = {}; obj.name = ''; obj.setName = function(name){ obj.name = name; }; return obj; }); //usage: myFactory.setName('wang'); $scope.Name = myFactory.name; when to use: use it with constructor Service: Doesn't return anything app.service('myService', function(){ this.name = ''; this.setName = function(newname){ this.name = newname; return this.name; }; }) //usage: $scope.Name = myService.setName('wang'); when to use: a singleton object. when needing to share a single object across the application. Authenticated user details Provider: create a configurable service object. app.provider('configurable', function(){ var privateName = ''; this.setName = function(newName){ privateName = newName; }; this.$get = function(){ return {name:privateName}; }; }); //usage: app.config(function(configurableProvider){ configurableProvider.setName('wang'); }); $scope.Name = configurable.name; 1.1. Routing To build a SPA. divide app into multiple views and bind different views. $routeProvider, ngRoute module let app = angular.module('myApp', ['ngRoute']); app.config(['$routeProvider'], function($routeProvider) { $routeProvider. when('/products', { templateUrl: 'Views/products.html', controller: 'productController' }).when('/products/:productId', { templateUrl: 'Views/product.html', controller: 'productController' }).otherwise({ redirectTo: '/index' }); }); 1.1.1. How angular is compiled The compiler allows you attaching new behaviors or attributes to any Html element. Angular uses $compiler service to compile page after DOM is fully loaded. 2 phases: Compile: It traverse the DOM and collect directives. Foreach directive, it adds it to a list of directives. It will sort that list by priority. Then each directive's compile function is executed, and each compile function returns a linking function, which is then composed into a combined linking function. Link: link function gets called. This in turn calls linking function of individual directives, registering listeners on the elements and setting up $watch with the scope. after combining directives with a scope, it produces the view. prelink: executed before elements are linked. Not safe to do DOM transformation postlink: executed after elements are linked. Safe to do DOM transformation The concept of compile and link comes from C language, where you first compile the code and then link it to execute it 1.1.2. How Data binding happens (apply, digest, watch) $watch: observe scope variable change. $scope.$watch('name', function(newVal, oldVal){ }); $digest: iterates thru all watchers and check if value has changed. If changing, calls the listener with new value and old value. $apply: angular auto updates only model changes within angular context. if any model change happens outside of context, like DOM events, setTimeout, XHR ajax, third party libraries, we need inform angular of the changes by calling $apply manually. When $apply finishes, angular calls $digest internally so all bindings are updated. document.getElementById('hello').addEventListener('click', function(){ $scope.$apply(function(){ $scope.time = new Date(); }); }, false); digest is faster than apply, since apply triggers watchers on the entire scope chain (parents, children) while digest only current scope and its children. 1.1.3. Digest life cycle responsible for updating DOM elements with model changes, executing watcher functions digest loop is fired when browser receives an event that can be managed by angular context. It includes 2 smaller loops digest loop keeps iterating until the $evalAsnc queue is empty and $watch list doesn't detect any model change $evalAsync queue contains all tasks which are scheduled by $evalAsync function from a directive or controller $watch list contains all watches correspondence to each DOM element which is bound to the $scope object. These watches are resolved in the $digest loop through a process called dirty checking. If a values changes, $scope is dirty, another digest loop is triggered. 1.1.4. How to handles exception automatically? when error occurs in one of watchers, digest cannot handle errors via $exceptionHandler service. In this case you have to handle manually. while apply uses try catch block to handle errors then pass them to exceptionHandler service. function $apply(exp){ try return $eval(exp) catch(e) $exceptionHandler(e); finally $root.digest(); } 1.1.5. $watch, $watchGroup, $watchCollection $watch: watch a variable $watchGroup: watch variables in array $scope.a = 1; $scope.b = 2; $scope.$watchGroup(['a','b'], function(newval,oldval){} ); $watchCollection: watch if any property changes in an object $scope.names = ['a','b','c']; //{'a':1,'b':2} $scope.$watchCollection('names', function(newval,oldval){}); 1.1.6. Difference between $observe and $watch $observe is a method on the attr object which is only used to observe attribute change $watch is a method on the $scope object which is to watch expression(string, function) 1.1.7. $parse and $eval $parse is a service that converts an expression into a function. Then function can be invoked and passed a context(usually scope) in order to retrieve the expression's value $eval executes an expression on the current scope and returns the result $scope.a=1; $scope.b=2; $scope.$eval('b+a'); 1.1.8. Isolate scope by default, a custom directive has access to parent scope. If we don't have access to parent scope, only access to current directive's scope. angular.module('myapp').directive('hi',function(){ return { scope: {}, // create an isolate scope template: 'Name: {{emp.name}}' } }); Below is not from dotnetTricks 1.1.9. How Angular service return a promise? To add promise functionality to a service, we inject the $q dependency in the service angular.factory('testService', function($q) { return { getName: function() { var deferred = $q.defer(); //API call here that returns data testAPI.getName().then(function(name) { deferred.resolve(name); }); return deferred.promise; } }; }); The $q library is a helper provider that implements promises and deferred objects to enable asynchronous functionality. Pasted from https://www.codementor.io/angularjs/tutorial/angularjs-interview-questions-sample-answers 1.1.10. Interceptor? What are common uses of it? An interceptor is a middleware code where all the $http requests go through. The interceptor is a factory that are registered in $httpProvider. You have 2 types of requests and response that go through the interceptor. This piece of code is very useful for error handling, authentication or middleware in all the requests/responses. Pasted from https://www.codementor.io/angularjs/tutorial/angularjs-interview-questions-sample-answers Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/angular1/ng-model-options.html":{"url":"Interview/angular1/ng-model-options.html","title":"ng-model-options","keywords":"","body":"1. angular-1.3 之ng-model-options指令1. angular-1.3 之ng-model-options指令 ng-model-options是angular-1.3新出的一个指令，允许我们控制ng-model何时进行同步。比如: 当某个确定的事件被触发的时候 在指定的防抖动延迟时间之后，这样视图值就会在指定的时间之后被同步到模型. 在angular-1.2版本就可以实现的ng-model双向绑定的核心代码: Hello {{name}} 它是实时同步更新的，input中每输入一个字，就立刻同步到数据模型。这是因为每次输入 input 都会触发一个 input 的事件，然后angular就会执行的$digest循环，直到模型稳定下来。我们不用手动设置任何事件监听来同步更新视图和模型。 然而由于每次键盘按下都会触发$digest循环，所以当你在输入input内容的时候，angular 不得不处理所有绑定在 scope 上的watch监听。这样它执行的效率就取决于你在 scope 上绑定了多少 watch 监听、以及这些监听的回调函数是怎样的，这个代价是十分昂贵的。 如果我们能够自己控制$digest的触发，比如当用户停止输入300毫秒后触发，又或者是当input元素失去焦点的时候再触发，那不是更好么? 于是angular-1.3的ng-model-options就为我们做了这件事。 通过 updataOn 指定同步ng-model的时间 ng-model-options 提供了一系列的选项去控制 ng-model 的更新。 通过 updateOn 参数我们可以定义 input 触发$digest的事件。举个栗子，我们希望当input失去焦点的时候更新模型，只需要按照如下的配置来实现: Hello {{name}} ng-model-options=\"{ updateOn: 'blur' }\"告诉 angular 在 input 触发了 onblur 事件的时候再更新 ng-model，而不是每次按下键盘就立即更新model。 http://plnkr.co/edit/URMCoON9qDFnxdlyiDSS?p=preview 如果我们想要保留默认的更新模型事件，另外再给它添加其它触发$digest的事件，可以使用一个特殊的事件: default。通过空格分隔的字符串来给它添加多个事件。下面这段代码能够在输入的时候同步更新模型，并且当input失去焦点的时候也更新模型. Hello {{name}} http://plnkr.co/edit/6VtaJrCIuO5ePfoz8UXA?p=preview (效果其实不太看不出来的...因为虽然blur的时候它在同步，但是其实输入的时候已经同步完了) 通过debounce延迟模型更新 接下来让我们看看怎么指定更新的延迟时间。我们可以通过ng-model-options来延迟模型的更新，以此来降低当用户和模型交互时触发的$digest循环的次数。这不仅减少了$digest循环的次数，同时也是处理异步数据模型时提升用户体验度的一个好方法。 想象有这样一个元素: input[type=\"search\"]，每当用户正在输入的时候，数据模型就会更新，并且用最新的字段向后台提交请求。这样是没错的。然而我们很可能并不想让用户每次按键的时候就立刻更新模型，而是希望当用户输入完了一段有意义的搜索字段以后才更新模型。在这种情况下，我们正适合使用ng-model-options的debounce参数。debounce定义了模型更新的延迟毫秒数(需要是整数)。比如刚才提到的这种情况，我们希望当用户停止输入1000毫秒以后再更新模型，停止输入1000毫秒差不多应该就是输入完了一段有意义的内容了吧。我们可以像下面这样，定义debounce参数的值为1000。 Search results for: {{searchQuery}} 现在当输入搜索内容的时候，会有1秒的延迟。http://plnkr.co/edit/lpFwWsTvZxMGfHFe38Bk?p=preview 我们还可以做更多的配置: 为指定的事件指定延迟时间。为不同的事件指定不同的延时，可以通过给debounce属性定义一个json对象来实现: 属性名代表事件名，属性值代表延迟时间。如果某个事件不需要延迟，那么它的属性值就是0。 下面这个栗子实现了这样的模型: 当用户在input里输入的时候，延迟1000毫秒更新模型，但是当input元素失去焦点的时候，立刻更新模型: Search results for: {{searchQuery}} http://plnkr.co/edit/yYsfcjW8KVt9ZESQUSB2?p=preview 通过$rollbackViewValue同步模型和视图 由于我们通过ng-model-options来控制了模型的更新时间，所有在很多时候模型和视图就会出现不同步的情况。举个栗子，我们配置ng-model-options，让input在失去焦点的时候同步数据模型，当用户正在输入内容时，数据模型没有发生更新。 假设在这种情境下，你希望在数据模型更新前把视图上的值回滚到它真实的值。这时，$rollbackViewValue可以同步数据模型到视图。这个方法会把数据模型的值返回给视图，同时取消所有的将要发生的延迟同步更新事件。 执行了 $rollbackViewValue() 方法 myValue1: \"{{ myValue1 }}\" 没有执行了 $rollbackViewValue() 方法 myValue2: \"{{ myValue2 }}\" app.controller('Rollback'，function($scope) { $scope.resetWithRollback = function(e) { if (e.keyCode == 27) { // press esc $scope.myForm2.myInput1.$rollbackViewValue(); } }; $scope.resetWithoutRollback = function(e) { if (e.keyCode == 27) { // press esc angular.noop() } } }); http://plnkr.co/edit/iMY8IqH5f8NLuIAxY8zN?p=preview myValue1使用了$rollbackViewValue()方法，可以回滚文本域里的值和数据模型同步，但是myValue2是不能的。 需要特别注意的一点是，在使用了ng-model-options这种情况下，如果直接修改模型值，有时可能让视图同步，有时却不能，什么意思，看这个栗子: app.controller('Rollback'，function($scope) { $scope.resetWithRollback = function(e) { if (e.keyCode == 27) { $scope.myValue1 = ''; //使用了$rollbackViewValue，总是可以同步视图，清空myValue1值 $scope.myForm2.myInput1.$rollbackViewValue(); } }; $scope.resetWithoutRollback = function(e) { if (e.keyCode == 27) { //并不是每次都可以成功的同步的，有时可以，有时不可以. $scope.myValue2 = ''; } } }); http://plnkr.co/edit/vve2Xh7LROQLQFa6FFrn?p=preview 按Esc的时候，不是直接回滚视图值到当前的数据模型，而是先设置数据模型为空，然后再回滚视图值。而myValue2，直接设置数据模型为空，不使用回滚。 在demo里多试几次就会发现，在这种情况下，在myValue2的 input 里按 Esc，有时可以同步视图值为空，有时则不能。 所以，在用了 ng-model-opitons 的时候，如果在模型没有被视图同步之前需要让视图被模型同步，不能简单通过设置模型，必须使用$rollbackViewValue()方法。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/angular4/":{"url":"Interview/angular4/","title":"Interview/angular4","keywords":"","body":"1. TOC1. TOC Angular2的数据绑定 Angular2装饰器 modules Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/angular4/Angular2的数据绑定.html":{"url":"Interview/angular4/Angular2的数据绑定.html","title":"Angular2的数据绑定","keywords":"","body":"1. Angular2 的数据绑定1.1. 分类1.2. 使用1.2.1. 方括号单向数据绑定1.2.2. 字符串插值绑定1.2.3. 圆括号单向数据绑定（事件绑定）1.2.4. 使用双向数据绑定1.3. 实现原理1. Angular2 的数据绑定 1.1. 分类 方括号单向数据绑定。 [目标]=\"表达式\": 数据流动方向为组件 --> 模板 字符串插值绑定。 ``: 数据流动方向为组件 --> 模板 圆括号单向数据绑定。 (目标)=\"表达式\": 数据流动方向为模板 --> 组件。通常用来处理事件。 双向绑定。 [(目标)]=\"表达式\": 数据流动方向为模板 组件 1.2. 使用 1.2.1. 方括号单向数据绑定 绑定属性时需要分清属性(property)和特性(attribute)绑定，绑定样式时有四种可选操作 property 绑定 property 是存在于 DOM 里的，例如 input 元素的 value属性。 为了防止表达式返回 null，在表达式后面跟上一个? 每个元素的property可以参考文档 attribute 绑定 attribute 是存在于 HTML元素里的，不是所有的 HTML元素的 property 都和 attribute 相符，比如说 colspan。NG 提供了绑定 attribute 属性的解决办法。 {{model.getProduct(1)?.name || 'None'}} 类和样式绑定 可以直接绑定HTML元素的样式或者类，也可以使用NG提供的指令达到目标。 类绑定 有三种方式。 [class]=\"表达式\": 把表达式的结果替代原来存在的class [class]=\"getClasses(1)\" [class.myClass]=\"表达式\": 根据表达式返回结果添加myClass这个类 [class.myClass]=\"model.getProduct(2).price [ngClass]=\"map\": 把 map 对象的值添加到class里去，支持三种返回值:字符串,数组,对象 //html [ngClass]=\"map\" //ts map= { \"text-xs-center bg-danger\": product.name == \"Kayak\", \"bg-info\": product.price 样式绑定 同样三种方式。不过没有替换样式的写法。 [style.color]=\"表达式\": 把表达式的结果设置成单个样式属性。 [style.font-size.em]=\"表达式\": 把表达式的结果设置成指定的样式和单位值。 [ngStyle]=\"map\": 把样式设置成map对象的值。 //ts map= { fontSize: \"30px\", \"margin.px\": 100, color: product.price > 50 ? \"red\" : \"green\" } 1.2.2. 字符串插值绑定 它被用于宿主元素的文本内容中。也是一种单向数据绑定，常常用于显示某个数据。 {{data||getData()}} 1.2.3. 圆括号单向数据绑定（事件绑定） 事件绑定用于响应宿主元素发送的事件。是用户交互的核心。事件种类请参考文档 {{i + 1}} 也可以直接传入一个Event对象到组件里去。 当需要传入 HTML 元素到组件时，可以借助模板引用变量 1.2.4. 使用双向数据绑定 使用ngModel指令可以简化了双向绑定的语法。 其实NG中的双向绑定就是同时利用了两个方向上的单向绑定,拆开看其实就是： 1.3. 实现原理 NG 不像 angular1.x 使用脏检查来更新数据，而是使用了 zone.js 库来监视数据的变更，当组件里的数据发生了改变，NG 会渲染模板 DOM。当 DOM的事件被触发了，NG会改变组件里的数据。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/angular4/Angular2装饰器.html":{"url":"Interview/angular4/Angular2装饰器.html","title":"Angular2装饰器","keywords":"","body":"1. Angular 2 装饰器1. Angular 2 装饰器 装饰器是一个函数，它将元数据添加到类、类成员（属性、方法）和函数参数。 装饰器是一个 JavaScript 的语言特性，装饰器在 TypeScript 里已经实现，并被推荐到了 ES2016（也就是ES7）。 要想应用装饰器，把它放到被装饰对象的上面或左边。 Angular 使用自己的一套装饰器来实现应用程序各部件之间的相互操作 @NgModule 装饰器，它接收一个用来描述模块属性的元数据对象。其中最重要的属性是： declarations - 声明本模块中拥有的视图类。 Angular 有三种视图类：组件、指令和管道。 exports - declarations 的子集，可用于其它模块的组件模板。 imports - 本模块声明的组件模板需要的类所在的其它模块。 providers - 服务的创建者，并加入到全局服务列表中，可用于应用任何部分。 bootstrap - 指定应用的主视图（称为根组件），它是所有其它视图的宿主。只有根模块才能设置bootstrap属性。 @Component 组件装饰器，它把紧随其后的类标记成了组件类。能接受一个配置对象， Angular 会基于这些信息创建和展示组件及其视图。 moduleId - 为与模块相关的 URL（例如templateUrl）提供基地址。 selector - CSS 选择器，它告诉 Angular 在父级 HTML 中查找标签，创建并插入该组件。 例如，如果应用的 HTML 包含， Angular 就会把HeroListComponent的一个实例插入到这个标签中。 templateUrl - 组件 HTML 模板的模块相对地址，如前所示。 providers - 组件所需服务的依赖注入提供商数组。 这是在告诉 Angular：该组件的构造函数需要一个HeroService服务，这样组件就可以从服务中获得数据 @Injectable 装饰器，声明当前类有一些依赖，当依赖注入器创建该类的实例时，这些依赖应该被注入到构造函数中。 @Pipe({...})装饰器，声明当前类是一个管道，并且提供关于该管道的元数据 @Directive 装饰器，声明当前类是一个指令，并提供关于该指令的元数据 @Input() @Output() @HostBinding @HostListener @ContentChild 装饰器: 装饰器 介绍 @Input() myProperty; 声明一个输入属性，以便我们可以通过属性绑定更新它。(比如： ). @Output() myEvent = new EventEmitter(); 声明一个输出属性，以便我们可以通过事件绑定进行订阅。(比如：). @HostBinding('[class.valid]') isValid; 把宿主元素的属性(比如CSS类：valid)绑定到指令/组件的属性(比如：isValid)。 @HostListener('click', ['$event']) onClick(e) {...} 通过指令/组件的方法(例如onClick)订阅宿主元素的事件(例如click)，可选传入一个参数($event)。 @ContentChild(myPredicate) myChildComponent; 把组件内容查询(myPredicate)的第一个结果绑定到类的myChildComponent属性。 @ContentChildren(myPredicate) myChildComponents; 把组件内容查询(myPredicate)的全部结果，绑定到类的myChildComponents属性。 @ViewChild(myPredicate) myChildComponent; 把组件视图查询(myPredicate)的第一个结果绑定到类的myChildComponent属性。对指令无效。 @ViewChildren(myPredicate) myChildComponents; 把组件视图查询(myPredicate)的全部结果绑定到类的myChildComponents属性。对指令无效 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/angular4/modules.html":{"url":"Interview/angular4/modules.html","title":"modules","keywords":"","body":"1. Modules1. Modules import { NgModule } from '@angular/core' import { RouterModule } from '@angular/router' import { CommonModule } from '@angular/common' @NgModule({ imports: [ CommonModule ], declarations: [ ], providers: [ ], bootstrap: [] }) export class userModule { } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/design_pattern.html":{"url":"Interview/design_pattern.html","title":"design_pattern","keywords":"","body":"1. Design Pattern1.1. Singleton Pattern1.2. Factory Method Pattern1.3. facade Pattern1.4. Proxy Pattern1.5. Adapter Pattern1.6. DI1. Design Pattern 1.1. Singleton Pattern Singleton pattern is one of the simplest design patterns. This pattern ensures that a class has only one instance and provides a global point of access to it. var Singleton = (function () { var instance; function createInstance() { var object = new Object(\"I am the instance\"); return object; } return { getInstance: function () { if (!instance) { instance = createInstance(); } return instance; } }; })(); function run() { var instance1 = Singleton.getInstance(); var instance2 = Singleton.getInstance(); alert(\"Same instance? \" + (instance1 === instance2)); } 1.2. Factory Method Pattern In Factory pattern, we create object without exposing the creation logic. In this pattern, an interface is used for creating an object, but let subclass decide which class to instantiate. The creation of object is done when it is required. The Factory method allows a class later instantiation to subclasses. 1.3. facade Pattern Facade pattern hides the complexities of the system and provides an interface to the client using which the client can access the system. This pattern involves a single wrapper class which contains a set of members which are required by client. These members access the system on behalf of the facade client and hide the implementation details. The facade design pattern is particularly used when a system is very complex or difficult to understand because system has a large number of interdependent classes or its source code is unavailable. 1.4. Proxy Pattern The proxy design pattern is used to provide a surrogate object, which references to other object. Proxy pattern involves a class, called proxy class, which represents functionality of another class. 1.5. Adapter Pattern Adapter pattern acts as a bridge between two incompatible interfaces. This pattern involves a single class called adapter which is responsible for communication between two independent or incompatible interfaces. 1.6. DI Dependency Injection (DI) is a software design pattern that allow us to develop loosely coupled code. DI is a great way to reduce tight coupling between software components. DI also enables us to better manage future changes and other complexity in our software. The purpose of DI is to make code maintainable. The Dependency Injection pattern uses a builder object to initialize objects and provide the required dependencies to the object means it allows you to \"inject\" a dependency from outside the class. For example, Suppose your Client class needs to use a Service class component, then the best you can do is to make your Client class aware of an IService interface rather than a Service class. In this way, you can change the implementation of the Service class at any time (and for how many times you want) without breaking the host code. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/":{"url":"Interview/dotnet/","title":"Interview/dotnet","keywords":"","body":"1. TOC1. TOC DI dotnet_interview dotnetFramework lock reflection SignalR集群 webapi 面向切面变成AOP Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/dotnet/DI.html":{"url":"Interview/dotnet/DI.html","title":"DI","keywords":"","body":"1. DI 原理解析及 Castle、Unity 框架使用1. DI 原理解析及 Castle、Unity 框架使用 控制反转（Inversion of Control）目的是解耦合 ==DI基本原理本质上是通过容器来反射创建实例== class Person { public void Say() { Console.WriteLine(\"Person's say method is Called\"); } } // 反射代码(className:类的全限定名) private static object CreateInstance(Assembly assembly, string className) { var type = assembly.GetType(className); return type != null ? Activator.CreateInstance(type) : null; } // 执行(XX为命名空间) static void Main(string[] args) { var obj = CreateInstance(Assembly.GetExecutingAssembly(), \"XX.Person\"); var person = obj as Person; if (person != null) { person.Say(); } Console.ReadKey(); } 在上面能看到1个问题，一般情况下既然使用DI，就不知道具体的注入对象，所以强调面向接口编程。所以实际上一般先定义接口，再通过DI容器创建对象。 interface IPerson { void Say(); } class Person : IPerson { public void Say() { Console.WriteLine(\"Person's say method is Called\"); } } //执行 static void Main(string[] args) { var obj = CreateInstance(Assembly.GetExecutingAssembly(), \"Demo.Person\"); var person = obj as IPerson; if (person != null) { person.Say(); } Console.ReadKey(); } DI 框架流行的有 Castle Windsor, Unity...(Autofac, Spring.Net) ==在DI框架中，一般需要将对象注册到容器中，然后从容器解析出来。== Castle Install-Package Castle.Windsor //待注入类 interface ITransient { } interface IPerson { void Say(); } class Person : IPerson, ITransient { public void Say() { Console.WriteLine(\"Person's say method is Called\"); } } //注册解析方式一 static void Main(string[] args) { using (var container = new WindsorContainer()) { container.Register(Component.For()); var person = container.Resolve(); person.Say(); } Console.ReadKey(); } //注册解析方式二 public class AssmInstaller : IWindsorInstaller { public void Install(IWindsorContainer container, IConfigurationStore store) { container.Register(Classes.FromThisAssembly() //选择Assembly .IncludeNonPublicTypes() //约束Type .BasedOn() //约束Type .WithService.DefaultInterfaces() //匹配类型 .LifestyleTransient()); //注册生命周期 } } static void Main(string[] args) { using (var container = new WindsorContainer()) { container.Install(new AssmInstaller()); var person = container.Resolve(); person.Say(); } Console.ReadKey(); } 构造函数注入 class Task : ITransient { public IPerson Person { get; set; } public Task(IPerson person) { Person = person; Person.Say(); } } static void Main(string[] args) { using (var container = new WindsorContainer()) { container.Install(new AssmInstaller()); container.Resolve(); } Console.ReadKey(); } 属性注入 class Task : ITransient { public IPerson Person { get; set; } public Task() { } public void Say() { Person.Say(); } } static void Main(string[] args) { using (var container = new WindsorContainer()) { container.Install(new AssmInstaller()); container.Resolve().Say(); } Console.ReadKey(); } MVC集成 Install-Package Castle.Windsor.Mvc Application_Start注册 protected void Application_Start() { RouteConfig.RegisterRoutes(RouteTable.Routes); var container = new WindsorContainer() .Install(FromAssembly.This()); var controllerFactory = new WindsorControllerFactory(container.Kernel); ControllerBuilder.Current.SetControllerFactory(controllerFactory); } Installer 注册 public class AssmInstaller : IWindsorInstaller { public void Install(IWindsorContainer container, IConfigurationStore store) { container.Register(Classes.FromThisAssembly() .IncludeNonPublicTypes() .BasedOn() .WithService.DefaultInterfaces() .LifestyleTransient()); container.Register(Classes.FromThisAssembly() .BasedOn() .LifestyleTransient() ); } } 这样 Castle Windsor 就能接管解析 Controller 了 Unity Install-Package Unity 待注入类 public interface IPerson { void Say(); } public class Person : IPerson { public void Say() { Console.WriteLine(\"Person's say method is Called\"); } } 注册解析一 static void Main(string[] args) { using (var container = new UnityContainer()) { container.RegisterType(new TransientLifetimeManager()); var person = container.Resolve(); person.Say(); } Console.ReadKey(); } 注册解析二 static void Main(string[] args) { using (var container = new UnityContainer()) { container.RegisterInstance(new Person()); var person = container.Resolve(); person.Say(); } Console.ReadKey(); } 构造函数注入 class Task : ITask { public IPerson Person { get; set; } public Task(IPerson person) { Person = person; Person.Say(); } } public interface ITask { } static void Main(string[] args) { using (var container = new UnityContainer()) { container.RegisterInstance(new Person()); container.RegisterType(); container.Resolve(); } Console.ReadKey(); } 属性注入 class Task : ITask { [Dependency] public IPerson Person { get; set; } public Task(IPerson person) { Person = person; } public void Say() { Person.Say(); } } static void Main(string[] args) { using (var container = new UnityContainer()) { container.RegisterInstance(new Person()); container.RegisterType(); var task = container.Resolve(); task.Say(); } Console.ReadKey(); } MVC集成 Install-Package Unity.Mvc Application_Start注册 protected void Application_Start() { RouteConfig.RegisterRoutes(RouteTable.Routes); var container = new UnityContainer(); container.RegisterType(); DependencyResolver.SetResolver(new UnityDependencyResolver(container)); } 这样 Unity 就接管了 Controller 的创建 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/dotnet_interview.html":{"url":"Interview/dotnet/dotnet_interview.html","title":"dotnet_interview","keywords":"","body":"1. .net interview1. .net interview 冒泡排序 for (int i = 0; i data[j + 1]) { int temp = data[j]; data[j] = data[j + 1]; data[j + 1] = temp; } } } StringBuilder vs string string joinWords(string[] words) { string sentence =\"\"; foreach (string w in words) { sentence += w; } return sentence; } On each concatenation, a new copy of the string is created, and the two strings are copied over, character by character. The first iteration requires us to copy x characters. The second iteration requires copying 2x characters. The third iteration requires 3x, and so on. The total time is O(x + 2x + ... + nx) => O(n^2). StringBuilder simply creates a resizable array of all the strings, copying them back to a string only when necessary. O(n) using System.Text; string joinWords(string[] words) { StringBuilder sentence = new StringBuilder(); foreach (string w in words) { sentence.append(w); } return sentence.toString(); } 单例模式 资源共享的情况下，避免由于资源操作时导致的性能或损耗等。 控制资源的情况下，方便资源之间的互相通信。如线程池等。 Windows 的 Task Manager（任务管理器） windows 的 Recycle Bin（回收站）也是典型的单例应用。在整个系统运行过程中，回收站一直维护着仅有的一个实例。 网站的计数器，一般也是采用单例模式实现，否则难以同步。 应用程序的日志应用，一般都何用单例模式实现，这一般是由于共享的日志文件一直处于打开状态，因为只能有一个实例去操作，否则内容不好追加。 Web 应用的配置对象的读取，一般也应用单例模式，这个是由于配置文件是共享的资源。 数据库连接池的设计一般也是采用单例模式，因为数据库连接是一种数据库资源。数据库软件系统中使用数据库连接池，主要是节省打开或者关闭数据库连接所引起的效率损耗，这种效率上的损耗还是非常昂贵的，因为何用单例模式来维护，就可以大大降低这种损耗。 多线程的线程池的设计一般也是采用单例模式，这是由于线程池要方便对池中的线程进行控制。 操作系统的文件系统，也是大的单例模式实现的具体例子，一个操作系统只能有一个文件系统。 HttpApplication 也是单例的典型应用。熟悉 ASP.Net(IIS) 的整个请求生命周期的人应该知道 HttpApplication 也是单例模式，所有的 HttpModule 都共享一个 HttpApplication 实例。 实现方法： static 属性里面 new，构造函数private，如果是要求多线程情况，线程安全要double check 实现 1.将该类的构造方法定义为私有方法，这样其他处的代码就无法通过调用该类的构造方法来实例化该类的对象，只有通过该类提供的静态方法来得到该类的唯一实例； 2.在该类内提供一个静态方法，当我们调用这个方法时，如果类持有的引用不为空就返回这个引用，如果类保持的引用为空就创建该类的实例并将实例的引用赋予该类保持的引用。 饿汉式 静态常量(经典写法) public class Singleton { private static Singleton _instance = new Singleton(); private Singleton() { } public static Singleton Instance() { return _instance; } } 适用：单/多线程 模式：饿汉式（静态常量）[可用] 优点：写法比较简单，避免了线程同步问题 缺点：没能实现延迟加载 静态代码块 public class Singleton2 { private static Singleton2 _instance; static Singleton2() { _instance = new Singleton2(); } private Singleton2(){} public Singleton2 Instance() { return _instance; } } 适用：单/多线程 模式：饿汉式（静态代码块）[可用] 优点：写法比较简单，避免了线程同步问题 缺点：没能实现延迟加载 懒汉式 线程不安全 public class Singleton3 { private static Singleton3 _instance; private Singleton3() { } public static Singleton3 Instance() { return _instance ?? (_instance = new Singleton3()); } } 适用：单线程 模式：懒汉式(线程不安全)[不可用] 优点：适用于单线程，实现简单，延迟加载 缺点：多线程不安全，违背了单列模式的原则 线程安全 public class Singleton4 { private static Singleton4 _instance; private static readonly object SyncObject = new object(); private Singleton4() { } public static Singleton4 Instance() { lock (SyncObject) { if (_instance == null) { _instance = new Singleton4(); } } return _instance; } } 适用：单线程 模式：懒汉式(线程安全，不推荐) 优点：线程安全；延迟加载； 缺点：这种实现方式增加了额外的开销，损失了性能(当有多个调用时，第一个调用的会进入lock，而其他的则等待第一个结束后才能调用，后面的依次访问、等待……) 双重检查锁定 public class Singleton5 { private static Singleton5 _instance; private static readonly object SyncObject = new object(); private Singleton5() { } public static Singleton5 Instance() { if (_instance==null) { lock (SyncObject) { if (_instance == null) { _instance = new Singleton5(); } } } return _instance; } } 适用：单/多线程 模式：双重检查锁定(Double-Check Locking)(线程安全，推荐) 优点：线程安全；延迟加载；效率较高(只会实例化一次，首先会判断是否实例化过，如果实例化了，直接返回实例，不需要进入lock；如果未实例化，进入lock，就算是多个调用也无妨，第一次调用的会实例化，第二个进入lock时会再次判断是否实例化，这样线程就不会阻塞了。) 缺点：基本没有 静态内部类 public class Singleton6 { private Singleton6() { } private static class SingletonInstance { public static Singleton6 Instance = new Singleton6(); } public static Singleton6 Instance() { return SingletonInstance.Instance; } } 适用：单/多线程 模式：静态内部类(线程安全，推荐) 优点：避免了线程不安全；延迟加载；效率高(这种方式跟饿汉式方式采用的机制类似：都是采用了类装载的机制来保证初始化实例时只有一个线程。不同的地方是：饿汉式只要Singleton类被装载就会实例化，没有Lazy-Loading的作用；而静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化时，调用Instance方法，才会装载SingletonInstance类，从而完成Singleton的实例化。) 缺点：基本没有 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/dotnetFramework.html":{"url":"Interview/dotnet/dotnetFramework.html","title":"dotnetFramework","keywords":"","body":"Describe the Events in the Life Cycle of a Web Application. A web application starts when a browser requests a page of the application first time. The request is received by the IIS which then starts ASP.NET worker process (aspnet_wp.exe). The worker process then allocates a process space to the assembly and loads it. An application_start event occurs followed by Session_start. The request is then processed by the ASP.NET engine and sends back response in the form of HTML. The user receives the response in the form of page. The page can be submitted to the server for further processing. The page submitting triggers postback event that causes the browser to send the page data, also called as view state to the server. When server receives view state, it creates new instance of the web form. The data is then restored from the view state to the control of the web form in Page_Init event. The data in the control is then available in the Page_load event of the web form. The cached event is then handled and finally the event that caused the postback is processed. The web form is then destroyed. When the user stops using the application, Session_end event occurs and session ends. The default session time is 20 minutes. The application ends when no user accessing the application and this triggers Application_End event. Finally all the resources of the application are reclaimed by the Garbage collector. What is connection pooling and how to enable and disable connection pooling? Connection pool is created when we open connection first time. When a new connection is created with same connection string as the first one, it reuses the same and existing connection object from the pool without creating a new one. If the connection string is different then a new connection pooling will be created, thus won't use the existing connection object. By default, we have connection pooling enabled in .Net. To disable connection pooling, set Pooling = false in the connection string. State the differences between the Dispose() and Finalize() CLR uses the Dispose and Finalize methods to perform garbage collection of run-time objects of .NET applications. The Finalize method is called automatically by the runtime. CLR has a garbage collector (GC), which periodically checks for objects in heap that are no longer referenced by any object or program. It calls the Finalize method to free the memory used by such objects. The Dispose method is called by the programmer. Dispose is another method to release the memory used by an object. The Dispose method needs to be explicitly called in code to dereference an object from the heap. The Dispose method can be invoked only by the classes that implement the IDisposable interface. Differentiate between managed and unmanaged code? Managed code is the code that is executed directly by the CLR instead of the operating system. The code compiler first compiles the managed code to intermediate language (IL) code, also called as MSIL code. This code doesn't depend on machine configurations and can be executed on different machines. Managed code execution order: Choosing a language compiler (JIT) Compiling the code to MSIL Compiling MSIL to native code Executing the code. Unmanaged code is the code that is executed directly by the operating system outside the CLR environment. It is directly compiled to native machine code which depends on the machine configuration. In the managed code, since the execution of the code is governed by CLR, the runtime provides different services, such as garbage collection, type checking, exception handling, and security support. These services help provide uniformity in platform and language-independent behavior of managed code applications. In the unmanaged code, the allocation of memory, type safety, and security is required to be taken care of by the developer. If the unmanaged code is not properly handled, it may result in memory leak. Examples of unmanaged code are ActiveX components and Win32 APIs that execute beyond the scope of native CLR. Describe the roles of CLR in .NET Framework CLR provides an environment to execute .NET applications on target machines. CLR is also a common runtime environment for all .NET code irrespective of their programming language, as the compilers of respective language in .NET Framework convert every source code into a common language known as MSIL or IL (Intermediate Language). CLR also provides various services to execute processes, such as memory management service and security services. CLR performs various tasks to manage the execution process of .NET applications. The responsibilities of CLR are listed as follows: Automatic memory management Garbage Collection Code Access Security Code verification JIT compilation of .NET code Explain covariance(协变) and contra-variance(逆变) in .NET Framework 4.0. Give an example for each. In .NET 4.0, the CLR supports covariance and contravariance of types in generic interfaces and delegates. Covariance enables you to cast a generic type to its base types, that is, you can assign a instance of type IEnumerable to a variable of type IEnumerable. For example, IEnumerable str1= new List (); IEnumerable str2= str1; Contravariance allows you to assign a variable of Action to a variable of type Action. For example, IComparer obj1 = GetComparer() IComparer obj2 = obj1; .NET framework 4.0 uses some language keywords (out and in) to annotate covariance and contra-variance. Out is used for covariance, while in is used for contra-variance. Variance can be applied only to reference types, generic interfaces, and generic delegates. These cannot be applied to value types and generic types. httpHandler, httpModule Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/lock.html":{"url":"Interview/dotnet/lock.html","title":"lock","keywords":"","body":"1. lock1. lock 首先先上官方Msdn的说法 lock 关键字可确保当一个线程位于代码的临界区时，另一个线程不会进入该临界区。 如果其他线程尝试进入锁定的代码，则它将一直等待（即被阻止），直到该对象被释放。 lock 关键字在块的开始处调用 Enter，而在块的结尾处调用 Exit。 ThreadInterruptedException 引发，如果 Interrupt 中断等待输入 lock 语句的线程。 通常，应避免锁定 public 类型，否则实例将超出代码的控制范围。 常见的结构 lock (this)、lock (typeof (MyType)) 和 lock (\"myLock\") 违反此准则： 如果实例可以被公共访问，将出现 lock (this) 问题。 如果 MyType 可以被公共访问，将出现 lock (typeof (MyType)) 问题。 由于进程中使用同一字符串的任何其他代码都将共享同一个锁，所以出现 lock(\"myLock\") 问题。 最佳做法是定义 private 对象来锁定, 或 private static 对象变量来保护所有实例所共有的数据。 在 lock 语句的正文不能使用 等待 关键字。 Enter 指的是 Monitor.Enter(获取指定对象上的排他锁。)，Exit指的是Monitor.Exit(释放指定对象上的排他锁。) 有上面msdn的解释及Exit方法，可以这样猜测“直到该对象被释放”，”该对象“应该是指锁的对象，对象释放了或者对象改变了，其他的线程才可以进入代码临界区（是不是可以这样来理解？）。 在多线程中，每个线程都有自己的资源，但是代码区是共享的，即每个线程都可以执行相同的函数。这可能带来的问题就是几个线程同时执行一个函数，导致数据的混乱，产生不可预料的结果，因此我们必须避免这种情况的发生。 打个比方，有这样一个情景，很多公司所在的大厦的厕所的蹲位都是小单间型的，也就是一次只能进去一个人，那么为了避免每次进去一个人，那怎么做呢？不就是一个人进去之后顺手把门锁上么？这样你在里面干啥事，外边的人也只能等待你解放完了，才能进入。而蹲位的资源（蹲位，手纸等）是共享的。 最常使用的锁是如下格式的代码段： private static object objlock = new object(); lock (objlock) { //要执行的代码逻辑 } 为什么锁的对象是私有的呢？还是以厕所为例子吧，私有就好比，这把锁只有你能访问到，而且最好这把锁不会因为外力而有所改变，别人访问不到，这样才能保证你进去了，别人就进不去了，如果是公有的，就好比你蹲位小单间的锁不是安装在里面而是安装在外边的，别人想不想进就不是你所能控制的了，这样也不安全。 lock(this) 通过字面的意思就是锁的当前实例对象。那是否对其他实例对象产生影响？那下面看一个例子： namespace Wolfy.LockDemo { class Program { static void Main(string[] args) { Test t = new Test(); Test t2 = new Test(); Thread[] threads = new Thread[10]; for (int i = 0; i { t2.Print(); }); //为每个线程设置一个名字 threads[i].Name = \"thread\" + i; } //开启创建的十个线程 for (int i = 0; i 如果在不加锁的情况下输出如下： 从上面的输出结果也可以看出，线程出现了争抢的现象，而这并不是我们想要的结果，我们想要的是，每次只有一个线程去执行Print方法。那我们就尝试一下 lock(this) class Test { public void Print() { lock (this) { for (int i = 0; i 输出结果 从输出结果，觉得大功告成了，可是现在情况又来了，在项目中的其他的地方，有同事也这样写了这样的代码，又创建了一个Test对象，而且他也知道使用多线程执行耗时的工作，那么就会出现类似下面的代码。 namespace Wolfy.LockDemo { class Program { static void Main(string[] args) { Test t = new Test(); Test t2 = new Test(); t2.Age = 20; Thread[] threads = new Thread[10]; for (int i = 0; i { t.Print(); t2.Print(); }); //为每个线程设置一个名字 threads[i].Name = \"thread\" + i; } //开启创建的十个线程 for (int i = 0; i 这里为Test加了一个Age属性，为了区别当前创建的对象不是同一个对象。 输出的结果为 在输出的结果中已经出现了线程抢占执行的情况了，而不是一个线程执行完另一个线程在执行。 lock(private obj) 那么我们现在使用一个全局的私有的对象试一试。 namespace Wolfy.LockDemo { class Program { private static object objLock = new object(); static void Main(string[] args) { Test t = new Test(); Test t2 = new Test(); t2.Age = 20; Thread[] threads = new Thread[10]; for (int i = 0; i { lock (objLock) { t.Print(); t2.Print(); } }); //为每个线程设置一个名字 threads[i].Name = \"thread\" + i; } //开启创建的十个线程 for (int i = 0; i 输出的结果 从输出的结果也可以看出，有序的，每次进来一个线程执行。 那通过上面的比较可以有这样的一个结论，lock的结果好不好，还是关键看锁的谁，如果外边能对这个谁进行修改，lock就失去了作用。所以一般情况下，使用静态的并且是只读的对象。 也就有了类似下面的代码 private static readonly object objLock = new object(); 你可能会说，不对啊，你下面的代码跟上面的代码不一样啊，为什么就得出这样的结论？难道就不能把Object放在test类中么，放在test类中的话，在new Test()的时候，其实放在Test中也是可以的，只要保证objLock在外部是无法修改的就可以。 上面说的最多的是lock对象，那么它能不能lock值类型？ 答案是否定的，如 当然lock(null)也是不行的，如图 虽然编译可以通过，但是运行就会出错。 lock(string) string也是应用类型，从语法上来说是没有错的。 但是锁定字符串尤其危险，因为字符串被公共语言运行库 (CLR)“暂留”。 这意味着整个程序中任何给定字符串都只有一个实例，就是这同一个对象表示了所有运行的应用程序域的所有线程中的该文本。因此，只要在应用程序进程中的任何位置处具有相同内容的字符串上放置了锁，就将锁定应用程序中该字符串的所有实例。通常，最好避免锁定 public 类型或锁定不受应用程序控制的对象实例。例如，如果该实例可以被公开访问，则 lock(this) 可能会有问题，因为不受控制的代码也可能会锁定该对象。这可能导致死锁，即两个或更多个线程等待释放同一对象。出于同样的原因，锁定公共数据类型（相比于对象）也可能导致问题。而且lock(this)只对当前对象有效，如果多个对象之间就达不到同步的效果。lock(typeof(Class))与锁定字符串一样，范围太广了。 总结 lock的是引用类型的对象，string类型除外。 ==lock推荐的做法是使用静态的、只读的、私有的对象。== 保证lock的对象在外部无法修改才有意义，如果lock的对象在外部改变了，对其他线程就会畅通无阻，失去了lock的意义。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/reflection.html":{"url":"Interview/dotnet/reflection.html","title":"reflection","keywords":"","body":"1. .net反射1. .net反射 反射就是动态发现类型信息的能力。它帮助程序设计人员在程序==运行时利用一些信息去动态地使用类型==，这些信息在设计时是未知的，这种能力类型于后期绑定。反射还支持的更高级的行为，能在运行时==动态创建新类型，并且对这些新类型的操作进行调用==。 常用的反射例子 变化数据库，通过反射动态读取配置文件 SqlHelper SqlDataReader读取数据库，表明通过反射加载 开发windows form插件： 创建接口项目，通过接口定义插件实现方式 创建插件项目，创建两个插件一个实现汉英翻译功能，一个实现定时关机功能。插件项目要引用接口项目。编译时让插件项目生成在主程序的debug/plugin目录下 创建主程序，主程序要添加对接口项目的引用(不需要对插件引用，对插件的调用是动态的) 主程序中读取 Plugin 目录下的所有dll文件，加载成Assembly。Ass.GetExportedTypes 读取 Assembly中的公共类型。 IsAssignableFrom判断对象能否委派给某类型，是否是类并且不能使抽象类 反射中经常使用的类 Assembly类 Assembly类是可重用、无版本冲突并且可自我描述的公共语言运行库应用程序构造块。可以使用Assembly.Load和Assembly.LoadFrom方法动态地加载程序集。 Type类 反射的中心是System.Type类。System.Type类是一个抽象类，代表公用类型系统中的一种类型。这个类使您能够查询类型名、类型中包含的模块和名称空间、以及该类型是一个数值类型还是一个引用类型。System.Type类使您能够查询几乎所有与类型相关的属性，包括类型访问限定符、类型是否、类型的COM属性等等。 Activator类 Activator类支持动态创建.NET程序集和COM对象。可以通过CreateComInstanceFrom、CreateInstance、CreateInstanceFrom、GetObject四个静态方法加载COM对象或者程序集，并能创建指定类型的实例。 Binder类 Binder类是一个用于执行类型转换的绑定器，Type对象的InvokeMember方法接受Binder对象，这个对象描述了如何将传递给InvokeMember的参数转换成方法实际需要的类型。Binder类是一个抽象类，要创建绑定器，需要重写方法BindToMethod、BindToField、SelectMehtod、SelectProperty和ChangeType。 DefaultMemberAttribute类 DefaultMemberAttribute类用于类型并带有一个指明默认成员名称的字符串参数。能够通过InvokeMember调用默认成员，而不需要传递调用成员的名称。当需要绑定器但不需要特别的绑定行为时就可以使用它。 还有一些对元素类型信息描述的类，ConstrutorInfo（构造函数）、MethodInfo（方法）、FieldInfo（字段）、PropertyInfo（属性）、EventInfo（事件）、MemberInfo（成员）、ParameterInfo（参数）。如果查询得到了具有任何类型信息的实例，就可以获得该类型中任意元素的类型信息，当然出于安全原因，不保证会得到程序集中的任何信息。 示例 using System; using System.Collections.Generic; using System.Text; namespace ReflectionSample { public class ClassSample { // 默认构造 public ClassSample() { this.name = \"您调用了默认构造创建了一个类实例。\"; } // 带参构造 public ClassSample(string name) { this.name = name; } // 字段 public string name; public string Field; // 属性 private string property; public string Property { set { this.property = value; } get { return property; } } // public方法 public string PublicClassMethod() { return string.Format(\"您反射了一个Public方法\"); } // private方法 private string PrivateClassMethod() { return string.Format(\"您反射了一个Private方法\"); } // static方法 public static string StaticMethod() { return \"您反射了一个Static方法\"; } // 帶參方法 public string ParameterMethod(string para) { return para; } public event EventHandler eventHandler; public void DoEvent() { eventHandler(null,EventArgs.Empty); } } } using System; using System.Data; using System.Configuration; using System.Web; using System.Web.Security; using System.Web.UI; using System.Web.UI.WebControls; using System.Web.UI.WebControls.WebParts; using System.Web.UI.HtmlControls; using System.Reflection; using ReflectionSample; public partial class _Default : System.Web.UI.Page { protected void Page_Load(object sender, EventArgs e) { string path = Server.MapPath(Request.Path); string filePath = path.Substring(0, path.LastIndexOf(''\\\\'')) + @\"\\bin\\ReflectionSample.dll\"; // 获取程序集 Assembly classSampleAssembly = Assembly.LoadFrom(filePath); // 从程序集中获取指定对象类型 Type classSampleType = classSampleAssembly.GetType(\"ReflectionSample.ClassSample\"); // 通过对象类型创建对象实例 ClassSample s1 = Activator.CreateInstance(classSampleType) as ClassSample; Response.Write(s1.name + \"（使用Activator创建一个实例）\"); // 动态调用无参构造 ConstructorInfo studentConstructor1 = classSampleType.GetConstructor(new Type[] { }); ClassSample s2 = studentConstructor1.Invoke(new object[] { }) as ClassSample; Response.Write(s2.name + \"\"); // 动态调用有参构造 ConstructorInfo studentConstructor2 = classSampleType.GetConstructor(new Type[] { typeof(string) }); ClassSample s3 = studentConstructor2.Invoke(new object[] { \"您调用了有参构造创建了一个类实例。\" }) as ClassSample; Response.Write(s3.name + \"\"); // 调用非静态方法 string returnValue1 = classSampleType.InvokeMember(\"PublicClassMethod\", BindingFlags.InvokeMethod | BindingFlags.Public | BindingFlags.Instance, null, s1, new object[] { }) as string; Response.Write(returnValue1 + \"\"); // 调用静态方法 string returnValue2 = classSampleType.InvokeMember(\"StaticMethod\", BindingFlags.InvokeMethod | BindingFlags.Public | BindingFlags.Static, null, s1, new object[] { }) as string; Response.Write(returnValue2 + \"\"); // 调用私有方法 string returnValue3 = classSampleType.InvokeMember(\"PrivateClassMethod\", BindingFlags.InvokeMethod | BindingFlags.NonPublic | BindingFlags.Instance, null, s1, new object[] { }) as string; Response.Write(returnValue3 + \"\"); //反射参数 MethodInfo parameterMethod = classSampleType.GetMethod(\"ParameterMethod\"); ParameterInfo[] paras = parameterMethod.GetParameters(); for (int i = 0; i .net反射优缺点 缺点： 编译器无法对对象进行类型检查 编写更多的代码来实现 速度慢 优势： 为创建对象和调用其他方法提供了替代方案。比如为了提高代码的灵活性 将指定具体类推迟到了运行时刻。 使用反射机制调用方法的四步曲 加载程序集 获取类的类型 创建该类的实例 调用该实例的方法 System.Reflection.Assembly 类中有两个静态方法 Assembly.Load(string assemblyName)和Assembly.LoadFrom(string fileName)来把程序集加载到应用程序序域中。 在.NET中当一个对象被创建时，幕后到底发生了什么？当我们运行某一个应用程序时，.NET CLR会首先创建一个应用程序域来容纳这个应用程序，接着将应该引用的程序集加载到应用程序域中。其中MSCorLib.dll是一个程序集，它包含了很多系统命名空间及其子命名空间中的类：System;System.Text,System.IO等。然后CLR加载正在运行的应用程序所属的程序集。 namespace ClassLibrarySport { // define abstract class public abstract class Sport { protected string Name; public abstract string GetName(); public abstract string GetDuration(); } } namespace ClassLibrarySomeSports { public class Football : ClassLibrarySport.Sport { public Football() { Name = \"Football\"; } public override string GetName() { return Name; } public override string GetDuration() { return \"four 15 minute quarters\"; } } } // reflection usage: using System; using System.Reflection; namespace ConsoleAssemblyTest { class Program { static void Main(string[] args) { Assembly assembly = Assembly.LoadFrom(@\"E:\\ClassLibrarySomeSports\\bin\\Debug\\ClassLibrarySomeSports.dll\"); Type[] types = assembly.GetTypes(); Console.WriteLine(\"Get Type From ClassLibrarySomeSports.dll:\"); for (int i = 0; i 类型 作用 Assembly 通过此类可以加载操纵一个程序集，并获取程序集内部信息 EventInfo 该类保存给定的事件信息 FieldInfo 该类保存给定的字段信息 MethodInfo 该类保存给定的方法信息 MemberInfo 该类是一个基类，它定义了EventInfo、FieldInfo、MethodInfo、PropertyInfo的多个公用行为 Module 该类可以使你能访问多个程序集中的给定模块 ParameterInfo 该类保存给定的参数信息 PropertyInfo 该类保存给定的属性信息 System.Reflection.Assembly类 通过Assembly可以动态加载程序集，并查看程序集的内部信息，其中最常用的就是Load()这个方法。 Assembly assembly=Assembly.Load(\"MyAssembly\"); 利用Assembly的object CreateInstance(string) 方法可以反射创建一个对象，参数0为类名。 System.Type类 Type是最常用到的类，通过Type可以得到一个类的内部信息，也可以通过它反射创建一个对象。一般有三个常用的方法可得到Type对象。 利用typeof() 得到Type对象 Type type=typeof(Example); 利用System.Object.GetType() 得到Type对象 Example example=new Example(); Type type=example.GetType(); 利用System.Type.GetType() 得到Type对象 Type type=Type.GetType(\"MyAssembly.Example\",false,true); 注意参数0是类名，参数1表示若找不到对应类时是否抛出异常，参数1表示类名是否区分大小写 例子： 我们最常见的是利用反射与Activator结合来创建对象。 Assembly assembly= Assembly.Load(\"MyAssembly\"); Type type=assembly.GetType(\"Example\"); object obj=Activator.CreateInstance(type); 反射方法 通过 System.Reflection.MethodInfo能查找到类里面的方法 Type type=typeof(Example); MethodInfo[] listMethodInfo=type.GetMethods(); foreach(MethodInfo methodInfo in listMethodInfo) Cosole.WriteLine(\"Method name is \"+methodInfo.Name); 我们也能通过反射方法执行类里面的方法 Assembly assembly= Assembly.Load(\"MyAssembly\"); Type type=assembly.GetType(\"Example\"); object obj=Activator.CreateInstance(type); MethodInfo methodInfo=type.GetMethod(\"Hello World\"); //根据方法名获取MethodInfo对象 methodInfo.Invoke(obj,null); //参数1类型为object[]，代表Hello World方法的对应参数，输入值为null代表没有参数 四、反射属性 通过 System.Reflection.PropertyInfo 能查找到类里面的属性 常用的方法有GetValue（object,object[]) 获取属性值和 SetValue(object,object,object[]) 设置属性值 Type type=typeof(Example); PropertyInfo[] listPropertyInfo=type.GetProperties(); foreach(PropertyInfo propertyInfo in listPropertyInfo) ​ Console.WriteLine(\"Property name is \"+ propertyInfo.Name); 我们也可以通过以下方法设置或者获取一个对象的属性值 Assembly assembly=Assembly.Load(\"MyAssembly\"); Type type=assembly.GetType(\"Example\"); object obj=Activator.CreateInstance(type); PropertyInfo propertyInfo=obj.GetProperty(\"Name\"); //获取Name属性对象 var name=propertyInfo.GetValue(obj,null）; //获取Name属性的值 PropertyInfo propertyInfo2=obj.GetProperty(\"Age\"); //获取Age属性对象 propertyInfo.SetValue(obj,34,null); //把Age属性设置为34 五、反射字段 通过 System.Reflection.FieldInfo 能查找到类里面的字段 它包括有两个常用方法SetValue（object ,object )和GetValue（object) 因为使用方法与反射属性非常相似 六、反射特性 通过System.Reflection.MemberInfo的GetCustomAttributes(Type,bool)就可反射出一个类里面的特性,以下例子可以反射出一个类的所有特性 Type type=typeof(\"Example\"); object[] typeAttributes=type.GetCustomAttributes(false); //获取Example类的特性 foreach(object attribute in typeAttributes) Console.WriteLine(\"Attributes description is \"+attribute.ToString()); 通过下面例子，可以获取 Example 类Name属性的所有特性 public class Example { [DataMemberAttribute] publics string Name { get; set; } } Type type = typeof(Example); PropertyInfo propertyInfo = type.GetProperty(\"Name\"); //获取Example类的Name属性 foreach (object attribute in propertyInfo.GetCustomAttributes(false)) { //遍历Name属性的所有特性 Console.WriteLine(\"Property attribute: \"+attribute.ToString()); } 七、常用实例 虽然反射有很多奥妙之处，但要注意使用反射生成对象会耗费很多性能，所能必须了解反射的特性，在合适的地方使用。最常见例子就是利用单体模式与反射一并使用，在BLL调用DAL的时候，通过一个反射工厂生成DAL实例。 namespace Project.Common { public class Factory { //记录dal的对象 private static Hashtable dals; //用assemblyString记录DAL程序集的全名称 private static string assemblyString = ConfigurationManager.AppSettings[\"LinqDAL\"]; private static Assembly assembly; static Factory() { dals = new Hashtable(); assembly = Assembly.Load(assemblyString); } private static object CreateInstance(string typeName) { //当第一次加载时，将反射对象保存于dals集合里 if (!dals.ContainsKey(typeName)) { //创建反射对象 object object1 = assembly.CreateInstance(typeName); if (object1 == null) throw new Exception(\"未能创建此对象\"); //把对象加入dals集合 dals[\"typeName\"] = object1; } return dals[\"typeName\"]; } public static IExampleDAL CreateExampleDAL() { return (IExampleDAL)CreateInstance(assemblyString + \".ExampleDAL\"); } } class Program { //利用工厂模式生成对象 static void Main(string[] args) { IExampleDAL iExampleDAL=Factory.CreateExampleDAL(); ................. Console.ReadKey(); } } } namespace Project.IDAL { public interface IExampleDAL { /// /// 插入Example行，若插入成功，则返回新增Example的行数 /// ///Example对象 ///返回新增Example行数，默认值为-1 int AddExample(Example example); /// /// 更新Example表,Update成功返回已经更新的数据条数,失败返回-1 /// ///Example对象 ///Update成功返回已经更新的数据条数,失败返回-1 int UpdateExample(Example example); /// /// 删除Example表中ID等于exampleID的行,返回已删除行数 /// ///Example对象的ID值 ///返回删除行数 int DeleteExample(int exampleID); /// /// 获取Example表的所有行 /// ///返回Example表中的所有Example对象 IList GetList(); /// /// 根据ID获取对应Example对象 /// /// /// Example GetExampleByID(int id); } } namespace Project.DAL { public class ExampleDAL:IExampleDAL { public int AddExample(Example example) { //实现AddExample方法 } } } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/SignalR集群.html":{"url":"Interview/dotnet/SignalR集群.html","title":"SignalR集群","keywords":"","body":"1. Asp.Net SignalR 集群会遇到的问题1.1. SqlServer来做底板1.2. redis来做底板1. Asp.Net SignalR 集群会遇到的问题 当客户端数量上来，一台server自然是吃不消的。多个server集群部署是必然的解决方案。再通过负载均衡，嗯 简直是完美。但是问题也接踵而来。每个server只能管理到当前server下的client，比如 server1 要给连接在 server2 的 client 发一条消息是实现不了的。 这时我们需要“底板”中间件，什么叫底板 ，也就是在server的集群上再加一层，由底板来维护这些server，像上面server1给连接在server2的client发消息，底板会告诉server2给client发一条消息。就达到了我们需要的效果 常用的有Redis与SqlServer，其实 Redis性能是最优的。 1.1. SqlServer来做底板 需要下载nuget包 Microsoft.AspNet.SignalR.SqlServer 然后在startup类中进行配置,也是非常简单的,数据库是signalR。把程序运行一下，我们会得到以下这些表 1.2. redis来做底板 需要下载 nuget 包 Microsoft.AspNet.SignalR.Redis 同样在startup类中进行配置， GlobalHost.DependencyResolver.UseRedis(\"localhost\", 6379, string.Empty, \"signalR\"); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/webapi.html":{"url":"Interview/dotnet/webapi.html","title":"webapi","keywords":"","body":"Explain what is REST and RESTFUL? REST represents REpresentational State Transfer; it is relatively new aspect of writing web api. RESTFUL is referred for web services written by applying REST architectural concept are called RESTful services, it focuses on system resources and how state of resource should be transported over HTTP protocol to a different clients written in different language. In RESTFUL web service http methods like GET, POST, PUT and DELETE can be used to perform CRUD operations. Explain the architectural style for creating web api? HTTP for client server communication XML/JSON as formatting language: Simple URI as the address for the services Stateless communication what tools are required to test your web api? Chrome postman, SOAPUI tool for SOAP WS and Firefox \"poster\" plugin for RESTFUL services. what are the HTTP methods supported by REST? GET: It requests a resource at the request URL. It should not contain a request body as it will be discarded. May be it can be cached locally or on the server. POST: It submits information to the service for processing; it should typically return the modified or new resource PUT: At the request URL it update the resource DELETE: At the request URL it removes the resource OPTIONS: It indicates which techniques are supported HEAD: About the request URL it returns meta information Mention what is the difference between SOAP and REST? SOAP is a protocol through which two computer communicates by sharing XML document SOAP permits only XML SOAP based reads cannot be cached SOAP is like custom desktop application, closely connected to the server SOAP is slower than REST It runs on HTTP but envelopes the message Rest is a service architecture and design for network*based software architectures REST supports many different data formats REST reads can be cached A REST client is more like a browser; it knows how to standardized methods and an application has to fit inside it REST is faster than SOAP It uses the HTTP headers to hold meta information Explain Web API Routing? Routing is the mechanism of pattern matching as we have in MVC. These routes will get registered in Route Tables. Below is the sample route in Web API – Routes.MapHttpRoute( Name: \"MyFirstWebAPIRoute\", routeTemplate: \"api/{controller}/{id} defaults: new { id = RouteParameter.Optional} }; List out the differences between WCF and Web API? WCF It is framework build for building or developing service oriented applications. WCF can be consumed by clients which can understand XML. WCF supports protocols like – HTTP, TCP, Named Pipes etc. Web API It is a framework which helps us to build/develop HTTP services Web API is an open source platform. It supports most of the MVC features which keep Web API over WCF. What are the advantages of using REST in Web API? REST always used to make less data transfers between client and server which makes REST an ideal for using it in mobile apps. Web API supports HTTP protocol thereby it reintroduces the old way of HTTP verbs for communication. Difference between WCF Rest and Web API? WCF Rest \"WebHttpBinding\" to be enabled for WCF Rest. For each method there has to be attributes like – \"WebGet\" and \"WebInvoke\" For GET and POST verbs respectively. Web API Unlike WCF Rest we can use full features of HTTP in Web API. Web API can be hosted in IIS or in application. List out differences between MVC and Web API? MVC MVC is used to create a web app, in which we can build web pages. For JSON it will return JSONResult from action method. All requests are mapped to the respective action methods. Web API This is used to create a service using HTTP verbs. This returns XML or JSON to client. All requests are mapped to actions using HTTP verbs. What are the advantages of Web API? OData Filters Content Negotiation Self Hosting Routing Model Bindings Can we return view from Web API? No. We cannot return view from Web API. How we can restrict access to methods with specific HTTP verbs in Web API? Attribute programming is used for this functionality. Web API will support to restrict access of calling methods with specific HTTP verbs. We can define HTTP verbs as attribute over method as shown below [HttpPost] public void UpdateTestCustomer(Customer c) { TestCustomerRepository.AddCustomer(c); } Explain how to give alias name for action methods in Web API? Using attribute \"ActionName\" we can give alias name for Web API actions. Eg: [HttpPost] [ActionName(\"AliasTestAction\")] public void UpdateTestCustomer(Customer c) { TestCustomerRepository.AddCustomer(c); } What is the difference between MVC Routing and Web API Routing? There should be at least one route defined for MVC and Web API to run MVC and Web API application respectively. In Web API pattern we can find \"api/\" at the beginning which makes it distinct from MVC routing. In Web API routing \"action\" parameter is not mandatory but it can be a part of routing. Explain Exception Filters? Exception filters will be executed whenever controller methods (actions) throws an exception which is unhandled. Exception filters will implement \"IExceptionFilter\" interface. Explain about the new features added in Web API 2.0 version? OWIN Attribute Routing External Authentication Web API OData How can we pass multiple complex types in Web API? Using ArrayList Newtonsoft JArray Write a code snippet for passing arraylist in Web API? ArrayList paramList = new ArrayList(); Category c = new Category { CategoryId = 1, CategoryName = \"SmartPhones\"}; Product p = new Product { ProductId = 1, Name = \"Iphone\", Price = 500, CategoryID = 1 }; paramList.Add(c); paramList.Add(p); Give an example of MVC Routing? Below is the sample code snippet to show MVC Routing – routes.MapRoute( name: \"MyRoute\", //route name url: \"{controller}/{action}/{id}\", //route pattern defaults: new { controller = \"a4academicsController\", action = \"a4academicsAction\", id = UrlParameter.Optional } ); How we can handle errors in Web API? HttpResponseException Exception Filters Registering Exception Filters HttpError Explain how we can handle error from HttpResponseException? public TestClass MyTestAction(int id) { TestClass c = repository.Get(id); if (c == null) { throw new HttpResponseException(HttpStatusCode.NotFound); } return c; } HttpResponseMessage myresponse = new HttpResponseMessage(HttpStatusCode.Unauthorized); myresponse.RequestMessage = Request; myresponse.ReasonPhrase = ReasonPhrase; How to register Web API exception filters? From Action From Controller Global registration Write a code snippet to register exception filters from action? [NotImplExceptionFilter] public TestCustomer GetMyTestCustomer(int custid) { //Your code goes here } Write a code snippet to register exception filters from controller? [NotImplExceptionFilter] public class TestCustomerController : Controller { //Your code goes here } Write a code snippet to register exception filters globally? GlobalConfiguration.Configuration.Filters.Add(new MyTestCustomerStore.NotImplExceptionFilterAttribute()); How to handle error using HttpError? HttpError will be used to throw the error info in response body. CreateErrorResponse method is used along with this, which is an extension method defined in \"HttpRequestMessageExtensions\". Write a code snippet to show how we can return 404 error from HttpError? string message = string.Format(\"TestCustomer id = {0} not found\", customerid); return Request.CreateErrorResponse(HttpStatusCode.NotFound, message); How to enable tracing in Web API? in Register method of WebAPIConfig.cs file. config.EnableSystemDiagnosticsTracing(); Explain how Web API tracing works? Tracing in Web API done in facade pattern i.e, when tracing for Web API is enabled, Web API will wrap different parts of request pipeline with classes, which performs trace calls. Explain Authentication in Web API? Web API authentication will happen in host. In case of IIS it uses Http Modules for authentication or we can write custom Http Modules. When host is used for authentication it used to create principal, which represent security context of the application. Explain ASP.NET Identity? This is the new membership system for ASP.NET. This allows to add features of login in our application. One ASP.NET Identity System Persistence Control What are Authentication Filters in Web API? Authentication Filter will let you set the authentication scheme for actions or controllers. So this way our application can support various authentication mechanisms. How to set the Authentication filters in Web API? Authentication filters can be applied at the controller or action level. Decorate attribute – \"IdentityBasicAuthentication\" over controller where we have to set the authentication filter. Explain method – \"AuthenticateAsync\" in Web API? \"AuthenticateAsync\" method will create IPrincipal and will set on request Task AuthenticateAsync( HttpAuthenticationContext mytestcontext, CancellationToken mytestcancellationToken ) Explain method – ChallengeAsync in Web API? to add authentication challenges to response. Below is the method signature – Task ChallengeAsync( HttpAuthenticationChallengeContext mytestcontext, CancellationToken mytestcancellationToken ) What are media types? It is also called MIME, which is used to identify the data. In Html, media types is used to describe message format in the body. List out few media types of HTTP? Image/Png Text/HTML Application/Json Explain Media Formatters in Web API? Media Formatters in Web API can be used to read the CLR object from our HTTP body and Media formatters are also used for writing CLR objects of message body of HTTP. How to serialize read*only properties? Read*Only properties can be serialized in Web API by setting the value \"true\" to the property SerializeReadOnlyTypes of class: DataContractSerializerSettings How to get Microsoft JSON date format? Use \"DateFormatHandling\" property in serializer settings as below var myjson = GlobalConfiguration.Configuration.Formatters.JsonFormatter; myjson.SerializerSettings.DateFormatHandling = Newtonsoft.Json.DateFormatHandling.MicrosoftDateFormat; How to indent the JSON in web API? var mytestjson = GlobalConfiguration.Configuration.Formatters.JsonFormatter; mytestjson.SerializerSettings.Formatting = Newtonsoft.Json.Formatting.Indented; How to JSON serialize anonymous and weakly types objects? Using Newtonsoft.Json.Linq.JObject we can serialize and deserialize weakly typed objects. What is the use of IgnoreDataMember By default if the properties are public then those can be serialized and deserialized, if we does not want to serialize the property then decorate the property with this attribute. How to write indented XML in Web API? To write the indented xml set \"indent\" property to true. How to set Per*Type xml serializer? We can use method – \"SetSerializer\". Below is the sample code snippet for using it var mytestxml = GlobalConfiguration.Configuration.Formatters.XmlFormatter; // Use XmlSerializer for instances of type \"Product\" mytestxml.SetSerializer(new XmlSerializer(typeof(MyTestCustomer))); What is UnderPosting and \"OverPosting\" in Web API? \"UnderPosting\" When client leaves out some of the properties while binding then it’s called under–posting. \"OverPosting\" – If the client sends more data than expected in binding then it’s called overposting. How to handle validation errors in Web API? Web API will not return error to client automatically on validation failure. So its controller’s duty to check the model state and response to that. We can create a custom action filter for handling the same. Give an example of creating custom action filter in Web API? public class MyCustomModelAttribute : ActionFilterAttribute { public override void OnActionExecuting(HttpActionContext actionContext) { if (actionContext.ModelState.IsValid == false) { //Code goes here } } } In case validation fails here it returns HTTP response which contains validation errors. How to apply custom action filter in WebAPI.config? Add a new action filter in \"Register\" method as shown * public static class WebApiConfig { public static void Register(HttpConfiguration config) { config.Filters.Add(new MyCustomModelAttribute()); } } How to set the custom action filter in action methods in Web API? Below is the sample code of action with custom action filter – public class MyCustomerTestController : ApiController { [MyCustomModelAttribute] public HttpResponseMessage Post(MyTestCustomer customer) { } } What is BSON in Web API? It’s is a binary serialization format. \"BSON\" stands for \"Binary JSON\". BSON serializes objects to key*value pair as in JSON. Its light weight and its fast in encode/decode. How to enable BSON in server? Add \"BsonMediaTypeFormatter\" in WebAPI.config as shown below public static class WebApiConfig { public static void Register(HttpConfiguration config) { config.Formatters.Add(new BsonMediaTypeFormatter()); } } How parameter binding works in Web API? If it is simple parameters like – bool, int, double etc. then value will be obtained from the URL. Value read from message body in case of complex types. Why to use \"FromUri\" in Web API? In Web API to read complex types from URL we will use \"FromUri\" attribute to the parameter in action method. Eg: public MyValuesController : ApiController { public HttpResponseMessage Get([FromUri] MyCustomer c) { ... } } Why to use \"FromBody\" in Web API? This attribute is used to force Web API to read the simple type from message body. \"FromBody\" attribute is along with parameter. Eg: public HttpResponseMessage Post([FromBody] int customerid, [FromBody] string customername) { ... } Why to use \"IValueprovider\" interface in Web API? This interface is used to implement custom value provider. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/dotnet/面向切面变成AOP.html":{"url":"Interview/dotnet/面向切面变成AOP.html","title":"面向切面变成AOP","keywords":"","body":"1. 面向切面编程1.1. 例子1. 面向切面编程 你的程序写好了。现在发现要针对所有业务操作添加一个日志，或者在前面加一道权限控制，怎么办呢？传统的做法是，改造每个业务方法，这样势必把代码弄得一团糟 aop 的思想是引导你从另一个切面来看待和插入这些工作。日志不管加在哪，它其实都是属于日志系统这个角度的。权限控制也一样。aop允许你以一种统一的方式在运行时期在想要的地方插入这些逻辑。 1.1. 例子 中间件、拦截器、过滤器、.net actionFilter, exceptionFilter Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/":{"url":"Interview/frontend/","title":"Interview/frontend","keywords":"","body":"1. TOC1. TOC cookie_localStorage_sessionStorage DOM事件 Graceful-degradation_vs progressive-enhancement grunt_vs_gulp interview_react interview_闭包 Javascript异步编程 Javascript运行机制 JIT_vs_AOT JS对象_原型链 JS对象_继承 Object.defineProperty oop_delete_from_list React_Angular_Vue view_位置 webpack-hot-reloading_browserSync原理 内存泄漏和垃圾回收 前端开发知识点 前端路由原理 前端面试杂 协议_HTTP 协议_HTTP2 协议_TCP_UDP_Http的区别 协议_Websocket_SSE_vs_polling 协议_WebSocket 图片隐层且浏览器不下载 安全 模块化_AMD_CMD_UMD 浏览器渲染机制 浏览器缓存 深拷贝_浅拷贝 盒模型及宽高 算法 资源preload_prefetch 通信_跨域 错误监控 页面性能 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/frontend/cookie_localStorage_sessionStorage.html":{"url":"Interview/frontend/cookie_localStorage_sessionStorage.html","title":"cookie_localStorage_sessionStorage","keywords":"","body":"1. Cookie, localStorage, sessionStorage 区别1.1. cookie1.1.1. 什么是Cookie 隔离？（或者说：请求资源的时候不要让它带cookie怎么做）1.2. localStorage1. Cookie, localStorage, sessionStorage 区别 cookie 在浏览器和服务器间来回传递。 sessionStorage 和 localStorage不会 cookie 有 secure 属性要求 HTTPS 传输 cookie 属性有名，值，max-age，path, domain，secure cookie 默认有效期为浏览器会话，一旦用户关闭浏览器，数据就丢失，通过设置 max-age=seconds 属性告诉浏览器 cookie 有效期 cookie 作用域通过文档源和文档路径来确定，通过 path 和 domain 进行配置，web页面同目录或子目录文档都可访问 浏览器不能保存超过300个 cookie，单个服务器不能超过20个，每个 cookie 不能超过4k。web storage 大小支持能达到5M sessionStorage 和 localStorage 有更多丰富易用的接口 sessionStorage 和 localStorage 各自独立的存储空间 sessionStorage 在窗口关闭前有效，关闭窗口而非浏览器就会丢失数据。在新标签或窗口打开一个页面会初始化一个新的会话 localStorage 的数据会一直存在，即使在浏览器被关闭以后。localStorage 的修改会促发其他文档窗口的 update 事件，所以可以多窗口通信 Storage 对象通常被当做普通 javascript 对象使用：通过设置属性来存取字符串值，也可以通过 setItem(key, value)设置，getItem(key)读取，removeItem(key)删除，clear()删除所有数据，length表示已存储的数据项数目，key(index)返回对应索引的key 1.1. cookie 通过cookie保存数据的方法为：document.cookie = 'name=qiu; max-age=9999; path=/; domain=domain; secure';。设置 max-age 为0可以删除指定cookie var cookieUtil = (function(window, undefined) { var doc = window.document; var cookieUtil = { /** * 根据 opt 中设置的值设置cookie * * @param {Object} opt 包含cookie信息的对象，选项如下 * key {string} 需要设置的名字 * value {string} 需要设置的值 * maxAge {number} 有效期 * domain {string} domain * path {string} path * secure {boolean} secure * * @return {string} opt 对应的设置 cookie的字符串 */ setItem: function(opt) { var result = []; var str; if (opt.key) { result.push(encodeURIComponent(opt.key) + '=' + encodeURIComponent(opt.value)); if ('maxAge' in opt) { result.push('max-age=' + opt.maxAge); } if ('domain' in opt) { result.push('domain=' + opt.domain); } if ('path' in opt) { result.push('path=' + opt.path); } if (opt.secure) { result.push('secure'); } str = result.join('; '); doc.cookie = str; } return str; }, /** * 从 cookie 读取指定 key 的值，如果key有多个值，返回数组，如果没有 * 对应key，返回undefined * * @param {string} key 需要从 cookie 获取值得 key * @return {string|Array|undefined} 根据cookie数据返回不同值 */ getItem: function(key) { key = encodeURIComponent(key); var result; var pairs = doc.cookie.split('; '); var i, len, item, value; for (i = 0, len = pairs.length; i 1.1.1. 什么是Cookie 隔离？（或者说：请求资源的时候不要让它带cookie怎么做） 如果静态文件都放在主域名下，那静态文件请求的时候都带有的 cookie 的数据提交给 server 的，非常浪费流量，所以不如隔离开。 因为 cookie 有域的限制，因此不能跨域提交请求，故使用非主域名的时候，请求头中就不会带有 cookie 数据，这样可以降低请求头的大小，降低请求时间，从而达到降低整体请求延时的目的。同时这种方式不会将 cookie 传入 Web Server，也减少了 Web Server 对 cookie的处理分析环节，提高了 webserver 的 http 请求的解析速度。 1.2. localStorage localStorage.setItem('x', 1); // storage x->1 localStorage.getItem('x'); // return value of x // 枚举所有存储的键值对 for (var i = 0, len = localStorage.length; i 多个标签页通信主要是利用了 localStorage 的增删改事件监听 页面A发送事件: function sendMsg(text) { window.localStorage.setItem('msg', text); } 页面B接收事件: window.addEventListener('storage', function (evt) { if(evt.key === 'msg') console.log(evt.newValue); }); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/DOM事件.html":{"url":"Interview/frontend/DOM事件.html","title":"DOM事件","keywords":"","body":"1. DOM 事件1.1. 事件级别1.2. 事件模型1.3. 事件流1.3.1. 事件委托(event delegation)？为何有事件委托存在？它有什么好处？1.4. 描述事件捕获流程1.5. Event 对象常见应用1.6. 自定义事件1.7. document.DOMContentLoaded, window.onload, document.readyState1.7.1. IE 和 Chrome 标准浏览器事件处理的解决办法(老题目，了解)1. DOM 事件 1.1. 事件级别 DOM0: element.onclick = function(){} DOM2: element.addEventListener('click', function(){}, false) DOM3: element.addEventListener('keyup', function(){}, false) 1.2. 事件模型 捕获（上到下）、冒泡（下到上） 1.3. 事件流 捕获阶段 --> 目标阶段 --> 冒泡阶段 Capture: When you clicked, browser knows a click event occurred. It starts from the window (lowest level/root of your website), then goes to document, then html root tag, then body, then table... its trying to reach as the lowest level of element as possible. This is called capture phase. (从上到下到达目标元素) Target: When browser reach the lowest level of element. In this case, you have clicked on a table cell (table data) hence target would be td tag. Then browser checks whether you have any click handler attached to this element. If there is any, browser executes that click handler. This is called target phase. (执行目标元素的事件) Bubbling: After firing click handler attached to td, browser walks toward root. One level upward and check whether there is any click handler attached with table row (tr element). If there is any it will execute that. Then it goes to tbody, table, body, html, document, window. In this stage its moving upward and this is called event bubbling or bubbling phase. (从目标元素向上直到 window, 所有注册的事件都会一次由内向外执行) 1.3.1. 事件委托(event delegation)？为何有事件委托存在？它有什么好处？ You clicked on cell but all the event handler with parent elements will be fired. This is actually very powerful (check event delegation). 因为有事件冒泡，才会有事件委托出现。 好处：不需要循环为每个子元素 li 注册事件，节省空间和运算效率。第二如果不使用事件委托，添加新 li 时候还要为它注册事件，麻烦。用 e.CurrentTarget 获取父级元素。 1.4. 描述事件捕获流程 window --> document --> html (document.documentElement) --> body --> ... --> target 1.5. Event 对象常见应用 event.preventDefault() event.stopPropagation() event.stopImmediatePropagation() // 如果一个元素注册了多个点击事件，第一个事件触发时候想终止第二个事件触发，在一个事件中调用此方法。 prevent multiple event handler to be fired for an event? event.target // 被点击的子元素 event.currentTarget // 绑定事件父级元素 https://jsfiddle.net/thisman/gkdeocd6/ 1.6. 自定义事件 浏览器： let ev = new Event('myEvent') dom.addEventListener('myEvent', () => {}) // fire the event dom.dispatchEvent(ev) 也可以使用 new CustomEvent('name', obj) 传递数据 Node端自定义事件： // 使用 EventEmitter 模块 const EventEmitter = require('events'); class MyEmitter extends EventEmitter {} const myEmitter = new MyEmitter(); myEmitter.on('event', () => { console.log('an event occurred!'); }); myEmitter.emit('event'); 1.7. document.DOMContentLoaded, window.onload, document.readyState The DOMContentLoaded event is fired when the initial HTML document has been completely loaded and parsed, without waiting for stylesheets, images, and subframes to finish loading. document.addEventListener(\"DOMContentLoaded\", function(event) { console.log(\"DOM fully loaded and parsed. Images might be loading\"); }); for(var i=0; i The load event is fired when everything has finished loading. window.addEventListener(\"load\", function(event) { console.log(\"All resources finished loading!\"); }); The Document.readyState property of a document describes the loading state of the document. The readyState of a document can be one of following: loading: The document is still loading. interactive(DOMContentLoaded): The document has finished loading and the document has been parsed but sub-resources such as images, stylesheets and frames are still loading. complete(load): The document and all sub-resources have finished loading. The state indicates that the load event is about to fire. https://developer.mozilla.org/en-US/docs/Web/API/Document/readyState 1.7.1. IE 和 Chrome 标准浏览器事件处理的解决办法(老题目，了解) IE 只有事件只能在冒泡阶段触发。标准浏览器通过 addEventListener('click', function(){}, true/false) 来指定触发阶段。false 为冒泡阶段触发。 IE: attachEvent('click', function(){}) 添加事件 detachEvent('click', function(){}) 删除事件 标准浏览器 DOM 中的事件对象 type：获取事件类型 target：事件目标 stopPropagation() 阻止事件冒泡 preventDefault() 阻止事件的默认行为 IE中的事件对象 type：获取事件类型 srcElement：事件目标 cancelBubble = true 阻止事件冒泡 returnValue = false 阻止事件的默认行为 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/Graceful-degradation_vs progressive-enhancement.html":{"url":"Interview/frontend/Graceful-degradation_vs progressive-enhancement.html","title":"Graceful-degradation_vs progressive-enhancement","keywords":"","body":"1. Graceful degradation versus Progressive enhancement (优雅降级和渐进增强)1.1. Graceful degradation(╮(╯﹏╰)╭)1.2. Progressive enhancement(✌️)1.3. Sum1.3.1. When to use what1. Graceful degradation versus Progressive enhancement (优雅降级和渐进增强) 都试图兼顾软件在不同环境下的运行状态。渐进增强是从一个基本的功能点出发，不断扩充新的特性功能，越好的浏览器得到越好的效果，是在向前看。优雅降级是一开始就想好一个相对较为完整的解决方案，当遇到老的浏览器时，可能效果和特性有所折损，是一种想回看的思维。现代开发渐进增强更有优势。 1.1. Graceful degradation(╮(╯﹏╰)╭) graceful degradation is the practice of building your web functionality so that it provides a certain level of user experience in more modern browsers, but it will also degrade gracefully to a lower level of user in experience in older browsers. This lower level is not as nice to use for your site visitors, but it does still provide them with the basic functionality that they came to your site to use; things do not break for them. Print this page Print a copy of your confirmation. Select the \"Print\" icon in your browser, or select \"Print\" from the \"File\" menu. 1.2. Progressive enhancement(✌️) Starting with a baseline of usable functionality, then increasing the richness of the user experience step by step by testing for support for enhancements before applying them. Progressive enhancement is similar, but it does things the other way round. You start by establishing a basic level of user experience that all browsers will be able to provide when rendering your web site, but you also build in more advanced functionality that will automatically be available to browsers that can use it. example: gmail, better browser has better experience. Thank you for your order. Please print this page for your records. (function(){ // true means javascript enabled if(document.getElementById){ var pt = document.getElementById('print'); if(pt && typeof window.print === 'function'){ var but = document.createElement('input'); but.setAttribute('type','button'); but.setAttribute('value','Print this now'); but.onclick = function(){ window.print(); }; pt.appendChild(but); } } })(); 1.3. Sum graceful degradation starts from the status quo 现状 of complexity and tries to fix for the lesser experience whereas progressive enhancement starts from a very basic, working example and allows for constant extension for future environments. Degrading gracefully means looking back whereas enhancing progressively means looking forward whilst keeping your feet on firm ground. It can be said that both progressive enhancement and graceful degradation try to do the same thing: keep our products useful to every user. Progressive enhancement is a more sophisticated and at the same time stable way of assuring that but it takes more time and effort. Graceful degradation can be used more easily as a patch for an already existing product; it means harder maintenance later on, but requires less initial work. 1.3.1. When to use what graceful degradation becomes viable in a few situations: You retrofit an old product and you don’t have the time, access or insight to change or replace it. You just don’t have time to finish a product with full progressive enhancement (often a sign of bad planning or running out of budget). The product you have is an edge case, for example very high traffic sites where every millisecond of performance means a difference of millions of dollars. Your product by definition is so dependent on scripting that it makes more sense to maintain a “basic” version rather than enhancing one (Maps, email clients, feed readers). In all other cases, progressive enhancement will make both the end users and you happier: Regardless of environment and ability you deliver a product that works. When a new browser comes out or a browser extension becomes widely adopted you can enhance to yet another level without having to touch the original solution — graceful degradation would require you to alter the original solution. You allow technology to be what it is supposed to be — an aid to reach a goal faster than without it, not a “must” to be able to reach a goal in the first place. If you need to add new features, you can do so after checking if they are supported at a certain stage, or you can add it to the most basic level of functionality and make it better in more sophisticated environments. In any case, the maintenance happens at the same spot and not in two different places. Keeping a progressively enhanced product up-to-date is much less work than maintaining two versions. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/grunt_vs_gulp.html":{"url":"Interview/frontend/grunt_vs_gulp.html","title":"grunt_vs_gulp","keywords":"","body":"1. Grunt vs gulp1.1. Gulp1.2. Grunt1. Grunt vs gulp 1.1. Gulp Gulp 优势： 代码优于配置策略，写代码控制而不是像 grunt 传入大 json 配置 高效：核心设计基于Unix流的概念。通过利用Node.js强大的流，通过管道连接，不需要往磁盘写中间文件，可以更快地完成构建。 插件纯粹：Gulp 的每个插件只完成一个功能，这也是Unix的设计原则之一，各个功能通过流进行整合并完成复杂的任务。 Gulp 的核心 API 只有5个 var gulp = require('gulp'); var jshint = require('gulp-jshint'); var concat = require('gulp-concat'); var rename = require('gulp-rename'); var uglify = require('gulp-uglify'); // Lint JS gulp.task('lint', function() { return gulp.src('src/*.js') .pipe(jshint()) .pipe(jshint.reporter('default')); }); // Concat & Minify JS gulp.task('minify', function(){ return gulp.src('src/*.js') .pipe(concat('all.js')) .pipe(gulp.dest('dist')) .pipe(rename('all.min.js')) .pipe(uglify()) .pipe(gulp.dest('dist')); }); // Watch Our Files gulp.task('watch', function() { gulp.watch('src/*.js', ['lint', 'minify']); }); // Default gulp.task('default', ['lint', 'minify', 'watch']); 1.2. Grunt // core grunt.initConfig({huge json}) // Load Our Plugins grunt.loadNpmTasks('grunt-contrib-watch'); // Register Default Task grunt.registerTask('default', ['jshint', 'concat', 'uglify']); // Invoke 'strict' JavaScript mode 'use strict'; // Define the Grunt configuration method module.exports = function(grunt) { // Initialize Grunt configuration grunt.initConfig({ // Configure the grunt-env task env: { test: { NODE_ENV: 'test' }, dev: { NODE_ENV: 'development' } }, // Configure the grunt-nodemon task nodemon: { dev: { script: 'server.js', options: { ext: 'js,html', watch: ['server.js', 'config/**/*.js', 'app/**/*.js'] } }, debug: { script: 'server.js', options: { nodeArgs: ['--debug'], ext: 'js,html', watch: ['server.js', 'config/**/*.js', 'app/**/*.js'] } } }, // Configure the grunt-mocha-test task mochaTest: { src: 'app/tests/**/*.js', options: { reporter: 'spec' } }, // Configure the grunt-karma task karma: { unit: { configFile: 'karma.conf.js' } }, // Configure the grunt-protractor-runner task protractor: { e2e: { options: { configFile: 'protractor.conf.js' } } }, // Configure the grunt-contrib-jshint task jshint: { all: { src: ['server.js', 'config/**/*.js', 'app/**/*.js', 'public/js/*.js', 'public/modules/**/*.js'], options: { node: true, predef: [ \"define\", \"require\", \"exports\", \"module\", \"describe\", \"before\", \"beforeEach\", \"after\", \"afterEach\", \"it\", \"inject\", \"expect\" ] } } }, // Configure the grunt-contrib-csslint task csslint: { all: { src: 'public/modules/**/*.css' } }, // Configure the grunt-contrib-watch task watch: { js: { files: ['server.js', 'config/**/*.js', 'app/**/*.js', 'public/js/*.js', 'public/modules/**/*.js'], tasks: ['jshint'] }, css: { files: 'public/modules/**/*.css', tasks: ['csslint'] } }, // Configure the grunt-concurrent task concurrent: { dev: { tasks: ['nodemon', 'watch'], options: { logConcurrentOutput: true } }, debug: { tasks: ['nodemon:debug', 'watch', 'node-inspector'], options: { logConcurrentOutput: true } } }, // Configure the grunt-node-inspector task 'node-inspector': { debug: {} } }); // Load the external Grunt tasks grunt.loadNpmTasks('grunt-env'); grunt.loadNpmTasks('grunt-nodemon'); grunt.loadNpmTasks('grunt-mocha-test'); grunt.loadNpmTasks('grunt-karma'); grunt.loadNpmTasks('grunt-protractor-runner'); grunt.loadNpmTasks('grunt-contrib-jshint'); grunt.loadNpmTasks('grunt-contrib-csslint'); grunt.loadNpmTasks('grunt-contrib-watch'); grunt.loadNpmTasks('grunt-concurrent'); grunt.loadNpmTasks('grunt-node-inspector'); // Create the 'default' Grunt task grunt.registerTask('default', ['env:dev', 'lint', 'concurrent:dev']); // Create the 'debug' Grunt task grunt.registerTask('debug', ['env:dev', 'lint', 'concurrent:debug']); // Create the 'test' Grunt task grunt.registerTask('test', ['env:test', 'mochaTest', 'karma', 'protractor']); // Create the 'lint' Grunt task grunt.registerTask('lint', ['jshint', 'csslint']); }; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/interview_react.html":{"url":"Interview/frontend/interview_react.html","title":"interview_react","keywords":"","body":"What happens when you call setState The first thing React will do when setState is called is merge the object you passed into setState into the current state of the component. This will kick off a process called reconciliation. The end goal of reconciliation is to, in the most efficient way possible, update the UI based on this new state. To do this, React will construct a new tree of React elements (which you can think of as an object representation of your UI). Once it has this tree, in order to figure out how the UI should change in response to the new state, React will diff this new tree against the previous element tree. By doing this, React will then know the exact changes which occurred, and by knowing exactly what changes occurred, will able to minimize its footprint on the UI by only making updates where absolutely necessary. What’s the difference between an Element and a Component in React Simply put, a React element describes what you want to see on the screen. Not so simply put, a React element is an object representation of some UI. A React component is a function or a class which optionally accepts input and returns a React element (typically via JSX which gets transpiled to a createElement invocation). For more info, check out React Elements vs React Components When would you use a Class Component over a Functional Component If your component has state or a lifecycle method(s), use a Class component. Otherwise, use a Functional component. What are ref in React and why are they important ref are an escape hatch which allow you to get direct access to a DOM element or an instance of a component. In order to use them you add a ref attribute to your component whose value is a callback function which will receive the underlying DOM element or the mounted instance of the component as its first argument. class UnControlledForm extends Component { handleSubmit = () => { console.log(\"Input Value: \", this.input.value) } render () { return ( this.input = input} /> Submit ) } } Above notice that our input field has a ref attribute whose value is a function. That function receives the actual DOM element of input which we then put on the instance in order to have access to it inside of the handleSubmit function. It’s often misconstrued that you need to use a class component in order to use ref, but ref can also be used with functional components by leveraging closures in JavaScript. function CustomForm ({handleSubmit}) { let inputElement return ( handleSubmit(inputElement.value)}> inputElement = input} /> Submit ) } What are keys in React and why are they important Keys are what help React keep track of what items have changed, been added, or been removed from a list. render () { return ( {this.state.todoItems.map(({task, uid}) => { return {task} })} ) } It’s important that each key be unique among siblings. We’ve talked a few times already about reconciliation and part of this reconciliation process is performing a diff of a new element tree with the most previous one. Keys make this process more efficient when dealing with lists because React can use the key on a child element to quickly know if an element is new or if it was just moved when comparing trees. And not only do keys make this process more efficient. But without keys, React can’t know which local state corresponds to which item on move. So never neglect keys when mapping. If you created a React element like Twitter below, what would the component definition of Twitter look like {(user) => user === null ? : } import React, { Component, PropTypes } from 'react' import fetchUser from 'twitter' // fetchUser take in a username returns a promise which will resolve with that username's data. class Twitter extends Component { // finish this } Take notice of what’s inside the opening and closing tags above. Instead of another component as you’ve probably seen before, the Twitter component’s child is a function. What this means is that in the implementation of the Twitter component, we’ll need to treat props.children as a function. import React, { Component, PropTypes } from 'react' import fetchUser from 'twitter' class Twitter extends Component { state = { user: null, } static propTypes = { username: PropTypes.string.isRequired, } componentDidMount () { fetchUser(this.props.username) .then((user) => this.setState({user})) } render () { return this.props.children(this.state.user) } } Notice that, just as I mentioned above, I treat props.children as a function by invoking it and passing it the user. What’s great about this pattern is that we’ve decoupled our parent component from our child component. The parent component manages the state and the consumer of the parent component can decide in which way they’d like to apply the arguments they receive from the parent to their UI. To demonstrate this, let’s say in another file we want to render a Profile instead of a Badge, because we’re using the render callback pattern, we can easily swap around the UI without changing our implementation of the parent (Twitter) component. {(user) => user === null ? : } What is the difference between a controlled component and an uncontrolled component A large part of React is this idea of having components control and manage their own state. What happens when we throw native HTML form elements (input, select, textarea, etc) into the mix? Should we have React be the “single source of truth” like we’re used to doing with React? Or should we allow that form data to live in the DOM like we’re used to typically doing with HTML form elements? These questions are at the heart of controlled vs uncontrolled components. A controlled component is a component where React is in control and is the single source of truth for the form data. As you can see below, username doesn’t live in the DOM but instead lives in our component state. Whenever we want to update username, we call setState as we’re used to. class ControlledForm extends Component { state = { username: '' } updateUsername = (e) => { this.setState({ username: e.target.value, }) } handleSubmit = () => {} render () { return ( Submit ) } } An uncontrolled component is where your form data is handled by the DOM, instead of inside your React component. You use ref to accomplish this. class UnControlledForm extends Component { handleSubmit = () => { console.log(\"Input Value: \", this.input.value) } render () { return ( this.input = input} /> Submit ) } } Though uncontrolled components are typically easier to implement since you just grab the value from the DOM using ref, it’s typically recommended that you favor controlled components over uncontrolled components. The main reasons for this are that controlled components support instant field validation, allow you to conditionally disable/enable buttons, enforce input formats, and are more “the React way”. When using uncontrolled components 点击 button 后让鼠标 focus 到某个文本框，这种事件需要原生 API 控制，无法通过 state 去控制的。 In which lifecycle event do you make AJAX requests and why AJAX requests should go in the componentDidMount lifecycle event. There are a few reasons for this, Fiber, the next implementation of React’s reconciliation algorithm, will have the ability to start and stop rendering as needed for performance benefits. One of the trade-offs of this is that componentWillMount, the other lifecycle event where it might make sense to make an AJAX request, will be “non-deterministic”. What this means is that React may start calling componentWillMount at various times whenever it feels like it needs to. This would obviously be a bad formula for AJAX requests. You can’t guarantee the AJAX request won’t resolve before the component mounts. If it did, that would mean that you’d be trying to setState on an unmounted component, which not only won’t work, but React will yell at you for. Doing AJAX in componentDidMount will guarantee that there’s a component to update. What does shouldComponentUpdate do and why is it important Above we talked about reconciliation and what React does when setState is called. What shouldComponentUpdate does is it’s a lifecycle method that allows us to opt out of this reconciliation process for certain components (and their child components). Why would we ever want to do this? As mentioned above, “The end goal of reconciliation is to, in the most efficient way possible, update the UI based on new state.” If we know that a certain section of our UI isn’t going to change, there’s no reason to have React go through the trouble of trying to figure out if it should. By returning false from shouldComponentUpdate, React will assume that the current component, and all its child components, will stay the same as they currently are. How do you tell React to build in Production mode and what will that do Typically you’d use Webpack's DefinePlugin method to set NODE_ENV to production. This will strip out things like propType validation and extra warnings. On top of that, it’s also a good idea to minify your code because React uses Uglify's dead-code elimination to strip out development only code and comments, which will drastically reduce the size of your bundle. Why would you use React.Children.map(props.children, () => ) instead of props.children.map(() => ) It’s not guaranteed that props.children will be an array. Take this code for example: Welcome. Inside of Parent if we were to try to map over children using props.children.map it would throw an error because props.children is an object, not an array. React only makes props.children an array if there are more than one child elements, like this: Welcome. props.children will now be an array This is why you want to favor React.Children.map because its implementation takes into account that props.children may be an array or an object. Describe how events are handled in React. 事件在React中的处理方式 In order to solve cross browser compatibility issues, your event handlers in React will be passed instances of SyntheticEvent, which is React’s cross-browser wrapper around the browser’s native event. These synthetic events have the same interface as native events you’re used to, except they work identically across all browsers. What’s mildly interesting is that React doesn’t actually attach events to the child nodes themselves. React will listen to all events at the top level using a single event listener. This is good for performance and it also means that React doesn’t need to worry about keeping track of event listeners when updating the DOM. 在 React 底层，主要对合成事件做了两件事：事件委托和自动绑定。 事件委托：React的事件代理机制不会把事件处理函数直接绑定到真实的结点上，而是把所有事件绑定到结构的最外层，使用统一的事件监听器，这个事件监听器上维持了一个映射来保存所有组件内部的事件监听和处理函数。当事件发生时，首先被这个统一的事件监听器处理，然后在映射里找到真正的事件处理函数并调用。 自动绑定：在 React 组件中，每个方法的上下文都会指向该组件的实例，即自动绑定 this 为当前组件。在使用ES6 classes和纯函数时，这种自动绑定就不存在了，需要我们手动绑定this：bind方法、双冒号语法、构造器内声明、箭头函数。 What is the difference between createElement and cloneElement createElement is what JSX gets transpiled to and is what React uses to create React Elements (object representations of some UI). cloneElement is used in order to clone an element and pass it new props. They nailed the naming on these two &#x1F642;. What is the second argument that can optionally be passed to setState and what is its purpose A callback function which will be invoked when setState has finished and the component is re-rendered. setState is asynchronous, which is why it takes in a second callback function. Typically it’s best to use another lifecycle method rather than relying on this callback function, but it’s good to know it exists. this.setState( { username: 'tylermcginnis33' }, () => console.log('setState has finished and the component has re-rendered.') ) What is wrong with this code this.setState((prevState, props) => { return { streak: prevState.streak + props.count } }) Nothing is wrong with it &#x1F642;. It’s rarely used and not well known, but you can also pass a function to setState that receives the previous state and props and returns a new state, just as we’re doing above. And not only is nothing wrong with it, but it’s also actively recommended if you’re setting state based on previous state. React解决了什么问题？ a. React 实现了Virtual DOM 在一定程度上提升了性能，尤其是在进行小量数据更新时。因为 DOM 操作是很耗性能的，而Virtual DOM 是在内存中进行操作的，当数据发生变化时，通过 diff 算法 比较两棵树之间的变化，再进行必要的 DOM 更新，省去了不必要的高消耗的 DOM 操作。当然，这种性能优化主要体现在有小量数据更新的情况下。因为 React的基本思维模式是每次有变动就重新渲染整个应用，简单想来就是直接重置 innerHTML，比如说在一个大型列表所有数据都变动的情况下，重置 innerHTML 还比较合理，但若是只有一行数据变了，它也需要重置整个 innerHTML，就会造成大量的浪费。而 Virtual DOM 虽然进行了 JS 层面的计算，但是比起DOM操作来说，简直不要太便宜。 为什么操作真实 DOM 比 React 更快？ b. React的一个核心思想是声明式编程。 命令式编程是解决做什么的问题，就像是下命令一样，关注于怎么做，而声明式编程关注于得到什么结果，在React中，我们只需要关注“目前的状态是什么”，而不是“我需要做什么让页面变成目前的状态”。React就是不断声明，然后在特定的参数下渲染UI界面。这种编程方式可以让我们的代码更容易被理解，从而易于维护。 c. 组件化 React 天生组件化，我们可以将一个大的应用分割成很多小组件，这样有好几个优势。首先组件化的代码像一棵树一样清楚干净，比起传统的面条式代码可读性更高；其次前端人员在开发过程中可以并行开发组件而不影响，大大提高了开发效率；最重要的是，组件化使得复用性大大提高，团队可以沉淀一些公共组件或工具库。 d. 单向数据流 在 React 中数据流是单向的，由父节点流向子节点，如果父节点的 props 发生了变化，那么React 会递归遍历整个组件树，重新渲染所有使用该属性的子组件。这种单向的数据流一方面比较清晰不容易混乱，另一方面是比较好维护，出了问题也比较好定位。 如何设计一个好组件 组件的主要目的是为了更好的复用，所以在设计组件的时候需要遵循高内聚低耦合的原则。 可以通过遵循几种设计模式原则来达到高复用的目的，比如单一职责原则：React 推崇的是“组合”而非“继承”，所以在设计时尽量不设计大的组件，而是开发若干个单一功能的组件，重点就是每个组件只做一件事；开放/封闭原则，就是常说的对修改封闭，对扩展开放。在React中我们可以用高阶组件来实现。 使用高阶组件来实现组件的复用。高阶组件就是一个包装了另一个 React 组件的 React 组件，它包括属性代理（高阶组件操控着传递给被包裹组件的属性）和反向继承（实际上高阶组件继承被包裹组件）。我们可以用高阶组件实现代码复用，逻辑抽象。 使用容器组件来处理逻辑，展示组件来展示数据（也就是逻辑处理与数据展示分离）。比如可以在容器组件中进行数据的请求与处理，然后将处理后的数据传递给展示组件，展示组件只负责展示，这样容器组件和展示组件就可以更好地复用了。 编写组件代码时要符合规范，总之就是要可读性强、复用性高、可维护性好。 组件的render函数何时被调用 组件 state 发生改变时会调用 render 函数，比如通过 setState 函数改变组件自身的 state 值 继承的 props 属性发生改变时也会调用 render 函数，即使改变的前后值一样 React 生命周期中有个 componentShouldUpdate 函数，默认返回 true，即允许 render 被调用，我们也可以重写这个函数，判断是否应该调用 render 函数 调用 render 时 DOM 就一定会被更新吗 不一定更新。 React 组件中存在两类 DOM，render 函数被调用后， React 会根据 props 或者 state 重新创建一棵 virtual DOM 树，虽然每一次调用都重新创建，但因为创建是发生在内存中，所以很快不影响性能。而 virtual dom 的更新并不意味着真实 DOM 的更新，React 采用 diff算法 将 virtual DOM 和真实 DOM 进行比较，找出需要更新的最小的部分，这时 Real DOM 才可能发生修改。 所以每次 state 的更改都会使得 render 函数被调用，但是页面DOM不一定发生修改。 组件的生命周期 组件生命周期有三种阶段：初始化阶段（Mounting）、更新阶段（Updating）、析构阶段（Unmouting）。 初始化阶段： constructor()：初始化 state、绑定事件 componentWillMount()：在 render() 之前执行，除了同构，跟 constructor 没啥差别 render()：用于渲染 DOM。如果有操作 DOM 或和浏览器打交道的操作，最好在下一个步骤执行。 componentDidMount()：在 render() 之后立即执行，可以在这个函数中对 DOM 就进行操作，可以加载服务器数据，可以使用 setState() 方法触发重新渲染 组件更新阶段： componentWillReceiveProps(nextProps)：在已挂载的组件接收到新 props 时触发，传进来的 props 没有变化也可能触发该函数，若需要实现 props 变化才执行操作的话需要自己手动判断 componentShouldUpdate(nextProps，nextState)：默认返回 true，我们可以手动判断需不需要触发 render，若返回 false，就不触发下一步骤 componentWillUpdate()：componentShouldUpdate 返回 true 时触发，在 render之前，可以在里面进行操作 DOM render()：重渲染 componentDidUpdate()：render 之后立即触发 组件卸载阶段： componentWillUnmount()：在组件销毁之前触发，可以处理一些清理操作，如无效的timers 等 在哪些生命周期中可以修改组件的state componentDidMount 和 componentDidUpdate constructor、componentWillMount 中 setState 会发生错误：setState 只能在mounted 或 mounting 组件中执行 componentWillUpdate 中 setState 会导致死循环 不同父节点的组件需要对彼此的状态进行改变时应该怎么实现 lifting state to parent of A and B 用 Flux/Redux 管理状态 如何对组件进行优化 使用上线构建（Production Build）：会移除脚本中不必要的报错和警告，减少文件体积 避免重绘：重写shouldComponentUpdate函数，手动控制是否应该调用render函数进行重绘 尽可能使用Immutable Data不修改数据，而是重新赋值数据。这样在检测数据对象是否发生修改方面会非常快，因为只需要检测对象引用即可，不需要挨个检测对象属性的更改 在渲染组件时尽可能添加key，这样virtual DOM在对比的时候就更容易知道哪里是修改元素，哪里是新插入的元素 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/interview_闭包.html":{"url":"Interview/frontend/interview_闭包.html","title":"interview_闭包","keywords":"","body":"1. 闭包是什么？closure1.1. 闭包有三个特性：1.2. 闭包有什么用，使用场景1.3. 闭包的缺点1.4. 函数套函数就是闭包吗？1. 闭包是什么？closure 内层函数可以访问外层函数的变量。外层函数的局部变量得到暂存。 专业说法：当一个内部函数被其外部函数之外的变量引用时，就形成了一个闭包。 闭包就是一个具有封闭功能与包裹功能的结构，是为了实现具有私有访问空间的函数的，函数可以构成闭包，因为函数内部定义的数据函数外部无法访问，即函数具有封闭性；函数可以封装代码即具有包裹性，所以函数可以构成闭包。 1.1. 闭包有三个特性： 函数嵌套函数 函数内部可以引用外部的参数和变量 参数和变量不会被垃圾回收机制回收 1.2. 闭包有什么用，使用场景 当我们需要在模块中定义一些变量，并希望这些变量一直保存在内存中但又不会“污染”全局的变量时，就可以用闭包来定义这个模块。 1.3. 闭包的缺点 闭包的缺点就是常驻内存，会增大内存使用量，使用不当很容易造成内存泄露。 1.4. 函数套函数就是闭包吗？ 不是！当一个内部函数被其外部函数之外的变量引用时，才会形成了一个闭包。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/Javascript异步编程.html":{"url":"Interview/frontend/Javascript异步编程.html","title":"Javascript异步编程","keywords":"","body":"1. javascript 异步编程1.1. 回调函数1.2. Promise1.3. await/async1.4. event1.4.1. event + promise + await/async1.4.2. rxjs1. javascript 异步编程 1.1. 回调函数 var result = function() { setTimeout(() => { return 5; }, 1000); }; console.log(result()); // undefined 用回调函数处理怎么弄呢？让 result 的参数为一个回调函数就可以了，于是代码变成下面这样 var result = function(callback) { setTimeout(() => { callback(5); }, 1000); }; result(console.log); 现在我们用一个真实的io调用替代抢红包，新建一个numbers.txt，在里面写若干个红包金额,代码如下： const fs = require('fs'); const readFileAsArray = function(file, cb) { fs.readFile(file, (err, data) => { if (err) return cb(err); const lines = data.toString().trim().split('\\n'); cb(null, lines); }); }; readFileAsArray('./numbers.txt', (err, lines) => { if (err) throw err; const numbers = lines.map(Number); console.log(`分别抢到了${numbers}块红包`); }); 定义了一个readFileAsArray函数，传两个参：文件名和回调函数，然后调用这个函数，把回调函数写入第二个参数里，就可以控制代码执行顺序了。不过，回调的缺点就是写多了，层层嵌套，又会造成回调地狱的坑爹情况，代码变得难以维护和阅读。 1.2. Promise Promise实现了控制反转。原来这个顺序的控制是在代码那边而不是程序员控制，现在有了Promise，控制权就由人来掌握了，通过一系列 Promise 的方法如 then/catch/all/race 等控制异步流程。Promise文档 const fs = require('fs'); const readFileAsArray = function(file) { return new Promise((resolve, reject) => { fs.readFile(file, (err, data) => { if (err) { reject(err); } const lines = data.toString().split('\\n'); resolve(lines); }); }); }; readFileAsArray('./numbers.txt') .then((lines) => { const numbers = lines.map(Number); console.log(`分别抢到了${numbers}块红包`); }) .catch((error) => console.error(error)); 在这里已经把控制权交给了程序员，代码也变得更好理解。虽然 Promise 有 单值/不可取消 等缺点，不过在现在大部分的情况下实现异步还是够用的。 1.3. await/async 有没有简化的办法呢？ES7推出了一个语法糖：await/async，它的内部封装了 Promise 和 Generator 的组合使用方式 const fs = require('fs'); const readFileAsArray = function(file) { return new Promise((resolve, reject) => { fs.readFile(file, (err, data) => { if (err) { reject(err); } const lines = data.toString().split('\\n'); resolve(lines); }); }); }; async function result() { try { const lines = await readFileAsArray('./numbers.txt'); const numbers = lines.map(Number); console.log(`分别抢到了${numbers}块红包`); } catch (err) { console.log('await出错！'); console.log(err); } } result(); 这样做的结果是不是让代码可读性更高了！而且也屏蔽了 Promise 和 Generator 的细节。 1.4. event 另一个实现异步的方式是event，回调(promise、await/async)和 event 的关系就像计划经济和市场经济一样，一个是人为的强制性的控制，一个是根据需求和供给这只看不见的手控制。 const EventEmitter = require('events'); const fs = require('fs'); class MyEventEmitter extends EventEmitter { executeAsync(asyncFunc, args) { this.emit('开始'); console.time('执行耗时'); asyncFunc(args, (err, data) => { if (err) return this.emit('error', err); this.emit('data', data); console.timeEnd('执行耗时'); this.emit('结束'); }); } } const myEventEmitter = new MyEventEmitter(); myEventEmitter.on('开始', () => { console.log('开始执行了'); }); myEventEmitter.on('data', (data) => { console.log(`分别抢到了${data}块红包`); }); myEventEmitter.on('结束', () => { console.log('结束执行了'); }); myEventEmitter.on('error', (err) => { console.error(err); }); myEventEmitter.executeAsync(fs.readFile, './numbers.txt'); 这种事件驱动非常灵活，也不刻意去控制代码的顺序，一旦有事件的供给(emit)，它就会立刻消费事件(on)，不过正是因为这样，它的缺点也很明显：让程序的执行流程很不清晰。 1.4.1. event + promise + await/async 结合 event 和 promise 的写法: const EventEmitter = require('events'); const fs = require('fs'); class MyEventEmitter extends EventEmitter { async executeAsync(asyncFunc, args) { this.emit('开始'); try { console.time('执行耗时'); const data = await asyncFunc(args); this.emit('data', data); console.timeEnd('执行耗时'); this.emit('结束'); } catch (err) { console.log('出错了!'); this.emit('error', err); } } } const readFileAsArray = function(file) { return new Promise((resolve, reject) => { fs.readFile(file, (err, data) => { if (err) { reject(err); } const lines = data.toString().split('\\r\\n'); resolve(lines); }); }); }; const myEventEmitter = new MyEventEmitter(); myEventEmitter.on('开始', () => { console.log('开始执行了'); }); myEventEmitter.on('data', (data) => { console.log(`分别抢到了${data}块红包`); }); myEventEmitter.on('结束', () => { console.log('结束执行了'); }); myEventEmitter.on('error', (err) => { console.error(err); }); myEventEmitter.executeAsync(readFileAsArray, './numbers.txt'); 这种结合的方式基本上可以应付现今的异步场景了，缺点嘛。。。就是代码量比较多 1.4.2. rxjs 简单介绍下 rxjs 和异步的关系：它可以把数据转化成一股流，无论这个数据是同步得到的还是异步得到的，是单值还是多值。 Rx.Observable.of 来包装单值同步数据 Rx.Observable.fromPromise 来包装单值异步数据 Rx.Observable.fromEvent 来包装多值异步数据 const fs = require('fs'); const Rx = require('rxjs'); const EventEmitter = require('events'); class MyEventEmitter extends EventEmitter { async executeAsync(asyncFunc, args) { this.emit('开始'); try { console.time('执行耗时'); const data = await asyncFunc(args); this.emit('data', data); console.timeEnd('执行耗时'); this.emit('结束'); } catch (err) { console.log('出错了!'); this.emit('error', err); } } } const readFileAsArray = function(file) { return new Promise((resolve, reject) => { fs.readFile(file, (err, data) => { if (err) { reject(err); } const lines = data.toString().split('\\r\\n'); resolve(lines); }); }); }; const myEventEmitter = new MyEventEmitter(); myEventEmitter.executeAsync(readFileAsArray, './numbers.txt'); let dataObservable = Rx.Observable.fromEvent(myEventEmitter, 'data'); let subscription = dataObservable.subscribe( (data) => { console.log(`分别抢到了${data}块红包`); }, (err) => { console.error(err); }, (complete) => { console.info('complete!'); } ); rxjs还有很多重要的概念，比如生产者 Observe 和消费者 Observable、推拉模型、各种方便的操作符和函数式编程等等 Object.observe() This feature is obsolete Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/Javascript运行机制.html":{"url":"Interview/frontend/Javascript运行机制.html","title":"Javascript运行机制","keywords":"","body":"1. 单线程1.1. 任务队列1.2. 理解 event loop1.3. 哪些语句被会在异步队列1.4. 理解放入到异步队列的时机1.5. 例子1. 单线程 一个时间只能做一件事 1.1. 任务队列 异步队列，运行栈里面放的是同步任务队列。 1.2. 理解 event loop js 运行分为同步任务和异步任务，同步任务先执行，都执行完了才会执行异步任务。以下前2个例子就是先执行同步任务 console, while ，之后才执行 setTimeout 。 js 引擎把所有同步任务放到运行栈中，异步任务不会放在运行栈中，而是放到 event table。浏览器 timer模块 拿走 setTimeout，到了时间后（下面例子1s时）从 event table 把任务放到 异步队列 event queue 中（注意：不是遇到 setTimeout 就把异步任务放到异步队列中，即使 setTimeout 时间设置0，浏览器一般默认给 4ms。setTimeout 的时间就是 event table 把任务放到 event loop 的时间）。单线程的 js 执行完所有运行栈中的同步任务后，异步队列中的任务被放到了运行栈中并执行。运行栈不断监听异步队列是否有任务需要执行，有的话就拿过来执行，这个循环过程就是事件循环 Event loop. So when exactly can functions in the event queue move over to the call stack? Well, the JavaScript engine follows a very simple rule: there’s a process that constantly checks whether the call stack is empty, and whenever it’s empty, it checks if the event queue has any functions waiting to be invoked. If it does, then the first function in the queue gets invoked and moved over into the call stack. If the event queue is empty, then this monitoring process just keeps on running indefinitely. And voila — what I just described is the infamous Event Loop! 1.3. 哪些语句被会在异步队列 开启异步任务： setTimeout, setInterval DOM 事件，addEventListener('click', function(){}, false) Promise 1.4. 理解放入到异步队列的时机 异步任务放入到异步队列的时机是 setTimeout 传入的时间，不是立马放入。即使时间传入0，默认 4ms。 1.5. 例子 console.log(1); setTimeout(function () { console.log(2); }, 0); console.log(3); console.log(4); // 结果为 1 3 4 2 console.log('A'); setTimeout(function () { console.log('B'); }, 0); while (1) { } // 结果为：A // B 永远不会输出。运行栈 while 没执行完毕，不会去查看异步队列。 for (var i = 0; i for 循环是同步任务，在运行栈执行4次。第一次执行时，发现调用 setTimeout，浏览器 js 引擎并没立马把它放到异步队列。当 for 同步任务全部执行完毕（1ms以内）后，过了一秒异步队列中有了 4个 setTimeout 里面的函数体。运行栈检测到异步队列中的4个函数体，一个个取到运行栈中依次执行，此时的 i = 4，所以最终结果4 4 4 4。（几乎是同时出现结果，而不是 1s 出现一个） 想要结果为 0 1 2 3 的办法： let 形成块级作用域 for 循环里面每个 li[i].index = i; 使用闭包 for (var i = 0; i Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/JIT_vs_AOT.html":{"url":"Interview/frontend/JIT_vs_AOT.html","title":"JIT_vs_AOT","keywords":"","body":"1. JIT vs AOT1. JIT vs AOT AOT：Ahead Of Time，指在运行前编译，比如普通的静态编译 JIT：Just In Time，指在运行时编译，边运行边编译，比如 java 虚拟机在运行时就用到 JIT 技术 由于 JIT 编译耗费运行时间，则对于某些优化点就无法做到百分百支持，必须在代码优化和执行卡顿之间做一个权衡，AOT 就没有这个问题，另外，AOT 可以做到编译后持久化到存储，而 JIT 一般是每运行一次就会搞一遍重复的编译。 JIT 在这里的优势就是，它能精准地得知运行时状态，而不是像 AOT 那样预测，成本更低，如果一个 AOT 优化的成本过高，则应该选择 JIT。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/JS对象_原型链.html":{"url":"Interview/frontend/JS对象_原型链.html","title":"JS对象_原型链","keywords":"","body":"1. 原型链和原型1.1. 创建对象方法1.1.1. Object.create 的原理1.2. 基本概念1.2.1. 原型1.2.2. 构造函数1.2.3. 实例1.2.4. 原型链1.2.5. instanceOf 原理1.2.6. new 原理1. 原型链和原型 new 构造函数 --> 实例对象 实例对象.__proto__ === 原型对象 == 构造函数.prototype 原型对象.constructor === 构造函数 1.1. 创建对象方法 对象字面量的方式、内置工厂 new Object let o1 = { name: 'hello' } // Object { name : 'hello' } let o11 = new Object({ name: 'hi' }) // Object { name: 'hi' } var wcDog = new Object(); wcDog.name = \"旺财\"; wcDog.age = 3; 用 function 来模拟无参的构造函数 function Person() {} var person = new Person(); //定义一个function，如果使用 new \"实例化\"，该 function 可以看作是一个 Class person.name = \"Mark\"; person.age = \"25\"; person.work = function() { alert(person.name + \" hello...\"); } person.work(); 用 function 来模拟参构造函数来实现（用 this 关键字定义构造的上下文属性。每个实例属性不同，方法一般不在这定义，应定义到原型中） function Pet(name, age, hobby) { this.name = name; //this作用域：当前对象 this.age = age; this.hobby = hobby; this.eat = function() { alert(\"我叫\" + this.name + \",我喜欢\" + this.hobby + \",是个程序员\"); } } var maidou = new Pet(\"麦兜\", 25, \"coding\"); //实例化、创建对象 maidou.eat(); //调用eat方法 用原型方式来创建(所有实例共有属性和方法) function Dog() {} Dog.prototype.name = \"旺财\"; Dog.prototype.eat = function() { alert(this.name + \"是个吃货\"); } var wangcai = new Dog(); wangcai.eat(); 用混合方式来创建 function Car(name, price) { this.name = name; this.price = price; } Car.prototype.sell = function() { alert(\"我是\" + this.name + \"，我现在卖\" + this.price + \"万元\"); } var camry = new Car(\"凯美瑞\", 27); camry.sell(); Object.create 传入原型对象 x，得到对象 y 是 x 原型链下一级（创建新空对象，继承自原型对象，这里继承 p） var p = {name: 'hello'} let o3 = Object.create(p) // Object { } o3.name === 'hello' // true, 其实是o3本身没有name，是通过原型链找到p,拿到了name。即o3.__proto__ === p 1.1.1. Object.create 的原理 Object.create = function(obj) { function F() {} F.prototype = obj; return new F(); // 返回 F 的原型对象是 obj }; 1.2. 基本概念 1.2.1. 原型 构造函数.prototype 就是原型对象。 1.2.2. 构造函数 F.prototype.constructor === F // true. F是构造函数，构造函数的prototype是原型对象，这里为Object{constructor: function, __proto__: Object}，原型对象中constructor指向了构造函数 1.2.3. 实例 o2.__proto__ === F.prototype // 实例的__proto__ 指向构造函数的prototype,即原型对象。 1.2.4. 原型链 实例通过 __proto__ 向上找到对应的原型对象，原型对象还可以通过 __proto__ 找到上一级原型对象，一直到 Object.prototype 顶端停止。原型链依靠的是 __proto__ 而不是 prototype 一些公用的方法不要放在构造函数中，因为那样实例化后每个实例都在内存中拷贝了一份。公共的方法和属性放在原型对象上。实例都可以通过原型链找到原型对象，原型对象上的方法被所有实例所共有。先找自己实例内部，没找到找最近一层原型对象，没找到的话一层一层向上查找。如果都没找到，原路返回告诉他没找到。如果中间找到了就不再向上查找 特点：JavaScript对象是通过引用来传递的，我们创建的每个新对象实体中并没有一份属于自己的原型副本。当我们修改原型时，与之相关的对象也会继承这一改变。当我们需要一个属性的时，Javascript引擎会先看当前对象中是否有这个属性，如果没有的话，就会通过 __proto__ 查找他的原型对象是否有这个属性，如此递推下去，一直检索到Object内建对象。 1.2.5. instanceOf 原理 简单说判断实例是不是由某个构造函数创建的。原理是判断 实例.__proto__ 和 构造函数.prototype (原型对象)是不是同一个引用。但注意，A 继承 B，a由A实例化创建，a instanceOf A,B,Object 都对，只要在原型链上级都算。这样的话就不能精确判断 a 到底是 A 还是 B 直接生成的。 这时候用 constructor 更加严谨 a.__proto__.constructor === A //true 原型的constructor 指向 构造函数 A a.__proto__.constructor === Object //false 1.2.6. new 原理 一个新空对象创建，继承自原型对象 (构造函数.prototype) 构造函数执行，执行时参数传入，上下文 this 指向新对象 看构造函数结果，如果返回对象，则前两步白忙活直接返回这个对象；如果不返回对象，则返回 step 1 中的新对象 // func 是构造函数 var newSimulate = function(func) { var o = Object.create(func.prototype); //step1 新对象继承自原型对象 var temp = func.call(o); //step2 构造函数执行，修改 this 指向 if (typeof temp === 'object') { //step3 判断构造函数返回结果 return temp; } else { return o; } }; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/JS对象_继承.html":{"url":"Interview/frontend/JS对象_继承.html","title":"JS对象_继承","keywords":"","body":"1. 面向对象继承1.1. 类的声明和实例化1.2. 继承和继承方式1.2.1. 1. 借助构造函数实现继承1.2.2. 2. 借助原型链实现继承1.2.3. 3. 组合方式1.2.4. 4. 组合继承的优化11.2.5. 5. 组合继承的优化2，完美方案1. 面向对象继承 1.1. 类的声明和实例化 /** * 类的声明 构造函数模拟类 */ var Animal = function () { this.name = 'Animal'; }; /** * es6中class的声明 */ class Animal2 { constructor() { this.name = 'Animal2'; } } /** * 实例化 */ console.log(new Animal(), new Animal2()); 1.2. 继承和继承方式 本质就是通过原型链。 1.2.1. 1. 借助构造函数实现继承 原理：实例化子类时，父类构造函数执行，传入this，指向了实例化的子类。父类属性挂在到子类中 缺点：只实现了部分继承。只能继承构造函数中的属性方法，父类原型上方法或属性不会被继承。say不存在 function Parent1() { this.name = 'parent1'; } Parent1.prototype.say = function () {}; function Child1() { Parent1.call(this); //父类构造函数执行，传入this，指向了实例化的子类。父类属性挂在到子类中。也可以apply this.type = 'child1'; } console.log(new Child1(), new Child1().say()); // 报错，没有 say 1.2.2. 2. 借助原型链实现继承 原理：子类原型对象 指向 父类的实例。我们已知 子类实例.__proto__ 就是子类的原型对象，即 构造函数.prototype (new Child2().__proto__ === Child2.prototype)。加上条件 Child2.prototype = new Parent2(); 后，new Child2().__proto__ === new Parent2()。所以子实例中的 __proto__ 通过原型链查找到了父类的属性方法 new Child2().__proto__.name 。 缺点：多个子类实例没有隔离。因为原型对象的属性大家公用。父类中增加了新的属性，那么所有实例都会同时改变，如果某个来自父类的属性值发生了变化，那么其他实例也都随着发生变化，因为所有实例的 __proto__ 都是同一个，所以相互之间会有影响。 function Parent2() { this.name = 'parent2'; this.play = [1, 2, 3]; } function Child2() { this.type = 'child2'; } Child2.prototype = new Parent2(); //子类原型对象 指向 父类的实例 var s1 = new Child2(); var s2 = new Child2(); s1.__proto__ === s2.__proto__ //true console.log(s1.play, s2.play); s1.play.push(4); console.log(s1.play, s2.play); //缺点：此时他俩引用一处，没有隔离。因为原型对象的属性大家公用 1.2.3. 3. 组合方式 优点：有方法1 和 2的优势 缺点： 只看s3，不考虑s4的情况下，父类构造函数执行了2次。new Parent3(), Parent3.call(this) Child3 constructor 指向错误到了 parent function Parent3() { this.name = 'parent3'; this.play = [1, 2, 3]; } function Child3() { Parent3.call(this); this.type = 'child3'; } Child3.prototype = new Parent3(); var s3 = new Child3(); var s4 = new Child3(); s3.play.push(4); console.log(s3.play, s4.play); 1.2.4. 4. 组合继承的优化1 原理：子类原型对象 = 父类原型对象，解决了2次执行构造函数的问题 缺点：还是子类的构造函数指向不对。 function Parent4() { this.name = 'parent4'; this.play = [1, 2, 3]; } function Child4() { Parent4.call(this); this.type = 'child4'; } Child4.prototype = Parent4.prototype; var s5 = new Child4(); var s6 = new Child4(); console.log(s5, s6); console.log(s5 instanceof Child4, s5 instanceof Parent4); //true,不知道到底谁直接创建的 console.log(s5.constructor); //Parent4！指向错误 1.2.5. 5. 组合继承的优化2，完美方案 原理：Object.create() 创建的对象指向 Parent 原型对象，所以 Child 和 Parent 通过创建的对象进行了关联。不像第四个方法 Parent 和 Child 指向同一个引用。导致 constructor 即使修正后，也只能都指向 Parent 或者都 Child，即给 Child.prototype.constructor 修正为 Child 构造函数后，Parent 的 constructor 也被修成 Child 构造函数了。 function Parent5() { this.name = 'parent5'; this.play = [1, 2, 3]; } function Child5() { Parent5.call(this); this.type = 'child5'; } var x = Object.create(Parent5.prototype); console.log(x.__proto__ === Parent5.prototype) //true,新对象的上级原型链是 Parent5 原型对象，继承了 Parent5 的一切 Child5.prototype = x //子类原型对象指向x，子实例通过 __proto__ 找到上一级 x。关系为 Child5 --> x --> Parent5 Child5.prototype.constructor = Child5 // 修正 var s7 = new Child5(); console.log(s7 instanceof Child5, s7 instanceof Parent5); //true true console.log(s7.constructor); //Child5 Object.create polyfill: function create(obj) { if (Object.create) { return Object.create(obj); } function F() {} F.prototype = obj; return new F(); // 返回 obj 的上层原型对象 } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/Object.defineProperty.html":{"url":"Interview/frontend/Object.defineProperty.html","title":"Object.defineProperty","keywords":"","body":"1. Object.defineProperty1.1. 传入参数1.2. descriptor1.2.1. descriptor 默认值1.2.2. configurable1.2.3. writable1.2.4. enumerable1.2.5. set 和 get1. Object.defineProperty vue.js 和 avalon.js 都是通过它实现双向绑定的。。而且 Object.observe 也被草案发起人撤回了。。所以 defineProperty 更有必要了解了 var guanghui = {}; Object.defineProperty(guanghui, 'age', { value: 12 }); console.log(guanghui.age); // 12 1.1. 传入参数 第一个参数:目标对象 第二个参数:需要定义的属性或方法的名字。 第三个参数:目标属性所拥有的特性。（descriptor） 1.2. descriptor value: 属性的值(不用多说了) writable: 如果为false，属性的值就不能被重写,只能为只读了 configurable: 总开关，一旦为false，就不能再设置他的（value，writable，configurable） enumerable: 是否能在 for...in 循环中遍历出来或在 Object.keys 中列举出来。 get:一会细说 set:一会细说 1.2.1. descriptor 默认值 var guanghui = {}; Object.defineProperty(guanghui, 'age', { value: 12 }); console.log(guanghui.age); // 12 我们只设置了 value，别的并没有设置，但是 第一次的时候可以简单的理解为（暂时这样理解）它会默认帮我们把 writable，configurable，enumerable 都设上值，而且值还都是false。。也就是说，上面代码和下面是等价的的（ 仅限于第一次设置的时候） var guanghui = {}; Object.defineProperty(guanghui, 'age', { value: 12, writable: false, enumerable: false, configurable: false }); console.log(guanghui.age); // 12 1.2.2. configurable 总开关，第一次设置 false 之后，，第二次什么设置也不行了，比如说 var a = {}; Object.defineProperty(a, 'b', { configurable: false }); Object.defineProperty(a, 'b', { configurable: true }); //error: Uncaught TypeError: Cannot redefine property: b 就会报错了。。注意上面讲的默认值。。。如果第一次不设置它会怎样。。会帮你设置为false。。所以。。第二次。再设置他会怎样？。。对喽，，会报错 1.2.3. writable 如果设置为 false，就变成只读了。。 var guanghui = {}; Object.defineProperty(guanghui, 'age', { value: 12 }); console.log(guanghui.age); // 12 console.log(guanghui.age); // 打印 12 guanghui.age = 25; // 没有错误抛出（在严格模式下会抛出，即使之前已经有相同的值） console.log(guanghui.age); // 打印 12， 赋值不起作用。 1.2.4. enumerable 属性特性 enumerable 定义了对象的属性是否可以在 for...in 循环和 Object.keys() 中被枚举。 var guanghui = {}; Object.defineProperty(guanghui, 'age', { value: 12, enumerable: true }); console.log(Object.keys(guanghui)); // 打印[ 'age' ] 改为false var guanghui = {}; Object.defineProperty(guanghui, 'age', { value: 12, enumerable: false }); console.log(Object.keys(guanghui)); // nothing 1.2.5. set 和 get 在 descriptor 中不能 同时设置访问器 (get 和 set) 和 writable 或 value，否则会错，就是说想用(get 和 set)，就不能用（writable 或 value中的任何一个） var a = {}; Object.defineProperty(a, 'b', { set: function(newValue) { console.log('你要赋值给我,我的新值是' + newValue); }, get: function() { console.log('你取我的值'); return 2; //注意这里，我硬编码返回2 } }); a.b = 1; // 你要赋值给我,我的新值是1 console.log(a.b); // 你取我的值 // 2 “b” 赋值 或者 取值的时候会分别触发 set 和 get 对应的函数 这就是实现 observe 的关键啊。。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/oop_delete_from_list.html":{"url":"Interview/frontend/oop_delete_from_list.html","title":"oop_delete_from_list","keywords":"","body":"1. 面向对象删除选中 li(阿里面试)1. 面向对象删除选中 li(阿里面试) 阿里2017校招编程题 .del { cursor: pointer; } 第一行 这是内容区，点击X删除当前行，X 第二行 这是内容区，点击X删除当前行，X 第三行 这是内容区，点击X删除当前行，X 第四行 这是内容区，点击X删除当前行，X 这是另一个List第一行 这是内容区，点击X删除当前行，X 这是另一个List第二行 这是内容区，点击X删除当前行，X 这是另一个List第三行 这是内容区，点击X删除当前行，X 这是另一个List第四行 这是内容区，点击X删除当前行，X class List { constructor(sel) { this.ulElements = Array.from(document.querySelectorAll(sel)); let self = this; this.ulElements.forEach(item => { item.addEventListener('click', function (e) { if (e.target.className.indexOf('del') > -1) { self.removeItem.call(self, e.target); } }); }); } removeItem(target) { let self = this; let findParent = function (node) { let parent = node.parentNode; let root = self.ulElements.find(item => item === parent); if (root) { // 当能从 ul 中找到时，删除 ul 下结点 li root.removeChild(node); } else { findParent(parent); } }; findParent(target); } } window.addEventListener('DOMContentLoaded', function () { new List('.list'); }); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/React_Angular_Vue.html":{"url":"Interview/frontend/React_Angular_Vue.html","title":"React_Angular_Vue","keywords":"","body":"1. 前端主流框架区别1.1. React1.2. Angular41.3. Vue.js1.3.1. React 和 Vue.js 有一些相似的特征1.4. Scalability1.5. size1. 前端主流框架区别 1.1. React Component-based MVC's V: small view library Virtual DOM: lightweight, representation of actual DOM in memory one way data flow manage state => UI updates automatically by React React is smart to update only necessary UI by comparing previous state and new state Presentational and Container Components 1.2. Angular4 MVVM: full framework with all the tooling Component-based too Typescript @Component has template or templateUrl, style or styleUrl. Styles work only in current component Data Validation Angular 拥有很多工具，也有大量复杂的语法 1.3. Vue.js Lightweight Like angular1 syntax 更加灵活的、（相对于 Angular）并不那么“专制”的解决方案。这允许你按照自己的想法来构建你的应用，而不是强制按照 Angular 规定的方式去做。它只是一个接口层，所以你可以将其作为页面的一个功能来使用，而非一个完整的 SPA。 1.3.1. React 和 Vue.js 有一些相似的特征 使用了虚拟 DOM 提供了响应式、可组件化的视图组件 关注核心库，像路由和全局状态管理则交由其他库来处理 Vue 双向数据绑定实现比 React 简单 1.4. Scalability Angular is easy to scale thanks to its design as well as a powerful CLI. React claims to be more testable and therefore scalable than Vue and I think that is partly true. Vue being just behind react, it is a good choice however it lacks a list of best scaling practices, resulting in a lot of spaghetti code. 1.5. size Vue is the smallest and contains a lot as well. Actually you might think it doesn’t matter, but say that to a cheap android 3g smartphone and I don’t think you will be so sure about it. react is bigger than Vue, but still smaller than angular. That’s all I’ve got to say. angular is way bigger, causing longer load times and performance issues on mobiles. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/view_位置.html":{"url":"Interview/frontend/view_位置.html","title":"view_位置","keywords":"","body":"1. offsetWidth/offsetHeight, clientWidth/clientHeight 与 scrollWidth/scrollHeight 的区别1. offsetWidth/offsetHeight, clientWidth/clientHeight 与 scrollWidth/scrollHeight 的区别 offsetWidth/offsetHeight 返回值包含 content + padding + border，效果与 e.getBoundingClientRect() 相同 clientWidth/clientHeight 返回值只包含 content + padding，如果有滚动条，也不包含滚动条 scrollWidth/scrollHeight 返回值包含 content + padding + 溢出内容的尺寸 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/webpack-hot-reloading_browserSync原理.html":{"url":"Interview/frontend/webpack-hot-reloading_browserSync原理.html","title":"webpack-hot-reloading_browserSync原理","keywords":"","body":"webpack 热插拔 hot reloading 原理 webpack-hot-middleware 中间件是 webpack 的一个 plugin，通常结合 webpack-dev-middleware 一起使用。借助它可以实现浏览器的无刷新更新（热更新），即 webpack 里的 HMR（Hot Module Replacement）。内部使用 Server-sent event(SSE)。 SSE 参看 Websocket_vs_polling.md browser-sync 原理 一个网页里的所有交互动作（包括滚动，输入，点击等等），可以实时地同步到其他所有打开该网页的设备，能够节省大量的手工操作时间，从而带来流畅的开发调试体验。目前 browser-sync 可以结合 Gulp 或 Grunt 一起使用，其 API 请参考：Browser-sync API。 EventSource 的使用是比较便捷的，那为什么 browser-sync 不使用 EventSource 技术进行代码推送呢？这是因为 browser-sync 插件共做了两件事： 开发更新了一段新的逻辑，服务器实时推送代码改动信息。数据流：服务器 —> 浏览器，使用 EventSource 技术同样能够实现。 用户操作网页，滚动、输入或点击等，操作信息实时发送给服务器，然后再由服务器将操作同步给其他已打开的网页。数据流：浏览器 —> 服务器 —> 浏览器，该部分功能 EventSource 技术已无能为力。 browser-sync 使用 WebSocket 技术达到实时推送代码改动和用户操作两个目的。至于它是如何计算推送内容，根据不同推送内容采取何种响应策略，不在本次讨论范围之内。 WebSocket 参看 Websocket_vs_polling.md Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/内存泄漏和垃圾回收.html":{"url":"Interview/frontend/内存泄漏和垃圾回收.html","title":"内存泄漏和垃圾回收","keywords":"","body":"1. JavaScript 内存泄漏教程1.1. 一、什么是内存泄漏？1.2. 二、垃圾回收机制1.3. 三、内存泄漏的识别方法1.3.1. 3.1 浏览器1.3.2. 3.2 命令行1.4. 四、WeakMap1.5. v8 引擎内存分配和垃圾回收1.5.1. 新生代1.5.2. 老生代1.5.3. 三种回收策略比较1.5.4. 垃圾回收引起的性能问题1. JavaScript 内存泄漏教程 http://www.ruanyifeng.com/blog/2017/04/memory-leak.html 1.1. 一、什么是内存泄漏？ 程序的运行需要内存。只要程序提出要求，操作系统或者运行时（runtime）就必须供给内存。 对于持续运行的服务进程（daemon），必须及时释放不再用到的内存。否则，内存占用越来越高，轻则影响系统性能，重则导致进程崩溃。 不再用到的内存，没有及时释放，就叫做内存泄漏（memory leak）。 有些语言（比如 C 语言）必须手动释放内存，程序员负责内存管理。 char * buffer; buffer = (char*) malloc(42); // Do something with buffer free(buffer); 上面是 C 语言代码，malloc方法用来申请内存，使用完毕之后，必须自己用free方法释放内存。 这很麻烦，所以大多数语言提供自动内存管理，减轻程序员的负担，这被称为\"垃圾回收机制\"（garbage collector）。 1.2. 二、垃圾回收机制 垃圾回收机制怎么知道，哪些内存不再需要呢？ 最常使用的方法叫做\"引用计数\"（reference counting）：语言引擎有一张\"引用表\"，保存了内存里面所有的资源（通常是各种值）的引用次数。如果一个值的引用次数是0，就表示这个值不再用到了，因此可以将这块内存释放。 上图中，左下角的两个值，没有任何引用，所以可以释放。 如果一个值不再需要了，引用数却不为0，垃圾回收机制无法释放这块内存，从而导致内存泄漏。 const arr = [1, 2, 3, 4]; console.log('hello world'); 上面代码中，数组[1, 2, 3, 4]是一个值，会占用内存。变量arr是仅有的对这个值的引用，因此引用次数为1。尽管后面的代码没有用到arr，它还是会持续占用内存。 如果增加一行代码，解除arr对[1, 2, 3, 4]引用，这块内存就可以被垃圾回收机制释放了。 let arr = [1, 2, 3, 4]; console.log('hello world'); arr = null; 上面代码中，arr重置为null，就解除了对[1, 2, 3, 4]的引用，引用次数变成了0，内存就可以释放出来了。 因此，并不是说有了垃圾回收机制，程序员就轻松了。你还是需要关注内存占用：那些很占空间的值，一旦不再用到，你必须检查是否还存在对它们的引用。如果是的话，就必须手动解除引用。 1.3. 三、内存泄漏的识别方法 怎样可以观察到内存泄漏呢？ 经验法则是，如果连续五次垃圾回收之后，内存占用一次比一次大，就有内存泄漏。这就要求实时查看内存占用。 1.3.1. 3.1 浏览器 Chrome 浏览器查看内存占用，按照以下步骤操作。 打开开发者工具，选择 Timeline 面板 在顶部的Capture字段里面勾选 Memory 点击左上角的录制按钮。 在页面上进行各种操作，模拟用户的使用情况。 一段时间后，点击对话框的 stop 按钮，面板上就会显示这段时间的内存占用情况。 如果内存占用基本平稳，接近水平，就说明不存在内存泄漏。 反之，就是内存泄漏了。 1.3.2. 3.2 命令行 命令行可以使用 Node 提供的process.memoryUsage方法。 console.log(process.memoryUsage()); // { rss: 27709440, // heapTotal: 5685248, // heapUsed: 3449392, // external: 8772 } process.memoryUsage返回一个对象，包含了 Node 进程的内存占用信息。该对象包含四个字段，单位是字节，含义如下。 rss（resident set size）：所有内存占用，包括指令区和堆栈。 heapTotal：\"堆\"占用的内存，包括用到的和没用到的。 heapUsed：用到的堆的部分。 external： V8 引擎内部的 C++ 对象占用的内存。 判断内存泄漏，以heapUsed字段为准。 1.4. 四、WeakMap 前面说过，及时清除引用非常重要。但是，你不可能记得那么多，有时候一疏忽就忘了，所以才有那么多内存泄漏。 最好能有一种方法，在新建引用的时候就声明，哪些引用必须手动清除，哪些引用可以忽略不计，当其他引用消失以后，垃圾回收机制就可以释放内存。这样就能大大减轻程序员的负担，你只要清除主要引用就可以了。 ES6 考虑到了这一点，推出了两种新的数据结构：WeakSet 和 WeakMap。它们对于值的引用都是不计入垃圾回收机制的，所以名字里面才会有一个\"Weak\"，表示这是弱引用。 下面以 WeakMap 为例，看看它是怎么解决内存泄漏的。 const wm = new WeakMap(); const element = document.getElementById('example'); wm.set(element, 'some information'); wm.get(element) // \"some information\" 上面代码中，先新建一个 WeakMap 实例。然后，将一个 DOM 节点作为键名存入该实例，并将一些附加信息作为键值，一起存放在 WeakMap 里面。这时，WeakMap 里面对 element 的引用就是弱引用，不会被计入垃圾回收机制。 也就是说，DOM 节点对象的引用计数是 1，而不是 2。这时，一旦消除对该节点的引用，它占用的内存就会被垃圾回收机制释放。WeakMap 保存的这个键值对，也会自动消失。 基本上，如果你要往对象上添加数据，又不想干扰垃圾回收机制，就可以使用 WeakMap。 只要外部的引用消失，WeakMap 内部的引用，就会自动被垃圾回收清除。由此可见，有了它的帮助，解决内存泄漏就会简单很多。 1.5. v8 引擎内存分配和垃圾回收 v8 将内存分为 新生代 和 老生代。 1.5.1. 新生代 大多数对象 存活时间短 空间小 分为2块内存：使用状态（from 空间）和 闲置状态（to 空间） 采用 Scavenge 算法 新对象创建时使用 from 空间，当 from 空间满了后，存活对象复制到了 to 空间；不存活的消灭，完成一次 from 到 to 空间的转化。再次垃圾回收时执行上述操作。 当存活对象经历过一次 Scavenge 回收后或者 to 空间内存占用比超过25%，对象晋升：新生代拷贝到老生代。 1.5.2. 老生代 存活时间长 老生代内存空间大，不能用 Scavenge 算法复制那么多空间里的对象 垃圾回收采用 Mark-Sweep 和 Mark-Compact Mark-Sweep: 遍历所有对象，标记活着的对象。清除阶段只清除没被标记的少数死活对象，效率高 但有一个缺点，就是对象清除后内存不连续，内存碎片。 Mark-Compact: 为了解决上述内存碎片。将活的对象在内存区域进行移动，清理掉边界外的内存。因为涉及到对象移动，所以效率很低，但好处就是保证了不会有碎片。 因为效率低，v8 不会在每次 Mark-Sweep 后就执行 Mark-Compact，而是当新生代对象晋升时发现碎片空间不够用后才进行 Mark-Compact。 1.5.3. 三种回收策略比较 回收策略 速度 空间、碎片 是否移动对象 Scavenge 速度快 双倍空间无碎片 不移动对象 Mark-Sweep 中速 有碎片 不移动对象 Mark-Compact 最慢 无碎片 移动对象 1.5.4. 垃圾回收引起的性能问题 垃圾回收的三种算法都会停止应用逻辑，待垃圾回收完成后再恢复执行应用逻辑，这个现象叫做全停顿！为了避免它： 限制内存大小：新生代64位系统 32M, 老生代64位 1400M 增量式垃圾回收：不要一口气回收，回收一会执行一会应用逻辑再回收。增量标记、延迟清除、增量式整理。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/前端开发知识点.html":{"url":"Interview/frontend/前端开发知识点.html","title":"前端开发知识点","keywords":"","body":"1. 前端开发知识点1.1. 前端面试1.2. 面试准备1.3. 问题1.3.1. \"attribute\" 和 \"property\" 的区别是什么？1.3.2. HTML5的离线储存怎么使用，工作原理1.3.3. What's the difference between feature detection, feature inference, and using the UA string?1.3.4. FOUC (Flash of Unstyled Content)1.3.5. How many resources will a browser download from a given domain at a time? Traditionally, why has it been better to serve site assets from multiple domains?1.3.6. Describe z-index and how stacking context is formed1.3.7. 页面可见性（Page Visibility API） 可以有哪些用途？1.3.8. 对象到字符串的转换步骤1.3.9. 函数内部 arguments 特性, 如何将它转换为数组1.3.10. 说几条写JavaScript的基本规范？1.4. Test1.4.1. 对Node的优点和缺点提出了自己的看法1. 前端开发知识点 https://github.com/markyun/My-blog/blob/master/Front-end-Developer-Questions/Questions-and-Answers/README.md HTML&CSS： 对Web标准的理解、浏览器内核差异、兼容性、hack、CSS基本功：布局、盒子模型、选择器优先级、 HTML5、CSS3、Flexbox JavaScript： 数据类型、运算、对象、Function、继承、闭包、作用域、原型链、事件、RegExp、JSON、Ajax、 DOM、BOM、内存泄漏、跨域、异步装载、模板引擎、前端MVC、路由、模块化、Canvas、ECMAScript 6、Nodejs 其他： 移动端、响应式、自动化构建、HTTP、离线存储、WEB安全、优化、重构、团队协作、可维护、易用性、SEO、UED、架构、职业生涯、快速学习能力 1.1. 前端面试 一面：页面布局、css盒模型、DOM事件、HTTP协议、面向对象、原型链、算法、安全、通信 二面：vue 源码、优缺点、原理、生命周期 三面：业务负责人，职业生涯特色业务，角色，推动了、改变了什么 终面：HR面试，沟通、性格、潜力 抽象设计能力、项目把控能力、经验。 1.2. 面试准备 职位描述 JD 分析 业务分析或实战模拟 技术栈准备 自我介绍 1.3. 问题 https://github.com/yu521088/fee-interview-questions 1.3.1. \"attribute\" 和 \"property\" 的区别是什么？ .property, getAttribute。大部分情况值一样，但 getAttribute('checked') == 'checked', ele.checked == true 1.3.2. HTML5的离线储存怎么使用，工作原理 在用户没有与因特网连接时，可以正常访问站点或应用，在用户与因特网连接时，更新用户机器上的缓存文件。 原理：HTML5 的离线存储是基于一个新建的 .appcache 文件的缓存机制(不是存储技术)，通过这个文件上的解析清单离线存储资源，这些资源就会像 cookie 一样被存储了下来。之后当网络在处于离线状态下时，浏览器会通过被离线存储的数据进行页面展示。 在线的情况下，浏览器发现 html 头部有 manifest 属性，它会请求manifest文件，如果是第一次访问app，那么浏览器就会根据 manifest 文件的内容下载相应的资源并且进行离线存储。如果已经访问过app并且资源已经离线存储了，那么浏览器就会使用离线的资源加载页面，然后浏览器会对比新的 manifest 文件与旧的 manifest 文件，如果文件没有发生改变，就不做任何操作，如果文件改变了，那么就会重新下载文件中的资源并进行离线存储。离线的情况下，浏览器就直接使用离线存储的资源。 如何使用 页面头部像下面一样加入一个manifest的属性: 在cache.manifest文件的编写离线存储的资源； CACHE MANIFEST #v0.11 CACHE: js/app.js css/style.css NETWORK: resource/logo.png FALLBACK: // offline.html在离线状态时，操作window.applicationCache进行需求实现。 自动化工具: (http://yanhaijing.com/html/2014/12/28/html5-manifest/) manifest 文件中的 cache 部分不能使用通配符，必须手动指定，这实在太让人不可理解，文件一多，就成了体力活了，这里介绍的 grunt-manifest 能自动生成 manifest 文件的目的。grunt-manifest 依赖 grunt 如下的命令可以安装grunt-manifest，并加入到依赖文件。 npm install grunt-manifest --save-dev 如下的代码，可以在 grunt 中载入 grunt-manifest，然后便可使用。 grunt.loadNpmTasks('grunt-manifest'); 使用grunt-manifest的一个典型的配置文件如下所示： grunt.initConfig({ manifest: { generate: { options: { basePath: \"../\", cache: [\"js/app.js\", \"css/style.css\"] network: [\"http://*\", \"https://*\"], fallback: [\"/ /offline.html\"], exclude: [\"js/jquery.min.js\"], preferOnline: true, verbose: true, timestamp: true }, src: [ \"some_files/*.html\", \"js/*.min.js\", \"css/*.css\" ], dest: \"index.manifest\" } } }); 其中 options 定义生成 manifest 的一些自定义参数，src是要生成的文件，dest是输出文件。 options 下有很多参数，主要参数如下： basePath 设置出入文件的根目录 cache 手动添加缓存文件 network 手动添加网络文件 fallback 手动添加后备文件 exclude 设置不添加到cache的文件 verbose 是否添加版权信息 timestamp 是否添加时间戳 这里有 Basejs 的配置文件和生成的 manifest 文件的例子。 1.3.3. What's the difference between feature detection, feature inference, and using the UA string? Feature Detection (✅) Feature Detection is to verify if a feature works in a particular browser or not. The feature can be either a CSS property or a Java Script Method. A good example is a modern HTML5 feature Location. if (navigator.geolocation) { // detect users location here B-) and do something awesome } Feature Inference 推理 Feature Inference is to assume that a CSS property or JS method is available in all the browsers, by verifying it in a single browser. The fact is it can or it cannot be available. For ex. the text() function is implemented in Chrome, but it is not implemented in Firefox which will give out an error eventually when used. So we have to be careful. UA String Identifies your operating system, browser and its version via navigator.userAgent. These “string text of data” contains information of the browser environment you are targeting. navigator.userAgent // Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.71 1.3.4. FOUC (Flash of Unstyled Content) 由于 external css 没有加载完成导致页面使用浏览器默认样式去显示页面。加载好后样式回归。 避免方法： 把 external css 放到页面 head 中而不是 body 后面。head 中 css 会阻止 DOM 解析。 代码控制 .no-fouc {display: none;} document.documentElement.className = 'no-fouc'; document.addEventListener('DOMContentLoaded', function(){ document.querySelector('.no-fouc').classList.remove('no-fouc') }) 1.3.5. How many resources will a browser download from a given domain at a time? Traditionally, why has it been better to serve site assets from multiple domains? IE7 allowed only two concurrent connections per host. But most browsers today allow more than that. IE8 allows 6 concurrent connections, Chrome allows 6, and Firefox allows 8. 多个 subdomain 查询也需要时间。Let's say you have 24 images on a page. Well, few things in life are free and there's such a thing as death by parallelization. If you host your images in 4 different subdomains, then that means that every single image could theoretically be downloaded in parallel. However, it also means that there are 3 additional DNS lookups involved. And a DNS lookup could be 100 ms, 150 ms, or sometimes longer. This added delay could easily offset any benefit of parallel downloads. You can see real-world examples of this by testing sites with http://www.webpagetest.org/ Of course the best solution is to use CSS sprites when possible to cut down on the number of requests. Most of the U.S. top ten web sites do domain sharding. What’s the optimal number? Yahoo! released a study that recommends sharding across at least two, but no more than four, domains. Above four, performance actually degrades. Note however that this was written in 2009. And in 2011 he posted a comment... Since newer browsers open more connections per domain, it’s probably better to revise the number downwards. I think 2 is a good compromise, but that’s just a hunch. It’d be great if some production property ran a test to determine the optimal number. You should also keep in mind that the big reason it's even necessary for the big sites like Yahoo and Amazon to do domain sharding is that their sites are so dynamic. The images are attached to products or stories which are displayed dynamically. So it's not feasible for them to use CSS sprites as aggressively as would be optimal. A site like StackOverflow, however, is light on these sorts of images and they have cut down on the number of requests so much that they don't need to do sharding. A big step towards making that happen is their usage of this sprites.png image... http 2.0 时代使用多个 subdomain 没必要了，反而性能不会提升。。Perhaps the strongest argument against domain sharding is that it’s unnecessary in the world of SPDY (as well as HTTP 2.0). In fact, domain sharding probably hurts performance under SPDY. SPDY supports concurrent requests (send all the request headers early) as well as request prioritization. Sharding across multiple domains diminishes these benefits. SPDY is supported by Chrome, Firefox, Opera, and IE 11. If your traffic is dominated by those browsers, you might want to skip domain sharding. 1.3.6. Describe z-index and how stacking context is formed z-index 需要配合 position (非 static) 使用。值越大，相应的 layer 位置越高。z-index 的使用场景之一是我做模态框的时候，这种我把它叫天马派，有最高层级，可能 z-index 设置999；还有些是 低空飞行派，z-index 从 1 - 10。但我不建议乱用 z-index，其实在 html 结构写的合理的时候，大部分情况下层级上下关系根据 html 结果确定好了，不需要为人加入 z-index 去干涉合理的层级结构。认为加入可能导致 z-index 混乱。我之前有个项目就是大家随意设置 z-index。10，999， 500 等。我是觉得 z-index 对于低空飞行派，1-5就够用了。过多了说明 html 结构不合理。 stacking context：简单理解就是具有 z轴方向 属性的元素。该元素有层级属性，或者里面 children 有层级。 stacking context 如何形成： html 标签 Element with a position value \"absolute\" or \"relative\" and z-index value other than \"auto\". Element with a position value \"fixed\" or \"sticky\" (sticky for all mobile browsers, but not older desktop). Element that is a child of a flex (flexbox) container, with z-index value other than \"auto\". Element with a opacity value less than 1 (See the specification for opacity). Element with any of the following properties with value other than \"none\": transform perspective clip-path mask / mask-image / mask-border 特点： 同级别的 div 之间层级关系由 z-index 决定。某个 div 里面 children 的层级和该 div 的兄弟没有层级关系。 div 1 2 3 层级关系有他们的 z-index 决定，div 4 5 6 的关系由 456 决定。 DIV #1 DIV #2 DIV #3 DIV #4 DIV #5 DIV #6 https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context 1.3.7. 页面可见性（Page Visibility API） 可以有哪些用途？ 通过 visibilityState 的值检测页面当前是否可见，以及打开网页的时间等; 在页面被切换到其他后台进程的时候，自动暂停音乐或视频的播放； 1.3.8. 对象到字符串的转换步骤 如果对象有 toString() 方法，javascript 调用它。如果返回一个原始值（primitive value如：string number boolean）,将这个值转换为字符串作为结果 如果对象没有 toString() 方法或者返回值不是原始值，javascript 寻找对象的 valueOf() 方法，如果存在就调用它，返回结果是原始值则转为字符串作为结果 否则，javascript 不能从 toString() 或者 valueOf() 获得一个原始值，此时throws a TypeError 1.3.9. 函数内部 arguments 特性, 如何将它转换为数组 arguments 是所有函数中都包含的一个局部变量，是一个类数组对象，对应函数调用时的实参。如果函数定义同名参数会在调用时覆盖默认对象 arguments[index] 分别对应函数调用时的实参，并且通过 arguments 修改实参时会同时修改实参 arguments.length 为实参的个数（Function.length表示形参长度） arguments.callee 为当前正在执行的函数本身，使用这个属性进行递归调用时需注意this的变化。匿名函数递归调用使用。严格模式下不能用 callee arguments.caller 为调用当前函数的函数（已被遗弃） 转换为数组： var args = Array.prototype.slice.call(arguments); var args = [].slice.call(arguments) var args = Array.from(arguments) var args = [...arguments] 1.3.10. 说几条写JavaScript的基本规范？ 不要在同一行声明多个变量。 请使用 ===/!== 来比较 true/false 或者数值 使用对象字面量替代 new Array 这种形式 不要使用全局函数。 Switch 语句必须带有 default分支 函数不应该有时候有返回值，有时候没有返回值。 For 循环必须使用大括号 If 语句必须使用大括号 for-in 循环中的变量 应该使用 var 关键字明确限定作用域，从而避免作用域污染。 1.4. Test // Load the test dependencies var app = require('../../server'), request = require('supertest'), should = require('should'), mongoose = require('mongoose'), User = mongoose.model('User'), Article = mongoose.model('Article'); // Define global test variables var user, article; // Create an 'Articles' controller test suite describe('Article Controller Unit Tests:', function() { // Define a pre-tests function beforeEach(function(done) { // Create a new 'User' model instance user = new User({ firstName: 'Full', lastName: 'Name', displayName: 'Full Name', email: 'test@test.com', username: 'username', password: 'password' }); // Save the new 'User' model instance user.save(function() { article = new Article({ title: 'Article Title', content: 'Article Content', user: user }); article.save(function(err) { done(); }); }); }); // Test the 'Article' GET methods describe('Testing the GET methods', function() { it('Should be able to get the list of articles', function(done) { // Create a SuperTest request request(app).get('/api/articles/') .set('Accept', 'application/json') .expect('Content-Type', /json/) .expect(200) .end(function(err, res) { // res.body.should.have.lengthOf(1).and.be.an.Array; //should.js res.body.should.be.an.instanceof(Array).and.have.lengthOf(1); // should.js // res.body.should.be.an.Array.and.have.lengthOf(1); // this doesn't work in late should.js since Array cannot chain res.body[0].should.have.property('title', article.title); // here is should.js res.body[0].should.have.property('content', article.content); // here is should.js done(); }); }); it('Should be able to get the specific article', function(done) { // Create a SuperTest request request(app).get('/api/articles/' + article.id) .set('Accept', 'application/json') .expect('Content-Type', /json/) .expect(200) .end(function(err, res) { // res.body.should.be.an.Object.and.have.property('title', article.title); // here is should.js // res.body.should.have.property('content', article.content); // here is should.js done(); }); }); }); // Define a post-tests function afterEach(function(done) { // Clean the database Article.remove(function() { User.remove(function() { done(); }); }); }); }); 1.4.1. 对Node的优点和缺点提出了自己的看法 优点: Node是基于事件驱动和无阻塞的，所以非常适合处理并发请求，因此构建在Node上的代理服务器相比其他技术实现（如Ruby）的服务器表现要好得多。 客户端和服务端统一语言 javascript 缺点： 早期 Node是一个相对新的开源项目，所以不太稳定，它总是一直在变，而且缺少足够多的第三方库支持。看起来，就像是Ruby/Rails当年的样子。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/前端路由原理.html":{"url":"Interview/frontend/前端路由原理.html","title":"前端路由原理","keywords":"","body":"1. 前端路由主要由两种方式实现1.1. location.hash, hashchange1.2. History Api: history.pushState() + popstate1.2.1. reference1. 前端路由主要由两种方式实现 有一个路由表，以 path 为 key，value 是触发给 path 的回调函数。 location.hash + hashchange history.pushState() + popState 1.1. location.hash, hashchange 说一下前端路由实现的简要原理，以 hash 形式（也可以使用 History API 来处理）为例，当 url 的 hash 发生变化时，触发 hashchange 注册的回调，回调中去进行不同的操作，进行不同的内容的展示。直接看代码或许更直观。 缺点：url 不好看，不利于 SEO function Router() { this.routes = {}; this.currentUrl = ''; } Router.prototype.route = function(path, callback) { this.routes[path] = callback || function(){}; }; Router.prototype.refresh = function() { this.currentUrl = location.hash.slice(1) || '/'; this.routes[this.currentUrl](); }; Router.prototype.init = function() { window.addEventListener('load', this.refresh.bind(this), false); window.addEventListener('hashchange', this.refresh.bind(this), false); } window.Router = new Router(); window.Router.init(); 上面路由系统 Router 对象实现，主要提供三个方法 init 监听浏览器 url hash 更新事件 route 存储路由更新时的回调到回调数组routes中，回调函数将负责对页面的更新 refresh 执行当前url对应的回调函数，更新页面 Router 调用方式以及呈现效果如下：点击触发 url 的 hash 改变，并对应地更新内容（这里为 body 背景色） turn white turn blue turn green var content = document.querySelector('body'); // change Page anything function changeBgColor(color) { content.style.backgroundColor = color; } Router.route('/', function() { changeBgColor('white'); }); Router.route('/blue', function() { changeBgColor('blue'); }); Router.route('/green', function() { changeBgColor('green'); }); 1.2. History Api: history.pushState() + popstate history.pushState(data, title, url): 修改 url 的地址 history.replaceState(data, title, url) popstate 事件: 监听地址的改变 手动的进行 pushState() 并不会触发 popstate 事件。点击浏览器前进后退时候触发。 s0 k0 var div1 = document.getElementById('div1'); var a1 = document.getElementById('a1'); var a2 = document.getElementById('a2'); var count1 = 0; var count2 = 0; history.replaceState({ count1: count1, count2: count2 }, null, ''); //最开始的状态，采用replace直接替换 a1.addEventListener('click', function() { count1++; history.pushState({ count1: count1, count2: count2 }, null, '#/s' + count1); //之后的状态，需要进行保存 a1.innerHTML = 's' + count1; }); a2.addEventListener('click', function() { count2++; history.pushState({ count1: count1, count2: count2 }, null, '#/k' + count2); //之后的状态，需要进行保存 a2.innerHTML = 'k' + count2; }); window.addEventListener('popstate', function(e) { console.log(e.state); a1.innerHTML = 's' + e.state.count1; //监听popstate事件，对状态进行还原 a2.innerHTML = 'k' + e.state.count2; }); 1.2.1. reference https://github.com/flatiron/director Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/前端面试杂.html":{"url":"Interview/frontend/前端面试杂.html","title":"前端面试杂","keywords":"","body":"1. 前端开发面试题1.1. HTML5 增加功能1.2. 语义化的理解1.3. 介绍一下你对浏览器内核的理解？1.4. 常见的浏览器内核有哪些？1.5. css 多列等高如何实现？1.6. 移动端的布局用过媒体查询吗？1.7. 如果需要手动写动画，你认为最小时间间隔是多久，为什么？（阿里）1.8. display:inline-block 什么时候会显示间隙？怎么处理？(携程)1.9. javascript 代码中的\"use strict\";是什么意思 ? 使用它区别是什么？1.10. Ajax 解决浏览器缓存问题？1.11. requireJS的核心原理是什么？（如何动态加载的？如何避免多次加载的？如何缓存的？）1.12. jquery.extend 与 jquery.fn.extend的区别？1.13. Object.is() 与原来的比较操作符“===”、“==”的区别？1.14. 是否了解公钥加密和私钥加密。1. 前端开发面试题 https://github.com/markyun/My-blog/tree/master/Front-end-Developer-Questions/Question 1.1. HTML5 增加功能 绘画 canvas 元素 用于媒介回放的 video 和 audio 元素 本地离线存储 localStorage 长期存储数据，浏览器关闭后数据不丢失；sessionStorage 的数据在浏览器关闭后自动删除 语意化更好的内容元素，比如 article、footer、header、nav、section 表单控件，calendar、date、time、email、url、search CSS3 实现圆角，阴影，对文字加特效，增加了更多的CSS选择器和多背景 rgba 新的技术 webworker, websocket, Geolocation 1.2. 语义化的理解 html 语义化就是让页面的内容结构化，便于对浏览器、搜索引擎解析 在没有样式 CSS 情况下也以一种文档格式显示，并且是容易阅读的 搜索引擎的爬虫依赖于标记来确定上下文和各个关键字的权重，利于 SEO 使阅读源代码的人对网站更容易将网站分块，便于阅读维护理解 1.3. 介绍一下你对浏览器内核的理解？ 主要分成两部分：渲染引擎(layout engine 或 Rendering Engine) 和 JS引擎。 渲染引擎：负责取得网页的内容（HTML、XML、图像等等）、整理讯息（例如加入CSS等），以及计算网页的显示方式，然后会输出至显示器或打印机。浏览器的内核的不同对于网页的语法解释会有不同，所以渲染的效果也不相同。所有网页浏览器、电子邮件客户端以及其它需要编辑、显示网络内容的应用程序都需要内核。 JS引擎：解析和执行javascript来实现网页的动态效果。 最开始渲染引擎和JS引擎并没有区分的很明确，后来JS引擎越来越独立，内核就倾向于只指渲染引擎。 1.4. 常见的浏览器内核有哪些？ Trident内核：IE, MaxThon, TT, The World, 360, 搜狗浏览器等。 Gecko内核：Netscape6及以上版本，FF, MozillaSuite/SeaMonkey等 Presto内核：Opera7及以上。 [Opera内核原为：Presto，现为：Blink;] Webkit内核：Safari, Chrome等。 [ Chrome的：Blink（WebKit的分支）] 浏览器内核的解析和对比 1.5. css 多列等高如何实现？ 利用 padding-bottom|margin-bottom 正负值相抵；设置父容器设置超出隐藏（overflow:hidden），这样子父容器的高度就还是它里面的列没有设定 padding-bottom 时的高度，当它里面的任一列高度增加了，则父容器的高度被撑到里面最高那列的高度，其他比这列矮的列会用它们的padding-bottom补偿这部分高度差。 1.6. 移动端的布局用过媒体查询吗？ 当媒体查询为真时，相关的样式表或样式规则会按照正常的级联规被应用。当媒体查询返回假， 标签上带有媒体查询的样式表 仍将被下载 （只不过不会被应用）。 @media (min-width: 700px) and (orientation: landscape){ .sidebar { display: none; } } 1.7. 如果需要手动写动画，你认为最小时间间隔是多久，为什么？（阿里） 多数显示器默认频率是60Hz，即1秒刷新60次，所以理论上最小间隔为1/60＊1000ms ＝ 16.7ms 1.8. display:inline-block 什么时候会显示间隙？怎么处理？(携程) 移除空格、使用margin负值、使用font-size:0、letter-spacing、word-spacing 1.9. javascript 代码中的\"use strict\";是什么意思 ? 使用它区别是什么？ 使 JS 编码更加规范化的模式，消除 Javascript 语法的一些不合理、不严谨之处，减少一些怪异行为。 默认支持的糟糕特性都会被禁用，比如不能用 with，也不能在意外的情况下给全局变量赋值; 全局变量的显示声明，函数必须声明在顶层，不允许在非函数代码块内声明函数，arguments.callee 也不允许使用； 消除代码运行的一些不安全之处，保证代码运行的安全,限制函数中的 arguments 修改，严格模式下的 eval 函数的行为和非严格模式的也不相同; 提高编译器效率，增加运行速度；为未来新版本的 Javascript 标准化做铺垫。 1.10. Ajax 解决浏览器缓存问题？ 在ajax发送请求前加上 anyAjaxObj.setRequestHeader(\"If-Modified-Since\",\"0\") 在ajax发送请求前加上 anyAjaxObj.setRequestHeader(\"Cache-Control\",\"no-cache\") 在URL后面加上一个随机数： \"fresh=\" + Math.random(); 在URL后面加上时间戳：\"nowtime=\" + new Date().getTime(); 如果是使用 jQuery，直接这样就可以了 $.ajaxSetup({cache:false})。这样页面的所有 ajax 都会执行这条语句就是不需要保存缓存记录 1.11. requireJS的核心原理是什么？（如何动态加载的？如何避免多次加载的？如何缓存的？） 参考：http://annn.me/how-to-realize-cmd-loader/ 1.12. jquery.extend 与 jquery.fn.extend的区别？ jquery.extend 为 jquery 添加类方法，可以理解为添加静态方法 jquery.fn.extend: 源码中 jquery.fn = jquery.prototype，所以对 jquery.fn 的扩展，就是为 jquery 类添加成员函数 jquery.extend 扩展，需要通过 jquery 类来调用，而 jquery.fn.extend 扩展，所有 jquery 实例都可以直接调用。 $.fn.stringifyArray = function(array) { return JSON.stringify(array) } $.fn.parseArray = function(array) { return JSON.parse(array) } // 然后调用： $(\"\").stringifyArray(array) 1.13. Object.is() 与原来的比较操作符“===”、“==”的区别？ 两等号判等，会在比较时进行类型转换； 三等号判等(判断严格)，比较时不进行隐式类型转换,（类型不同则会返回false）； Object.is 在三等号判等的基础上特别处理了 NaN 、-0 和 +0 ，保证 -0 和 +0 不再相同。但 Object.is(NaN, NaN) 会返回 true. 1.14. 是否了解公钥加密和私钥加密。 一般情况下是指私钥用于对数据进行签名，公钥用于对签名进行验证; HTTP 网站在浏览器端用公钥加密敏感数据，然后在服务器端再用私钥解密。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/协议_HTTP.html":{"url":"Interview/frontend/协议_HTTP.html","title":"协议_HTTP","keywords":"","body":"1. Http 协议特点1.1. 概念1.2. 报文组成1.3. 方法1.4. post get 区别1.5. 状态码1.6. 持久化连接1.7. 管线化1.8. HTTPS 的握手过程1. Http 协议特点 无连接：连接一次就断掉，不会保持连接 无状态：一次连接后，服务器不回去记住上次请求的状态，通过 session 才能实现。 简单快速：每个资源都是固定的，统一资源符。uri 输入就可访问想要的 灵活：通过一个 Http 协议就可以完成不同数据类型的传输。只需要更改头文件中的数据类型。 1.1. 概念 HTTP (超文本传输协议) 是利用 TCP 在两台电脑(通常是 Web 服务器和客户端)之间传输信息的协议。客户端使用 Web 浏览器发起 HTTP 请求给 Web 服务器，Web服务器发送被请求的信息给客户端。 基本概念： 连接(Connection)：一个传输层的实际环流，它是建立在两个相互通讯的应用程序之间。 消息(Message)：HTTP通讯的基本单位，包括一个结构化的八元组序列并通过连接传输。 请求(Request)：一个从客户端到服务器的请求信息包括应用于资源的方法、资源的标识符和协议的版本号 响应(Response)：一个从服务器返回的信息包括HTTP协议的版本号、请求的状态(例如“成功”或“没找到”)和文档的MIME类型。 资源(Resource)：由URI标识的网络数据对象或服务。 实体(Entity)：数据资源或来自服务资源的回映的一种特殊表示方法，它可能被包围在一个请求或响应信息中。一个实体包括实体头信息和实体的本身内容。 客户机(Client)：一个为发送请求目的而建立连接的应用程序。 用户代理(Useragent)：初始化一个请求的客户机。它们是浏览器、编辑器或其它用户工具。 服务器(Server)：一个接受连接并对请求返回信息的应用程序。 源服务器(Origin server)：是一个给定资源可以在其上驻留或被创建的服务器。 代理(Proxy)：一个中间程序，它可以充当一个服务器，也可以充当一个客户机，为其它客户机建立请求。请求是通过可能的翻译在内部或经过传递到其它的服务器中。一个代理在发送请求信息之前，必须解释并且如果可能重写它。代理经常作为通过防火墙的客户机端的门户，代理还可以作为一个帮助应用来通过协议处理没有被用户代理完成的请求。 网关(Gateway)：一个作为其它服务器中间媒介的服务器。与代理不同的是，网关接受请求就好象对被请求的资源来说它就是源服务器；发出请求的客户机并没有意识到它在同网关打交道。网关经常作为通过防火墙的服务器端的门户，网关还可以作为一个协议翻译器以便存取那些存储在非HTTP系统中的资源。 通道(Tunnel)：是作为两个连接中继的中介程序。一旦激活，通道便被认为不属于HTTP通讯，尽管通道可能是被一个HTTP请求初始化的。当被中继的连接两端关闭时，通道便消失。当一个门户(Portal)必须存在或中介(Intermediary)不能解释中继的通讯时通道被经常使用。 缓存(Cache)：反应信息的局域存储。 关闭连接： 客户和服务器双方都可以通过关闭套接字来结束 TCP/IP 对话 1.2. 报文组成 请求报文：请求行、请求头、空行、请求体 请求行：http方法、页面地址、协议、版本 请求头：key-value，告诉服务端请求内容，主要包括用户可以接受的数据类型、长度、压缩方法、最后一次修改时间、数据有效期等。 请求体: queryString 数据 请求行 GET /Protocols/rfc2616/rfc2616-sec5.html HTTP/1.1 请求头 Host: www.w3.org Connection: keep-alive Cache-Control: max-age=0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36 Referer: https://www.google.com.hk/ Accept-Encoding: gzip,deflate,sdch Accept-Language: zh-CN,zh;q=0.8,en;q=0.6 Cookie: authorstyle=yes If-None-Match: \"2cc8-3e3073913b100\" 请求头结束 If-Modified-Since: Wed, 01 Sep 2004 13:24:52 GMT 空行 请求体 name=qiu&age=25 响应报文：状态行、响应头、空行、响应体 状态行：200 ok 状态行 HTTP/1.1 200 OK 响应头 Date: Tue, 08 Jul 2014 05:28:43 GMT Server: Apache/2 Last-Modified: Wed, 01 Sep 2004 13:24:52 GMT ETag: \"40d7-3e3073913b100\" Accept-Ranges: bytes Content-Length: 16599 Cache-Control: max-age=21600 Expires: Tue, 08 Jul 2014 11:28:43 GMT P3P: policyref=\"http://www.w3.org/2001/05/P3P/p3p.xml\" 响应头结束 Content-Type: text/html; charset=iso-8859-1 空行 响应体 {\"name\": \"qiu\", \"age\": 25} 1.3. 方法 Get, post, put, patch, delete, head(获取报文头) 1.4. post get 区别 get 请求参数长度有限制，post 没有限制 get 相对 post 不安全，参数暴露在 url 中 get 参数 url 中，post 在 request body 中 get 在浏览器中回退是无害的，post 会再次提交 get url 参数完整保存在浏览器历史记录，post 不行 get 浏览器自动缓存。post 需要主动去缓存 get 只接受 ASCII 字符，post 无限制 get 的 url 可以被收藏，post 不行 1.5. 状态码 1XX：指示信息-表示请求已接受，继续处理 2XX：成功-表示请求已被成功接收 200 OK ：客户端请求成功 206 Partial Content：video/audio 文件大的时候，客户端发送了带 range 头的 get 请求，服务器完成了他 3XX：重定向-要完成请求必须进行更进一步的操作 301 Move Permanently：所请求的页面已经转移至新的URL 302 Found：所请求的页面已经临时转移到新的URL 304 Not Modified：客户端有缓冲的文档并发出一个条件性的请求，服务器告诉客户，原来缓冲的文档还可以继续使用 4XX：客户端错误-请求有语法错误或请求无法实现 400 Bad Request：客户端请求有语法错误，不能被服务器所理解 401 Unauthorized：请求未经授权，这个状态代码必须和 WWW-Authenticate 报头域一起使用 403 Forbidden：对被请求页面的访问被禁止 404 Not Found：请求资源不存在 5XX：服务错误-服务器未能实现合法的请求 500 Internal Server Error：服务器发生不可预期的错误，原来缓冲的文档还可以继续使用 503 Server Unavailable：请求未完成，服务器临时过载或当机，一段事件后恢复正常 1.6. 持久化连接 http 1.1 支持，Keep-Alive 模式 1.7. 管线化 持久连接下：请求1 --> 响应1 --> 请求2 --> 响应2 管线化：请求和响应都打包：请求123 --> 响应123 管线化是通过持久连接完成，至少 1.1 只有 get、head 请求可以管线化，post有限制 初次建立不应该启动管线化、因为服务端不一定支持 1.1 不会带来性能提升，很多服务端对他支持不好，现代浏览器 chrome 默认不开启 1.8. HTTPS 的握手过程 浏览器将自己支持的一套加密规则发送给服务器。 服务器从中选出一组加密算法与 HASH 算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 浏览器获得网站证书之后浏览器要做以下工作： 验证证书的合法 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。 使用约定好的 HASH 算法计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给服务器 网站接收浏览器发来的数据之后要做以下的操作： 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证 HASH 是否与浏览器发来的一致。 使用密码加密一段握手消息，发送给浏览器。 浏览器解密并计算握手消息的 HASH，如果与服务端发来的 HASH 一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。 http://blog.jobbole.com/105633/ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/协议_HTTP2.html":{"url":"Interview/frontend/协议_HTTP2.html","title":"协议_HTTP2","keywords":"","body":"1. HTTP/2 Server Push with Node.js1.1. About HTTP/21.2. Server Push1.3. HTTP/2 Server Push Example in Node.js1.4. HTTP/2 & Node1. HTTP/2 Server Push with Node.js node 8.4 --expose-http2 server push: 通过 full request 和 多路响应大大减少请求响应时间。不像 http 1 时代 浏览器加载html，再分别加载里面的 js, css, image 资源。并且 http 1 每次浏览器从一个 domain 下载的资源数受限，chrome/firefox 最多同时下载8个。 http 2 的多路响应、加上 server push 甚至在浏览器没有向服务端发送请求时 服务端都能迅速返回所需要的资源。 Node.js 8.4.0 just arrived with the experimental support of HTTP/2, which you can enable by using the --expose-http2 flag. In this blog post, we will introduce the most important aspects of HTTP/2 Server Push and create a small Node.js app that gains benefit from using it. 1.1. About HTTP/2 通过使用 full request and response multiplexing 多路传输 等措施 减少延迟！ The primary goals for HTTP/2 are to reduce latency by enabling full request and response multiplexing, minimize protocol overhead via efficient compression of HTTP header fields, and add support for request prioritization and server push. To read more about HTTP/2 in general, check out the Introduction to HTTP/2 article. 1.2. Server Push HTTP/2 Server Push allows the server to send assets to the browser before it has even asked for them. Before we jump into HTTP/2 let's take a look how it works with HTTP/1: In HTTP/1 the client sends a request to the server, which replies with the requested content, usually with an HTML file that contains links to many assets (.js, .css, etc. files). As the browser processes this initial HTML file, it starts to resolve these links and makes separate requests to fetch them. Check out the following image that demonstrates the process. Pay extra attention to the independent requests on the timeline and to the initiator of those requests: HTTP/1 assets loading This is how HTTP/1 works, and this is how we develop our application for so many years. Why change it now? The problem with the current approach is that the user has to wait while the browser parses responses, discovers links and fetches assets. This delays rendering and increases load times. There are workarounds like inlining some assets, but it also makes the initial response bigger and slower. This is where HTTP/2 Server Push capabilities come into the picture as the server can send assets to the browser before it has even asked for them. Look at the following picture where the same website is served via HTTP/2. Check out the timeline and the initiator. You can see that HTTP/2 multiplexing reduced the number of requests, and the assets were sent immediately together with the initial request. HTTP/2 with Server Push Let's see how you can use HTTP/2 Server Push today with Node.js and speed up your client's load time. 1.3. HTTP/2 Server Push Example in Node.js With requiring the built-in http2 module, we can create our server just like we would do it with the https module. The interesting part is that we push other resources when the index.html is requested: const http2 = require('http2') const server = http2.createSecureServer( { cert, key }, onRequest ) function push (stream, filePath) { const { file, headers } = getFile(filePath) const pushHeaders = { [HTTP2_HEADER_PATH]: filePath } stream.pushStream(pushHeaders, (pushStream) => { pushStream.respondWithFD(file, headers) }) } function onRequest (req, res) { // Push files with index.html if (reqPath === '/index.html') { push(res.stream, 'bundle1.js') push(res.stream, 'bundle2.js') } // Serve file res.stream.respondWithFD(file.fileDescriptor, file.headers) } This way the bundle1.js and bundle2.js assets will be sent to the browser even before it asks for them. You can find the full example here: https://github.com/RisingStack/http2-push-example 1.4. HTTP/2 & Node HTTP/2 in @nodejs can help us at many points to optimize our client-server communication. With Server Push, we can send assets to the browser before it has even asked for them to reduce the initial loading time for our users. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/协议_TCP_UDP_Http的区别.html":{"url":"Interview/frontend/协议_TCP_UDP_Http的区别.html","title":"协议_TCP_UDP_Http的区别","keywords":"","body":"1. TCP/IP、Http的区别1.1. TCP UDP 区别1.2. HTTP1. TCP/IP、Http的区别 TPC/IP 协议是传输层协议，主要解决数据如何在网络中传输，而 HTTP 是应用层协议，主要解决如何包装数据。关于TCP/IP 和 HTTP协议的关系，网络有一段比较容易理解的介绍：“我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET等，也可以自己定义应用层协议。WEB 使用 HTTP协议作应用层协议，以封装 HTTP 文本信息，然后使用TCP/IP做传输层协议将它发到网络上。” TCP/IP代表传输控制协议/网际协议，指的是一系列协议。“IP”代表网际协议，TCP 和 UDP 使用该协议从一个网络传送数据包到另一个网络。把IP 想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP 和 UDP 是高速公路上的“卡车”，它们携带的货物就是像 HTTP，文件传输协议FTP这样的协议等。​TCP 和 UDP 是 FTP、HTTP 和 SMTP 之类使用的传输层协议。 1.1. TCP UDP 区别 虽然 TCP 和 UDP都是用来传输其他协议的，它们却有一个显著的不同：TCP 提供有保证的数据传输，而 UDP 不提供。这意味着TCP 有一个特殊的机制来确保数据安全的不出错的从一个端点传到另一个端点，而 UDP 不提供任何这样的保证。 下面的图表试图显示不同的TCP/IP和其他的协议在最初OSI模型中的位置： 7 应用层 例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP 6 表示层 例如XDR、ASN.1、SMB、AFP、NCP 5 会话层 例如ASAP、TLS、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、Winsock、BSD sockets 4 传输层 例如TCP、UDP、RTP、SCTP、SPX、ATP、IL 3 网络层 例如IP、ICMP、IGMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、 X.25 2 数据链路层 例如以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP 1 物理层 例如线路、无线电、光纤、信鸽 1.2. HTTP 参见 协议_HTTP.md Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/协议_Websocket_SSE_vs_polling.html":{"url":"Interview/frontend/协议_Websocket_SSE_vs_polling.html","title":"协议_Websocket_SSE_vs_polling","keywords":"","body":"1. HTTP, Ajax Polling, Ajax Long polling, Websocket, Comet, SSE1.1. Regular HTTP1.2. Ajax Polling:1.3. Ajax Long-Polling:1.4. HTML5 Server Sent Events (SSE) / EventSource:1.5. HTML5 WebSockets1.5.1. 小结1.6. Comet:1. HTTP, Ajax Polling, Ajax Long polling, Websocket, Comet, SSE 1.1. Regular HTTP A client requests a webpage from a server. The server calculates the response The server sends the response to the client. 1.2. Ajax Polling: A client requests a webpage from a server using regular HTTP (see HTTP above). The requested webpage executes JavaScript which requests a file from the server at regular intervals (e.g. 0.5 seconds). The server calculates each response and sends it back, just like normal HTTP traffic. 1.3. Ajax Long-Polling: A client requests a webpage from a server using regular HTTP (see HTTP above). The requested webpage executes JavaScript which requests a file from the server. The server does not immediately respond with the requested information but waits until there's new information available. When there's new information available, the server responds with the new information. The client receives the new information and immediately sends another request to the server, re-starting the process. 1.4. HTML5 Server Sent Events (SSE) / EventSource: A client requests a webpage from a server using regular HTTP (see HTTP above). The requested webpage executes javascript which opens a connection to the server. The server sends an event to the client when there's new information available. Real-time traffic from server to client, mostly that's what you'll need You'll want to use a server that has an event loop Not possible to connect with a server from another domain If you want to read more, I found these very useful: (article), (article), (article), (tutorial). EventSource 不是一个新鲜的技术，正式一点应该叫Server-sent events，即 SSE。 EventSource 本质上还是 HTTP，基于流，通过 response 流实时推送服务器信息到客户端。 新创建的 EventSource 对象拥有如下属性： 属性 描述 url(只读) es对象请求的服务器url readyState(只读) es对象的状态，初始为0，包含CONNECTING (0)，OPEN (1)，CLOSED (2)三种状态 withCredentials 是否允许带凭证等，默认为false，即不支持发送cookie 服务端实现/message接口，需要返回类型为 text/event-stream的响应头。 // 服务端： var http = require('http'); http.createServer(function(req，res){ if(req.url === '/message'){ res.writeHead(200，{ 'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache', 'Connection': 'keep-alive' }); setInterval(function(){ res.write('data: ' + new Date() + '\\n\\n'); }, 1000); } }).listen(8888); 我们注意到，为了避免缓存，Cache-Control 特别设置成了 no-cache，为了能够发送多个 response， Connection 被设置成了 keep-alive。发送数据时，请务必保证服务器推送的数据以 data:开始，以\\n\\n结束，否则推送将会失败(约定的)。 以上，服务器每隔1s主动向客户端发送当前时间戳，为了接受这个信息，客户端需要监听服务器。如下： // 客户端: // 新建一个EventSource对象 const es = new EventSource('/message'); // message 是服务端支持 EventSource 的接口 es.onmessage = function(e){ console.log(e.data); // 打印服务器推送的信息 } 如下是消息推送的过程： 你以为 es 只能监听 message 事件吗？并不是，message只是缺省的事件类型。实际上，它可以监听任何指定类型的事件。 es.addEventListener(\"####\", function(e) {// 事件类型可以随你定义 console.log('####:', e.data); }，false); 服务器发送不同类型的事件时，需要指定event字段。 res.write('event: ####\\n'); res.write('data: 这是一个自定义的####类型事件\\n'); res.write('data: 多个data字段将被解析成一个字段\\n\\n'); 如下所示： 可以看到，服务端指定event事件名为”####”后，客户端触发了对应的事件回调，同时服务端设置的多个data字段，客户端使用换行符连接成了一个字符串。 不仅如此，事件流中还可以混合多种事件，请看我们是怎么收到消息的，如下： 除此之外，es对象还拥有另外3个方法: onopen()、onerror()、close()，请参考如下实现。 es.onopen = function(e){// 链接打开时的回调 console.log('当前状态readyState:', es.readyState); // open 时readyState===1 } es.onerror = function(e){// 出错时的回调(网络问题,或者服务下线等都有可能导致出错) console.log(es.readyState);// 出错时readyState===0 es.close();// 出错时，chrome浏览器会每隔3秒向服务器重发原请求,直到成功. 因此出错时，可主动断开原连接. } 使用 EventSource 技术实时更新网页信息十分高效。实际使用中，我们几乎不用担心兼容性问题，主流浏览器都了支持EventSource，当然，除了掉队的IE系。对于不支持的浏览器，其PolyFill方案请参考HTML5 Cross Browser Polyfills。 SSE 配合 CORS 实现跨域 另外，如果需要支持跨域调用，请设置响应头 Access-Control-Allow-Origin': '*'。 如需支持发送cookie，请设置响应头 Access-Control-Allow-Origin': req.headers.origin 和 Access-Control-Allow-Credentials: true，并且创建es对象时，需要明确指定是否发送凭证。如下： var es = new EventSource('/message', { withCredentials: true }); // 创建时指定配置才是有效的 // es.withCredentials = true; // 与ajax不同，这样设置是无效的 1.5. HTML5 WebSockets A client requests a webpage from a server using regular http (see HTTP above). The requested webpage executes JavaScript which opens a connection with the server. The server and the client can now send each other messages when new data (on either side) is available. Real-time traffic from the server to the client and from the client to the server You'll want to use a server that has an event loop With WebSockets it is possible to connect with a server from another domain. It is also possible to use a third party hosted websocket server, for example Pusher or others. This way you'll only have to implement the client side, which is very easy! If you want to read more, I found these very useful: (article), (article) (tutorial). WebSocket 是基于 TCP 的全双工通讯的协议，它与 EventSource 有着本质上的不同.(前者基于TCP，后者依然基于HTTP) WebSocket 使用和 HTTP 相同的 TCP 端口，默认为80， 统一资源标志符为 ws，运行在 TLS 之上时，默认使用443，统一资源标志符为 wss。它通过 101 switch protocol 进行一次TCP握手，即从 HTTP 协议切换成 WebSocket 通信协议。 相对于 HTTP 协议，WebSocket 拥有如下优点： 全双工，实时性更强。 相对于 http 携带完整的头部，WebSocket 请求头部明显减少。 保持连接状态，不用再验权了。 二进制支持更强，Websocket 定义了二进制帧，处理更轻松。 Websocket 协议支持扩展，可以自定义的子协议，如 permessage-deflate 扩展。 Frame WebSocket 协议基于 Frame 而非 Stream（EventSource 是基于 Stream 的）。因此其传输的数据都是Frame（帧）。如下便是Frame的结构： 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued，if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key，if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+ 第一个字节包含FIN、RSV、Opcode。 FIN：size为1bit，标示是否最后一帧。%x0表示还有后续帧，%x1表示这是最后一帧。 RSV1、2、3，每个size都是1bit，默认值都是0，如果没有定义非零值的含义，却出现了非零值，则WebSocket链接将失败。 Opcode，size为4bits，表示『payload data』的类型。如果收到未知的opcode，连接将会断开。已定义的opcode值如下： %x0: 代表连续的帧 %x1: 文本帧 %x2: 二进制帧 %x3~7: 预留的非控制帧 %x8: 关闭握手帧 %x9: ping帧，后续心跳连接会讲到 %xA: pong帧，后续心跳连接会讲到 %xB~F: 预留的非控制帧 第二个字节包含Mask、Payload len。 Mask：size为1bit，标示『payload data』是否添加掩码。所有从客户端发送到服务端的帧都会被置为1，如果置1，Masking-key便会赋值。 //若 server 是一个 WebSocket 服务端实例 //监听客户端消息 server.on('message', function(msg, flags) { console.log('client say: %s', msg); console.log('mask value:', flags.masked);// true，进一步佐证了客户端发送到服务端的Mask帧都会被置为1 }); //监听客户端pong帧响应 server.on('pong', function(msg, flags) { console.log('pong data: %s', msg); console.log('mask value:', flags.masked);// true，进一步佐证了客户端发送到服务端的Mask帧都会被置为1 }); Payload len：size为7bits，即使是当做无符号整型也只能表示0~127的值，所以它不能表示更大的值，因此规定”Payload data”长度小于或等于125的时候才用来描述数据长度。如果Payload len==126，则使用随后的2bytes（16bits）来存储数据长度。如果Payload len==127，则使用随后的8bytes（64bits）来存储数据长度。 以上，扩展的Payload len可能占据第三至第四个或第三至第十个字节。紧随其后的是”Mask-key”。 Mask-key：size为0或4bytes（32bits），默认为0，与前面Mask呼应，从客户端发送到服务端的帧都包含4bytes（32bits）的掩码，一旦掩码被设置，所有接收到的”payload data”都必须与该值以一种算法做异或运算来获取真实值。 Payload data：size为”Extension data” 和 “Application data” 的总和，一般”Extension data”数据为空。 Extension data：默认为0，如果扩展被定义，扩展必须指定”Extension data”的长度。 Application data：占据”Extension data”之后剩余帧的空间。 关于Frame的更多理论介绍不妨读读 学习WebSocket协议—从顶层到底层的实现原理（修订版）。 关于Frame的数据帧解析不妨读读 WebSocket(贰) 解析数据帧 及其后续文章。 建立连接 // 新建一个ws对象十分简单 let ws = new WebSocket('ws://127.0.0.1:10103/');// 本地使用10103端口进行测试 新建的WebSocket对象如下所示： 这中间包含了一次Websocket握手的过程，我们分两步来理解。 第一步，客户端请求。 这是一个GET请求，主要字段如下： Connection: Upgrade Upgrade: websocket Sec-WebSocket-Key:61x6lFN92sJHgzXzCHfBJQ== Sec-WebSocket-Version:13 Connection 字段指定为 Upgrade，表示客户端希望连接升级。 Upgrade 字段设置为 websocket，表示希望升级至 Websocket协议。 Sec-WebSocket-Key 字段是随机字符串，服务器根据它来构造一个SHA-1的信息摘要。 Sec-WebSocket-Version 表示支持的 Websocket 版本。RFC6455要求使用的版本是13。 甚至我们可以从请求截图里看出，Origin是file://，而Host是127.0.0.1:10103，明显不是同一个域下，但依然可以请求成功，说明Websocket协议是不受同源策略限制的(同源策略限制的是http协议)。 第二步，服务端响应。 Status Code: 101 Switching Protocols 表示 Websocket 协议通过101状态码进行握手。 Sec-WebSocket-Accept 字段是由 Sec-WebSocket-Key 字段加上特定字符串”258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，计算SHA-1摘要，然后再base64编码之后生成的. 该操作可避免普通http请求，被误认为Websocket协议。 Sec-WebSocket-Extensions 字段表示服务端对 Websocket 协议的扩展。 以上，WebSocket 构造器不止可以传入 url，还能传入一个可选的协议名称字符串或数组。 ws = new WebSocket('ws://127.0.0.1:10103/', ['abc','son_protocols']); 服务端实现 ws 是一个 nodejs 版的 WebSocketServer 实现。使用 npm install ws 即可安装。 var WebSocketServer = require('ws').Server， server = new WebSocketServer({port: 10103}); server.on('connection', function(s) { s.on('message', function(msg) { //监听客户端消息 console.log('client say: %s', msg); }); s.send('server ready!');// 连接建立好后，向客户端发送一条消息 }); 以上，new WebSocketServer() 创建服务器时如需权限验证，请指定 verifyClient 为验权的函数。 server = new WebSocketServer({ port: 10103, verifyClient: verify }); function verify(info){ console.log(Object.keys(info));// [ 'origin', 'secure', 'req' ] console.log(info.orgin);// \"file://\" return true;// 返回true时表示验权通过，否则客户端将抛出\"HTTP Authentication failed\"错误 } 以上，verifyClient 指定的函数只有一个形参，若为它显式指定两个形参，那么第一个参数同上 info，第二个参数将是一个cb回调函数。该函数用于显式指定拒绝时的 HTTP 状态码等，它默认拥有3个形参，依次为： result，布尔值类型，表示是否通过权限验证。 code，数值类型，若 result 值为 false 时，表示HTTP的错误状态码。 name，字符串类型，若 result 值为 false时，表示HTTP状态码的错误信息。 // 若verify定义如下 function verify(info, cb){ //一旦拥有第二个形参，如果不调用，默认将通过验权 cb(false, 401, '权限不够');// 此时表示验权失败，HTTP状态码为401，错误信息为\"权限不够\" return true;// 一旦拥有第二个形参，响应就被cb接管了，返回什么值都不会影响前面的处理结果 } 除了port 和 verifyClient设置外，其它设置项及更多API，请参考文档 ws-doc。 发送和监听消息 接下来，我们来实现消息收发。如下是客户端发送消息。 ws.onopen = function(e){ // 可发送字符串，ArrayBuffer 或者 Blob数据 ws.send('client ready!); }; 客户端监听信息。 ws.onmessage = function(e){ console.log('server say:', e.data); }; 如下是浏览器的运行截图。 消息的内容都在Frames栏，第一条彩色背景的信息是客户端发送的，第二条是服务端发送的。两条消息的长度都是13。 如下是Timing栏，不止是WebSocket，包括EventSource，都有这样的黄色高亮警告。 该警告说明：请求还没完成。实际上，直到一方连接close掉，请求才会完成。 关闭连接 说到close，ws 的 close 方法比 es 的略复杂。 语法：close(short code，string reason); close默认可传入两个参数。code是数字，表示关闭连接的状态号，默认是1000，即正常关闭。（code取值范围从0到4999，其中有些是保留状态号，正常关闭时只能指定为1000或者3000~4999之间的值，具体请参考CloseEvent - Web APIs）。reason是UTF-8文本，表示关闭的原因（文本长度需小于或等于123字节）。 由于code 和 reason都有限制，因此该方法可能抛出异常，建议catch下. try{ ws.close(1001, 'CLOSE_GOING_AWAY'); }catch(e){ console.log(e); } ws 对象还拥有 onclose 和 onerror 监听器，分别监听关闭和错误事件。（注：EventSource 没有 onclose 监听） 拥有的属性 ws 的 readyState 属性拥有4个值，比 es 的 readyState 的多一个 CLOSING 的状态。 常量 描述 EventSource(值) WebSocket(值) CONNECTING 连接未初始化 0 0 OPEN 连接已就绪 1 1 CLOSING 连接正在关闭 - 2 CLOSED 连接已关闭 2 3 另外，除了两种都有的url属性外，WebSocket对象还拥有更多的属性。 属性 描述 binaryType 被传输二进制内容的类型，有blob, arraybuffer 两种 bufferedAmount 待传输的数据的长度 extensions 表示服务器选用的扩展 protocol 指的是构造器第二个参数传入的子协议名称 文件上传 以前一直是使用ajax做文件上传，实际上，Websocket 上传文件也是一把好刀. 其 send 方法可以发送 String，ArrayBuffer，Blob 共三种数据类型，发送二进制文件完全不在话下。 由于各个浏览器对Websocket单次发送的数据有限制，所以我们需要将待上传文件切成片段去发送。如下是实现。 const ws = new WebSocket('ws://127.0.0.1:10103/');// 连接服务器 const fileSelect = document.getElementById('file'); const size = 1024 * 128;// 分段发送的文件大小(字节) let curSize, total, file, fileReader; fileSelect.onchange = function(){ file = this.files[0];// 选中的待上传文件 curSize = 0;// 当前已发送的文件大小 total = file.size;// 文件大小 ws.send(file.name);// 先发送待上传文件的名称 fileReader = new FileReader();// 准备读取文件 fileReader.onload = loadAndSend; readFragment();// 读取文件片段 }; function loadAndSend(){ if(ws.bufferedAmount > size * 5){// 若发送队列中的数据太多,先等一等 setTimeout(loadAndSend，4); return; } ws.send(fileReader.result);// 发送本次读取的片段内容 curSize += size;// 更新已发送文件大小 curSize server(node): var WebSocketServer = require('ws').Server, server = new WebSocketServer({port: 10103}),// 启动服务器 fs = require('fs'); server.on('connection', function(wsServer){ var fileName, i = 0;// 变量定义不可放在全局,因每个连接都不一样,这里才是私有作用域 server.on('message', function(data, flags){// 监听客户端消息 if(flags.binary){// 判断是否二进制数据 var method = i++ ? 'appendFileSync' : 'writeFileSync'; // 当前目录下写入或者追加写入文件(建议加上try语句捕获可能的错误) fs[method]('./' + fileName, data，'utf-8'); }else{// 非二进制数据则认为是文件名称 fileName = data; } }); wsServer.send('server ready!');// 告知客户端服务器已就绪 }); 运行效果如下： 上述测试代码中没有过多涉及服务器的存储过程。通常，服务器也会有缓存区上限，如果客户端单次发送的数据量超过服务端缓存区上限，那么服务端也需要多次读取。 心跳连接 生产环境下上传一个文件远比本地测试来得复杂。实际上，从客户端到服务端，中间存在着大量的网络链路，如路由器，防火墙等等。一份文件的上传要经过中间的层层路由转发，过滤。这些中间链路可能会认为一段时间没有数据发送，就自发切断两端的连接。这个时候，由于TCP并不定时检测连接是否中断，而通信的双方又相互没有数据发送，客户端和服务端依然会一厢情愿的信任之前的连接，长此以往，将使得大量的服务端资源被WebSocket连接占用。 正常情况下，TCP的四次挥手完全可以通知两端去释放连接。但是上述这种普遍存在的异常场景，将使得连接的释放成为梦幻。 为此，早在websocket协议实现时，设计者们便提供了一种 Ping/Pong Frame的心跳机制。一端发送Ping Frame，另一端以 Pong Frame响应。这种Frame是一种特殊的数据包，它只包含一些元数据，能够在不影响原通信的情况下维持住连接。 根据规范RFC 6455，Ping Frame包含一个值为9的opcode，它可能携带数据。收到Ping Frame后，Pong Frame必须被作为响应发出。Pong Frame包含一个值为10的opcode，它将包含与Ping Frame中相同的数据。 借助ws包，服务端可以这么来发送 Ping Frame。 wsServer.ping(); 同时，需要监听客户端响应的 pong Frame. wsServer.on('pong', function(data, flags) { console.log(data);// \"\" console.log(flags);// { masked: true，binary: true } }); 以上，由于Ping Frame 不带数据，因此作为响应的Pong Frame 的data 值为空串。遗憾的是，目前浏览器只能被动发送Pong Frame作为响应（Sending websocket ping/pong frame from browser），无法通过 JS API 主动向服务端发送Ping Frame。因此对于web服务，可以采取服务端主动ping的方式，来保持住链接。实际应用中，服务端还需要设置心跳的周期，以保证心跳连接可以一直持续。同时，还应该有重发机制，若连续几次没有收到心跳连接的回复，则认为连接已经断开，此时便可以关闭Websocket连接了。 Socket.IO WebSocket 出世已久，很多优秀的大神基于此开发出了各式各样的库。其中 Socket.IO 是一个非常不错的开源 WebSocket 库，旨在抹平浏览器之间的兼容性问题。它基于 Node.js，支持以下方式优雅降级： Websocket Adobe® Flash® Socket AJAX long polling AJAX multipart streaming Forever Iframe JSONP Polling 如何在项目中使用 Socket.IO，请参考第一章 socket.io 简介及使用。 1.5.1. 小结 EventSource，本质依然是 HTTP，基于流，它仅提供服务端到客户端的单向文本数据传输，不需要心跳连接，连接断开会持续触发重连。 WebSocket 双全工通信方式，基于 TCP 协议，基于帧 frame，它提供双向数据传输，支持二进制，需要心跳连接，连接断开不会重连。 EventSource 更轻量和简单，WebSocket 支持性更好（因其支持IE10+）。通常来说，使用 EventSource 能够完成的功能，使用 WebSocket 一样能够做到，反之却不行，使用时若遇到连接断开或抛错，请及时调用各自的close 方法主动释放资源。 1.6. Comet: Comet is a collection of techniques prior to HTML5 which use streaming and long-polling to achieve real time applications. Read more on wikipedia or this article. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/协议_WebSocket.html":{"url":"Interview/frontend/协议_WebSocket.html","title":"协议_WebSocket","keywords":"","body":"1. WebSocket 教程1.1. 一、为什么需要 WebSocket？1.2. 二、简介1.3. 三、客户端的简单示例1.4. 四、客户端的 API1.4.1. 4.1 WebSocket 构造函数1.4.2. 4.2 webSocket.readyState1.4.3. 4.3 webSocket.onopen1.4.4. 4.4 webSocket.onclose1.4.5. 4.5 webSocket.onmessage1.4.6. 4.6 webSocket.send()1.4.7. 4.7 webSocket.bufferedAmount1.4.8. 4.8 webSocket.onerror1.5. 五、服务端的实现1.6. 六、WebSocketd1.7. 七、参考链接1. WebSocket 教程 作者： 阮一峰 日期： 2017年5月15日 WebSocket 是一种网络通信协议，很多高级功能都需要它。 1.1. 一、为什么需要 WebSocket？ 初次接触 WebSocket 的人，都会问同样的问题：我们已经有了 HTTP 协议，为什么还需要另一个协议？它能带来什么好处？ 答案很简单，因为 HTTP 协议有一个缺陷：通信只能由客户端发起。 举例来说，我们想了解今天的天气，只能是客户端向服务器发出请求，服务器返回查询结果。HTTP 协议做不到服务器主动向客户端推送信息。 这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。我们只能使用\"轮询\"：每隔一段时候，就发出一个询问，了解服务器有没有新的信息。最典型的场景就是聊天室。 轮询的效率低，非常浪费资源（因为必须不停连接，或者 HTTP 连接始终打开）。因此，工程师们一直在思考，有没有更好的方法。WebSocket 就是这样发明的。 1.2. 二、简介 WebSocket 协议在2008年诞生，2011年成为国际标准。所有浏览器都已经支持了。 它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。 其他特点包括： real-time 双全工双向通信 建立在 TCP 协议之上，服务器端的实现比较容易。 可以发送文本，也可以发送二进制数据。 没有同源限制，客户端可以与任意服务器通信。 与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。 数据格式比较轻量，性能开销小，通信高效。 协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。 ws://example.com:80/some/path 1.3. 三、客户端的简单示例 WebSocket 的用法相当简单。 下面是一个网页脚本的例子（点击这里看运行结果），基本上一眼就能明白。 var ws = new WebSocket(\"wss://echo.websocket.org\"); ws.onopen = function(evt) { console.log(\"Connection open ...\"); ws.send(\"Hello WebSockets!\"); }; ws.onmessage = function(evt) { console.log( \"Received Message: \" + evt.data); ws.close(); }; ws.onclose = function(evt) { console.log(\"Connection closed.\"); }; 1.4. 四、客户端的 API WebSocket 客户端的 API 如下。 1.4.1. 4.1 WebSocket 构造函数 WebSocket 对象作为一个构造函数，用于新建 WebSocket 实例。 var ws = new WebSocket('ws://localhost:8080'); 执行上面语句之后，客户端就会与服务器进行连接。 实例对象的所有属性和方法清单，参见这里。 1.4.2. 4.2 webSocket.readyState readyState属性返回实例对象的当前状态，共有四种。 CONNECTING：值为0，表示正在连接。 OPEN：值为1，表示连接成功，可以通信了。 CLOSING：值为2，表示连接正在关闭。 CLOSED：值为3，表示连接已经关闭，或者打开连接失败。 下面是一个示例。 switch (ws.readyState) { case WebSocket.CONNECTING: // do something break; case WebSocket.OPEN: // do something break; case WebSocket.CLOSING: // do something break; case WebSocket.CLOSED: // do something break; default: // this never happens break; } 1.4.3. 4.3 webSocket.onopen 实例对象的onopen属性，用于指定连接成功后的回调函数。 ws.onopen = function () { ws.send('Hello Server!'); } 如果要指定多个回调函数，可以使用addEventListener方法。 ws.addEventListener('open', function (event) { ws.send('Hello Server!'); }); 1.4.4. 4.4 webSocket.onclose 实例对象的onclose属性，用于指定连接关闭后的回调函数。 ws.onclose = function(event) { var code = event.code; var reason = event.reason; var wasClean = event.wasClean; // handle close event }; ws.addEventListener(\"close\", function(event) { var code = event.code; var reason = event.reason; var wasClean = event.wasClean; // handle close event }); 1.4.5. 4.5 webSocket.onmessage 实例对象的onmessage属性，用于指定收到服务器数据后的回调函数。 ws.onmessage = function(event) { var data = event.data; // 处理数据 }; ws.addEventListener(\"message\", function(event) { var data = event.data; // 处理数据 }); 注意，服务器数据可能是文本，也可能是二进制数据（blob对象或Arraybuffer对象）。 ws.onmessage = function(event){ if(typeof event.data === String) { console.log(\"Received data string\"); } if(event.data instanceof ArrayBuffer){ var buffer = event.data; console.log(\"Received arraybuffer\"); } } 除了动态判断收到的数据类型，也可以使用binaryType属性，显式指定收到的二进制数据类型。 // 收到的是 blob 数据 ws.binaryType = \"blob\"; ws.onmessage = function(e) { console.log(e.data.size); }; // 收到的是 ArrayBuffer 数据 ws.binaryType = \"arraybuffer\"; ws.onmessage = function(e) { console.log(e.data.byteLength); }; 1.4.6. 4.6 webSocket.send() 实例对象的send()方法用于向服务器发送数据。 发送文本的例子。 ws.send('your message'); 发送 Blob 对象的例子。 var file = document.querySelector('input[type=\"file\"]')w.files[0]; ws.send(file); 发送 ArrayBuffer 对象的例子。 // Sending canvas ImageData as ArrayBuffer var img = canvas_context.getImageData(0, 0, 400, 320); var binary = new Uint8Array(img.data.length); for (var i = 0; i 1.4.7. 4.7 webSocket.bufferedAmount 实例对象的bufferedAmount属性，表示还有多少字节的二进制数据没有发送出去。它可以用来判断发送是否结束。 var data = new ArrayBuffer(10000000); socket.send(data); if (socket.bufferedAmount === 0) { // 发送完毕 } else { // 发送还没结束 } 1.4.8. 4.8 webSocket.onerror 实例对象的onerror属性，用于指定报错时的回调函数。 socket.onerror = function(event) { // handle error event }; socket.addEventListener(\"error\", function(event) { // handle error event }); 1.5. 五、服务端的实现 WebSocket 服务器的实现，可以查看维基百科的列表。 常用的 Node 实现有以下三种。 µWebSockets Socket.IO WebSocket-Node 具体的用法请查看它们的文档，这里不详细介绍了。 1.6. 六、WebSocketd 下面，我要推荐一款非常特别的 WebSocket 服务器：Websocketd。 它的最大特点，就是后台脚本不限语言，标准输入（stdin）就是 WebSocket 的输入，标准输出（stdout）就是 WebSocket 的输出。 举例来说，下面是一个 Bash 脚本counter.sh。 #!/bin/bash echo 1 sleep 1 echo 2 sleep 1 echo 3 命令行下运行这个脚本，会输出1、2、3，每个值之间间隔1秒。 $ bash ./counter.sh 1 2 3 现在，启动websocketd，指定这个脚本作为服务。 $ websocketd --port=8080 bash ./counter.sh 上面的命令会启动一个 WebSocket 服务器，端口是8080。每当客户端连接这个服务器，就会执行counter.sh脚本，并将它的输出推送给客户端。 var ws = new WebSocket('ws://localhost:8080/'); ws.onmessage = function(event) { console.log(event.data); }; 上面是客户端的 JavaScript 代码，运行之后会在控制台依次输出1、2、3。 有了它，就可以很方便地将命令行的输出，发给浏览器。 $ websocketd --port=8080 ls 上面的命令会执行ls命令，从而将当前目录的内容，发给浏览器。使用这种方式实时监控服务器，简直是轻而易举（代码）。 更多的用法可以参考官方示例。 Bash 脚本读取客户端输入的例子 五行代码实现一个最简单的聊天服务器 websocketd 的实质，就是命令行的 WebSocket 代理。只要命令行可以执行的程序，都可以通过它与浏览器进行 WebSocket 通信。下面是一个 Node 实现的回声服务greeter.js。 process.stdin.setEncoding('utf8'); process.stdin.on('readable', function() { var chunk = process.stdin.read(); if (chunk !== null) { process.stdout.write('data: ' + chunk); } }); 启动这个脚本的命令如下。 $ websocketd --port=8080 node ./greeter.js 官方仓库还有其他各种语言的例子。 1.7. 七、参考链接 How to Use WebSockets WebSockets - Send & Receive Messages Introducing WebSockets: Bringing Sockets to the Web Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/图片隐层且浏览器不下载.html":{"url":"Interview/frontend/图片隐层且浏览器不下载.html","title":"图片隐层且浏览器不下载","keywords":"","body":"1. 隐藏图片且不下载1.1. visibility 和 display 区别1.2. 浏览器不下载图片的办法1. 隐藏图片且不下载 1.1. visibility 和 display 区别 visibility 隐藏元素但标签位置还占用着。display 在 DOM 树中存在，但标签在页面上不占位，审查元素其看不到大小和位置 修改常规流中元素的 display 通常会造成文档重排。修改 visibility 属性只会造成本元素的重绘。 读屏器不会读取 display: none; 元素内容；会读取 visibility: hidden; 元素内容 1.2. 浏览器不下载图片的办法 无论是 display 还是 visibility 都无法阻止图片下载。只能隐藏。 用 div 套着 img，div display none 也无法组织图片请求。 img { display: none; visibility: hidden; } 但是div 换成 textarea 就好用，图片不会被请求。 更好的方法，使用 html template 标签 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/安全.html":{"url":"Interview/frontend/安全.html","title":"安全","keywords":"","body":"1. 前端安全类1.1. CSRF1.1.1. 原理1.2. XSS1.2.1. 原理1.2.2. XSS攻击类型1.2.3. 防御措施1. 前端安全类 XSS CSRF sql 注入：使用 parameterized stored procedure 1.1. CSRF cross-site request forgery 跨站请求伪造 1.1.1. 原理 用户登录过网站A A网站给用户下发 cookie 用户访问网站B B网站引诱用户点击 用户点击后请求了网站A的某个接口，因为cookie还在，A网站认为该登录用户进行了操作，可能添加删除数据 \b发生前提: 用户登陆过网站A，用户点击请求时cookie有效 document.write(` 来自csrf `); var iframe = document.createElement('iframe'); iframe.name = 'csrf'; iframe.style.display = 'none'; document.body.appendChild(iframe); setTimeout(() => { document.querySelector('[name=commentForm]').submit();//执行在攻击页面该脚本 }, 1000); 防御测试: Token 验证: 访问网站是会主动上传 cookie，但不会主动传 token。访问接口是没有 token 则不予通过验证，或者 验证码 referral 验证: \b页面来源是自己站点（同域名）才通过 隐层令牌: 隐藏在 http head 中，类似 token，使用方式有些区别 1.2. XSS cross-site scripting 跨站脚本攻击 1.2.1. 原理 不需要登录认证，向页面注入脚本，写入标签，执行有害脚本。可能是评论区添加注入的 1.2.2. XSS攻击类型 反射型 URL参数直接注入。http://loacalhost:8080/?fromalert(1)Google 存储型 存储到DB后读取时注入。xss 代码会保存到网站的数据中，比如保存到数据库，当其他用户在访问到一篇文章或一个评论时，这段代码会被从数据库中读取取出来，显示在用户页面上。XSS 攻击注入点: HTML节点内容、HTML属性、JavaScript代码、富文本 1.2.3. 防御措施 让插入的东西无法执行。KB\bB 编辑器。html escape。 转义 和 > &gt var escapeHtml = function(str) { if(!str) return ''; str = str.replace(//g,'&gt;'); return str; } .net 默认开启 XSS 防御，在提交表单的数据时会检测是否有 <> 这样危险字符 使用 cookie 的 httpOnly 属性，加上了这个属性的 cookie 字段，js 是无法进行读写的 浏览器自带的 XSS 攻击拦截机制: 设置 Header X-XSS-Protection。此机制只适用于参数出现在 HTML内容或属性 才会去拦截。只适用于反射型。并不是所有浏览器都支持 新的防御方法-CSP 内容安全策略 该安全策略的实现基于一个称作 Content-Security-Policy 的 HTTP 首部。 限制规则: child-src: 为 web workers 和其他内嵌浏览器内容定义 合法的源，例如用 和 加载到页面的内容。 connect-src: 限制能通过脚本接口加载的URL。 default-src: 为其他取指令提供备用服务 fetch directives. font-src: 限制通过 @font-face 加载的字体源。 frame-src: 限制通过类似 和 标签加载的内嵌内容源。 img-src: 限制图片和图标源 manifest-src: 限制 application manifest 文件源。 media-src: 限制通过 或 标签加载的媒体文件源。 object-src: 限制通过 , , 标签加载源。 script-src: 限制 javascript 源。 style-src: 限制层叠样式表文件源。 worker-src: 限制 Worker, SharedWorker, 或者 ServiceWorker 脚本源。 指定哪些可信，哪些不可信 'self' 'unsafe-inline''ubsafe-eval''none' XSS攻击重点: 检测页面内容(信任规则) 'nonce-' 一次性凭证 后台hash传递 'strit-dynamic' 后续脚本的信任 事例 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/模块化_AMD_CMD_UMD.html":{"url":"Interview/frontend/模块化_AMD_CMD_UMD.html","title":"模块化_AMD_CMD_UMD","keywords":"","body":"1. 模块化: AMD, CMD, CommonJS, UMD1.1. AMD (Asynchronous Module Definition)，代表 RequireJs1.2. CMD (Common Module Definition 公共模块定义)1.2.1. RequireJs seajs 比较1.3. CommonJS1.4. UMD（Universal Module Definition * 通用模块定义）1.5. ES6 import1.6. 自执行函数简单实现不暴露私有成员1. 模块化: AMD, CMD, CommonJS, UMD AMD 模块以浏览器第一的原则发展，异步加载模块，依赖前置提前加载，代表 RequireJS。RequireJS 从 2.0 开始，也改成可以延迟执行 CMD 异步加载，延迟执行，依赖后置就近加载，代表 seajs CommonJS 模块以服务器第一原则发展，选择同步加载，Node.js 使用 UMD 是 AMD 和 CommonJS 的糅合，ES2015 import 才是王道 (UMD) ES6 import 1.1. AMD (Asynchronous Module Definition)，代表 RequireJs ==AMD 是 RequireJS 在推广过程中对模块定义的规范化产出，AMD 是异步加载模块，推崇依赖前置。== define('module1', ['jquery'], ($) => { //do something... }); 代码中依赖被前置，当定义模块（module1）时，就会加载依赖（jquery） define(id?, dependencies?, factory) 第一个参数 id 为字符串类型，表示了模块标识，为可选参数。若不存在则模块标识应该默认定义为在加载器中被请求脚本的标识。如果存在，那么模块标识必须为顶层的或者一个绝对的标识。 第二个参数，dependencies ，是一个当前模块依赖的，已被模块定义的模块标识的数组字面量。 第三个参数，factory，是一个需要进行实例化的函数或者一个对象。 通过参数的排列组合，这个简单的API可以从容应对各种各样的应用场景，如下所述。 定义无依赖的模块 define({ add: function(x, y) { return x + y; } }); 定义有依赖的模块 define([\"alpha\"], function( alpha ){ return { verb : function(){ return alpha.verb() + 1 ; } } }); 定义数据对象模块 define({ users: [], members: [] }); 具名模块 define(\"alpha\", [ \"require\", \"exports\", \"beta\" ], function( require, exports, beta ){ export.verb = function(){ return beta.verb(); // or: return require(\"beta\").verb(); } }); 包装模块 define(function(require, exports, module) { var a = require('a'), b = require('b'); exports.action = function() {}; } ); // Or require(['foo', 'bar'], function(foo, bar) { foo.func(); bar.func(); }); 不考虑多了一层函数外，格式和 Node.js 是一样的：使用 require 获取依赖模块，使用 exports 导出 API。 除了define外，AMD 还保留一个关键字 require。require 作为规范保留的全局标识符，可以实现为 module loader，也可以不实现。 1.2. CMD (Common Module Definition 公共模块定义) CMD 是 SeaJS 在推广过程中对模块定义的规范化产出，对于模块的依赖，CMD 是延迟执行，推崇依赖就近。 define((require, exports, module) => { module.exports = { fun1: () => { var $ = require('jquery'); return $('#test'); } }; }); 如上代码，只有当真正执行到 fun1 方法时，才回去执行jquery。 同时 CMD 也是延自 CommonJS Modules/2.0 规范 1.2.1. RequireJs seajs 比较 //AMD define(['./a', './b'], function(a, b) { //依赖一开始就写好 a.test(); b.test(); }); //CMD define(function(require, exports, module) { //依赖可以就近书写 var a = require('./a'); a.test(); //软依赖 if (status) { var b = require('./b'); b.test(); } }); 虽然 AMD 也支持 CMD 写法，但依赖前置是官方文档的默认模块定义写法。 AMD 的 API 默认是一个当多个用，CMD严格的区分推崇职责单一。例如：AMD 里 require 分全局的和局部的。CMD 里面没有全局的 require，提供 seajs.use() 来实现模块系统的加载启动。CMD 里每个 API 都简单纯粹。 1.3. CommonJS 提到 CMD，就不得不提起 CommonJS，CommonJS 是服务端模块的规范，由于 Node.js 被广泛认知。 根据 CommonJS 规范，一个单独的文件就是一个模块。加载模块使用 require 方法，该方法读取一个文件并执行，最后返回文件内部的 module.exports 对象。 //file1.js module.exports = { a: 1 }; //file2.js var f1 = require('./file1'); var v = f1.a + 2; module.exports ={ v: v }; CommonJS 加载模块是同步的，所以只有加载完成才能执行后面的操作。像 Node.js 主要用于服务器的编程，加载的模块文件一般都已经存在本地硬盘，所以加载起来比较快，不用考虑异步加载的方式，所以 CommonJS 规范比较适用。但如果是浏览器环境，要从服务器加载模块，这是就必须采用异步模式。所以就有了 AMD CMD 解决方案。 1.4. UMD（Universal Module Definition * 通用模块定义） UMD 是 AMD 和 CommonJS 的一个糅合。AMD 是浏览器优先，异步加载；CommonJS 是服务器优先，同步加载。 既然要通用，怎么办呢？那就先判断是否支持 node.js 的模块，存在就使用 node.js；再判断是否支持 AMD（define是否存在），存在则使用 AMD 的方式加载。这就是所谓的 UMD。 ((root, factory) => { if (typeof define === 'function' && define.amd) { //AMD define(['jquery'], factory); } else if (typeof exports === 'object') { //CommonJS var $ = require('jquery'); module.exports = factory($); } else { //都不是，浏览器全局定义 root.testModule = factory(root.jQuery); } })(this, ($) => { //do something... 这里是真正的函数体 }); 1.5. ES6 import ES6 modules 的 import 和 export statements 相比完全动态的 CommonJS require，有着本质的区别。 只能作为模块顶层的语句出现，不能出现在 function 里面或是 if 里面。（ECMA-262 15.2) import 的模块名只能是字符串常量。(ECMA-262 15.2.2) 不管 import 的语句出现的位置在哪里，在模块初始化的时候所有的 import 都必须已经导入完成。换句话说，ES6 imports are hoisted。(ECMA-262 15.2.1.16.4 - 8.a) import binding 是 immutable 的，类似 const。比如说你不能 import { a } from './a' 然后给 a 赋值个其他什么东西。(ECMA-262 15.2.1.16.4 - 12.c.3) 这些设计虽然使得灵活性不如 CommonJS 的 require，但却保证了 ES6 modules 的依赖关系是确定 (deterministic) 的，和运行时的状态无关，从而也就保证了 ES6 modules 是可以进行可靠的静态分析的。对于主要在服务端运行的 Node 来说，所有的代码都在本地，按需动态 require 即可。但对于要下发到客户端的 web 代码而言，要做到高效的按需使用，不能等到代码执行了才知道模块的依赖，必须要从模块的静态分析入手。这是 ES6 modules 在设计时的一个重要考量，也是为什么没有直接采用 CommonJS。正是基于这个基础上，才使得 tree-shaking 成为可能（这也是为什么 rollup 和 webpack 2 都要用 ES6 module syntax 才能 tree-shaking），所以说与其说 tree-shaking 这个技术怎么了不起，不如说是 ES6 module 的设计在模块静态分析上的种种考量值得赞赏。 1.6. 自执行函数简单实现不暴露私有成员 var module1 = (function() { var _count = 0; var m1 = function() { //... }; var m2 = function() { //... }; return { x: m1, y: m2 }; })(); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/浏览器渲染机制.html":{"url":"Interview/frontend/浏览器渲染机制.html","title":"浏览器渲染机制","keywords":"","body":"1. 渲染机制1.1. doctype1.2. 浏览器渲染过程1.2.1. 重排 reflow1.2.2. 重绘 repaint1.2.3. 注意1.3. 一个页面从输入 URL 到页面加载显示完成，这个过程中都发生了什么？(重要)1.3.1. 参考1. 渲染机制 1.1. doctype DTD (document type definition，文档类型定义) 告诉浏览器文档类型，浏览器再决定用什么引擎解析渲染之 doctype 告诉浏览器 当前DTD(当前使用的文档类型) 常见的 doctype 类型： html5： html4.01 strict：不包括废弃标签如 font html4.01 transitional 过渡版本 1.2. 浏览器渲染过程 首先，解析 HTML Source，构建 DOM Tree 同时，解析 CSS Style，构建 CSSOM Tree 然后，组合 DOM Tree 与 CSSOM Tree，去除不可见元素，构建 Render Tree，同时进行 Layout Painting Composition Display 页面变化重新渲染时： 再执行 Reflow，根据 Render Tree 计算每个可见元素的布局(几何属性) 最后，执行 Repaint，通过绘制流程，将每个像素渲染到屏幕上。 在第三步，==在建立 Render Tree 时(WebKit 中的「Attachment」过程)，浏览器就要为每个 DOM Tree 中的元素根据 CSS 的解析结果(Style Rules)来确定生成怎样的 renderer。对于每个 DOM 元素，必须在所有 Style Rules 中找到符合的 selector 并将对应的规则进行合并。选择器的「解析」实际是在这里执行的，在遍历 DOM Tree 时，从 Style Rules 中去寻找对应的 selector。== 所以，css 解析顺序: 从右到左进行查找。如果从左到右的顺序，那么每条选择器都需要遍历整个 DOM 树，性能很受影响。所谓高效的 CSS 就是让浏览器在查找 style 匹配的元素的时候尽量进行少的查找, 所以选择器最好写的简洁一点。 Layout 告诉 render tree 每个元素位置，宽高等信息。 Painting: This is the process of filling in pixels. It involves drawing out elements. Compositing: parts of the page were drawn into potentially multiple layers they need to be drawn to the screen in the correct order so that the page renders correctly. (组合：多层显示顺序) For more information: https://developers.google.com/web/fundamentals/performance/rendering/?hl=en 1.2.1. 重排 reflow 页面字体大小改变或者元素移动位置等，浏览器需要重新计算每个元素盒子模型的位置。这个过程叫 reflow。回炉(重新塑形)。举个例子，页面上节点是以树的形式展现的。假如我使用 JavaScript 砍掉一个节点，这棵树为了不脱节，肯定要重新梳理一遍，将砍掉的那个断点重新结合起来又形成一颗完整的树，而这个结合梳理过程就是这里的 reflow，所谓回流，就是由于某些原因(如修改)，要将元素回过头来重新“流”一遍 触发 reflow: 增删改 DOM 结点 移动 DOM 位置、动画 css 样式 display, height 等改变 resize scroll 有可能 修改网页字体(不要这样做，性能问题) 特殊：offset、scroll、clientX、getComputedStyle、currentStyle： 由于浏览器在处理批量修改页面元素样式时，会将批量操作缓存起来，然后再做一次 reflow 过程(异步 reflow)，避免每次操作都执行 reflow 消耗资源。但是如果在某个上述特殊操作之后立马调用了以上执行属性，为了等够得到最新的样式，会检查缓存的操作，是否需要 reflow，这样就 flush 出最新的样式。 如何减少 reflow ？ 不轻易增删改 DOM，不要修改网页字体，不轻易移动 DOM 等。 少用 display:none 而使用 visibility:hidden 减少不必要的 DOM 深度。改变 DOM 节点树上任何一个层级都会影响从根结点一直到修改的子节点。 精简 css，去除没有用处的 css 如果你想让复杂的表现发生改变，例如动画效果，那么请在这个流动线之外实现它。使用 position-absolute 或 position-fixed 来实现它。 避免不必要的复杂的 css 选择符，尤其是使用子选择器，或消耗更多的CPU去做选择器匹配。 减少样式的重新计算，即减少 offset、scroll、client*、getComputedStyle、currentStyle 的使用，因为每次调用都会刷新操作缓冲区，执行 reflow & repaint。 避免 window.onresize 1.2.2. 重绘 repaint repaint happens when you change the look of an element without changing the size and shape. This doesn't cause reflow as geometry of the element didn't changed. 触发 repaint： change background color change text color visibility hidden DOM 改变，如添加了新元素，reflow repaint 都发生。 如何尽量减少 repaint 频率：减少页面颜色改变。最后一次性添加结点，而不要每次操作 DOM 都立马修改DOM。 1.2.3. 注意 Render Tree 只包含渲染网页所需要的节点 Reflow 过程是布局计算每个对象的精确位置和大小 Repaint 过程则是将 Render Tree 的每个像素渲染到屏幕上。 1.3. 一个页面从输入 URL 到页面加载显示完成，这个过程中都发生了什么？(重要) 从 URL 规范、HTTP协议、DNS、CDN、数据库查询、到浏览器流式解析、CSS 规则构建、layout、repaint、onload/DOMContentLoaded、JS 执行、JS API 绑定等等 在浏览器地址栏输入 URL 浏览器查看 强缓存 是否命中 如果资源未缓存，发起新请求 如果已缓存，检验是否足够新鲜，足够新鲜直接提供给客户端，否则与服务器进行验证。 检验新鲜通常有两个 HTTP 头进行控制 Expires 和 Cache-Control： HTTP1.0 提供 Expires，值为一个绝对时间表示缓存新鲜日期 HTTP1.1 增加了 Cache-Control: max-age=,值为以秒为单位的相对过期时间 浏览器 解析 URL 获取协议，主机，端口，path。并 组装一个 HTTP(GET)请求报文 浏览器 获取主机 ip 地址，过程如下：通过 DNS 解析获取网址 浏览器缓存 本机缓存 hosts文件 路由器缓存 ISP DNS缓存 通过 DNS 解析获取网址 递归查询(可能存在负载均衡导致每次IP不一样) 打开一个 socket 与目标IP地址、端口建立 TCP 链接，三次握手如下： 客户端发送一个 TCP 的SYN=1，Seq=X的包到服务器端口 （客户端：我要和你连接） 服务器发回SYN=1， ACK=X+1， Seq=Y的响应包（服务端：行啊，你发个约定指令给我，我就跟你继续通信） 客户端发送ACK=Y+1， Seq=Z（客户端：我按照约定发这个指令了） TCP 链接建立后 发送 HTTP 请求 服务器接受请求并解析，将请求转发到服务程序 服务器检查 HTTP 请求头是否包含协商缓存验证信息(Last-Modified, Etag)，如果验证缓存新鲜，返回304等对应状态码 处理程序读取完整请求并准备 HTTP 响应，可能需要查询数据库等操作 服务器将响应报文通过 TCP 连接发送回浏览器 浏览器接收HTTP响应，然后根据情况选择关闭 TCP 连接或者保留重用，关闭 TCP 连接的四次握手如下： 主动方发送 Fin=1, Ack=Z, Seq= X (服务器：我给你发送结果了) 报文被动方发送 ACK=X+1, Seq=Z （客户端：我收到结果了） 报文被动方发送 Fin=1, ACK=X, Seq=Y （客户端：请关闭链接吧） 报文主动方发送 ACK=Y, Seq=X 报文 （服务器：行，我关闭了哈） 浏览器检查响应状态码：是否为1XX，3XX， 4XX， 5XX，这些情况处理与2XX不同 如果资源可缓存，进行缓存 对响应进行解码(例如gzip压缩) 根据资源类型决定如何处理(假设资源为HTML文档) 解析HTML文档，构件DOM树，下载资源，构造 CSSOM 树，Render Tree，Layout, 执行js脚本，这些操作没有严格的先后顺序，以下分别解释 构建DOM树： Tokenizing：根据HTML规范将字符流解析为标记 Lexing：词法分析将标记转换为对象并定义属性和规则 DOM construction：根据 HTML 标记关系将对象组成 DOM 树 解析过程中遇到图片、样式表、js文件，启动下载 构建CSSOM树： Tokenizing：字符流转换为标记流 Node：根据标记创建节点 CSSOM：节点创建CSSOM树 根据 DOM 树和 CSSOM 树构建渲染树: 从DOM树的根节点遍历所有可见节点，不可见节点包括：1)script, meta这样本身不可见的标签。2)被css隐藏的节点，如display: none 对每一个可见节点，找到恰当的 CSSOM 规则并应用 发布可视节点的内容和计算样式 js 解析如下： 浏览器创建 Document 对象并解析 HTML，将解析到的元素和文本节点添加到文档中，此时 document.readyState 为 loading HTML解析器遇到没有 async 和 defer 的 script 时，将他们添加到文档中，然后执行行内或外部脚本。这些脚本会同步执行，并且在脚本下载和执行时解析器会暂停。这样就可以用 document.write() 把文本插入到输入流中。同步脚本经常简单定义函数和注册事件处理程序，他们可以遍历和操作 script 和他们之前的文档内容 当解析器遇到设置了 async 属性的 script 时，开始下载脚本并继续解析文档。脚本会在它下载完成后尽快执行，但是解析器不会停下来等它下载。异步脚本禁止使用document.write()，它们可以访问自己 script 和之前的文档元素 当文档完成解析，document.readState 变成 interactive 所有 defer 脚本会按照在文档出现的顺序执行，延迟脚本能访问完整文档树，禁止使用 document.write() 浏览器在 Document 对象上触发 DOMContentLoaded 事件 此时文档完全解析完成，浏览器可能还在等待如图片等内容加载，等这些内容完成载入并且所有异步脚本完成载入和执行，document.readState 变为 complete , window 触发 load 事件 reflow, repaint, 显示页面(HTML解析过程中会逐步显示页面) 浏览器会开启一个线程来处理这个请求，对 URL 分析判断如果是 http 协议就按照 Web 方式来处理; 调用浏览器内核中的对应方法，比如 WebView 中的 loadUrl 方法; 通过 DNS 解析获取网址的 IP 地址，设置 UA 等信息发出第二个GET请求; 进行 HTTP 协议会话，客户端发送报头(请求报头); 进入到web服务器上的 Web Server，如 Apache、Tomcat、Node.JS 等服务器; 进入部署好的后端应用，如 PHP、Java、JavaScript、Python 等，找到对应的请求处理; 处理结束回馈报头，此处如果浏览器访问过，缓存上有对应资源，会与服务器最后修改时间对比，一致则返回304; 浏览器开始下载 html文档(响应报头，状态码200)，同时使用缓存; 文档树建立，根据标记请求所需指定MIME类型的文件(比如css、js)，同时设置了 cookie; 页面开始渲染DOM(这里继续说)，JS 根据 DOM API 操作 DOM，执行事件绑定等，页面显示完成。 1.3.1. 参考 https://segmentfault.com/a/1190000008849210 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/浏览器缓存.html":{"url":"Interview/frontend/浏览器缓存.html","title":"浏览器缓存","keywords":"","body":"1. 缓存1.1. 缓存类型1.1.1. 强缓存1.1.2. 协商缓存1.2. 浏览器请求流程图1.3. 写法1. 缓存 分类：服务器缓存，第三方缓存，浏览器缓存 http://imweb.io/topic/55c6f9bac222e3af6ce235b9 1.1. 缓存类型 强缓存与协商缓存区别：强缓存不发请求到服务器，协商缓存会发请求到服务器。 1.1.1. 强缓存 浏览器在加载资源时，先根据这个资源的一些 http header 判断它是否命中强缓存，强缓存如果命中，浏览器直接从自己的缓存中读取资源，不会发请求到服务器。比如某个 css 文件，如果浏览器在加载它所在的网页时，这个 css 文件的缓存配置命中了强缓存，浏览器就直接从缓存中加载这个 css，连请求都不会发送到网页所在服务器。注意：以下两个 header 可以只启用一个，也可以同时启用，当 response header 中，Expires 和 Cache-Control 同时存在时，Cache-Control 优先级高于 Expires。 Expires 设置 绝对过期时间 。http 1.0 提出的一个表示资源过期时间的 header，由服务器返回，用 GMT 格式的字符串表示，如：Expires:Thu, 31 Dec 2016 23:55:55 GMT。问题：如果客户端的时间与服务器的时间相差很大（比如时钟不同步，或者跨时区），那么误差就很大 Cache-Control max-age=[秒] — 相对时间间隔，而不是绝对过期时间。从请求时间开始到过期时间之间的秒数。 no-cache - 强制每次请求直接发送给源服务器，而不经过本地缓存版本的校验。这对于需要确认认证应用很有用（可以和public结合使用），或者严格要求使用最新数据的应用（不惜牺牲使用缓存的所有好处） must-revalidate no-store no-transform public private 1.1.2. 协商缓存 当强缓存没有命中的时候，浏览器一定会发送一个请求到服务器，通过服务器端依据资源的另外一些 http header 验证这个资源是否命中协商缓存，如果协商缓存命中，服务器会将这个请求返回（304），但是不会返回这个资源的数据，而是告诉客户端可以直接从缓存中加载这个资源，于是浏览器就又会从自己的缓存中去加载这个资源；若未命中请求，则将资源返回客户端，并更新本地缓存数据（200）。 Last-Modified/If-Modified-Since 配合 Cache-Control 如果你第二次请求相同的数据，你可以告诉服务器你上一次获得的最后修改日期：在你的请求中发送一个 If-Modified-Since 头信息，它包含了上一次从服务器连同数据所获得的日期。如果数据从那时起没有改变，服务器将返回一个特殊的 HTTP 状态代码 304 ，这意味着 \"从上一次请求后这个数据没有改变\"，不再重新发送数据。你去缓存中拿数据。 Last-Modified：web 服务器在响应请求时，告诉浏览器资源的最后修改时间。 If-Modified-Since：当资源过期时（强缓存失效），发现资源具有 Last-Modified 声明，则再次向 web 服务器请求时带上头 If-Modified-Since，表示请求时间。服务器收到请求后发现有头 If-Modified-Since 则与被请求资源的最后修改时间进行比对。若最后修改时间较新，说明资源又被改动过，则响应整片资源内容（写在响应消息包体内），HTTP 200；若最后修改时间较旧，说明资源无新修改，则响应 HTTP 304 (无需包体，节省浏览)，告知浏览器继续使用所保存的 cache。 缺点： Last-Modified 标注的最后修改只能精确到秒级，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间（无法及时更新文件） 如果某些文件会被定期生成，但内容并没变，而 Last-Modified 却改变了，导致文件没法使用缓存。 HTTP 1.1 中 Etag 解决了上述问题。 Etag/If-None-Match 配合 Cache-Control Etag 例子见 Aspnetcore.Camps repo Etag：web服务器响应请求时，告诉浏览器当前资源在服务器的唯一标识（生成规则由服务器决定）。Apache 中 Etag 的值，默认是对文件的索引节（INode），大小（Size）和最后修改时间（MTime）进行 Hash 后得到的。是实现与最近修改数据检查同样的功能的另一种方法：没有变化时不重新下载数据。其工作方式是：服务器发送你所请求的数据的同时，响应报文里面 Etag: hash。hash 的确定完全取决于服务器。当第二次请求相同的数据时，在浏览器请求头带上 If-None-Match: hash (hash 来自之前服务器返回的 Etag)，服务器进行比对，如果数据没有改变，服务器将返回 304 状态代码。 If-None-Match：当资源过期时（使用 Cache-Control 标识的 max-age），发现资源具有 Etag 声明，则再次向服务器请求时带上头 If-None-Match（ Etag 的值）。服务器收到请求后发现有头 If-None-Match 则与被请求资源的相应校验串进行比对，决定返回200或304。 Last-Modified 与 Etag 一起使用时，服务器会优先验证 Etag。 1.2. 浏览器请求流程图 浏览器第一次请求流程图: 浏览器再次请求时: 1.3. 写法 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/深拷贝_浅拷贝.html":{"url":"Interview/frontend/深拷贝_浅拷贝.html","title":"深拷贝_浅拷贝","keywords":"","body":"1. 深拷贝 和 浅拷贝1.1. 实现浅拷贝1.2. 实现深拷贝1. 深拷贝 和 浅拷贝 浅拷贝只复制指向某个对象的指针，而不复制对象本身，新旧对象还是共享同一块内存。 深拷贝会另外创造一个一模一样的对象，新对象跟原对象不共享内存，修改新对象不会改到原对象。 1.1. 实现浅拷贝 var obj1 = { a: 10, b: 20, c: 30 }; var obj2 = obj1; obj2.b = 100; console.log(obj1); // { a: 10, b: 100, c: 30 } 1.2. 实现深拷贝 method 1: 手动复制方式 var obj1 = { a: 10, b: 20, c: 30 }; var obj2 = { a: obj1.a, b: obj1.b, c: obj1.c }; obj2.b = 100; console.log(obj1); // { a: 10, b: 20, c: 30 } method 2: Object.assign, { ...obj } obj1 = { a: 10, b: 20, c: 30 }; obj2 = Object.assign({}, obj1); // { ...obj1 } obj2.b = 100; console.log(obj1); // { a: 10, b: 20, c: 30 } method 3: 转成 JSON 再转回来 用 JSON.stringify 把对象转成字符串，再用 JSON.parse 把字符串转成新的对象。 缺点：只有可以转成 JSON 格式的对象才可以这样用，像 function 没办法转成 JSON。 method 4: 第三方 jquery，有提供一个 $.extend 可以用来做 Deep Copy。 lodash，也有提供 _.cloneDeep 用来做 Deep Copy。 method 5: 递归实现深拷贝 easy version: create an empty obj which will be returned as a new object loop thru each property of original object if the value for a property is not object, assign it to new obj else if property is object, recursively call deepClone function deepClone(o) { var temp = {}; for (var k in o) { if (typeof o[k] == 'object') { temp[k] = deepClone(o[k]); } else { temp[k] = o[k]; } } return temp; } complex version: please search common.js -- deepClone Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/盒模型及宽高.html":{"url":"Interview/frontend/盒模型及宽高.html","title":"盒模型及宽高","keywords":"","body":"1. 盒模型1.1. js 获取盒模型的宽高1. 盒模型 标准盒模型 + IE 盒模型（怪异盒模型） box-sizing: content-box /*标准盒模型：default*/ box-sizing: border-box /*IE 盒模型：padding border 算在 宽高中*/ 1.1. js 获取盒模型的宽高 dom.style.height // 只能获取内联样式 dom.currentStyle.width // IE，3种都能获得 window.getComputedStyle(dom).width // 其他浏览器，3种都能获得 dom.getBoundingClientRect().width // 计算一个元素在视窗中的绝对位置以及宽，高。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/算法.html":{"url":"Interview/frontend/算法.html","title":"算法","keywords":"","body":"1. 算法1. 算法 阿里云金融性业务一定考算法 排序 堆栈、队列、链表 递归 波兰式和逆波兰式（时间紧张不看） 快速排序 选择排序 希尔排序 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/资源preload_prefetch.html":{"url":"Interview/frontend/资源preload_prefetch.html","title":"资源preload_prefetch","keywords":"","body":"1. resource preload, prefetch1.1. Cache Behavior1. resource preload, prefetch https://medium.com/reloading/preload-prefetch-and-priorities-in-chrome-776165961bbf preload is a declarative fetch, allowing you to force the browser to make a request for a resource without blocking the document’s onload event. Prefetch is a hint to the browser that a resource might be needed, but delegates deciding whether and when loading it is a good idea or not to the browser. Preload resources you have high-confidence will be used in the current page. Prefetch resources likely to be used for future navigation across multiple navigation boundaries. 1.1. Cache Behavior Chrome has four caches: the HTTP cache, memory cache, Service Worker cache & Push cache. Both preload and prefetched resources are stored in the HTTP cache. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/通信_跨域.html":{"url":"Interview/frontend/通信_跨域.html","title":"通信_跨域","keywords":"","body":"1. 前后端通信1.1. 同源策略和限制1.2. 前后端通信方式1.2.1. 如何实现浏览器内多个标签页之间的通信? (阿里)1.2.2. WebSocket 如何兼容低浏览器？(阿里)1.3. 创建 Ajax 要点1.4. 跨域1.4.1. Jsonp1.4.2. Hash 原理1.4.3. WebSocket1.4.4. postMessage1.4.5. CORS 跨域资源共享 (Cross-Origin Resource Sharing)1. 前后端通信 1.1. 同源策略和限制 源：协议、域名、端口 限制：不是一个源的文档没有权利去操作另一个源的文档，包括 cookie, localStorage, indexDB, DOM 无法获取, Ajax 无法发送 1.2. 前后端通信方式 Ajax 同源限制 WebSocket 不受限制，因为请求头中加入了 Origin CORS 支持同源和非同源 1.2.1. 如何实现浏览器内多个标签页之间的通信? (阿里) WebSocket、SharedWorker；也可以调用 localStorage、cookies 等本地存储方式； localStorage 另一个浏览上下文里被添加、修改或删除时，它都会触发一个事件，我们通过监听事件，控制它的值来进行页面信息通信。 Safari 在无痕模式下设置 localStorage 值时会抛出 QuotaExceededError 的异常； // localStorage change, trigger below event window.addEventListener('storage', function(e) { document.querySelector('.my-key').textContent = e.key; document.querySelector('.my-old').textContent = e.oldValue; document.querySelector('.my-new').textContent = e.newValue; document.querySelector('.my-url').textContent = e.url; document.querySelector('.my-storage').textContent = e.storageArea; }); 1.2.2. WebSocket 如何兼容低浏览器？(阿里) Adobe Flash Socket ActiveX HTMLFile (IE) 基于 multipart 编码发送 XHR 基于长轮询的 XHR 1.3. 创建 Ajax 要点 XMLHttpRequest 对象的工作流程、兼容性、事件触发条件和顺序 /** * [json 实现 ajax 的json] * @param {[type]} options [description] * @return {[type]} [description] */ util.json = function(options) { var opt = { url: '', type: 'get', data: {}, success: function() {}, error: function() {} }; util.extend(opt, options); if (opt.url) { var xhr = XMLHttpRequest ? new XMLHttpRequest() : new ActiveXObject('Microsoft.XMLHTTP'); var data = opt.data, url = opt.url, type = opt.type.toUpperCase(), dataArr = []; for (var k in data) { dataArr.push(k + '=' + data[k]); } if (type === 'GET') { url = url + '?' + dataArr.join('&'); xhr.open(type, url.replace(/\\?$/g, ''), true); xhr.send(); } if (type === 'POST') { xhr.open(type, url, true); xmlhttp.setRequestHeader('Content-type', 'application/x-www-form-urlencoded'); xhr.send(dataArr.join('&')); } xhr.onload = function() { // 304 缓存中数据未变，206 video等大文件媒体资源成功 if (xhr.status === 200 || xhr.status === 304) { var res; if (opt.success && opt.success instanceof Function) { res = xhr.responseText; if (typeof res === 'string') { res = JSON.parse(res); opt.success.call(xhr, res); } } } else { if (opt.error && opt.error instanceof Function) { opt.error.call(xhr, res); } } }; } }; 1.4. 跨域 Jsonp Hash (hash # 改变页面不刷新，? 后面 queryString 改变会刷新页面) postMessage (html5) WebSocket (html5) CORS（支持跨域的变种 ajax，当发送 ajax 跨域请求时，http 请求头加入 origin） 1.4.1. Jsonp 利用 script 标签可以不同源加载实现的。Jsonp 只支持 GET 请求 在主站客户端 window 全局注册一个函数 cb url 传递参数和回调函数名字 服务端解析 url 后根据参数拿到数据，执行这个函数，数据作为函数的参数 删除全局注册函数 Jsonp 的优缺点 优点 它的兼容性更好，在更加古老的浏览器中都可以运行，不需要 XMLHttpRequest 或 ActiveX 的支持 在请求完毕后可以通过调用 callback 的方式回传结果。将回调方法的权限给了调用方。这个就相当于将 controller 层和 view 层分开了。我提供的 Jsonp 服务只提供纯服务的数据，至于提供服务以后的页面渲染和后续 view 操作都由调用者来自己定义就好了。如果有两个页面需要渲染同一份数据，你们只需要有不同的渲染逻辑就可以了，逻辑都可以使用同一个 Jsonp 服务。 缺点 它只支持 GET 请求而不支持 POST 等其它类型的HTTP请求 Jsonp 在调用失败的时候不会返回各种 HTTP 状态码。解决：timeout 触发 onerror 事件 安全性。万一假如提供 Jsonp 的服务存在页面注入漏洞，即它返回的 javascript 的内容被人控制的。那么所有调用这个 Jsonp 的网站都会存在漏洞。于是无法把危险控制在一个域名下。所以在使用 Jsonp 的时候必须要保证使用的 Jsonp 服务必须是安全可信的。 basic demo 1 Jsonp.html 页面定义一个函数，然后在远程 remote.js 中传入数据进行调用。 var localHandler = function(data){ alert('我是本地函数，可以被跨域的remote.js文件调用，远程js带来的数据是：' + data.result); }; remote.js文件代码如下： localHandler({\"result\":\"我是远程js带来的数据\"}); demo 2 怎么让远程 js 知道它应该调用的本地函数叫什么名字呢？ 通过 queryString 传递回调函数名字，Jsonp 服务端读取并动态创建 Jsonp.html页面的代码： // 得到航班信息查询结果后的回调函数 var flightHandler = function(data){ alert('你查询的航班结果是：票价 ' + data.price + ' 元，' + '余票 ' + data.tickets + ' 张。'); }; // 提供 Jsonp 服务的 url 地址（不管是什么类型的地址，最终生成的返回值都是一段javascript代码） var url = \"http://flightQuery.com/Jsonp/flightResult.aspx?code=CA1998&callback=flightHandler\"; // 创建 script 标签，设置其属性 var script = document.createElement('script'); script.setAttribute('src', url); // 把 script 标签加入 head，此时调用开始 document.getElementsByTagName('head')[0].appendChild(script); 不再直接把远程js文件写死，而是编码实现动态查询，而这也正是Jsonp客户端实现的核心部分。我们看到调用的 url 中传递了一个code参数，告诉服务器我要查的是CA1998次航班的信息，而callback参数则告诉服务器，我的本地回调函数叫做flightHandler，所以请把查询结果传入这个函数中进行调用。 服务器读取 url 根据 queryString 生成代码： flightHandler({ \"code\": \"CA1998\", \"price\": 1780, \"tickets\": 5 }); jQuery 如何实现 Jsonp 调用？ $.ajax({ type: \"get\", async: false, url: \"http://flightQuery.com/Jsonp/flightResult.aspx?code=CA1998\", dataType: \"jsonp\", jsonp: \"callback\",//传递给请求处理程序或页面的，用以获得Jsonp回调函数名的参数名(一般默认为:callback) jsonpCallback:\"flightHandler\",//自定义的Jsonp回调函数名称，默认为jQuery自动生成的随机函数名，也可以写\"?\"，jQuery会自动为你处理数据 success: function(json){ alert('您查询到航班信息：票价： ' + json.price + ' 元，余票： ' + json.tickets + ' 张。'); }, error: function(){ alert('fail'); } }); 为什么我这次没有写 flightHandler 这个函数呢？而且竟然也运行成功了！jquery 在处理 Jsonp 类型的 ajax 时（虽然 jquery 也把 Jsonp 归入了 ajax，但其实它们真的不是一回事儿），自动帮你生成回调函数并把数据取出来供 success 属性方法来调用。 jsonp 错误捕获 如果你把 url 参数改成某个不存在的地址，你会惊奇的发现：虽然浏览器终端报出错误(404或其他网络错误)，但你的error回调却没有被执行!? 那怎么做才能使 Jsonp 的 error 回调被执行呢？ 有两个方法，方法一：添加 timeout 参数。 $.ajax({ url: 'https://api.github.com/users/jarontai/repos', type: 'GET', dataType: 'Jsonp', // dataType 为 Jsonp timeout: 5000, // 添加timeout参数 success: function(data) { $('.result').text(JSON.stringify(data)); }, error: function(jqXHR, textStatus) { // 此时textStatus为‘timeout’ $('.result').text('error'); alert('Jsonp error!'); } }); 添加 timeout 参数后，虽然 Jsonp 请求本身的错误没有被捕获，但是最终会因为超时而执行 error 回调。 方法二出场：使用jquery Jsonp插件 - https://github.com/jaubourg/jquery-jsonp $.jsonp({ url: 'https://api.github.com/users/jarontai/repos', callbackParameter: 'callback', timeout: 5000, error: function(xOptions, textStatus) { // 错误发生时，立即执行 $('.result').text('error'); alert('Jsonp error!'); }, success: function(data) { $('.result').text(JSON.stringify(data)); } }); 使用 jsonp 插件，能够在错误发生时立即执行 error 回调，并且还附带如 数据过滤 等功能 jsonp 封装 /** * [function 在页面中注入js脚本] * @param {[type]} url [description] * @param {[type]} charset [description] * @return {[type]} [description] */ util.createScript = function(url, charset) { var script = document.createElement('script'); script.setAttribute('type', 'text/javascript'); charset && script.setAttribute('charset', charset); script.setAttribute('src', url); script.async = true; return script; }; /** * [function 获取一个随机的5位字符串] * @param {[type]} prefix [description] * @return {[type]} [description] */ util.getName = function(prefix) { return prefix + Math.random().toString(36).replace(/[^a-z]+/g, '').substr(0, 5); }; /** * [function jsonp] * @param {[type]} url [description] * @param {[type]} onsucess [description] * @param {[type]} onerror [description] * @param {[type]} charset [description] * @return {[type]} [description] */ util.jsonp = function(url, onsuccess, onerror, charset) { var callbackName = util.getName('tt_player'); window[callbackName] = function() { if (onsuccess && util.isFunction(onsuccess)) { onsuccess(arguments[0]); } }; var script = util.createScript(url + '&callback=' + callbackName, charset); script.onload = script.onreadystatechange = function() { if (!script.readyState || /loaded|complete/.test(script.readyState)) { script.onload = script.onreadystatechange = null; // 移除该script的 DOM 对象 if (script.parentNode) { script.parentNode.removeChild(script); } // 删除函数或变量 window[callbackName] = null; } }; script.onerror = function() { if (onerror && util.isFunction(onerror)) { onerror(); } }; document.getElementsByTagName('head')[0].appendChild(script); }; 1.4.2. Hash 原理 页面 A 中通过 iframe 嵌入 B，\b需求是 A 给 B 发消息 拿到 B 的 url 改变 B 的 hash B 中接受 onhashchange // 利用hash，场景是当前页面 A 通过 iframe 嵌入了跨域的页面 B // 在A中伪代码如下： var B = document.getElementsByTagName('iframe'); B.src = B.src + '#' + 'data'; // 在B中的伪代码如下 window.onhashchange = function () { var data = window.location.hash; }; 1.4.3. WebSocket WebSocket 是双全工、实时、基于 frame 的 tcp 通信协议，使用 ws://（非加密）和 wss://（加密）作为协议前缀。该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信。 GET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 Origin: http://example.com 上面代码中，有一个字段是 Origin，表示该请求的请求源（origin），即发自哪个域名。因为有了 Origin 这个字段，而且非 http 协议，所以 WebSocket 才没有实行同源政策。 var ws = new WebSocket('wss://echo.websocket.org'); onopen, onmessage, onclose // 客户端 var ws = new WebSocket('wss://echo.websocket.org'); ws.onopen = function (e) { console.log('Connection open ...'); ws.send('Hello WebSockets!'); }; ws.onmessage = function (e) { console.log('Received Message: ', e.data); ws.close(); }; ws.onclose = function (e) { console.log('Connection closed.'); }; 1.4.4. postMessage 窗口A(http:A.com)向跨域的窗口B(http:B.com)发送信息 // A 中代码 window.postMessage('Hi B, from A', 'http://B.com'); // B中监听代码 window.addEventListener('message', function (event) { console.log(event.origin); console.log(event.source); console.log(event.data); }, false); 这是一个安全的跨域通信方法，postMessage(message, targetOrigin) 也是HTML5引入的特性。 可以给任何一个 window 发送消息，不论是否同源。第二个参数可以是 *，但如果你设置了一个 URL 但不相符，那么该事件不会被分发。看一个普通的使用方式吧： /* * In window A's scripts, with A being on : */ var popup = window.open(...popup details...); // This does nothing, assuming the window hasn't changed its location. popup.postMessage(\"The user is 'bob' and the password is 'secret'\", \"https://secure.example.net\"); // This will successfully queue a message to be sent to the popup, assuming // the window hasn't changed its location. popup.postMessage(\"hello there!\", \"http://example.com\"); function receiveMessage(event) { // Do we trust the sender of this message? (might be // different from what we originally opened, for example). if (event.origin !== \"http://example.com\") return; // event.source is popup // event.data is \"hi there yourself! the secret response is: rheeeeet!\" } window.addEventListener(\"message\", receiveMessage, false); /* * In the popup's scripts, running on : */ // Called sometime after postMessage is called function receiveMessage(event) { // Do we trust the sender of this message? if (event.origin !== \"http://example.com:8080\") return; // event.source is window.opener // event.data is \"hello there!\" // Assuming you've verified the origin of the received message (which // you must do in any case), a convenient idiom for replying to a // message is to call postMessage on event.source and provide // event.origin as the targetOrigin. event.source.postMessage(\"hi there yourself! the secret response \" + \"is: rheeeeet!\", event.origin); } window.addEventListener(\"message\", receiveMessage, false); 1.4.5. CORS 跨域资源共享 (Cross-Origin Resource Sharing) 参考资料： https://www.maxcdn.com/one/visual-glossary/cors/ https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS CORS 就是为了让 AJAX 可以实现可控的跨域访问而生的。 服务器设置 Access-Control-Allow-Origin HTTP 响应头之后，允许浏览器跨域请求。 浏览器在头信息之中，增加一个 Origin 字段。Origin 字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。 服务器根据这个值，决定是否同意这次请求。CORS 支持所有类型的 HTTP 请求 如果服务器同意，响应结果头： Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBar Content-Type: text/html; charset=utf-8 Cookie, withCredentials 属性 step 1: CORS 请求默认不发送 Cookie 和 HTTP 认证信息。如果要把 Cookie 发到服务器，服务器需指定 Access-Control-Allow-Credentials 字段。 Access-Control-Allow-Credentials: true step 2: 客户端方面，在 AJAX 请求中打开 withCredentials 属性。 var xhr = new XMLHttpRequest(); xhr.withCredentials = true; 否则，即使服务器同意发送 Cookie，浏览器也不会发送。或者，服务器要求设置 Cookie，浏览器也不会处理。 但是，如果省略 withCredentials 设置，有的浏览器还是会一起发送 Cookie。这时，可以显式关闭 withCredentials。 xhr.withCredentials = false; 需要注意的是，如果要发送 Cookie，Access-Control-Allow-Origin 就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie 依然遵循同源政策，只有用服务器域名设置的 Cookie 才会上传，其他域名的 Cookie 并不会上传，且（跨源）原网页代码中的 document.cookie 也无法读取服务器域名下的 Cookie。 // CORS 参考资料: http://www.ruanyifeng.com/blog/2016/04/cors.html // url（必选），options（可选） // 实现了 CORS 通信 let myHeaders = new Headers({ 'Access-Control-Allow-Origin': '*', 'Content-Type': 'text/plain' }); fetch(url, { method: 'GET', headers: myHeaders, mode: 'cors' }) .then((res) => { // TODO }) 为什么 fetch、CORS 会实现跨域通信？ ajax 跨域请求默认会被浏览器拦截，fetch、CORS 在请求头加入了 origin，服务器端设置了 Access-Control-Allow-Origin 发在源是允许就返回数据。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/错误监控.html":{"url":"Interview/frontend/错误监控.html","title":"错误监控","keywords":"","body":"1. 保证产品质量 或 直接问错误监控1.1. 前端错误分类1.2. 错误的捕捉方式1.3. 上报错误的原理1. 保证产品质量 或 直接问错误监控 1.1. 前端错误分类 即使运行错误：代码错误 资源加载错误 1.2. 错误的捕捉方式 运行错误： try catch window.onerror 资源加载错误: 用 object.onerror(script/image.onerror)。但他们不会向上冒泡所以 window.onerror 不能检测到 performance.getEntries() 返回数组包含所有加载成功的资源，document.getElementsByTagName('img')拿到所有资源，想减知道没加载的资源 Error 事件捕获 window.addEventListener('error', function(e){}) 比如 //baidu.com/test.js 不存在，window.onerror 是冒泡不好用，但 addEventListener 可以设置 true 去捕获到。 window.addEventListener('error', function (e) { console.log('捕获', e); }, true); 延伸：跨域的js运行错误如何捕获？Jsonp 没响应怎么捕获错误？(1. timeout 2. json-jquery plugin) 错误提示： 错误信息：script error 出错文件： 出错行号: 0 出错列号: 0 如此做才能拿到具体信息： 客户端在 script 标签中增加 crossorigin 属性 \b服务端设置js资源响应头 Access-Control-Allow-Origin: * 1.3. 上报错误的原理 使用 trackjs 等第三方服务 ajax 通信，但实际不这么做 利用 image 对象上报 (new Image()).src = 'http://baidu.com'; window.addEventListener('error', function (e) { console.log('捕获', e.target.outerHTML); // // 这里可能构建一个 时间、名字 的字符串 (new Image()).src = 'http://errorCollection.com?error=' + e.target.outerHTML; }, true); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/frontend/页面性能.html":{"url":"Interview/frontend/页面性能.html","title":"页面性能","keywords":"","body":"1. 页面性能优化1.1. 异步加载方式1.1.1. 异步加载的区别1.2. 浏览器缓存1.2.1. 响应式图片1.2.2. 图片优化1.2.3. 视频1.3. 性能优化工具1.3.1. 前端需要注意哪些 SEO (重要)1.4. SPA 如何处理 SEO1. 页面性能优化 减少 http 请求: 资源\b压缩 Gzip、合并，图片精灵。 Apache: Use mod_deflate Nginx: Use HttpGzipModule IIS: Configure HTTP Compression.aspx) 非核心代码异步加载 --> 异步加载方式 --> 异步加载的区别，使用 defer async 比放到页面底部更 modern、更好 利用浏览器缓存 --> 缓存分类 --> 缓存原理 使用 CDN DNS 预解析: https 协议下 a 标签默认浏览器是关闭 dns 预解析。上面 meta 告诉浏览器强制打开对 a 标签的 dns 预解析。 图片优化，大小、格式。图片预加载，将样式表放在顶部，将脚本放在底部 页面静态化 减小 cookie 大小 用 innerHTML 代替 DOM 操作，减少DOM操作次数 当需要设置的样式很多时设置 className 而不是直接操作 style 少用全局变量、缓存DOM节点查找的结果。减少IO读取操作。 避免在页面的主体布局中使用 table，table 要等其中的内容完全下载之后才会显示出来，显示比 div+css 布局慢。 避免多次重定向 对普通的网站有一个统一的思路，就是尽量向前端优化、减少数据库操作、减少磁盘IO。向前端优化指的是，在不影响功能和体验的情况下，能在浏览器执行的不要在服务端执行，能在缓存服务器上直接返回的不要到应用服务器，程序能直接取得的结果不要到外部取得，本机内能取得的数据不要到远程取，内存能取到的不要到磁盘取，缓存中有的不要去数据库查询。减少数据库操作指减少更新次数、缓存结果减少查询次数、将数据库执行的操作尽可能的让你的程序完成（例如join查询），减少磁盘IO指尽量不使用文件系统作为缓存、减少读写文件次数等。 1.1. 异步加载方式 动态脚本加载。document.createElement('script')\u001d 加载到 body, head 中 defer async 1.1.1. 异步加载的区别 defer 不阻止\b文档解析，浏览器遇到 \bdefer 边下载 defer script 边往下解析。全解析完之后才执行 defer script。如果多个依次执行。 async 不阻止\b文档解析，浏览器遇到 async 边下载 async script 边往下解析。当下载好了 js 后立即执行，此时文档解析可能还没完成，执行 js 期间停止文档解析。如果多个 async script，执行顺序与加载顺序无关 性能优化 --> test console.log('write'); document.write('write'); for (var i = 0; i 结果都是 write，for循环数字，最后是 defer 或者 async 执行。区别 defer 按照加载顺序执行， async 不一定，看文件大小、加载时间。 1.2. 浏览器缓存 强缓存：不跟服务器对话，本地有拿来就用 \bExpires Expires: Thu 绝对时间 Cache-Control max-age：3600s 相对时间(以他为准，避免服务器和本地电脑时间不一致) 协商缓存: 问服务器磁盘上的缓存能不能用 Last-Modified If-Modified-Since 他俩值一样。服务器下发 Last-Modified, \b传给服务器If-Modified-Since 因为服务器要对比。 Etag If-None-Match Etag 判断文件内容是否变化 跟缓存的 http 头有哪些？Expires, Cache-Control, Last-Modified If-Modified-Since Etag 1.2.1. 响应式图片 JS 或者服务端硬编码，resize 事件，判断屏幕大小加载不同的图片 img srcset 方法 picture标签 -> source svg 第三方库 polyfill 1.2.2. 图片优化 图片优化：以前切图，现在某些效果可以用使用 css3。字体图标替换 图片分类：jpg小，png大透明，gif，svg地图，apng，webp css sprite：制作网站 GoPng http://alloyteam.github.io/gopng 概念：将多个小图片拼接到一个图片中。通过 background-position 和 元素尺寸 调节需要显示的背景图案。 优点： 减少HTTP请求数，极大地提高页面加载速度 增加图片信息重复度，提高压缩比，减少图片大小 更换风格方便，绿色、红色的样字一样的图标可以通过 background-position 改变 缺点： 图片合并麻烦 维护麻烦，修改一个图片可能需要重新布局整个图片 注意手机端一般像素是pc端一半，gopng 生成的像素是 pc 端的 fis3 grunt-sprite 响应式动态图片加载sdk 需要默认图片 分辨率信息告诉服务器 服务器返回优质图片 ==picture标签== 1.2.3. 视频 video 标签，不同浏览器默认样式不同 flash 播放器，过时 需求 按照设计师要求制作播放器 用户进来就能看 第三方 videojs flowplayer 视频优化点 提前加载视频资源、依赖。flowplayer 支持 html5 和 swf。如果使用 flash，即使 swf 文件写在图片前面，默认浏览器还是会最后加载 swf 这样的多媒体资源。这导致图片阻塞了视频加载。优化点就是如何才能让视频依赖前置。方法是使用样式 link 此时这些资源立马加载，之后这些资源从浏览器缓存中取出来很快。 1.3. 性能优化工具 YSlow Google PageSpeed pingdom jsPerf dromaeo 微软压力测试工具，模拟每秒轰炸 chrome 自带 performance 监控 1.3.1. 前端需要注意哪些 SEO (重要) 合理的 title、description、keywords：搜索对着三项的权重逐个减小，title 值强调重点即可，重要关键词出现不要超过2次，而且要靠前，不同页面 title 要有所不同；description 把页面内容高度概括，长度合适，不可过分堆砌关键词，不同页面 description 有所不同；keywords 列举出重要关键词即可 语义化的 HTML 代码，符合W3C规范：语义化代码让搜索引擎容易理解网页 重要内容 HTML 代码放在最前：搜索引擎抓取 HTML 顺序是从上到下，有的搜索引擎对抓取长度有限制，保证重要内容一定会被抓取 重要内容不要用 js 输出：爬虫不会执行js获取内容 少用 iframe：搜索引擎不会抓取 iframe 中的内容 非装饰性图片必须加 alt 提高网站速度：网站速度是搜索引擎排序的一个重要指标 1.4. SPA 如何处理 SEO 因为搜索引擎无法通过 js 抓取信息，所以 SPA 的 SEO 需要格外处理。 You can setup a headless browser like PhantomJS to run on your server. It will execute all the javascript on your page. Then you can send that result to Google. This will fix your problem, but someone has to manage the server for PhantomJS. Opening and processing all these webpages is slow. It might take several servers. Phantom isn't as stable as you'd hoped. react server render 首次生成 html 返回给浏览器。ReactDOMServer.renderToString 没人没时间，则用 PhantomJS 搞预渲染。 连这个都没时间弄的话，去接入 prerender 等预渲染服务。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/hash碰撞.html":{"url":"Interview/hash碰撞.html","title":"hash碰撞","keywords":"","body":"1. hash碰撞--equals()与hashCode()1.1. equals()方法详解1.2. hashcode() 方法详解1.3. Hashset、Hashmap、Hashtable与hashcode()和equals()的密切关系1. hash碰撞--equals()与hashCode() 1.1. equals()方法详解 equals()方法是用来判断其他的对象是否和该对象相等. equals()方法在object类中定义如下： public boolean equals(Object obj) { return (this == obj); } 很明显是对两个对象的地址值进行的比较（即比较引用是否相同）。但是我们知道，String 、Math、Integer、Double 等这些封装类在使用 equals()方法时，已经覆盖了 object 类的 equals() 方法。 比如在String类中如下： public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = count; if (n == anotherString.count) { char v1[] = value; char v2[] = anotherString.value; int i = offset; int j = anotherString.offset; while (n– != 0) { if (v1[i++] != v2[j++]) return false; } return true; } } return false; } 很明显，这是进行的内容比较，而已经不再是地址的比较。依次类推Math、Integer、Double 等这些类都是重写了equals()方法的，从而进行的是内容的比较。当然，基本类型是进行值的比较。 它的性质有： 自反性（reflexive）。对于任意不为null的引用值x，x.equals(x)一定是true。 对称性（symmetric）。对于任意不为null的引用值x和y，当且仅当x.equals(y)是true时，y.equals(x)也是true。 传递性（transitive）。对于任意不为null的引用值x、y和z，如果x.equals(y)是true，同时y.equals(z)是true，那么x.equals(z)一定是true。 一致性（consistent）。对于任意不为null的引用值x和y，如果用于equals比较的对象信息没有被修改的话，多次调用时x.equals(y)要么一致地返回true要么一致地返回false。 对于任意不为null的引用值x，x.equals(null)返回false。 对于Object类来说，equals()方法在对象上实现的是差别可能性最大的等价关系，即，对于任意非null的引用值x和y，当且仅当x和y引用的是同一个对象，该方法才会返回true。 需要注意的是当equals()方法被override时，hashCode()也要被override。按照一般hashCode()方法的实现来说，相等的对象，它们的hash code一定相等。 1.2. hashcode() 方法详解 hashCode()方法给对象返回一个hash code值。这个方法被用于hash tables，例如HashMap。 它的性质是： 在一个Java应用的执行期间，如果一个对象提供给equals做比较的信息没有被修改的话，该对象多次调用hashCode()方法，该方法必须始终如一返回同一个integer。 如果两个对象根据equals(Object)方法是相等的，那么调用二者各自的hashCode()方法必须产生同一个integer结果。 并不要求根据equals(java.lang.Object)方法不相等的两个对象，调用二者各自的hashCode()方法必须产生不同的integer结果。然而，程序员应该意识到对于不同的对象产生不同的integer结果，有可能会提高hash table的性能。 大量的实践表明，由Object类定义的hashCode()方法对于不同的对象返回不同的integer。 在object类中，hashCode定义如下： public native int hashCode(); 说明是一个本地方法，它的实现是根据本地机器相关的。当然我们可以在自己写的类中覆盖hashcode()方法，比如String、Integer、Double等这些类都是覆盖了hashcode()方法的。例如在String类中定义的hashcode()方法如下 public int hashCode() { int h = hash; if (h == 0) { int off = offset; char val[] = value; int len = count; for (int i = 0; i 解释一下这个程序（String的API中写到）：s[0]31^(n-1) + s[1]31^(n-2) + … + s[n-1] ​ 使用 int 算法，这里 s[i] 是字符串的第 i 个字符，n 是字符串的长度，^ 表示求幂（空字符串的哈希码为 0）。 ​ 想要弄明白hashCode的作用，必须要先知道Java中的集合。　　 ​ 总的来说，Java中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。这里就引出一个问题：要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？ ​ 这就是Object.equals方法了。但是，如果每增加一个元素就检查一次，那么当元素很多时，后添加到集合中的元素比较的次数就非常多了。也就是说，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，它就要调用1000次equals方法。这显然会大大降低效率。 ​ 于是，Java采用了哈希表的原理。哈希（Hash）实际上是个人名，由于他提出一哈希算法的概念，所以就以他的名字命名了。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上，初学者可以简单理解，hashCode方法实际上返回的就是对象存储的物理地址（实际可能并不是）。 ​ 这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就一下子能定位到它应该放置的物理位置上。如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址。所以这里存在一个冲突解决的问题。这样一来实际调用equals方法的次数就大大降低了，几乎只需要一两次。 简而言之，在集合查找时，hashcode 能大大降低对象比较次数，提高查找效率 Java对象的eqauls方法和hashCode方法是这样规定的： 1、相等（相同）的对象必须具有相等的哈希码（或者散列码）。 2、如果两个对象的hashCode相同，它们并不一定相同。 关于第一点，相等（相同）的对象必须具有相等的哈希码（或者散列码），为什么？ 想象一下，假如两个Java对象A和B，A和B相等（eqauls结果为true），但A和B的哈希码不同，则A和B存入HashMap时的哈希码计算得到的HashMap内部数组位置索引可能不同，那么A和B很有可能允许同时存入HashMap，显然相等/相同的元素是不允许同时存入HashMap，HashMap不允许存放重复元素。 关于第二点，两个对象的hashCode相同，它们并不一定相同 也就是说，不同对象的hashCode可能相同；假如两个Java对象A和B，A和B不相等（eqauls结果为false），但A和B的哈希码相等，将A和B都存入HashMap时会发生哈希冲突，也就是A和B存放在HashMap内部数组的位置索引相同这时HashMap会在该位置建立一个链接表，将A和B串起来放在该位置，显然，该情况不违反HashMap的使用原则，是允许的。当然，哈希冲突越少越好，尽量采用好的哈希算法以避免哈希冲突。 所以，Java对于eqauls方法和hashCode方法是这样规定的： 1.如果两个对象相同，那么它们的hashCode值一定要相同； 2.如果两个对象的hashCode相同，它们并不一定相同（这里说的对象相同指的是用eqauls方法比较）， 如不按要求去做了，会发现相同的对象可以出现在Set集合中，同时，增加新元素的效率会大大下降。 3.equals()相等的两个对象，hashcode()一定相等；equals()不相等的两个对象，却并不能证明他们的hashcode()不相等。 换句话说，equals()方法不相等的两个对象，hashcode()有可能相等（我的理解是由于哈希码在生成的时候产生冲突造成的）。反过来，hashcode()不等，一定能推出equals()也不等；hashcode()相等，equals()可能相等，也可能不等。 在object类中，hashcode()方法是本地方法，返回的是对象的地址值，而object类中的equals()方法比较的也是两个对象的地址值，如果equals()相等，说明两个对象地址值也相等，当然hashcode()也就相等了；在String类中，equals()返回的是两个对象内容的比较，当两个对象内容相等时，Hashcode()方法根据String类的重写代码的分析，也可知道hashcode()返回结果也会相等。以此类推，可以知道Integer、Double等封装类中经过重写的equals()和hashcode()方法也同样适合于这个原则。当然没有经过重写的类，在继承了object类的equals()和hashcode()方法后，也会遵守这个原则。 1.3. Hashset、Hashmap、Hashtable与hashcode()和equals()的密切关系 Hashset是继承Set接口，Set接口又实现Collection接口，这是层次关系。那么Hashset、Hashmap、Hashtable中的存储操作是根据什么原理来存取对象的呢？ ​ 下面以HashSet为例进行分析，我们都知道：在hashset中不允许出现重复对象，元素的位置也是不确定的。在hashset中又是怎样判定元素是否重复的呢？在java的集合中，判断两个对象是否相等的规则是： ​ 1.判断两个对象的hashCode是否相等 ​ 如果不相等，认为两个对象也不相等，完毕 ​ 如果相等，转入2 ​ （这一点只是为了提高存储效率而要求的，其实理论上没有也可以，但如果没有，实际使用时效率会大大降低，所以我们这里将其做为必需的。） ​ 2.判断两个对象用equals运算是否相等 ​ 如果不相等，认为两个对象也不相等 ​ 如果相等，认为两个对象相等（equals()是判断两个对象是否相等的关键） ​ 为什么是两条准则，难道用第一条不行吗？不行，因为前面已经说了，hashcode()相等时，equals()方法也可能不等，所以必须用第2条准则进行限制，才能保证加入的为非重复元素。 例1： package com.bijian.study; import java.util.HashSet; import java.util.Iterator; import java.util.Set; public class HashSetTest { public static void main(String args[]) { String s1 = new String(\"aaa\"); String s2 = new String(\"aaa\"); System.out.println(s1 == s2); System.out.println(s1.equals(s2)); System.out.println(s1.hashCode()); System.out.println(s2.hashCode()); Set hashset = new HashSet(); hashset.add(s1); hashset.add(s2); Iterator it = hashset.iterator(); while (it.hasNext()) { System.out.println(it.next()); } } } 运行结果： false true 96321 96321 aaa 这是因为String类已经重写了equals()方法和hashcode()方法，所以hashset认为它们是相等的对象，进行了重复添加。 例2 package com.bijian.study; import java.util.HashSet; import java.util.Iterator; public class HashSetTest { public static void main(String[] args) { HashSet hs = new HashSet(); hs.add(new Student(1, \"zhangsan\")); hs.add(new Student(2, \"lisi\")); hs.add(new Student(3, \"wangwu\")); hs.add(new Student(1, \"zhangsan\")); Iterator it = hs.iterator(); while (it.hasNext()) { System.out.println(it.next()); } } } class Student { int num; String name; Student(int num, String name) { this.num = num; this.name = name; } public String toString() { return num + \":\" + name; } } 运行结果： 1:zhangsan 3:wangwu 2:lisi 1:zhangsan 为什么hashset添加了相等的元素呢，这是不是和hashset的原则违背了呢？回答是：没有。因为在根据hashcode()对两次建立的new Student(1,“zhangsan”)对象进行比较时，生成的是不同的哈希码值，所以hashset把他当作不同的对象对待了，当然此时的equals()方法返回的值也不等。 ​ 为什么会生成不同的哈希码值呢？上面我们在比较s1和s2的时候不是生成了同样的哈希码吗？原因就在于我们自己写的Student类并没有重新自己的hashcode()和equals()方法，所以在比较时，是继承的object类中的hashcode()方法，而object类中的hashcode()方法是一个本地方法，比较的是对象的地址（引用地址），使用new方法创建对象，两次生成的当然是不同的对象了，造成的结果就是两个对象的hashcode()返回的值不一样，所以Hashset会把它们当作不同的对象对待。 ​ 怎么解决这个问题呢？答案是：在 Student 类中重新 hashcode() 和 equals() 方法。 class Student { int num; String name; Student(int num, String name) { this.num = num; this.name = name; } public int hashCode() { return num * name.hashCode(); } public boolean equals(Object o) { Student s = (Student) o; return num == s.num && name.equals(s.name); } public String toString() { return num + \":\" + name; } } 运行结果： 1:zhangsan 3:wangwu 2:lisi 可以看到重复元素的问题已经消除，根据重写的方法，即便两次调用了new Student(1,\"zhangsan\")，我们在获得对象的哈希码时，根据重写的方法hashcode()，获得的哈希码肯定是一样的，当然根据equals()方法我们也可判断是相同的，所以在向hashset集合中添加时把它们当作重复元素看待了。 重写equals()和hashcode()小结： 重点是equals，重写hashCode只是技术要求（为了提高效率） 为什么要重写equals呢？因为在java的集合框架中，是通过equals来判断两个对象是否相等的 在hibernate中，经常使用set集合来保存相关对象，而set集合是不允许重复的。在向HashSet集合中添加元素时，其实只要重写equals()这一条也可以。但当hashset中元素比较多时，或者是重写的equals()方法比较复杂时，我们只用equals()方法进行比较判断，效率也会非常低，所以引入了hashCode()这个方法，只是为了提高效率，且这是非常有必要的。比如可以这样写： public int hashCode(){ return 1; //等价于hashcode无效 } 这样做的效果就是在比较哈希码的时候不能进行判断，因为每个对象返回的哈希码都是1，每次都必须要经过比较equals()方法后才能进行判断是否重复，这当然会引起效率的大大降低。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/":{"url":"Interview/html/","title":"Interview/html","keywords":"","body":"1. TOC1. TOC canvas h5_drag h5_fileReader h5_navigator_geolocation html_template HTML自定义元素教程 meta WebComponent Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/html/canvas.html":{"url":"Interview/html/canvas.html","title":"canvas","keywords":"","body":"1. canvas 库1. canvas 库 easelJs: http://createjs.com/getting-started/easeljs paper.js: https://github.com/paperjs/paper.js fabrics: http://fabricjs.com/ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/h5_drag.html":{"url":"Interview/html/h5_drag.html","title":"h5_drag","keywords":"","body":"1. Drag and Drop 拖拽1.1. 一. 实现拖放的步骤：1.1.1. 步骤1：创建一个可拖拽对象：1.1.2. 步骤2：放置对象：1.1.3. dragenter 事件，用来确定放置目标是否接受放置。1.1.4. dragover 事件，用来确定给用户显示怎样的反馈信息。1.1.5. 最后是drop事件，允许放置对象。1.1.6. 例子：1.2. 二. 拖放的相关事件1.3. 三. DataTransfer对象的属性与方法1.3.1. DataTransfer对象的属性：1.4. 四. draggable 属性兼容性1. Drag and Drop 拖拽 在HTML5之前，如果要实现拖放效果，一般会使用 mousedown、mousemove 和 mouseup 三个事件进行组合来模拟出拖拽效果，比较麻烦。而HTML5规范实现了原生拖放功能，使得元素拖放的实现更加方便和高效。 默认情况下，图像、链接和文本是可以拖动的。文本只有在被选中的情况下才能拖动，而图像和链接在任何时候都可以拖动。 HTML5为所有的HTML元素规定了一个 draggable 属性，表示元素是否允许拖动。要想让其他元素也能被拖动，可以设置这个属性为 true。 A. 被拖动的源对象可以触发的事件 ondragstart：源对象开始被拖动 ondrag：源对象被拖动过程中(鼠标可能在移动也可能未移动) ondragend：源对象被拖动结束 B. 拖动源对象可以进入到上方的目标对象可以触发的事件： ondragenter：目标对象被源对象拖动着进入 ondragover：目标对象被源对象拖动着悬停在上方 ondragleave：源对象拖动着离开了目标对象 ondrop：源对象拖动着在目标对象上方释放/松手 C. 如何在拖动的源对象事件和目标对象事件间传递数据: 数据传递对象, 用于在源对象和目标对象的事件间传递数据: e.dataTransfer 源对象上的事件处理中保存数据：e.dataTransfer.setData(k, v); k-v 必须都是 string 类型 目标对象上的事件处理中读取数据：var v = e.dataTransfer.getData(k); 1.1. 一. 实现拖放的步骤： 1.1.1. 步骤1：创建一个可拖拽对象： 如果想要拖动某个元素，需要设置元素的 draggable 属性为 true。 给 dragstart 设置一个事件监听器存储拖拽数据。 document.getElementById(\"dragImg\").addEventListener(\"dragstart\", function(event) { // 存储拖拽数据和拖拽效果... event.dataTransfer.setData(\"Text\", ev.target.id); }, false); 1.1.2. 步骤2：放置对象： 假设放置对象的DOM为： 1.1.3. dragenter 事件，用来确定放置目标是否接受放置。 如果放置被接受，那么这个事件必须取消。 document.getElementById(\"dragTarget\").addEventListener(\"dragenter\", function(event) { // 阻止浏览器默认事件 event.preventDefault(); }, false); 1.1.4. dragover 事件，用来确定给用户显示怎样的反馈信息。 如果这个事件被取消，反馈信息（通常就是光标）就会基于 dropEffect 属性的值更新。 document.getElementById(\"dragTarget\").addEventListener(\"dragover\", function(event) { // 阻止浏览器默认事件. ondragover 有一个默认行为！！！那就是当ondragover 触发时，ondrop 会失效！！！ event.preventDefault(); }, false); 1.1.5. 最后是drop事件，允许放置对象。 document.getElementById(\"dragTarget\").addEventListener(\"drop\", function(event) { event.preventDefault(); var data = event.dataTransfer.getData(\"Text\"); event.target.appendChild(document.getElementById(data)); }, false); 1.1.6. 例子： （备注： 转载自：http://www.w3school.com.cn/tiy/t.asp?f=html5_draganddrop） #dragTarget { width: 488px; height: 70px; padding: 10px; border: 1px solid #aaaaaa; } function allowDrop(ev) { ev.preventDefault(); } function drag(ev) { ev.dataTransfer.setData(\"Text\", ev.target.id); } function drop(ev) { ev.preventDefault(); var data = ev.dataTransfer.getData(\"Text\"); ev.target.appendChild(document.getElementById(data)); } 请把 W3School 的图片拖放到矩形中： 1.2. 二. 拖放的相关事件 事件 产生事件的元素 描述 dragstart 被拖放的元素 开始拖放操作 drag 被拖放的元素 拖放过程中 dragenter 拖放过程中鼠标经过的元素 被拖放元素开始进入本元素的范围内 dragover 拖放过程中鼠标经过的元素 被拖放元素正在本元素范围内移动 dragleave 拖放过程中鼠标经过的元素 被拖放元素离开本元素的范围 drop 拖放的目标元素 有其他元素被拖放到本元素中 dragend 拖放的对象元素 拖放操作结束 1.3. 三. DataTransfer对象的属性与方法 1.3.1. DataTransfer对象的属性： 属性 描述 dropEffect 表示拖放操作的视觉效果，允许对其进行值的设定。该效果必须在用effectAllowed属性指定的允许的视觉效果范围内，允许指定的值有：none、copy、link、move。 effectAllowed 用来指定当元素被拖放时所允许的视觉效果。可以指定的值有：none、copy、copyLink、copyMove、link、linkMove、all、uninitialize。 files 返回表示被拖拽文件的 FileList。 types 存入数据的MIME类型。如果任意文件被拖拽，那么其中一个类型将会是字符串”Files”。 方法 描述 void setData(DOMString format, DOMString data) 向DataTransfer对象存入数据。 DOMString getData(DOMString data) 读取DataTransfer对象中的数据。 void clearData(DOMString format) 清除DataTransfer对象中的数据。如果省略参数format，则清除全部数据。 void setDragImage(Element image, long x, long y) 用img元素来设置拖放图标。 1.4. 四. draggable 属性兼容性 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/h5_fileReader.html":{"url":"Interview/html/h5_fileReader.html","title":"h5_fileReader","keywords":"","body":"1. HTML5 新增的文件操作对象1. HTML5 新增的文件操作对象 File: 代表一个文件对象 FileList: 代表一个文件列表对象，类数组 FileReader: 用于从文件中读取数据 FileWriter: 用于向文件中写出数据 从电脑托一张图片到网页目标区域，显示该图片。类似于上传头像的一种方式。 #container { border: 1px solid #aaa; border-radius: 3px; padding: 10px; margin: 10px; min-height: 400px; } 拖放API的扩展知识 请拖动您的照片到下方方框区域 //监听 document 的 drop 事件——取消其默认行为：在新窗口中打开图片 document.ondragover = function(e){ e.preventDefault(); //使得drop事件可以触发 } document.ondrop = function(e){ e.preventDefault(); //阻止在新窗口中打开图片，否则仍然会执行下载操作！！！ } //监听 div#container 的 drop 事件，设法读取到释放的图片数据，显示出来 container.ondragover = function(e){ e.preventDefault(); } container.ondrop = function(e){ console.log('客户端拖动着一张图片释放了...') //当前的目标对象读取拖放源对象存储的数据 //console.log(e.dataTransfer); //显示有问题 //console.log(e.dataTransfer.files.length); //拖进来的图片的数量 var f0 = e.dataTransfer.files[0]; //文件对象 File //从文件对象中读取数据 var fr = new FileReader(); //fr.readAsText(f0); //从文件中读取文本字符串 fr.readAsDataURL(f0); //从文件中读取URL数据 fr.onload = function(){ console.log('读取文件完成') console.log(fr.result); var img = new Image(); img.src = fr.result; //URL数据 container.appendChild(img); } } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/h5_navigator_geolocation.html":{"url":"Interview/html/h5_navigator_geolocation.html","title":"h5_navigator_geolocation","keywords":"","body":"1. H5 地址信息位置1. H5 地址信息位置 if ('geolocation' in navigator) { navigator.geolocation.getCurrentPosition(function(position) { console.log(position); }); } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/html_template.html":{"url":"Interview/html/html_template.html","title":"html_template","keywords":"","body":"1. Html template1. Html template 默认隐层的，html parser 会解析检查他的 content 是否合法，并不会渲染他。template 有 content 属性。var clonedNode = document.importNode(templateDOM.content, true) 得到 clone 节点，再 appendChild 到相应父级中。 element is a mechanism for holding client-side content that is not to be rendered when a page is loaded but may subsequently be instantiated during runtime using JavaScript. Think of a template as a content fragment that is being stored for subsequent use in the document. While the parser does process the contents of the element while loading the page, it does so only to ensure that those contents are valid; the element's contents are not rendered, however. UPC_Code Product_Name // Test to see if the browser supports the HTML template element by checking // for the presence of the template element's content attribute. if ('content' in document.createElement('template')) { // Instantiate the table with the existing HTML tbody // and the row with the template var t = document.querySelector('#productRow'), td = t.content.querySelectorAll(\"td\"); td[0].textContent = \"1235646565\"; td[1].textContent = \"Stuff\"; // Clone the new row and insert it into the table var tb = document.querySelector(\"tbody\"); var clone = document.importNode(t.content, true); tb.appendChild(clone); // Create a new row td[0].textContent = \"0384928528\"; td[1].textContent = \"Acme Kidney Beans\"; // Clone the new row and insert it into the table var clone2 = document.importNode(t.content, true); tb.appendChild(clone2); } else { // Find another way to add the rows to the table because // the HTML template element is not supported. } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/HTML自定义元素教程.html":{"url":"Interview/html/HTML自定义元素教程.html","title":"HTML自定义元素教程","keywords":"","body":"1. HTML 自定义元素教程1.1. 一、浏览器处理1.2. 二、HTML import1.3. 三、Custom Elements 标准1. HTML 自定义元素教程 组件是 Web 开发的方向，现在的热点是 JavaScript 组件，但是 HTML 组件未来可能更有希望。 1.1. 一、浏览器处理 我们一般都使用标准的 HTML 元素。 Hello World 上面代码中，就是标准的 HTML 元素。 如果使用非标准的自定义元素，会有什么结果？ Hello World 上面代码中，就是非标准元素，浏览器不认识它。这段代码的运行结果是，浏览器照常显示Hello World，这说明浏览器并没有过滤这个元素。 现在，为自定义元素加上样式。 greeting { display: block; font-size: 36px; color: red; } 运行结果如下。 接着，使用脚本操作这个元素。 function customTag(tagName, fn){ Array.from(document.getElementsByTagName(tagName)).forEach(fn); } function greetingHandler(element) { element.innerHTML = '你好，世界'; } customTag('greeting', greetingHandler); 运行结果如下。 这说明，浏览器对待自定义元素，就像对待标准元素一样，只是没有默认的样式和行为。这种处理方式是写入 HTML5 标准的。 \"User agents must treat elements and attributes that they do not understand as semantically neutral; leaving them in the DOM (for DOM processors), and styling them according to CSS (for CSS processors), but not inferring any meaning from them.\" 上面这段话的意思是，浏览器必须将自定义元素保留在 DOM 之中，但不会任何语义。除此之外，自定义元素与标准元素都一致。 事实上，浏览器提供了一个HTMLUnknownElement对象，所有自定义元素都是该对象的实例。 var tabs = document.createElement('tabs'); tabs instanceof HTMLUnknownElement // true tabs instanceof HTMLElement // true 上面代码中，tabs是一个自定义元素，同时继承了HTMLUnknownElement和HTMLElement接口。 1.2. 二、HTML import 有了自定义元素，就可以写出语义性非常好的 HTML 代码。 微博 微信 上面的代码，一眼就能看出语义。 如果将元素的样式与脚本，封装在一个 HTML 文件share-buttons.html之中，这个元素就可以复用了。 使用的时候，先引入share-buttons.html。 然后，就可以在网页中使用了。 Title ... ... HTML imports 的更多用法可以参考教程（1，2）。目前只有 Chrome 浏览器支持这个语法。 1.3. 三、Custom Elements 标准 HTML5 标准规定了自定义元素是合法的。然后，W3C 就为自定义元素制定了一个单独的 Custom Elements 标准。 它与其他三个标准放在一起---- HTML Imports，HTML Template、Shadow DOM----统称为 Web Components 规范。目前，这个规范只有 Chrome 浏览器支持。 Custom Elements 标准对自定义元素的名字做了限制。 \"自定义元素的名字必须包含一个破折号（-）所以、和都是正确的名字，而和是不正确的。这样的限制使得 HTML 解析器可以分辨那些是标准元素，哪些是自定义元素。\" 注意，一旦名字之中使用了破折号，自定义元素就不是HTMLUnknownElement的实例了。 var xTabs = document.createElement('x-tabs'); xTabs instanceof HTMLUnknownElement // false xTabs instanceof HTMLElement // true Custom Elements 标准规定了，自定义元素的定义可以使用 ES6 的class语法。 // 定义一个 class MyElement extends HTMLElement {...} window.customElements.define('my-element', MyElement); 上面代码中，原生的window.customElements对象的define方法用来定义 Custom Element。该方法接受两个参数，第一个参数是自定义元素的名字，第二个参数是一个 ES6 的class。 这个class使用get和set方法定义 Custom Element 的某个属性。 class MyElement extends HTMLElement { get content() { return this.getAttribute('content'); } set content(val) { this.setAttribute('content', val); } } 有了这个定义，网页之中就可以插入了。 Hello 处理脚本如下。 function customTag(tagName, fn){ Array.from(document.getElementsByTagName(tagName)).forEach(fn); } function myElementHandler(element) { element.textConent = element.content; } customTag('my-element', myElementHandler); 运行结果如下。 ES6 Class 的一个好处是，可以很容易地写出继承类。 class MyNewElement extends MyElement { // ... } customElements.define('my-new-element', MyNewElement); 更多用法请参考谷歌的官方教程。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/meta.html":{"url":"Interview/html/meta.html","title":"meta","keywords":"","body":"1. meta1. meta 注意 DNS 预解析 meta 参考资料 参考资料 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/html/WebComponent.html":{"url":"Interview/html/WebComponent.html","title":"WebComponent","keywords":"","body":"1. Web Components, Shadow DOM, template1.1. Web components1.2. Image Slider example1.2.1. Shadow DOM1.2.2. Templates1.2.3. Shadow DOM1.2.4. Shadowy Sliders1.2.5. Insertion Points by content1.2.6. Custom Elements1.2.7. Polymer1.2.8. SEO1.2.9. Accessibility1.2.10. Style tags? Um, no thanks.1. Web Components, Shadow DOM, template 1.1. Web components bundle markup and styles into custom HTML elements. They fully encapsulate all of their HTML and CSS. That means the styles that you write always render as you intended, and your HTML is safe from the prying eyes of external JavaScript. 1.2. Image Slider example Think about how you currently implement an image slider, it might look something like this: We want it to be something like: 1.2.1. Shadow DOM Think of tag: There's a play button, a scrubber, timecodes and a volume slider. Lots of stuff that you didn't have to write any markup for, it just appeared when you asked for . But what you're actually seeing is an illusion. The browser makers needed a way to guarantee that the tags they implemented would always render the same, regardless of any wacky HTML, CSS or JavaScript we might already have on the page. To do this, they created a secret passageway where they could hide their code and keep it out of our hot little hands. They called this secret place: the Shadow DOM. Use Chrome Developer Tools and enable the Show user agent shadow DOM flag. That'll let you inspect the element in more detail. Inside you'll find that there's a ton of HTML all hidden away. So how to use our custom tag like ? 1.2.2. Templates Hello there! This content is top secret :) ==Everything inside a template is considered inert by the browser. This means tags with external sources — , , , etc. — do not make http requests and tags do not execute. It also means that nothing from within the template is rendered on the page until we activate it using JavaScript.== So the first step in creating our is to put all of its HTML and CSS into a . Once we've done this, we're ready to move it into the shadow DOM. 1.2.3. Shadow DOM To create shadow DOM, select an element and call its createShadowRoot method. This will return a document fragment which you can then fill with content. var host = document.querySelector('.container'); var root = host.createShadowRoot(); root.innerHTML = 'How you doing?' Shadow Host In shadow DOM parlance, the element that you call createShadowRoot on is known as the Shadow Host. It's the only piece visible to the user, and it's where you would ask the user to supply your element with content. If you think about our tag from before, the element itself is the shadow host, and the contents are the tags you nest inside of it. Shadow Root The document fragment returned by createShadowRoot is known as the Shadow Root. The shadow root, and its descendants, are hidden from the user, but they're what the browser will actually render when it sees our tag. In the example, the play button, scrubber, timecode, etc. are all descendants of the shadow root. They show up on the screen but their markup is not visible to the user. Shadow Boundary Any HTML and CSS inside of the shadow root is protected from the parent document by an invisible barrier called the Shadow Boundary. The shadow boundary prevents CSS in the parent document from bleeding into the shadow DOM, and it also prevents external JavaScript from traversing into the shadow root. Translation: Let's say you have a style tag in the shadow DOM that specifies all h3's should have a color of red. Meanwhile, in the parent document, you have a style that specifies h3's should have a color of blue. In this instance, h3's appearing within the shadow DOM will be red, and h3's outside of the shadow DOM will be blue. The two styles will happily ignore each other thanks to our friend, the shadow boundary. And if, at some point, the parent document goes looking for h3's with $('h3'), the shadow boundary will prevent any exploration into the shadow root and the selection will only return h3's that are external to the shadow DOM. 1.2.4. Shadowy Sliders To get our img-slider into the shadow DOM we'll need to create a shadow host and populate it with the contents of our template. * { -webkit-box-sizing: border-box; -moz-box-sizing: border-box; -ms-box-sizing: border-box; box-sizing: border-box; } #slider { max-width: 600px; text-align: center; margin: 0 auto; } #overflow { width: 100%; overflow: hidden; } #slides .inner { width: 400%; } #slides .inner { -webkit-transform: translateZ(0); -moz-transform: translateZ(0); -o-transform: translateZ(0); -ms-transform: translateZ(0); transform: translateZ(0); -webkit-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -moz-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -o-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -ms-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -webkit-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -moz-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -o-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -ms-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); } #slides img { width: 25%; float: left; } #slide1:checked ~ #slides .inner { margin-left: 0; } #slide2:checked ~ #slides .inner { margin-left: -100%; } #slide3:checked ~ #slides .inner { margin-left: -200%; } #slide4:checked ~ #slides .inner { margin-left: -300%; } input[type=\"radio\"] { display: none; } label { background: #CCC; display: inline-block; cursor: pointer; width: 10px; height: 10px; border-radius: 5px; } #slide1:checked ~ label[for=\"slide1\"], #slide2:checked ~ label[for=\"slide2\"], #slide3:checked ~ label[for=\"slide3\"], #slide4:checked ~ label[for=\"slide4\"] { background: #333; } // Add the template to the Shadow DOM var tmpl = document.querySelector('template'); var host = document.querySelector('.img-slider'); var root = host.createShadowRoot(); root.appendChild(document.importNode(tmpl.content, true)); In this instance we've created a div and given it the class img-slider so it can act as our shadow host. We select the template and do a deep copy of its internals with document.importNode. These internals are then appended to our newly created shadow root. 1.2.5. Insertion Points by content At this point our img-slider is inside the shadow DOM but the image paths are hard coded. Just like the tags nested inside of , we'd like the images to come from the user, so we'll have to invite them over from the shadow host. To pull items into the shadow DOM we use the new tag. The tag uses CSS selectors to cherry-pick elements from the shadow host and project them into the shadow DOM. These projections are known as insertion points. We'll make it easy on ourselves and assume that the slider only contains images, that way we can create an insertion point using the img selector. ... Because we are projecting content into the Shadow DOM using an insertion point, we'll also need to use the new ::content pseudo-element to update our CSS. #slides ::content img { width: 25%; float: left; } If you want to know more about the new CSS selectors and combinators added by Shadow DOM, take a look at this cheat sheet I threw together. Now we're ready to populate our img-slider. final html: * { -webkit-box-sizing: border-box; -moz-box-sizing: border-box; -ms-box-sizing: border-box; box-sizing: border-box; } #slider { max-width: 600px; text-align: center; margin: 0 auto; } #overflow { width: 100%; overflow: hidden; } #slides .inner { width: 400%; } #slides .inner { -webkit-transform: translateZ(0); -moz-transform: translateZ(0); -o-transform: translateZ(0); -ms-transform: translateZ(0); transform: translateZ(0); -webkit-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -moz-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -o-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -ms-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -webkit-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -moz-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -o-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -ms-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); } #slides ::content img { width: 25%; float: left; } #slide1:checked ~ #slides .inner { margin-left: 0; } #slide2:checked ~ #slides .inner { margin-left: -100%; } #slide3:checked ~ #slides .inner { margin-left: -200%; } #slide4:checked ~ #slides .inner { margin-left: -300%; } input[type=\"radio\"] { display: none; } label { background: #CCC; display: inline-block; cursor: pointer; width: 10px; height: 10px; border-radius: 5px; } #slide1:checked ~ label[for=\"slide1\"], #slide2:checked ~ label[for=\"slide2\"], #slide3:checked ~ label[for=\"slide3\"], #slide4:checked ~ label[for=\"slide4\"] { background: #333; } // Polyfill support HTMLElement.prototype.createShadowRoot = HTMLElement.prototype.createShadowRoot || HTMLElement.prototype.webkitCreateShadowRoot || function() {}; // Add the template to the Shadow DOM var tmpl = document.querySelector('template'); var host = document.querySelector('.img-slider'); var root = host.createShadowRoot(); root.appendChild(document.importNode(tmpl.content, true)); Next, we can turn this img-slider div into its own tag. 1.2.6. Custom Elements A Custom Element two requirements: name must contain a dash prototype must extend HTMLElement // Grab our template full of slider markup and styles var tmpl = document.querySelector('template'); // Create a prototype for a new element that extends HTMLElement var ImgSliderProto = Object.create(HTMLElement.prototype); // Setup our Shadow DOM and clone the template ImgSliderProto.createdCallback = function() { var root = this.createShadowRoot(); root.appendChild(document.importNode(tmpl.content, true)); }; // Register our new element var ImgSlider = document.registerElement('img-slider', { prototype: ImgSliderProto }); The Object.create method returns a new prototype which extends HTMLElement. When the parser finds our tag in the document it will check to see if it has a method named createdCallback. If it finds this method it will run it immediately. This is a good place to do setup work, so we create some Shadow DOM and clone our template into it. We pass the tag name and prototype to a new method on the document, called registerElement, and after that we're ready to go. Now that our element is registered there are a few different ways to use it. The first, and most straightforward, is to just use the tag somewhere in our HTML. But we can also call document.createElement(\"img-slider\") or we can use the constructor that was returned by document.registerElement and stored in the ImgSlider variable. It's up to you which style you prefer. Final: * { -webkit-box-sizing: border-box; -moz-box-sizing: border-box; -ms-box-sizing: border-box; box-sizing: border-box; } #slider { max-width: 600px; text-align: center; margin: 0 auto; } #overflow { width: 100%; overflow: hidden; } #slides .inner { width: 400%; } #slides .inner { -webkit-transform: translateZ(0); -moz-transform: translateZ(0); -o-transform: translateZ(0); -ms-transform: translateZ(0); transform: translateZ(0); -webkit-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -moz-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -o-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -ms-transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); transition: all 800ms cubic-bezier(0.770, 0.000, 0.175, 1.000); -webkit-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -moz-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -o-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); -ms-transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); transition-timing-function: cubic-bezier(0.770, 0.000, 0.175, 1.000); } #slides ::content img { width: 25%; float: left; } #slide1:checked ~ #slides .inner { margin-left: 0; } #slide2:checked ~ #slides .inner { margin-left: -100%; } #slide3:checked ~ #slides .inner { margin-left: -200%; } #slide4:checked ~ #slides .inner { margin-left: -300%; } input[type=\"radio\"] { display: none; } label { background: #CCC; display: inline-block; cursor: pointer; width: 10px; height: 10px; border-radius: 5px; } #slide1:checked ~ label[for=\"slide1\"], #slide2:checked ~ label[for=\"slide2\"], #slide3:checked ~ label[for=\"slide3\"], #slide4:checked ~ label[for=\"slide4\"] { background: #333; } // Polyfill support HTMLElement.prototype.createShadowRoot = HTMLElement.prototype.createShadowRoot || HTMLElement.prototype.webkitCreateShadowRoot || function() {}; // Grab our template full of slider markup and styles var tmpl = document.querySelector('template'); // Create a prototype for a new element that extends HTMLElement var ImgSliderProto = Object.create(HTMLElement.prototype); // Setup our Shadow DOM and clone the template ImgSliderProto.createdCallback = function() { var root = this.createShadowRoot(); root.appendChild(document.importNode(tmpl.content, true)); }; // Register our new element var ImgSlider = document.registerElement('img-slider', { prototype: ImgSliderProto }); 1.2.7. Polymer Let's look at how we could rewrite our img-slider using Google's Web Component library, Polymer. Polymer adds a new tag to the browser, , which automagically turns templates into shadow DOM and registers custom elements for us. All we need to do is to tell Polymer what name to use for the tag and to make sure we include our template markup. I find it's often easier to create elements using Polymer because of all the niceties built into the library. This includes two-way binding between elements and models, automatic node finding and support for other new standards like Web Animations. Also, the developers on the polymer-dev mailing list are extremely active and helpful, which is great when you're first learning the ropes, and the StackOverflow community is growing. This is just a tiny example of what Polymer can do, so be sure to visit its project page and also checkout Mozilla's alternative, X-Tag. 1.2.8. SEO At this moment it's unclear how well crawlers support Custom Elements and Shadow DOM. The Polymer FAQ states: Search engines have been dealing with heavy AJAX based application for some time now. Moving away from JS and being more declarative is a good thing and will generally make things better. The Google Webmaster's blog recently announced that the Google crawler will execute JavaScript on your page before indexing it. And using a tool like Fetch as Google will allow you to see what the crawler sees as it parses your site. A good example is the Polymer website, which is built with custom elements and is easily searched in Google. One tip I've learned from speaking with members of the Polymer team is to try to make sure the content inside of your custom element is static, and not coming from a data binding. Here is some interesting, and searchable content... {{crazyDynamicContent}} Click here To be fair, this isn't a new problem. AJAX heavy sites have been dealing with this issue for a few years now and thankfully there are solutions out there. 1.2.9. Accessibility Obviously when you're hiding markup in secret shadow DOM sandboxes the issue of accessibility becomes pretty important. Steve Faulkner took a look at accessibility in shadow DOM and seemed to be satisfied with what he found. Results from initial testing indicate that inclusion of ARIA roles, states and properties in content wholly inside the Shadow DOM works fine. The accessibility information is exposed correctly via the accessibility API. Screen readers can access content in the Shadow DOM without issue. The full post is available here. Marcy Sutton has also written a post exploring this topic in which she explains: Web Components, including Shadow DOM, are accessible because assistive technologies encounter pages as rendered, meaning the entire document is read as “one happy tree”. Marcy also points out that the img-slider I built in this post is not accessible because our css label trick makes it inaccessible from the keyboard. Keep that in mind if you're looking to reuse it in a project. Surely there will be bumps along the way but that sounds like a pretty great start! 1.2.10. Style tags? Um, no thanks. Unfortunately tags do not work inside of the Shadow DOM, which means the only way to pull in external CSS is through @import. In other words, tags are—for the moment—unavoidable. Keep in mind that the styles we're talking about are relevant only to a component, whereas we've previously been trained to favor external files because they often affect our entire application. So is it such a bad thing to put a tag inside of an element, if all of those styles are scoped just to that one entity? Personally I think it's OK, but the option of external files would be very nice to have. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/IaaS-PaaS-SaaS的区别.html":{"url":"Interview/IaaS-PaaS-SaaS的区别.html","title":"IaaS-PaaS-SaaS的区别","keywords":"","body":"1. IaaS，PaaS，SaaS 的区别1. IaaS，PaaS，SaaS 的区别 作者： 阮一峰 日期： 2017年7月23日 越来越多的软件，开始采用云服务。 云服务只是一个统称，可以分成三大类。 IaaS：基础设施服务，Infrastructure-as-a-service PaaS：平台服务，Platform-as-a-service SaaS：软件服务，Software-as-a-service 它们有什么区别呢？ IBM 的软件架构师 Albert Barron 曾经使用披萨作为比喻，解释这个问题。David Ng 进一步引申，让它变得更准确易懂。 请设想你是一个餐饮业者，打算做披萨生意。 你可以从头到尾，自己生产披萨，但是这样比较麻烦，需要准备的东西多，因此你决定外包一部分工作，采用他人的服务。你有三个方案。 （1）方案一：IaaS 他人提供厨房、炉子、煤气，你使用这些基础设施，来烤你的披萨。 （2）方案二：PaaS 除了基础设施，他人还提供披萨饼皮。 你只要把自己的配料洒在饼皮上，让他帮你烤出来就行了。也就是说，你要做的就是设计披萨的味道（海鲜披萨或者鸡肉披萨），他人提供平台服务，让你把自己的设计实现。 （3）方案三：SaaS 他人直接做好了披萨，不用你的介入，到手的就是一个成品。你要做的就是把它卖出去，最多再包装一下，印上你自己的 Logo。 上面的三种方案，可以总结成下面这张图。 从左到右，自己承担的工作量（上图蓝色部分）越来越少，IaaS > PaaS > SaaS。 对应软件开发，则是下面这张图。 SaaS 是软件的开发、管理、部署都交给第三方，不需要关心技术问题，可以拿来即用。普通用户接触到的互联网服务，几乎都是 SaaS，下面是一些例子。 客户管理服务 Salesforce 团队协同服务 Google Apps 储存服务 Box 储存服务 Dropbox 社交服务 Facebook / Twitter / Instagram PaaS 提供软件部署平台（runtime），抽象掉了硬件和操作系统细节，可以无缝地扩展（scaling）。开发者只需要关注自己的业务逻辑，不需要关注底层。下面这些都属于 PaaS。 Heroku Google App Engine OpenShift IaaS 是云服务的最底层，主要提供一些基础资源。它与 PaaS 的区别是，用户需要自己控制底层，实现基础设施的使用逻辑。下面这些都属于 IaaS。 Amazon EC2 Digital Ocean RackSpace Cloud Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/nodejs_interview.html":{"url":"Interview/nodejs_interview.html","title":"nodejs_interview","keywords":"","body":" What is an error-first callback? How can you avoid callback hells? How can you listen on port 80 with Node? What's the event loop? What tools can be used to assure consistent style? What's the difference between operational and programmer errors? Why npm shrinkwrap is useful? What's a stub? Name a use case. What's a test pyramid? How can you implement it when talking about HTTP APIs? What's your favourite HTTP framework and why? What are Promises? When should you npm and when yarn? How can you secure your HTTP cookies against XSS attacks? How can you make sure your dependencies are safe? What is an error-first callback? Error-first callbacks are used to pass errors and data. The first argument is always an error object that the programmer has to check if something went wrong. Additional arguments are used to pass data. fs.readFile(filePath, function(err, data) { if (err) { //handle the error } // use the data object }); How can you avoid callback hells? modularization: break callbacks into independent functions use Promises use yield with Generators use a control flow library, like async use async/await (note that it is only available in the latest v7 release and not in the LTS version - you can read our experimental async/await how-to here) Why Modular programming Avoid naming conflict in global Separation of dependency concerns File concatenation for production //AMD define([module_id,] [dependencies], function (){ 'use strict'; //Put the module definition here }); define(['./UserModel', 'jquery'], function(User, $) { 'use strict'; var service = {}; service.fetchUsers = function(){ return $.ajax({ url: '/users', method: 'method', dataType: 'json', converters: { \"text json\": function(raw){ var data = JSON.parse(raw); var users = data.map(function(d){ var user = new User(); user.set('name', d.name); user.set('age', d.age); return user; }); return users; } } }); }; return service; }); //commonjs var $ = require('jquery'); var service = {}; service.fetchUsers = function() { return $.ajax({ url: '/mock/users.json', method: 'GET', dataType: 'json', converters: { 'text json': function(raw) { var data = JSON.parse(raw); var users = data.map(function(d) { var user = new User(); user.set('name', d.name); user.set('age', d.age); return user; }); return users; } } }); }; module.exports = service; //ES2015 import $ from 'jquery'; import User from './UserModel'; var service = {}; service.fetchUsers = function() { return $.ajax({ url: '/mock/users.json', method: 'GET', dataType: 'json', converters: { 'text json': function(raw) { var data = JSON.parse(raw); var users = data.map(function(d) { var user = new User(); user.set('name', d.name); user.set('age', d.age); return user; }); return users; } } }); }; export default service; How can you listen on port 80 with Node? Trick question! You should not try to listen with Node on port 80 (in Unix-like systems) - to do so you would need superuser rights, but it is not a good idea to run your application with it. Still, if you want to have your Node.js application listen on port 80, here is what you can do. Run the application on any port above 1024, then put a reverse proxy like nginx in front of it. What's the event loop? Node.js runs using a single thread. when you call sync functions, they will be pushed into call stack, and execute on javascript runtime. When calling async functions like setTimeout, it won't be execute on call stack immediately, browser webapi will execute it, and when it finishes, the result will be pushed to task queue. Event loop will check the status of call stack and task queue. When all sync functions on call stack are done, Event loop will send results on task queue to call stack and show results. Every I/O requires a callback - once they are done they are pushed onto the event loop for execution. Under the hood Node.js uses many threads through libuv. What tools can be used to assure consistent style? ESLint, Standard, JSLint These tools are really helpful when developing code in teams, to enforce a given style guide and to catch common errors using static analysis. What's the difference between operational and programmer errors? Operation errors are not bugs, but problems with the system, like request timeout or hardware failure. On the other hand programmer errors are actual bugs. Why npm shrinkwrap is useful? This command locks down the versions of a package's dependencies so that you can control exactly which versions of each dependency will be used when your package is installed. npmjs.com It is useful when you are deploying your Node.js applications - with it you can be sure which versions of your dependencies are going to be deployed. What's a stub? Name a use case. Stubs are functions/programs that simulate the behaviours of components/modules. Stubs provide canned answers to function calls made during test cases. Also, you can assert on with what these stubs were called. A use-case can be a file read, when you do not want to read an actual file: var fs = require('fs'); var readFileStub = sinon.stub(fs, 'readFile', function (path, cb) { return cb(null, 'filecontent'); }); expect(readFileStub).to.be.called; readFileStub.restore(); What's a test pyramid? How can you implement it when talking about HTTP APIs? A test pyramid describes that when writings test cases there should be a lot more low-level unit tests than high level end-to-end tests. When talking about HTTP APIs, it may come down to this: lots of low-level unit tests for models (dependencies **are stubbed**), fewer integration tests, where you check how your models interact with each other (dependencies **are not stubbed**), less end-to-end tests, where you call your actual endpoints (dependencies **are not stubbed**). What are Promises? Promises are a concurrency primitive. Promises can help you better handle async operations instead of callback functions. Also, note the catch, which can be used for error handling. Promises are chainable. new Promise((resolve, reject) => { setTimeout(() => { resolve('result') }, 100) }).then(console.log).catch(console.error) When are background/worker processes useful? How can you handle worker tasks? Worker processes are extremely useful if you'd like to do data processing in the background, like sending out emails or processing images. Canvas draw pixels. There are lots of options for this like RabbitMQ or Kafka. When to use yarn and npm? For now I would suggest keep using npm for open source libraries, so if a new update gets pushed, you will get that automatically as well, while for production application deployments yarn seems like a good fit. Ask interviewer How do you use them? How can you secure your HTTP cookies against XSS attacks? XSS occurs when the attacker injects executable JavaScript code into the HTML response. To mitigate these attacks, you have to set flags on the set-cookie HTTP header: HttpOnly - this attribute is used to help prevent attacks such as cross-site scripting since it does not allow the cookie to be accessed via JavaScript. secure - this attribute tells the browser to only send the cookie if the request is being sent over HTTPS. So it would look something like this: Set-Cookie: sid=; HttpOnly. If you are using Express, with express-cookie session, it is working by default. How can you make sure your dependencies are safe? When writing Node.js applications, ending up with hundreds or even thousands of dependencies can easily happen. For example, if you depend on Express, you depend on 27 other modules directly, and of course on those dependencies' as well, so manually checking all of them is not an option! The only option is to automate the update / security audit of your dependencies. For that there are free and paid options: npm outdated Trace by RisingStack NSP GreenKeeper Snyk What's wrong with the code snippet? new Promise((resolve, reject) => { throw new Error('error') }).then(console.log) As there is no catch after the then. This way the error will be a silent one, there will be no indication of an error thrown. To fix it, you can do the following: new Promise((resolve, reject) => { throw new Error('error') }).then(console.log).catch(console.error) If you have to debug a huge codebase, and you don't know which Promise can potentially hide an issue, you can use the unhandledRejection hook. It will print out all unhandled Promise rejections. process.on('unhandledRejection', (err) => { console.log(err) }) What's wrong with the following code snippet? function checkApiKey (apiKeyFromDb, apiKeyReceived) { if (apiKeyFromDb === apiKeyReceived) { return true } return false } When you compare security credentials it is crucial that you don't leak any information, so you have to make sure that you compare them in fixed time. If you fail to do so, your application will be vulnerable to timing attacks. But why does it work like that? V8, the JavaScript engine used by Node.js, tries to optimize the code you run from a performance point of view. It starts comparing the strings character by character, and once a mismatch is found, it stops the comparison operation. So the longer the attacker has from the password, the more time it takes. To solve this issue, you can use the npm module called cryptiles. function checkApiKey (apiKeyFromDb, apiKeyReceived) { return cryptiles.fixedTimeComparison(apiKeyFromDb, apiKeyReceived) } What's the output of following code snippet? Promise.resolve(1) .then((x) => x + 1) .then((x) => { throw new Error('My Error') }) .catch(() => 1) .then((x) => x + 1) .then((x) => console.log(x)) //2 .catch(console.error) A new Promise is created, that will resolve to 1. The resolved value is incremented with 1 (so it is 2 now), and returned instantly. The resolved value is discarded, and an error is thrown. The error is discarded, and a new value (1) is returned. The execution did not stop after the catch, but before the exception was handled, it continued, and a new, incremented value (2) is returned. The value 2 is printed to the standard output. This line won't run, as there was no exception. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/oop.html":{"url":"Interview/oop.html","title":"oop","keywords":"","body":"1. OOP1.1. Give me an example you used OOP1.2. SOLID principles1. OOP 1.1. Give me an example you used OOP OOP: abstraction, Encapsulation, inheritance, polymorphism. In a .net core project, I used repository pattern. So there is an abstract BaseRepository, which includes Add, Remove, Update methods, etc. Any repository that inherits from this baseRepo will have these common methods. And we can also add some new properties or methods for a specific class. Javascript: OOP list, indicator 1.2. SOLID principles Single responsibility Open close: open for extension, but closed for modification Liskov substitution: Can use baseType accepts childType without altering the correctness of that program. (Shape s = new Rectangle();) Interface segregation: many small interfaces rather than a big one, only implement interfaces needed DI: decouple. High-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/shift_operator.html":{"url":"Interview/shift_operator.html","title":"shift_operator","keywords":"","body":"1. shift operator 位运算1.1. 左移 (1.2. 右移 (>>)1. shift operator 位运算 1.1. 左移 ( 将第一个操作数向左移动第二个操作数指定的位数，空出的位置补0。左移相当于乘。左移一位相当于乘2。左移两位相当于乘4。左移三位相当于乘8。 x 1.2. 右移 (>>) 将第一个操作数向右移动第二个操作数所指定的位数，空出的位置补0。右移相当于整除。右移一位相当于除以2。右移两位相当于除以4。右移三位相当于除以8。 x>>1 === x/2 x>>2 === x/4 x>>3 === x/8 x>>4 ===x/16 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/sql.html":{"url":"Interview/sql.html","title":"sql","keywords":"","body":"sql performance Avoid Multiple Joins in a Single Query Eliminate Cursors from the Query Try to remove cursors from the query and use set-based query; set-based query is more efficient than cursor-based. If there is a need to use cursor than avoid dynamic cursors as it tends to limit the choice of plans available to the query optimizer. For example, dynamic cursor limits the optimizer to using nested loop joins. Use of Indexes Use join instead of subQuery if possible avoid select * avoid count * asterisk normalization denormalization for performance in large app database sharding, partition. Master read/write Debugging in SQL Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/to learn.html":{"url":"Interview/to learn.html","title":"to learn","keywords":"","body":"前端面试 http://www.thatjsdude.com/interview http://www.cnblogs.com/LO-ME/p/3606675.html 移动端 混合式 原生 前端动画： DOM动画，位置变化 svg path 动画 http://www.cnblogs.com/coco1s/p/6225973.html http://isux.tencent.com/svg-animate.html css3动画 微信开发、小程序 vue源码 阿里经常问 https://github.com/getify/You-Dont-Know-JS/blob/master/up%20%26%20going/ch1.md https://github.com/wwwebman/front-end-interview-questions https://segmentfault.com/a/1190000010880049 http://www.jianshu.com/p/99d9eda110f6 javascript 设计模式与开发实践 曾探著 webgl: https://developer.mozilla.org/zh-CN/docs/learn/WebGL http://www.jianshu.com/p/e3d8a244f3d9 rxjs: http://reactivex.io/rxjs/ https://yq.aliyun.com/articles/65027 https://segmentfault.com/a/1190000008464065 https://github.com/qiu-deqing/google http://www.cnblogs.com/weiqu/p/5860945.html vue react 源码解析 https://segmentfault.com/a/1190000006599500 https://github.com/berwin/Blog/issues/11 http://transcoder.tradaquan.com/from=1012852s/bd_page_type=1/ssid=672ebbab/uid=0/pu=sz%40320_1004%2Cta%40iphone_2_6.0_11_9.0%2Cusm%401/baiduid=87EA91E1A4122F054A2B3E0D40131DEF/w=0_10_/t=iphone/l=3/tc?ref=www_iphone&lid=12732224663698296230&order=5&fm=alhm&h5ad=1&srd=1&dict=32&tj=h5_mobile_5_0_10_title&w_qd=IlPT2AEptyoA_yk5wuwcqxGuClNVj7wpzSQYaxPVzAYtLOe&sec=23364&di=0b8c5341cc7f01c5&bdenc=1&tch=124.339.255.1228.0.0&nsrc=IlPT2AEptyoA_yixCFOxXnANedT62v3IEQGG_ytK1DK6mlrte4viZQRAXjbxKXXLUoCb9n00sqcHuH7c_GUo6so4g43&eqid=b0b1f2df9834500010000000599982ae&wd=&clk_info=%7B%22srcid%22%3A%221599%22%2C%22tplname%22%3A%22h5_mobile%22%2C%22t%22%3A1503232754687%2C%22sig%22%3A%2286768%22%2C%22xpath%22%3A%22div-a-h3%22%7D https://github.com/cucygh/es6-vue-react-gulp https://mp.weixin.qq.com/s?__biz=MzAxODE2MjM1MA==&mid=2651552583&idx=2&sn=00c75778efaf4709d0752bffadeb5285&chksm=8025ac86b75225903e0bcf69a5ecc41d4728183d1b9c567b176115a1ad557500827e68ea267b&mpshare=1&scene=23&srcid=09081I5DeMDZExOU7qxtqRI4#rd Build the layout and interactions of common web applications, such as the Netflix browser site. Implement widgets like a date picker, carousel or e-commerce cart. Write a function similar to debounce or clone an object deeply. Execution context, especially lexical scope and closures. Hoisting, function & block scoping and function expressions & declarations. Binding – specifically call, bind, apply and lexical this. Object prototypes, constructors and mixins. Composition and high order functions. Event delegation and bubbling. Type Coercion using typeof, instanceof and Object.prototype.toString. Handling asynchronous calls with callbacks, promises, await and async. When to use function declarations and expressions. DOM How to traverse and manipulate the DOM is important, and this is where most candidates struggle if they have been depending on jQuery or have been writing a lot of React & Angular type apps recently. You might not do this on a daily basis since most of us are using an abstraction of sorts, but without using a library you should know how to do the following: Selecting or finding nodes using document.querySelector and in older browsers document.getElementsByTagName. Traversal up and down – Node.parentNode, Node.firstChild, Node.lastChild and Node.childNodes. Traversal left and right – Node.previousSibling and Node.nextSibling. Manipulation – add, remove, copy, and create nodes in the DOM tree. You should know operations such as how to change the text content of a node and toggle, remove or add a CSS classname. Performance – touching the DOM can be expensive when you have many nodes, you should at least know about document fragments and node caching. 1、手写jsonp的实现 2、手写链表倒数第K个查找 3、http请求头，请求体，cookie在哪个里面？url在哪里面？ 4、原型链的解释 5、对闭包的理解，实现一个暴露内部变量，而且外部可以访问修改的函数 6、基本的数据类型 7、基本的两列自适应布局 8、unix中常用的命令行 9、OSI模型，HTTP,TCP,UDP分别在哪些层 10、解释平衡二叉树，以及在数据结构中的应用（红黑树） 11、快排的时间复杂度和空间复杂度 12、手写一个jQuery插件 13、在jquery方法和原型上面添加方法的区别和实现，以及jquery对象的实现 14、手写一个递归函数 15、对前端路由的理解？前后端路由的区别？ 16、介绍一下webpack和gulp，以及项目中具体的使用 17、你对es6的了解 18、解释一下vue和react，以及异同点 19、关于平衡二叉树 20、前后端分离的意义以及对前端工程化的理解 21、使用css实现一个三角形 22、用promise手写ajax 23、手写一个类的继承，并解释一下 24、解释一下call函数和apply函数的作用，以及用法 25、你说自己抗压能力强，具体表现在哪里？ 26、对前端前景的展望，以后前端会怎么发展 27、手写第一次面试没有写出来的链表问题，要求用es6写 28、平时是怎么学技术的？ 29、平时大学里面时间是怎么规划的？ 30、接下来有什么计划？这个学期和下个学期的计划是？ 31、项目中遇到的难点，或者你学习路上的难点 32、你是通过什么方法和途径来学习前端的 33、手写一个简单遍历算法 34、解释一下react和vue，以及区别 35、你在团队中更倾向于什么角色？ 36、对java的理解 37、介绍node.js，并且介绍你用它做的项目 38、手写一个js的深克隆 39、for函数里面setTimeout异步问题 40、手写归并排序 41、介绍自己的项目 42、实现两个数组的排序合并 43、手写一个原生ajax 44、手写一个promise版的ajax 45、手写实现一个promise 46、手写实现requireJS模块实现 47、手写实现jquery里面的insertAfter 48、react和vue的介绍以及异同 49、AMD和CMD，commonJS的区别 50、介绍一下backbone 51、了解过SEO吗？ 52、低版本浏览器不支持HTML5标签怎么解决？ 53、用js使低版本浏览器支持HTML5标签 底层是怎么实现的？ 54、实现一个布局：左边固定宽度为200，右边自适应，而且滚动条要自动选择只出现最高的那个 55、画出盒子模型，要使谷歌浏览器的盒子模型显示得跟IE浏览器一致（让谷歌跟ie一致，不是ie跟谷歌一致），该怎么做？ 56、手写JS实现类继承，讲原型链原理，并解释new一个对象的过程都发生了什么 57、Array对象自带的方法，一一列举 58、若干个数字，怎么选出最大的五个 59、Array对象自带的排序函数底层是怎么实现的？ 60、常用的排序算法有哪些，介绍一下选择排序 61、了解navigator对象吗？ 62、手写一个正则表达式，验证邮箱 63、link和@import引入CSS的区别？ 64、刚才说有些浏览器不兼容@import，具体指哪些浏览器？ 65、介绍一下cookie,localstorage,sessionstorage,session 66、jquery绑定click的方法有几种 67、你的优点/竞争力 68、移动端适配问题 69、react的难点在哪里 70、做过css动画吗 71、如何优化网站 72、以后的规划 73、你做过最困难的事情是啥？ 74、css3 html5新特性 75、闭包，ES6，跨域 76、问做过啥项目，用到什么技术，遇到什么困难 77、兼容性 78、盒子模型 79、Array的unshift() method的作用是什么？如何连接两个Array？如何在Array里移除一个元素？ 80、用纸笔写一个Closure，任意形式和内容 81、知不知道Array-like Object？ 82、如何用Native JavaScript来读写Cookie？ 83、知不知道CSS Box-model？ 84、如何做一个AJAX Request？ 85、Cross-domain access有没有了解？ 86、前端安全方面有没有了解？XSS和CSRF如何攻防？ 87、HTTP Response的Header里面都有些啥？ 88、知不知道HTTP2？ 89、输入URL后发生了什么？ 90、new operator实际上做了什么？ 91、面向对象的属性有哪些？ 92、做一个两栏布局，左边fixed width，右边responsive，用纸笔手写 93、讲一下AJAX Request 94、讲一下Cross-domain access 95、介绍一下做过的项目 96、问到了多个服务器怎么弄，架构之类的 97、angular的渲染流程 98、脏检查 99、nodejs的架构、优缺点、回调 100、css 盒模型 101、css 布局，左边定宽右边自适应 102、冒泡和捕获，事件流哪三个阶段？ 103、实现事件代理 104、原型链 105、继承的两种方法 106、ajax，原生ajax的四个过程 107、闭包，简单说一个闭包的应用，然后闭包的主要作用是什么 108、css:两个块状元素上下的margin-top和margin-bottom会重叠。啥原因？怎么解决？ 109、js：写一个递归。就是每隔5秒调用一个自身，一共100次 110、cookie和session有什么区别 111、网络分层结构 112、你的不足是什么？ 113、做了那么多项目，有没有自己的归纳总结 114、工程怎么进行文件管理 115、less和sass掌握程度 116、Cookie 是否会被覆盖，localStorage是否会被覆盖 117、事件代理js实现 118、Css实现动画效果 119、Animation还有哪些其他属性 120、Css实现三列布局 121、Css实现保持长宽比1:1 122、Css实现两个自适应等宽元素中间空10个像素 123、requireJS的原理是什么 124、如何保持登录状态 125、浮动的原理以及如何清除浮动 126、Html的语义化 127、原生js添加class怎么添加，如果本身已经有class了，会不会覆盖，怎么保留？ 128、Jsonp的原理。怎么去读取一个script里面的数据？ 129、如果页面初始载入的时候把ajax请求返回的数据存在localStorage里面，然后每次调用的时候去localStorage里面取数，是否可行。 130、304是什么意思？有没有方法不请求不经过服务器直接使用缓存 131、http请求头有哪些字段 132、数组去除一个函数。用arr.splice。又问splice返回了什么？应该返回的是去除的元素。 133、js异步的方法（promise，generator，async） 134、Cookie跨域请求能不能带上 135、最近看什么开源项目？ 136、commonJS和AMD 137、平时是怎么学习的？ 138、为什么要用translate3d？ 139、对象中key-value的value怎么再放一个对象？ 140、Get和post的区别？ 145、Post一个file的时候file放在哪的？ 146、说说你对组件的理解 147、组件的html怎么进行管理 148、js的异步加载，promise的三种状态，ES7中的async用过么 149、静态属性怎么继承 150、js原型链的继承 151、jquery和zepto有什么区别 152、angular的双向绑定原理 153、angular和react的认识 154、MVVM是什么 155、移动端是指手机浏览器，还是native，还是hybrid 156、你用了移动端的什么库类和框架？ 157、移动端要注意哪些？ 158、适配有去考虑么，retina屏幕啊？ 159、rem是什么？em是什么？如果上一层就是根root了，em和rem等价么？ 160、怎么测试的？会自动化测试么？ 161、你觉得你什么技术最擅长？ 162、你平时有没有什么技术的沉淀？ 163、单向链表怎么查找有没有环？ 164、怎么得到一个页面的a标签？ 165、怎么在页面里放置一个很简单的图标，不能用img和background-img？ 166、正则表达式判断url 167、怎么去除字符串前后的空格 168、实现页面的局部刷新 169、绝对定位与相对定位的区别 170、js轮播实现思路 171、使用js画一个抛物线，抛物线上有个小球随着抛物线运动，有两个按钮能使小球继续运动停止运动 172、java五子棋，说下实现思路 173、如何让各种情况下的div居中(绝对定位的div,垂直居中,水平居中)？ 174、display有哪些值？说明他们的作用 175、css定义的权重 176、requirejs实现原理 177、requirejs怎么防止重复加载 178、ES6里头的箭头函数的this对象与其他的有啥区别 179、tcp/udp区别 180、tcp三次握手过程 181、xss与csrf的原理与怎么防范 182、mysql与 MongoDB的区别 183、w3c事件与IE事件的区别 184、有没有上传过些什么npm模块 185、IE与W3C怎么阻止事件的冒泡 186、gulp底层实现原理 187、webpack底层实现原理 188、gulp与webpack区别 189、vuejs与angularjs的区别 190、vuex是用来做什么的 191、说下你知道的响应状态码 192、ajax的过程以及 readyState几个状态的含义 193、你除了前端之外还会些什么？ 194、cookie与session的区别 195、一些关于php与java的问题 196、你觉得你哪个项目是你做的最好的 197、说说你在项目中遇到了哪些困难,是怎么解决的 198、前端优化你知道哪些 199、webpack是用来干嘛的 200、webpack与gulp的区别 201、es6与es7了解多少 202、说下你知道的响应状态码 203、看过哪些框架的源码 204、遇到过哪些浏览器兼容性问题 205、清除浮动有哪几种方式,分别说说 206、你知道有哪些跨域方式,分别说说 207、JavaScript有哪几种类型的值 208、使用 new操作符时具体是干了些什么 209、学习前端的方法以及途径 210、怎么实现两个大整数的相乘，说下思路 211、你学过数据结构没,说说你都了解些什么 212、你学过计算机操作系统没,说说你都了解些什么 213、你学过计算机组成原理没,说说你都了解些什么 214、你学过算法没,说说你都了解些什么 215、说下选择排序,冒泡排序的实现思路 216、用过哪些框架 217、让你设计一个前端css框架你怎么做 218、了解哪些设计模式说说看 219、说下你所了解的设计模式的优点 220、vue源码结构 221、状态码 222、浏览器缓存的区别 223、304与200读取缓存的区别 224、http请求头有哪些,说说看你了解哪些 225、js中this的作用 226、js中上下文是什么 227、js有哪些函数能改变上下文 228、你所了解的跨域的方法都说说看你了解的？ 229、要是让你自己写一个js框架你会用到哪些设计模式 230、平常在项目中用到过哪些设计模式,说说看 231、一来给了张纸要求写js自定义事件 232、前端跨域的方法 233、call与apply的区别 234、h5有个api能定位你知道是哪个吗？ 235、vue与angularjs中双向数据绑定是怎样实现的？ 236、webpack怎样配置？ 237、nodejs中的文件怎么读写？ 238、link和@import有什么区别？ 239、cookies，sessionStorage 和 localStorage 的区别 240、看过哪些前端的书？平时是怎么学习的 241、说下你所理解的mvc与mvvc 242、position有哪些值,说下各自的作用 243、写个从几个li中取下标的闭包代码 244、你的职业规划是怎么样的？ 245、移动端性能优化 246、lazyload如何实现 247、点透问题 248、前端安全 249、原生js模板引擎 250、repaint和reflow区别 251、requirejs如何避免循环依赖？ 252、实现布局：左边一张图片，右边一段文字（不是环绕） 253、window.onload和$(document).ready()的区别，浏览器加载转圈结束时哪个时间点？ 254、form表单当前页面无刷新提交 target iframe 255、setTimeout和setInterval区别，如何互相实现？ 256、如何避免多重回调—promise，promise简单描述一下，如何在外部进行resolve() 257、margin坍塌？水平方向会不会坍塌？ 258、伪类和伪元素区别 259、vue如何实现父子组件通信，以及非父子组件通信 260、数组去重 261、使用flex布局实现三等分，左右两个元素分别贴到左边和右边，垂直居中 262、平时如何学前端的，看了哪些书，关注了哪些公众号 263、实现bind函数 264、数组和链表区别，分别适合什么数据结构 265、对mvc的理解 266、描述一个印象最深的项目，在其中担任的角色，解决什么问题 267、http状态码。。。401和403区别？ 268、描述下二分查找 269、为什么选择前端，如何学习的，看了哪些书，《js高级程序设计》和《你不知道的js》有什么区别，看书，看博客，看公众号三者的时间是如何分配的？ 270、如何评价BAT？ 271、描述下在实习中做过的一个项目，解决了什么问题，在其中担任了什么角色？这个过程存在什么问题，有什么值得改进的地方？ 272、如何看待加班，如果有个项目需要连续一个月加班，你怎么看？ 273、遇到的压力最大的一件事是什么？如何解决的？ 274、平时有什么爱好 275、自身有待改进的地方 276、n长的数组放入n+1个数，不能重复，找出那个缺失的数 277、手里有什么offer 278、你对于第一份工作最看重的三个方面是什么？ 279、如何评价现在的前端？ 280、用原生js实现复选框选择以及全选非全选功能 281、用4个颜色给一个六面体上色有多少种情况 282、amd和cmd区别 283、为什么选择前端，移动端性能优化 284、vue的特点？双向数据绑定是如何实现的 285、Object.defineProperty 286、算法题：数组去重，去除重复两次以上的元素，代码题：嵌套的ul-li结构，根据input中输入的内容，去除相应的li节点，且如果某个嵌套的ul下面的li都被移除，则该ul的父li节点也要被移除 287、页面加载过程 288、浏览器如何实现图片缓存 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/代理.html":{"url":"Interview/代理.html","title":"代理","keywords":"","body":"1. 代理1.1. 正向代理1.2. 反向代理1. 代理 1.1. 正向代理 A同学在大众创业、万众创新的大时代背景下开启他的创业之路，目前他遇到的最大的一个问题就是启动资金，于是他决定去找马云爸爸借钱，可想而知，最后碰一鼻子灰回来了，情急之下，他想到一个办法，找关系开后门，经过一番消息打探，原来A同学的大学老师王老师是马云的同学，于是A同学找到王老师，托王老师帮忙去马云那借500万过来，当然最后事成了。不过马云并不知道这钱是A同学借的，马云是借给王老师的，最后由王老师转交给A同学。这里的王老师在这个过程中扮演了一个非常关键的角色，就是代理，也可以说是正向代理，王老师代替A同学办这件事，这个过程中，真正借钱的人是谁，马云是不知道的，这点非常关键。 我们常说的代理也就是只正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求，某些科学上网工具扮演的就是典型的正向代理角色。用浏览器访问 http://www.google.com 时，被残忍的block，于是你可以在国外搭建一台代理服务器，让代理帮我去请求google.com，代理把请求返回的相应结构再返回给我。 1.2. 反向代理 大家都有过这样的经历，拨打10086客服电话，可能一个地区的10086客服有几个或者几十个，你永远都不需要关心在电话那头的是哪一个，叫什么，男的，还是女的，漂亮的还是帅气的，你都不关心，你关心的是你的问题能不能得到专业的解答，你只需要拨通了10086的总机号码，电话那头总会有人会回答你，只是有时慢有时快而已。那么这里的10086总机号码就是我们说的反向代理。客户不知道真正提供服务人的是谁。 反向代理隐藏了真实的服务端，当我们请求 www.baidu.com 的时候，就像拨打10086一样，背后可能有成千上万台服务器为我们服务，但具体是哪一台，你不知道，也不需要知道，你只需要知道反向代理服务器是谁就好了，www.baidu.com 就是我们的反向代理服务器，反向代理服务器会帮我们把请求转发到真实的服务器那里去。Nginx 就是性能非常好的反向代理服务器，用来做负载均衡。 两者的区别在于代理的对象不一样：正向代理代理的对象是客户端，反向代理代理的对象是服务端 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/代码优化.html":{"url":"Interview/代码优化.html","title":"代码优化","keywords":"","body":"1. 代码优化，和性能优化不一样1. 代码优化，和性能优化不一样 代码优化的目标是： 减小代码的体积 提高代码运行的效率 尽量重用对象 特别是 String 对象的使用，出现字符串连接时应该使用 StringBuilder。连接池、线程池 尽可能使用局部变量 调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中，速度较快。其他变量，如静态变量、实例变量等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃圾回收。 尽量减少对变量的重复计算 因为 array 其实是个特殊的 object，需要遍历 object 才知道长度： for (var i = 0, length = list.length; i 尽量采用懒加载的策略，即在需要的时候才创建 String str = \"aaa\"; if (i == 1) { 　　list.add(str); } 建议替换为： if (i == 1) { 　　String str = \"aaa\"; 　　list.add(str); } 乘法和除法使用移位操作 for (val = 0; val 用移位操作可以极大地提高性能，因为在计算机底层，对位的操作是最方便、最快的，因此建议修改为： for (val = 0; val > 1; } 移位操作虽然快，但是可能会使代码不太好理解，因此最好加上相应的注释。 循环内不要不断创建对象引用 for (int i = 1; i 这种做法会导致内存中有 count 份 Object 对象引用存在，count 很大的话，就耗费内存了，建议为改为： Object obj = null; for (int i = 0; i 尽量在合适的场合使用单例 使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率，但并不是所有地方都适用于单例，简单来说，单例主要适用于以下三个方面： 控制资源的使用，通过线程同步来控制资源的并发访问 控制实例的产生，以达到节约资源的目的 控制数据的共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信 程序运行过程中避免使用反射 使用数据库连接池和线程池 这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程 使用带缓冲的输入输出流进行IO操作 带缓冲的输入输出流，即 BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream，这可以极大地提升IO效率 顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/":{"url":"Interview/大型网站架构/","title":"Interview/大型网站架构","keywords":"","body":"1. TOC1. TOC 1大型网站架构演化 2大型网站架构模式 3大型网站性能优化 4大型网站架构要素 5高可用架构 6可扩展架构 database_scale Web系统大规模并发——电商秒杀与抢购 亿级Web系统搭建——单机到分布式集群 压力性能测试 回答高并发和大型网站设计 多线程1 多线程2 大型网站分布式设计 大型网站架构 读写锁分离-封装ReaderWriterLockSlim 负载均衡方法和分布式缓存 高并发 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/大型网站架构/1大型网站架构演化.html":{"url":"Interview/大型网站架构/1大型网站架构演化.html","title":"1大型网站架构演化","keywords":"","body":"1. 大型网站1.1. 一、大型网站系统特点1.2. 二、大型网站架构演化过程1.3. 本章思维导图1. 大型网站 1.1. 一、大型网站系统特点 高并发、大流量：PV量巨大 高可用：7*24小时不间断服务 海量数据：文件数目分分钟xxTB 用户分布广泛，网络情况复杂：网络运营商 安全环境恶劣：黑客的攻击 需求快速变更，发布频繁：快速适应市场，满足用户需求 渐进式发展：慢慢地运营出大型网站 1.2. 二、大型网站架构演化过程 初始阶段网站架构：一台Server就刚需—应用程序、数据库、文件等所有资源都集中在一台Server上，典型案例：基于LAMP架构的 PHP网站 应用和数据服务分离：三台Server平天下—业务发展，单台不再适应业务的发展，将应用和数据分离后成三台Sever（应用服务器、文件服务器与数据库服务器）。分离后三台Server对硬件资源的需求各不相同：应用服务器需要更快更强大的CPU，而数据库服务器需要更快的硬盘和更大的内存，文件服务器则需要更大的硬盘； 缓存：3+X的 Server模式—减少数据库访问压力，提高网站的数据访问速度。缓存又可以分为：本地缓存和远程缓存（可以是分布式的），本地缓存访问速度快，但数据量有限；远程分布式缓存可以集群，因此容量不受限制； 使用应用服务器集群改善网站并发处理能力：集群—硬件方面解决高并发、海量数据问题的常用手段，实现系统的可伸缩性。通过负载均衡调度器，可将用户访问分发到集群中的某台Server上，应用服务器的负载压力不再成为整个网站的瓶颈。 数据库读写分离：使用缓存后绝大部分都可以不通过DB就能完成，但仍有一部分（缓存访问不命中、缓存过期）和全部的写操作需要访问DB，在网站的用户达到一定规模后，DB因为负载压力过高成为网站的瓶颈。大部分主流DB都提供主从热备功能，利用这一功能就可以配置两台DB主从关系，一台数据更新同步到另一台Server上。网站利用DB的这一功能，实现DB读写分离，从而改善DB负载压力。 使用反向代理和CDN加速网站响应：CDN和反向代理的基本原理都是缓存，区别在于CDN部署在网络提供商的机房，而反向代理则部署在网站的中心机房。使用CDN和反向代理的目的都是尽早返回数据给用户，一方面加快用户访问速度，另一方面也减轻后端服务器的负载压力。 使用分布式文件系统和分布式数据库系统：随着网站业务的发展，两台DB服务器依然不能满足需求，文件系统也一样。 使用NoSQL和搜索引擎：NoSQL和搜索引擎都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。 业务拆分：通过分而治之的手段将整个网站业务分成不同的产品线，如淘宝将首页、商铺、订单、卖家、买家等拆分成不同的产品线，分归不同的业务团队负责。各个应用之间可以通过建立一个超链接建立关系，也可以通过消息队列进行数据分发。 分布式服务：既然每一个应用系统都需要执行许多相通的业务操作，比如用户管理、商品管理等，那么可以将这些共用的业务提取出来，独立部署。 1.3. 本章思维导图 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/2大型网站架构模式.html":{"url":"Interview/大型网站架构/2大型网站架构模式.html","title":"2大型网站架构模式","keywords":"","body":"1. 一、分层2. 二、分割3. 三、分布式4. 四、集群5. 五、缓存6. 六、异步7. 七、冗余8. 八、自动化9. 九、安全10. 十、总结11. 本章思维导图1. 一、分层 最常见的架构模式，将系统在横向维度上切分成几个部分，每个部分单一职责。网站一般分为三个层次：应用层、服务层和数据层，其具体结构如下图所示： 但是，分层架构也有一些挑战：①必须合理规划层次边界和接口；②禁止跨层次的调用及逆向调用。 2. 二、分割 分割是在纵向方面对软件进行切分->将不同的功能和服务分割开来，比如将服务层拆成多个小服务。包装成高内聚低耦合的模块单元，有助于软件开发和维护，还便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展能力。 3. 三、分布式 分布式应用和服务：应用和服务模块分布式部署，便于业务功能扩展； 分布式静态资源：JS、CSS、LOGO图片等资源独立部署，采用独立域名->动静分离； 分布式数据和存储：传统RDBMS分布式部署和NoSQL产品； 分布式计算：Hadoop及其MapReduce分布式计算框架，其特点是移动计算而不是移动数据。 4. 四、集群 多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务。当某台服务器发生故障，负载均衡设备或者系统的失效转移机制将请求转发到集群中的其他服务器上，提高系统的可用性，即所谓的HA（高可用性）。 在网站应用中，即使是访问量很小的分布式应用和服务，也至少要部署两台服务器构成一个小集群。 5. 五、缓存 缓存是改善软件性能的第一手段。 CDN：内容分发网络，缓存网站的一些静态资源； 反向代理：部署在网站的前端，最先访问到的就是反向代理服务器； 本地缓存：在应用服务器本地缓存热点数据，无需访问数据库； 分布式缓存：应用程序通过网络通信访问缓存数据； 网站应用中，缓存除了可以加快数据访问速度，还可以减轻后端应用和数据存储的负载压力。 6. 六、异步 业务之间的消息传递不是同步调用，而是将一个业务操作分成多个阶段，每个阶段之间通过共享数据的方式异步执行进行协作。 异步架构是典型的生产者消费者模式，两者不存在直接调用，只要保持数据结构不变，彼此功能实现可以随意变化而不互相影响，这对网站扩展新功能非常便利。 异步消息队列可以提高系统可用性、加快网站响应速度，消除并发访问高峰。 7. 七、冗余 要想保证在服务器宕机的情况下网站依然可以继续服务，不丢失数据，就需要一定程度的服务器冗余运行，数据冗余备份，这样当某台服务器宕机时，可以将其上的服务和数据访问转移到其他机器上。 数据库除了定期备份存档保存实现冷备份之外，为了保证在线业务高可用，还需要对数据库进行主从分离，实时同步实现热备份。 8. 八、自动化 在无人值守的情况下，网站可以正常运行，一切都可以自动化是网站的理想状态。目前大型网站的自动化架构设计主要集中在发布运维方面。　 发布部署过程自动化 自动化代码管理 自动化测试 自动化安全监测 9. 九、安全 通过密码和手机校验码进行身份验证 对登录、交易等操作进行加密 使用验证码进行识别 对于常见的XSS攻击、SQL注入、编码转换等进行防范 对垃圾或敏感信息进行过滤 对交易转账等操作进行风险控制 10. 十、总结 好的设计绝对不是模仿，不是生搬硬套某个模式，而是对问题深刻理解之上的创造与创新，即使是“微创新”，也是让人耳目一新的似曾相识。山寨与创新的最大区别不在于是否抄袭，是否模仿，而在于对问题和需求是否真正理解与把握。 11. 本章思维导图 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/3大型网站性能优化.html":{"url":"Interview/大型网站架构/3大型网站性能优化.html","title":"3大型网站性能优化","keywords":"","body":"1. 网站性能测试2. 性能优化1. 网站性能测试 性能测试指标：①响应时间；②并发数；③吞吐量；④性能计数器； 性能测试方法：①性能测试；②负载测试；③压力测试；④稳定性测试； 性能优化策略： 　　①性能分析：检查请求处理各个环节的日志，分析哪个环节响应时间不合理，检查监控数据分析影响性能的因素； 　　②性能优化：Web前端优化，应用服务器优化，存储服务器优化； 　 2. 性能优化 web前端 浏览器缓存：设置http头中Cache-Control和Expires属性 使用页面压缩：可以对html、css、js文件启用Gzip压缩，可以达到较高的压缩效率，但是压缩会对服务器及浏览器产生一定的压力 PS：Gzip压缩效率非常高，通常可以达到70%的压缩率，也就是说，如果你的网页有30K，压缩之后就变成了9K左右。想要启用Gzip压缩，提高浏览速度，可以浏览这篇文章：http://www.chinaz.com/web/2012/1017/278682.shtml 合理布局页面： CSS：把样式表置于顶部，浏览器会在下载完全部CSS之后才开始对整个页面进行渲染，因此最好将CSS放在页面最上面；避免使用CSS表达式（expression_r）；用link代替@import；避免使用滤镜； JavaScript：把脚本置于页面底部，浏览器在加载JS后会立即执行，有可能会阻塞整个页面，造成页面显示缓慢；使用外部JavaScript和CSS；削减JavaScript和CSS；剔除重复脚本；减少DOM访问；开发智能事件处理程序； 减少Cookie传输：一方面，太大的Cookie会严重影响数据传输；另一方面，对于某些静态资源的访问（如CSS、JS等）发送Cookie没有意义 减少http请求：因为http是无状态的，每次请求的开销都比较昂贵（需要建立通信链路、进行数据传输，而服务器端对于每个http请求都需要启动独立的线程去处理）；减少http的主要手段是合并CSS、合并JS、合并图片（CSS精灵，利用偏移定位image）； CDN：内容分发网络（Content Delivery Network，简称CDN） 它将数据缓存在离用户最近的节点，缩短用户查看对象的延迟，提高用户访问网站的响应速度与网站的可用性，解决网络带宽小、用户访问量大、网点分布不均等问题。http://baike.baidu.com/view/8689800.htm?from_id=420951&type=search&fromtitle=CDN&fr=aladdin 反向代理 反向代理服务器位于网站机房，代理网站Web服务器接收Http请求 反向代理服务器具有以下功能： 　　①保护网站安全：任何来自Internet的请求都必须先经过代理服务器 　　②通过配置缓存功能加速Web请求：减轻真实Web服务器的负载压力 　　③实现负载均衡：均衡地分发请求，平衡集群中各个服务器的负载压力 应用服务器端：服务器本地缓存和分布式缓存 分布式缓存： PS：网站性能优化第一定律：优先考虑使用缓存优化性能。缓存是指将数据存储在相对较高访问速度的存储介质中（如内存），以供系统进行快速处理响应用户请求。 ①缓存本质是一个内存Hash表，数据以(Key,Value)形式存储在内存中。 ②缓存主要用来存放那些读写比很高、很少变化的数据，如商品的类目信息、热门商品信息等。这样，应用程序读取数据时，先到缓存中取，如缓存中没有或失效，再到数据库中取出，重新写入缓存以供下一次访问。因此，可以很好地改善系统性能，提高数据读取速度，降低存储访问压力。 ③分布式缓存架构：一方面是以以JBoss Cache为代表的互相通信派；另一方面是以Memcached为代表的互不通信派； 　　JBoss Cache需要将缓存信息同步到集群中的所有机器，代价比较大；而Memcached采用一种集中式的缓存集群管理，缓存与应用分离部署，应用程序通过一致性Hash算法选择缓存服务器远程访问缓存数据，缓存服务器之间互不通信，因而集群规模可以轻易地扩容，具有良好的伸缩性。 　　Memcached由两个核心组件组成：服务端（ms）和客户端（mc），在一个memcached的查询中，mc先通过计算key的hash值来确定kv对所处在的ms位置。当ms确定后，客户端就会发送一个查询请求给对应的ms，让它来查找确切的数据。因为这之间没有交互以及多播协议，所以 memcached交互带给网络的影响是最小化的。 异步操作： ①使用消息队列将调用异步化，可改善网站的扩展性，还可改善网站性能； ②消息队列具有削峰的作用->将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务； 使用集群： Web服务器集群、数据库服务器集群、分布式缓存服务器集群等等，通过部署多台服务器共同对外提供同类服务，提高整体处理能力。 ①在高并发场景下，使用负载均衡技术为一个应用构建多台服务器组成的服务器集群； ②可以避免单一服务器因负载压力过大而响应缓慢，使用户请求具有更好的响应延迟特性； ③负载均衡可以采用硬件设备，也可以采用软件负载。商用硬件负载设备（例如出名的F5）成本通常较高（一台几十万上百万很正常），所以在条件允许的情况下我们会采用软负载，软负载解决的两个核心问题是：选谁、转发，其中最著名的是LVS（Linux Virtual Server）。 PS：LVS是四层负载均衡，也就是说建立在OSI模型的第四层——传输层之上，传输层上有我们熟悉的TCP/UDP，LVS支持TCP/UDP的负载均衡。 LVS的转发主要通过修改IP地址（NAT模式，分为源地址修改SNAT和目标地址修改DNAT）、修改目标MAC（DR模式）来实现。有关LVS的详情请参考：http://www.importnew.com/11229.html 代码优化： ①多线程：使用多线程的原因：一是IO阻塞，二是多CPU，都是为了最大限度地利用CPU资源，提高系统吞吐能力，改善系统性能； ②资源复用：目的是减少开销很大的系统资源的创建和销毁，主要采用两种模式实现：单例（Singleton）和对象池（Object Pool）。例如，在.NET开发中，经常使用到的线程池，数据库连接池等，本质上都是对象池。 ③数据结构：在不同场合合理使用恰当的数据结构，可以极大优化程序的性能。 ④垃圾回收：理解垃圾回收机制有助于程序优化和参数调优，以及编写内存安安全的代码。这里主要针对Java（JVM）和C#（CLR）一类的具有GC（垃圾回收机制）的语言。 数据库服务器端 索引：索引（index）是对数据库表中一个或多个列（例如，employee 表的姓氏 (name) 列）的值进行排序的结构。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。 PS：要注意的是，建立太多的索引将会影响更新和插入的速度，因为它需要同样更新每个索引文件。 缓存：数据库缓存是介于应用程序和物理数据源之间，其作用是为了降低应用程序对数据库的物理数据源访问的频次，从而提高了应用的运行性能。 SQL优化：当一个基于数据库的应用程序运行起来很慢时，90%的可能都是由于数据访问程序的问题，要么是没有优化，要么是没有按最佳方法编写代码，因此你需要审查和优化你的数据访问/处理程序。具体可以浏览这篇文章：http://www.cnblogs.com/Shaina/archive/2012/04/22/2464576.html NoSQL：方兴未艾的NoSQL数据库通过优化数据模型、存储结构、伸缩性等手段在性能方面的优势日趋明显。 存储性能优化 （1）机械硬盘 还是 固态硬盘？ （2）B+树 vs LSM树 　　①传统关系型数据库广泛采用B+树，B+树是对数据排好序后再存储，加快数据检索速度。 PS：目前大多数DB多采用两级索引的B+树，树的层次最多三层。因此可能需要5次磁盘访问才能更新一条记录（三次磁盘访问获得数据索引及行ID，一次数据文件读操作，一次数据文件写操作，终于知道数据库操作有多麻烦多耗时了） 　　②NoSQL（例如：HBase）产品广泛采用LSM树： 　　具体思想是：将对数据的修改增量保持在内存中，达到指定的大小限制后将这些修改操作批量写入磁盘。不过读取的时候稍微麻烦，需要合并磁盘中历史数据和内存中最近的修改操作，所以写入性能大大提升，读取时可能需要先看是否命中内存，否则需要访问较多的磁盘文件。 　　LSM树的原理是：把一棵大树拆分成N棵小树，它首先写入内存中，随着小树越来越大，内存中的小树会被清除并写入到磁盘中，磁盘中的树定期可以做合并操作，合并成一棵大树，以优化读性能。 　　LSM树的优势在于：在LSM树上进行一次数据更新不需要磁盘访问，在内存即可完成，速度远快于B+树。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/4大型网站架构要素.html":{"url":"Interview/大型网站架构/4大型网站架构要素.html","title":"4大型网站架构要素","keywords":"","body":"1. 可用性—你能保证几个9？2. 伸缩性3. 扩展性4. 安全性5. 本章思维导图1. 可用性—你能保证几个9？ 如何衡量可用性？全靠9来撑腰：几乎所有网站都承诺7✖️24小时可用，但事实上都不可能完全实现，总会有一些故障时间。那么，去除这些故障时间就是网站的总可用时间。换算成网站的可用性指标，以此衡量网站的可用性，例如某些知名网站可用性达到99.99%。 哪些手段提高可用性？ 　　①核心：冗余-各服务器互相备份保证整体可用； 　　②应用服务器端：通过负载均衡设备建立集群，其中一台宕机立即切换到其他服务器继续提供服务，这就保证了高可用性。 　　③存储服务器端：需要对数据进行实时备份，当某台宕机立即将数据访问请求转换到其他服务器上，并进行数据恢复以保证数据高可用。 2. 伸缩性 衡量标准： 　　①是否可以多态服务器构建集群？ 　　②是否容易向集群中添加新服务器？ 　　③加入服务器后是否能提供无差别服务？ 主要手段： 　　①应用服务器：使用合适的负载均衡设备（硬件还是软件？F5还是LVS+KeepAlived）； 　　②缓存服务器：改进缓存路由算法保证缓存数据的可访问性； 　　③数据库服务器：通过路由区分等手段将多服务器组成一个集群； 3. 扩展性 衡量标准：增加新业务时是否可以实现对现有产品透明无影响 主要手段： 　　①事件驱动架构：利用消息队列实现； 　　②分布式服务：将业务和可复用服务分离； 4. 安全性 何为安全性？保护网站不受恶意访问和攻击，保护网站的重要数据不被窃取； 衡量标准：针对现存和潜在的攻击窃密手段，是否有可靠的应对策略； 5. 本章思维导图 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/5高可用架构.html":{"url":"Interview/大型网站架构/5高可用架构.html","title":"5高可用架构","keywords":"","body":"1. 一、可用性度量与考核2. 二、高可用的架构3. 三、高可用的应用4. 四、高可用的服务5. 五、高可用的数据6. 六、高可用的QA7. 七、网站运行监控8. 本章思维导图1. 一、可用性度量与考核 如何度量网站可用性？ 一个神奇的数字—9！你有几个9，就代表了你的可用性。例如QQ可用性达到了4个9：99.99% ①2个9=基本可用　　②3个9=较高可用　　③4个9=具有自动恢复能力的高可用　　④5个9=极高可用->理想状态 那么，可用性的9又是怎么计算出来的呢： ①网站不可用时间=故障修复时间点-故障发现时间点 ②网站年度可用性指标=（1-网站不可用时间/年度总时间）*100% 如何考核网站可用性？ 　　广泛采用故障分的，它是对网站故障进行分类加权计算故障责任的方法。一般会给每个分类的故障设置一个权重（例如事故级故障权重为100，A类为20等），其计算公式为：故障分=故障时间（分钟）*故障权重。公司对技术团队的考核一般会参考故障分，例如某团队今年发生了几个事故级故障，那么其绩效考核估计受到很大影响，年终奖什么的就悲剧了。 2. 二、高可用的架构 　　目前，通常企业级应用系统（特别是政府部门和大企业的应用系统）一般会采用安规的软硬件设备，如IOE（IBM的小型机、Oracle数据、EMC存储设备）系列。而一般互联网公司更多地采用PC级服务器（x86），开源的数据库（MySQL）和操作系统（Linux）组建廉价且高容错（硬件故障是常态）的应用集群。 设计的目的？ 保证服务器硬件故障服务依然可用，数据依然保存并能够被访问。 主要的手段？ ①冗余备份以及 ②失效转移： 对于服务而言，一旦某个服务器宕机，就将服务切换到其他可用的服务器上。对于数据而言，如果某个磁盘损坏，就从备份的磁盘（事先就做好了数据的同步复制）读取数据。 3. 三、高可用的应用 1. 通过负载均衡进行无状态服务的失效转移 2. ==应用服务器集群的Session管理== Session单机情况下由部署在服务器上得Web容器（如IIS、Tomcat、JBoss等）管理。在使用了负载均衡的集群环境中，由于请求的分发是随机的，所以保证每次请求依然能够获得正确的Session比单机时要复杂得多。 在集群环境中，Session管理的几种常见手段: Session复制： 该方案简单易行，集群中的几台服务器之间同步Session对象，任何一台服务器宕机都不会导致Session对象的丢失，服务器也只需要从本机获取即可。但是，该方案只适合集群规模较小的情况下。当规模较大时，大量的Session复制操作会占用服务器和网络的大量资源，系统不堪重负。 Session绑定： 利用负载均衡的源地址Hash算法，总是将源于同一IP地址的请求分发到同一台服务器上。这样的话，在整个会话期间，用户所有的请求都在同一台服务器上进行处理，即Session绑定在某台特定服务器上，保证Session总能在这台服务器上获取。（这种方案又叫做会话粘滞）。 　　但是，这种方案不符合高可用的需求。因为一旦某台服务器宕机，那么该机器上得Session也就不复存在了，用户请求切换到其他机器后因为没有Session而无法完成业务处理。因此，很少有网站采用此方案进行Session管理。 Cookie记录Session： 利用浏览器支持的Cookie记录Session简单易行，可用性高，并且支持服务器的线性伸缩，因此，许多网站都或多或少地使用了Cookie来记录Session。但是Cookie记录Session有缺点：比如受Cookie大小限制、每次请求响应都要传输Cookie影响性能、用户关闭了Cookie会造成访问不正常等。 ==Session服务器==：利用独立部署的Session服务器（集群）统一管理Session，应用服务器每次读写Session时，都访问Session服务器。这种方案实际上是将应用服务器的状态分离，分为无状态的应用服务器和有状态的Session服务器。 对于，有状态的Session服务器，一种较简单的方法是利用分布式缓存（如Memcached、Redis等，有关Redis的简单介绍可以阅读我的博文：NoSQL初探之人人都爱Redis）、数据库等，在这些产品的基础上进行封装，使其符合Session的存储和访问要求。 4. 四、高可用的服务 　　高可用的服务模块为业务产品提供基础公共服务，在大型站点中这些服务通常都独立分布式部署，被具体应用远程调用。 　　在具体实践中，有以下几点高可用的服务策略可以参考： 　　①分级管理：核心应用和服务具有更高的优先级，比如用户及时付款比能否评价商品更重要； 　　②超时设置：设置服务调用的超时时间，一旦超时后，通信框架抛出异常，应用程序则根据服务调度策略选择重试or请求转移到其他服务器上； 　　③异步调用：通过消息队列等异步方式完成，避免一个服务失败导致整个应用请求失败的情况。 PS：不是所有服务都可以异步调用，对于获取用户信息这类调用，采用异步方式会延长响应时间，得不偿失。对于那些必须确认服务调用成功后才能继续进行下一步的操作的应用也不适合异步调用。有关具体使用消息队列实现异步调用的案例，请阅读我的博文：《使用Redis作为消息队列服务场景的应用案例》。 　　④服务降级：网站访问高峰期间，为了保证核心应用的正常运行，需要对服务降级。 　　降级有两种手段：一是拒绝服务，拒绝较低优先级的应用的调用，减少服务调用并发数，确保核心应用的正常运行；二是关闭功能，关闭部分不重要的服务，或者服务内部关闭部分不重要的功能，以节约系统开销，为核心应用服务让出资源； 　　⑤幂等性设计：保证服务重复调用和调用一次产生的结果相同； 5. 五、高可用的数据 　　对于大多数网站而言，数据是其最宝贵的物质资产。 　　保证数据高可用的主要手段有两种：一是数据备份，二是失效转移机制； 　　①数据备份：又分为冷备份和热备份，冷备份是定期复制，不能保证数据可用性。热备份又分为异步热备和同步热备，异步热备是指多份数据副本的写入操作异步完成，而同步方式则是指多份数据副本的写入操作同时完成。 　　关系数据库的热备机制就是通常所说的主从同步机制，实践中通常使用读写分离的方法来访问Master和Slave数据库，也就是说写操作只访问Master库，读操作均访问Slave库。 PS：在MS SQL Server中，可以通过发布订阅功能实现主从分离。关于发布订阅，可以参考MSDN的这篇文章：http://technet.microsoft.com/zh-cn/ff806143.aspx 　　②失效转移：若数据服务器集群中任何一台服务器宕机，那么应用程序针对这台服务器的所有读写操作都要重新路由到其他服务器，保证数据访问不会失败。 6. 六、高可用的QA 　　①网站发布：在柔性的发布过程中，每次关闭的服务都是集群中的一小部分，并在发布完成后立即可以访问； 　　②自动化测试：使用自动测试工具或脚本完成测试； 　　③预发布验证：引入预发布服务器，与正式服务器几乎一致，只是没有配置在负载均衡服务器上，外部用户无法访问； 　　④代码控制：目前大多数网站采用SVN，分支开发，主干发布模式；另外，目前开源社区广泛采用Git作为版本控制工具，正逐步取代SVN的地位； 7. 七、网站运行监控 　　”不允许没有监控的系统上线“ 　　（1）监控数据采集 　　①用户行为日志收集：服务器端的日志收集和客户端的日志收集；目前许多网站逐步开发基于实时计算框架Storm的日志统计与分析工具； 　　②服务器性能监控：收集服务器性能指标，如系统Load、内存占用、磁盘IO等，及时判断，防患于未然； 　　③运行数据报告：采集并报告，汇总后统一显示，应用程序需要在代码中处理运行数据采集的逻辑； 　　（2）监控管理 　　①系统报警：配置报警阀值和值守人员联系方式，系统发生报警时，即使工程师在千里之外，也可以被及时通知； 　　②失效转移：监控系统在发现故障时，主动通知应用进行失效转移； 　　③自动优雅降级：为了应付网站访问高峰，主动关闭部分功能，释放部分系统资源，保证核心应用服务的正常运行；—>网站柔性架构的理想状态 8. 本章思维导图 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/6可扩展架构.html":{"url":"Interview/大型网站架构/6可扩展架构.html","title":"6可扩展架构","keywords":"","body":"1. 一、可伸缩与可扩展—傻傻分不清楚2. 二、利用分布式消息队列降低系统耦合性2.1. 2.1 事件驱动架构2.2. 2.2 分布式消息队列3. 三、利用分布式服务打造可复用的业务平台　　3.1. 3.1 巨无霸的应用系统带来的问题3.2. 3.2 拆分，拆分还是拆分4. 四、可扩展的数据结构5. 五、利用开放平台建设网站生态圈6. 本章思维导图1. 一、可伸缩与可扩展—傻傻分不清楚 　　（1）扩展性（Extensibiltiy） 　　指对现有系统影响最小的情况下，系统功能可持续扩展或提升的能力。我们不禁想到了面向对象中一大原则：开闭原则，对扩展开放，对修改封闭。也就说，当系统新增一个功能时，不需要对现有系统的结构和代码进行修改。 　　（2）伸缩性（Scalability） 　　指系统能够通过增加（或减少）自身资源规模的方式增强（或减少）自己计算事务的能力。在网站架构中，通常是指利用集群的方式增加服务器数量，从而提高系统的整体事务吞吐能力。 　　设计网站可扩展架构的核心思想是：模块化，并在此基础之上降低模块间的耦合，提高模块的复用性。在大型网站中，这些模块通过分布式部署的方式，独立的模块部署在独立的服务器（集群）上，从物理上分离模块之间的耦合关系，进一步降低耦合性从而提高复用性。 2. 二、利用分布式消息队列降低系统耦合性 　　上面我们提到说要分离模块之间的耦合，如果模块之间不存在直接调用，那么新增模块或者修改模块就对其他模块的影响最小，这样系统的可扩展性无疑会更好一些。那么，有没有一种架构是基于如此考虑而设计的呢？于是，我们将眼光转向一个名叫“事件驱动”的架构。 2.1. 2.1 事件驱动架构 　　根据事件驱动架构（Event Driven Architecture）的定义：通过在低耦合的模块之间传输消息，以保持模块的松散耦合，并借助事件消息的通信完成模块间合作。典型的EDA架构就是操作系统中常见的生产者消费者模式。在大型网站架构中，具体实现手段有很多，但是最常见的是分布式消息队列。 　　如上图所示，消息队列利用发布—订阅模式工作，消息发送者发布消息，一个或多个消息接受者订阅消息。消息发送者是消息源，在对消息进行处理后发送至分布式消息队列，消息接收者从分布式消息队列获取该消息后继续进行处理。可以明显看出，发送者与接受者之间没有直接耦合，消息发送者只需将消息发送给分布式消息队列即操作结束，而消息接受者也只需要从分布式消息队列获取消息后进行处理，不需要知道该消息从何而来。因此，对于新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展设计。 2.2. 2.2 分布式消息队列 　　队列是一种先进先出的数据结构，分布式消息队列则看以看作是将这种数据结构部署到独立服务器上，应用程序看以通过远程访问接口使用分布式消息队列，进行消息存取操作，进而实现分布式的异步调用。 　　如上图所示，我们可以明确三个步凑： 　　①消息生产者应用程序通过远程访问接口将消息推送给消息队列服务器，消息队列服务器将消息写入本地内存队列后马上返回成功响应给消息生产者。 　　②消息队列服务器根据消息订阅列表查找订阅该消息的消费者应用程序，将消息队列中的消息按照先进先出的原则将消息通过远程通信接口发送给消费者应用程序； 　　③消费者应用程序接收到推送过来的消息之后进行相关的一系列处理，过程终止； 有没有这样一种情况：消息队列服务器宕机后导致消息丢失。事实上，这种情况的确存在于实际的运维过程中。那么，我们如何来避免呢？这时，作者给出了一个方案：如果消息队列服务器宕机造成消息丢失，会将消息成功发送到消息队列的消息存储在消息生产者服务器，等消息真正被消息消费者服务器处理后才删除消息。在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中其他的服务器发布消息。 另外，有关于分布式消息队列的实践可以采用NoSQL产品来构建，例如Redis就提供了队列数据类型，可以方便地构建分布式消息队列，如果你有兴趣，也可以参阅我的另一篇博文：《使用Redis作为消息队列服务应用场景案例》 3. 三、利用分布式服务打造可复用的业务平台　　 　　如果说分布式消息队列通过消息对象分解系统耦合性，不同子系统处理同一个消息；那么分布式服务则通过接口分解系统耦合性，不同子系统通过相同的接口描述进行服务调用。 3.1. 3.1 巨无霸的应用系统带来的问题 　　网站由小到大的演化过程中，表现为整个网站是由单一系统逐步膨胀发展变化而来的，随着网站功能的日益复杂，网站应用系统会逐渐成为一个巨无霸，如下图所示。可以看出，一个应用中聚合了大量的应用和服务组件，这个巨无霸给整个网站的开发（编译麻烦、代码分支管理困难）、维护（新增业务困难）和部署（部署困难）都带来了巨大的麻烦。 3.2. 3.2 拆分，拆分还是拆分 　　解决方案还是我们多次提到的拆分，将模块独立部署，降低系统耦合性。拆分又分为：横向拆分和纵向拆分。这里我们再次回顾一下这两种方式： 　　（1）纵向拆分：将一个大应用拆分为多个小应用，如果新增的业务较为独立，那么就直接将其设计部署为一个独立的Web应用系统； 　　（2）横向拆分：将可以复用的业务拆分出来，独立部署为分布式服务，新增业务只需要调用这些分布式服务即可，不需要依赖于具体的模块代码。如果模块内业务逻辑发生变化时，只要接口保持一致就不会影响业务程序和其他模块。 4. 四、可扩展的数据结构 　　传统的关系数据库为了保证关系运算（通过SQL语句）的正确性，在设计表结构的时候就需要制定表的Schema—字段名称、数据类型等，还要遵循制定的设计范式（例如：1NF、2NF、3NF等等）。这些规范带来的一个问题就是僵硬的数据结构难以面对需求变更带来的挑战，有些系统设计者通过预先设计一些冗余字段来应付（在我所实习的一年里，我见过很多次这种设计，虽然可以解决问题，但从设计学来说，真的好Shit），但这显然是一种糟糕的数据库设计。 　　那么，有木有办法能够做到可扩展的数据结构设计呢？是否可以不需要修改表结构就可以新增字段呢？答案是肯定的，目前许多NoSQL数据库使用的ColumnFamily（列族）设计就是一个解决方案。ColumnFamily最早在Google的BigTable中使用，这是一种面向列族的稀疏矩阵存储格式。或许这么说大家还是不明白，但可以通过下图来理解： 　　这是一个学生基本信息表，不同学生的联系方式不同，选修的课程也不同，而且在将来会有更多的联系方式和课程加入这张表，如果按照传统的数据库设计，无论提前预设多少冗余字段都不够用，捉襟见肘，疲于应付。而是用ColumnFamily结构的NoSQL数据库，创建表的时候，只需要指定ColumnFamily的名字，无需指定字段（Column），可以在数据写入时再指定，通过这种方式，数据表可以包含数百万的字段，使应用程序的数据结构可以随意扩展。 5. 五、利用开放平台建设网站生态圈 　　网站的价值在于为他的用户创造价值，大型网站为了更好地服务自己的用户，会开发更多的增值服务，会把网站内部的服务封装一些调用接口开放出去，供外部的第三方开发者使用，这个提供开放接口的平台被称作开放平台。第三方开发者利用这些开放的接口开发应用程序（APP）或者网站，为更多的用户提供价值。这样一来，网站、用户、第三方开发者相互依赖，形成一个网站的生态圈，即为用户提供更多的价值，也提高了网站和第三方开发者的竞争能力和盈利能力。 6. 本章思维导图 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/database_scale.html":{"url":"Interview/大型网站架构/database_scale.html","title":"database_scale","keywords":"","body":"1. Database Scale1.1. 1. Database Partitioning Options1.1.1. Cluster Computing1.1.2. Table Partitioning1.1.3. Federated Tables1.1.4. Sum of Partitioning Options1.2. 2. Database Sharding, The “Shared-Nothing” Approach1.2.1. Usage1.2.2. Advantage1.2.3. Things to be considered1.3. When Database Sharding is Appropriate1.4. Disadvantages of sharding1. Database Scale 1.1. 1. Database Partitioning Options 1.1.1. Cluster Computing Cluster computing utilizes many servers operating in a group, with shared messaging between the nodes of the cluster. Most often this scenario relies on a centralized shared disk facility, typically a Storage Area Network (SAN). Each node in the cluster runs a single instance of the database server, operating in various modes: For high-availability, many nodes in the cluster can be used for reads, but only one for write (CRUD) operations. This can make reads faster, but write transactions do not see any benefit. If a failure of one node occurs, then another node in the cluster takes over, again continuing to operating against the shared disk facility. This approach has limited scalability due to the single bottleneck for CRUD operations. Even the reads will ultimately hit a performance limit as the centralized shared disk facility can only spread the load so much before diminishing returns are experienced. The read limitations are particularly evident when an application requires complex joins or contains non-optimized SQL statements. More advanced clustering techniques rely on real-time memory replication between nodes, keeping the memory image of nodes in the cluster up to date via a real-time messaging system. This allows each node to operate in both read or write mode, but is ultimately limited by the amount of traffic that can be transmitted between nodes (using a typical network or other high-speed communication mechanism). Therefore, as nodes are added, the communication and memory replication overhead increases geometrically, thus hitting severe scalability limits, often with a relatively small number of nodes. This solution also suffers from the same shared disk limitations of a traditional cluster, given that a growing, single large database has increasingly intensive disk I/O. 1.1.2. Table Partitioning data in a single large table can be split across multiple disks for improved disk I/O utilization. The partitioning is typically done horizontally (separating rows by range across disk partitions), but can be vertical in some systems as well (placing different columns on separate partitions). This approach can help reduce the disk I/O bottleneck for a given table. disadvantage: make joins and other operations slower. since the approach relies on a single server instance of the database management system, all other CPU and memory contention limitations apply 1.1.3. Federated Tables An offshoot of Table Partitioning is the Federated Table approach, where tables can be accessed across multiple servers. disadvantage: complex to administer, and lacks efficiency as the federated tables must be accessed over the network. This approach may work for some reporting or analytical tasks, but for general read/write transactions it is not a very likely choice. 1.1.4. Sum of Partitioning Options The common drawback is reliance on shared facilities and resources. Whether relying on shared memory, centralized disk, or processor capacity they each suffer with scalability limitations, not to mention many other drawbacks, including complex administration, lack of support for critical business requirements, and high availability limitations. 1.2. 2. Database Sharding, The “Shared-Nothing” Approach ==breaking up big database into many smaller databases that share nothing and can be spread across multiple servers.== 1.2.1. Usage customerWest vs customerEast; customerEurope vs customerUS 1.2.2. Advantage improved scalability, growing in a near-linear fashion as more servers are added to the network Smaller databases are easier to manage. Smaller databases are faster. By hosting each shard database on its own server, the ratio between memory and data on disk is greatly improved, thereby reducing disk I/O. This results in less contention for resources, greater join performance, faster index searches, and fewer database locks. Database Sharding can reduce costs. Most Database Sharding implementations take advantage of lower-cost open source databases, or can even take advantage of “workgroup” versions of commercial databases. Additionally, sharding works well with commodity multi-core server hardware, far less expensive than high-end multi-CPU servers and expensive SANs. The overall reduction in cost due to savings in license fees, software maintenance and hardware investment is substantial, in some cases 70% or more when compared to other solutions. 1.2.3. Things to be considered Reliability. Automated backups of individual Database Shards. Database Shard redundancy, ensuring at least 2 “live” copies of each shard are available in the event of an outage or server failure. This requires a high-performance, efficient, and reliable replication mechanism. Cost-effective hardware redundancy, both within and across servers. Automated failover when an outage or server failure occurs. Disaster Recovery site management. Distributed queries. Aggregation of statistics, requiring a broad sweep of data across the entire system. Such an example is the computation of sales by product, which ordinarily requires evaluation of the entire database. Queries that support comprehensive reports, such as listings of all individual customers that purchased a given product in the last day, week or month. Avoidance of cross-shard joins. The primary technique to avoid this is the replication of Global Tables, the relatively static lookup tables that are common utilized when joining to much larger primary tables. Tables containing values as Status Codes, Countries, Types, and even Products fall into this category. What is required is an automated replication mechanism that ensures values for Global Tables are in synch across all shards, minimizing or eliminating the need for cross-shard joins. Auto-increment key management. Typical auto-increment functionality provided by database management systems generate a sequential key for each new row inserted into the database. This is fine for a single database application, but when using Database Sharding, keys must be managed across all shards in a coordinated fashion. The requirement here is to provide a seamless, automated method of key generation to the application, one that operates across all shards, ensuring that keys are unique across the entire system. Support for multiple Shard Schemes. It is important to note that Database Sharding is effective because it offers an application specific technique for massive scalability and performance improvements. In fact it can be said that the degree of effectiveness is directly related to how well the sharding algorithms themselves are tailored to the application problem at hand. What is required is a set of multiple, flexible shard schemes, each designed to address a specific type of application problem. Each scheme has inherent performance and/or application characteristics and advantages when applied to a specific problem domain. In fact, using the wrong shard scheme can actually inhibit performance and the very results you are trying to obtain. It is also not uncommon for a single application to use more than one shard scheme, each applied to a specific portion of the application to achieve optimum results. Here is a list of some common shard schemes: Session-based sharding, where each individual user or process interacts with a specific shard for the duration of the user or process session. This is the simplest technique to implement, and adds virtually zero overhead to overall performance, since the sharding decision is made only once per session. Applications which can benefit from this approach are often customer-centric, where all data for a given customer is contained in a single shard, and that is all the data that the customer requires. Transaction-based sharding determines the shard by examining the first SQL Statement in a given database transaction. This is normally done by evaluating the “shard key” value used in the statement (such as an Order Number), and then directing all other statements in the transaction to the same shard. Statement-based sharding is the most process intensive of all types, evaluating each individual SQL Statement to determine the appropriate shard to direct it to. Again, evaluation of the shard key value is required. This option is often desirable on high-volume, granular transactions, such as recording phone call records. Determine the optimum method for sharding the data. This is another area that is highly variable, change from application to application. It is closely tied with the selection of the Database Shard Scheme described above. There are numerous methods for deciding how to shard your data, and its important to understand your transaction rates, table volumes, key distribution, and other characteristics of your application. This data is required to determine the optimum sharding strategy: Shard by a primary key on a table. This is the most straightforward option, and easiest to map to a given application. However, this is only effective if your data is reasonably well distributed. For example, if you elected to shard by Customer ID (and this is a sequential numeric value), and most of your transactions are for new customers, very little if anything will be gained by sharding your database. On the other hand, if you can select a key that does adequately and naturally distribute your transactions, great benefits can be realized. Shard by the modulus of a key value. This option works in a vast number of cases, by applying the modulus function to the key value, and distributing transactions based on the calculated value. In essence you can predetermine any number of shards, and the modulus function effectively distributes across your shards on a “round-robin” basis, creating a very even distribution of new key values. Maintain a master shard index table. This technique involves using a single master table that maps various values to specific shards. It is very flexible, and meets a wide variety of application situations. However, this option often delivers lower performance as it requires an extra lookup for each sharded SQL Statement. 1.3. When Database Sharding is Appropriate High-transaction database applications Mixed workload database usage Frequent reads, including complex queries and joins Write-intensive transactions (CRUD statements, including INSERT, UPDATE, DELETE) Contention for common tables and/or rows General Business Reporting Typical “repeating segment” report generation Some data analysis (mixed with other workloads) Database Sharding is a method of “horizontal” portioning, meaning that database rows (as opposed to columns) for a single schema table are distributed across multiple shards. To understand the characteristics of how well sharding fits a given situation, here are the important things to determine: Identify all transaction-intensive tables in your schema. Determine the transaction volume your database is currently handling (or is expected to handle). Identify all common SQL statements (SELECT, INSERT, UPDATE, DELETE), and the volumes associated with each. Develop an understanding of your “table hierarchy” contained in your schema; in other words the main parent-child relationships. Determine the “key distribution” for transactions on high-volume tables, to determine if they are evenly spread or are concentrated in narrow ranges. With this information, you can rapidly gain an assessment of the value and applicability of sharding to your application. As an example, here is a simple Bookstore schema showing how the data can be sharded: Figure 3. Example Bookstore schema showing how data is sharded. In the Bookstore example, the Primary Shard Table is the ‘customer’ entity. This is the table that is used to shard the data. The ‘customer’ table is the parent of the shard hierarchy, with the ‘customer_order’ and ‘order_item’ entities as child tables. The data is sharded by the ‘customer.id’ attribute, and all related rows in the child tables associated with a given ‘customer.id’ are sharded as well. The Global Tables are the common lookup tables, which have relatively low activity, and these tables are replicated to all shards to avoid cross-shard joins. 1.4. Disadvantages of sharding Sharding a database table before it has been optimized locally causes premature complexity. Sharding should be used only when all other options for optimization are inadequate. The introduced complexity of database sharding causes the following potential problems: Increased complexity of SQL - Increased bugs because the developers have to write more complicated SQL to handle sharding logic. Sharding introduces complexity - The sharding software that partitions, balances, coordinates, and ensures integrity can fail. Single point of failure - Corruption of one shard due to network/hardware/systems problems causes failure of the entire table. Failover servers more complex - Failover servers must themselves have copies of the fleets of database shards. Backups more complex - Database backups of the individual shards must be coordinated with the backups of the other shards. Operational complexity added - Adding/removing indexes, adding/deleting columns, modifying the schema becomes much more difficult. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/memcache/":{"url":"Interview/大型网站架构/memcache/","title":"Interview/大型网站架构/memcache","keywords":"","body":"1. TOC1. TOC consistent_hash Memcached与Redis的对比 memcached使用 memcached分布式原理 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/大型网站架构/memcache/consistent_hash.html":{"url":"Interview/大型网站架构/memcache/consistent_hash.html","title":"consistent_hash","keywords":"","body":"1. System Design for Big Data1.1. What is Consistent Hashing1.2. When to use Consistent Hashing1.3. Here's how consistent hashing works1.4. Now let's consider the load balance issue1.5. Monotone Keys1. System Design for Big Data Given n cache hosts, an intuitive hash function is key % n. It is simple and commonly used. But it has two major drawbacks: It is NOT horizontally scalable. Every time when adding one new cache host to the system, all existing mappings are broken. It will be a pain point in maintenance if the caching system contains a lot of data. Also, if the caching system is behind a popular service, it is not easy to schedule a downtime to update all caching mappings. It may NOT be load balanced, especially for non-uniformly distributed data. In real world, it is less likely that the data is uniformly distributed. Then for the caching system, it results that some caches are hot and saturated while the others idle and almost empty. In such situations, consistent hashing is a good way to improve the caching system. 1.1. What is Consistent Hashing Consistent Hashing is a hashing strategy such that when the hash table is resized (e.g. a new cache host is added to the system), only k/n keys need to be remapped, where k is the number of keys and n is the number of caches. Recall that in a caching system using the mod as hash function, all keys need to be remapped. Consistent hashing maps an object to the same cache host if possible. If a cache host is removed, the objects on that host will be shared by other hosts; If a new cache is added, it takes its share from other hosts without touching other shares. 1.2. When to use Consistent Hashing Consistent hashing is a very useful strategy for distributed caching system and distributed hash tables. It can reduce the impact of host failures. It can also make the caching system more easier to scale up (and scale down). Example of uses include: Last.fm: memcached client with consistent hashing Amazon: internal scalable key-value store, Dynamo Chord: a distributed hash table by MITHow it works? As a typical hash function, consistent hashing maps a key or a cache host to an integer. Suppose the output of the hash function are in the range of [0, 2^128) (e.g. MD5 hash). Image that the integers in the range are placed on a ring such that the values are wrapped around. 1.3. Here's how consistent hashing works Given a list of cache servers, hash them to integers in the range. To map a key to a server, hash it to a single integer. Move clockwise on the ring until finding the first cache it encounters. That cache is the one that contains the key. See animation below as an example: key1 maps to cache A; key2 maps to cache C. To add a new cache, say D, keys that were originally falling to C will be split and some of them will be moved to D. Other keys don't need to be touched. To remove a cache or if a cache failed, say C, all keys that were originally mapping to C will fall into A and only those keys need to be moved to A. Other keys don't need to be touched. 1.4. Now let's consider the load balance issue As we discussed at the beginning, the real data are essentially randomly distributed and thus may not be uniform. It may cause the keys on caches are unbalanced. To resolve this issue, we add \"virtual replicas\" for caches. For each cache, instead of mapping it to a single point on the ring, we map it to multiple points on the ring, i.e. replicas. By doing this, each cache is associated with multiple segments of the ring. If the hash function \"mixes well\", as the number of replicas increases, the keys will be more balanced. 1.5. Monotone Keys If keys are known to be monotonically increased, binary searching can be used to improve the performance of locating a cache for a given key. Then the locate time can be reduced to O(log(n)). Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/memcache/Memcached与Redis的对比.html":{"url":"Interview/大型网站架构/memcache/Memcached与Redis的对比.html","title":"Memcached与Redis的对比","keywords":"","body":"1. Memcached 与 Redis 的对比1. Memcached 与 Redis 的对比 没有必要过多的关心性能，因为二者的性能都已经足够高了。由于Redis 只使用单核，而Memcached 可以使用多核，所以在比较上，平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在100k以上的数据中，Memcached 性能要高于 Redis，虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。说了这么多，结论是，无论你使用哪一个，每秒处理请求的次数都不会成为瓶颈。（比如瓶颈可能会在网卡） 如果要说内存使用效率，使用简单的 key-value 存储的话，Memcached 的内存利用率更高，而如果 Redis 采用 hash 结构来做 key-value 存储，由于其组合式的压缩，其内存利用率会高于 Memcached。当然，这和你的应用场景和数据特性有关。 如果你对数据持久化和数据同步有所要求，那么推荐你选择 Redis，因为这两个特性Memcached都不具备。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。 需要慎重考虑的部分: Memcached 单个 key-value 大小有限，一个 value 最大只支持1MB，而Redis最大支持512MB Memcached 只是个内存缓存，对可靠性无要求；而 Redis 更倾向于内存数据库，因此对对可靠性方面要求比较高 从本质上讲，Memcached 只是一个单一 key-value 内存 Cache；而 Redis 则是一个数据结构内存数据库，支持五种数据类型，因此 Redis 除单纯缓存作用外，还可以处理一些简单的逻辑运算，Redis 不仅可以缓存，而且还可以作为数据库用 新版本（3.0）的 Redis 是指集群分布式，也就是说集群本身均衡客户端请求，各个节点可以交流，可拓展行、可维护性更强大。 MongoDB不支持事务。 结论：在简单的 Key/Value 应用场景（例如缓存），Memcached 拥有更高的读写性能；而在数据持久化和数据同步场景，Redis 拥有更加强大的功能和更为丰富的数据类型 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/memcache/memcached使用.html":{"url":"Interview/大型网站架构/memcache/memcached使用.html","title":"memcached使用","keywords":"","body":"1. 安装和启动1.1. 先把 memcached 用起来1.1.1. memcached 分布式缓存的设置与应用1.1.2. memcached的数据压缩机制1.1.3. 使用客户端多个SocketIO池1.1.4. 说说 memcached 的故障转移处理1.1.5. 说说 key-value 中的 key 与 value1.2. Memcached 客户端使用封装1.2.1. 抽象出来了一个接口1.2.2. MemcacheHelper.cs1.3. App.config1.3.1. Program.cs1. 安装和启动 install memcached.exe -d install start memcached.exe -d start stop memcached.exe -d stop unInstall memcached.exe -d uninstall 以上的安装和启动都是在默认环境下进行的，在安装时可设置如下参数： Memcached 默认使用端口是11211 默认最大连接数是1024个 默认最大使用内存是64M 默认每个键值对，值存储空间为1M -p 监听的端口 -l 连接的IP地址, 默认是本机 -d start 启动memcached服务 -d restart 重起memcached服务 -d stop|shutdown 关闭正在运行的memcached服务 -d install 安装memcached服务 -d uninstall 卸载memcached服务 -u 以身份运行 (仅在以root运行的时候有效) -m 最大内存使用，单位MB。默认64MB -M 内存耗尽时返回错误，而不是删除项 -c 最大同时连接数，默认是1024 -f 块大小增长因子，默认是1.25 -n 最小分配空间，key+value+flags默认是48 -h 显示帮助 怎么才知道Memcached服务已经安装成功并启动了呢? cmd 命令 services.msc 检测Memcached服务是否成功启动： 使用telnet命令连接到登录台：telnet 服务器IP地址 11211（11211是默认的Memcached服务端口号） 打印当前Memcache服务器状态：stats 可以看到，通过stats命令列出了一系列的Memcached服务状态信息 1.1. 先把 memcached 用起来 下载客户端的4个dll，IcSharpCode.SharpZipLib.dll，log4net.dll，Memcached.ClientLibrary.dll，Commons.dll 新建一个简单控制台应用程序 using Memcached.ClientLibrary; using System; namespace Tdf.RedisCacheTest { class AMemcached { public static MemcachedClient cache; static AMemcached() { string[] servers = { \"127.0.0.1:11211\" }; // 初始化池 SockIOPool pool = SockIOPool.GetInstance(); // 设置服务器列表 pool.SetServers(servers); // 各服务器之间负载均衡的设置比例 pool.SetWeights(new int[] { 1 }); // 初始化时创建连接数 pool.InitConnections = 3; // 最小连接数 pool.MinConnections = 3; // 最大连接数 pool.MaxConnections = 5; // 连接的最大空闲时间，下面设置为6个小时（单位ms），超过这个设置时间，连接会被释放掉 pool.MaxIdle = 1000 * 60 * 60 * 6; // socket连接的超时时间，下面设置表示不超时（单位ms），即一直保持链接状态 pool.SocketConnectTimeout = 0; // 通讯的超时时间，下面设置为3秒（单位ms），.Net版本没有实现 pool.SocketTimeout = 1000 * 3; // 维护线程的间隔激活时间，下面设置为30秒（单位s），设置为0时表示不启用维护线程 pool.MaintenanceSleep = 30; // 设置SocktIO池的故障标志 pool.Failover = true; // 是否对TCP/IP通讯使用nalgle算法，.net版本没有实现 pool.Nagle = false; // socket单次任务的最大时间（单位ms），超过这个时间socket会被强行中端掉，当前任务失败。 pool.MaxBusy = 1000 * 10; pool.Initialize(); cache = new MemcachedClient(); // 是否启用压缩数据：如果启用了压缩，数据压缩长于门槛的数据将被储存在压缩的形式 cache.EnableCompression = false; // 压缩设置，超过指定大小的都压缩 cache.CompressionThreshold = 1024 * 1024; } } class Program { static void Main(string[] args) { // 存入key为userName，value为Bobby的一个缓存 AMemcached.cache.Add(\"userName\", \"Bobby\"); // 读出key为a的缓存值 var s = AMemcached.cache.Get(\"userName\"); // 输出 Console.WriteLine(s); Console.Read(); } } } 1.1.1. memcached 分布式缓存的设置与应用 string[] servers = { \"127.0.0.1:11211\", \"192.168.2.100:11211\" }; // 初始化池 SockIOPool pool = SockIOPool.GetInstance(); // 设置服务器列表 pool.SetServers(servers); // 各服务器之间负载均衡的设置比例 pool.SetWeights(new int[] { 1, 10 }); Note： 在172.18.5.66，与192.168.10.121两台机器上装memcached服务端。 pool.SetWeights这里的1跟10意思是，负载均衡比例，假如11000条数据，大致数据分布为：172.18.5.66分布1000条数据左右。另外一台为10000条左右。 memcached服务端并不具备负载均衡的能力，而是memcachedClient实现的，具体存取数据实现的核心是采用一致性Hash算法，把key-value分布到某一台服务器中里边。 1.1.2. memcached的数据压缩机制 // 是否启用压缩数据：如果启用了压缩，数据压缩长于门槛的数据将被储存在压缩的形式 cache.EnableCompression = false; // 压缩设置，超过指定大小的都压缩 cache.CompressionThreshold = 1024 * 1024; Note： 这个处理是在MemcachedClient对象中，设置这个EnableCompression属性，是否使用压缩的意思，如果启用啦压缩功能 ,则IcSharpCode.SharpZipLib类库会在数据超过预设大小时，进行数据压缩处理。 CompressionThreshold这个属性是压缩的阀值，默认是15K，如果超过设定的阀值则使用memcached的通讯协议，存数据时给每个数据项分配一个16为的flag表示，用作记录是否有压缩，如果有压缩则提取数据是进行解压。如果没有超过阀值则不压缩，直接存储。 1.1.3. 使用客户端多个SocketIO池 using Memcached.ClientLibrary; using System; namespace Tdf.RedisCacheTest { class AMemcached { public MemcachedClient cache; public AMemcached(string poolName) { string[] servers = { \"127.0.0.1:11211\", \"192.168.2.100:11211\" }; // 初始化池 SockIOPool pool = SockIOPool.GetInstance(); // 设置服务器列表 pool.SetServers(servers); // 各服务器之间负载均衡的设置比例 pool.SetWeights(new int[] { 1, 10 }); // 初始化时创建连接数 pool.InitConnections = 3; // 最小连接数 pool.MinConnections = 3; // 最大连接数 pool.MaxConnections = 5; // 连接的最大空闲时间，下面设置为6个小时（单位ms），超过这个设置时间，连接会被释放掉 pool.MaxIdle = 1000 * 60 * 60 * 6; // socket连接的超时时间，下面设置表示不超时（单位ms），即一直保持链接状态 pool.SocketConnectTimeout = 0; // 通讯的超时时间，下面设置为3秒（单位ms），.Net版本没有实现 pool.SocketTimeout = 1000 * 3; // 维护线程的间隔激活时间，下面设置为30秒（单位s），设置为0时表示不启用维护线程 pool.MaintenanceSleep = 30; // 设置SocktIO池的故障标志 pool.Failover = true; // 是否对TCP/IP通讯使用nalgle算法，.net版本没有实现 pool.Nagle = false; // socket单次任务的最大时间（单位ms），超过这个时间socket会被强行中端掉，当前任务失败。 pool.MaxBusy = 1000 * 10; pool.Initialize(); cache = new MemcachedClient(); // 是否启用压缩数据：如果启用了压缩，数据压缩长于门槛的数据将被储存在压缩的形式 cache.EnableCompression = false; // 压缩设置，超过指定大小的都压缩 cache.CompressionThreshold = 1024 * 1024; } } class Program { static void Main(string[] args) { // 存入key为userName，value为Bobby的一个缓存 new AMemcached(\"poolName\").cache.Add(\"b\", 123); // AMemcached.cache.Add(\"userName\", \"Bobby\"); // 读出key为a的缓存值 var s = new AMemcached(\"poolName\").cache.Get(\"userName\"); // 输出 Console.WriteLine(s); Console.Read(); } } } 1.1.4. 说说 memcached 的故障转移处理 // 设置 SocketIO 池的故障标志 pool.Failover = true; Note：memcached 的故障转移是一套正常节点发生故障变为死节点时的处理机制。 开启故障转移：如果发生 socket 异常，则该节点被添加到存放死节点属性的 hostDead 中，新请求被映射到 dead server，检测尝试连接死节点的时间间隔属性 hostDeadDuration（默认设置为100ms），如果没有达到设定的间隔时间则 key 会被映射到可用的 server 处理，如果达到了时间间隔，则尝试重新链接，连接成功将此节点从 hostDead 中去除，连接失败则间隔时间翻倍存放，下次重新连接时间会被拉长。 不开启故障转移：新的请求都会被映射到 dead server 上，尝试重新建立 socket 链接，如果连接失败，返回null或者操作失败。 1.1.5. 说说 key-value 中的 key 与 value key在服务端的长度限制为250个字符，建议使用较短的key但不要重复。 value的大小限制为1mb，如果大拉，可以使用压缩，如果还大，那可能拆分到多个key中。 1.2. Memcached 客户端使用封装 1.2.1. 抽象出来了一个接口 using System; namespace Tdf.Memcached { public interface IMemcached { void Add(string key, object value); void Add(string key, object value, DateTime expiredDateTime); void Update(string key, object value); void Update(string key, object value, DateTime expiredDateTime); void Set(string key, object value); void Set(string key, object value, DateTime expiredTime); void Delete(string key); object Get(string key); bool KeyExists(string key); } } 1.2.2. MemcacheHelper.cs using Memcached.ClientLibrary; using System; using System.Configuration; namespace Tdf.Memcached { /// /// 基于Memcached.ClientLibrary 封装使用 Memcached 信息 /// 读取缓存存放在服务器 /// public class MemcacheHelper { /// /// 字段_instance,存放注册的缓存信息 /// private static MemcacheHelper _instance; /// /// 缓存客户端 /// private readonly MemcachedClient _client; /// /// 受保护类型的缓存对象，初始化一个新的缓存对象 /// protected MemcacheHelper() { // 读取app.Config中需要缓存的服务器地址信息，可以传递多个地址，使用\";\"分隔 string[] serverList = ConfigurationManager.AppSettings[\"readWriteHosts\"].Split(new char[] { ';' }); try { // 初始化池 var sockIoPool = SockIOPool.GetInstance(); // 设置服务器列表 sockIoPool.SetServers(serverList); // 各服务器之间负载均衡的设置比例 sockIoPool.SetWeights(new int[] { 1 }); // 初始化时创建连接数 sockIoPool.InitConnections = 3; // 最小连接数 sockIoPool.MinConnections = 3; // 最大连接数 sockIoPool.MaxConnections = 5; // 连接的最大空闲时间，下面设置为6个小时（单位ms），超过这个设置时间，连接会被释放掉 sockIoPool.MaxIdle = 1000 * 60 * 60 * 6; // socket连接的超时时间，下面设置表示不超时（单位ms），即一直保持链接状态 sockIoPool.SocketConnectTimeout = 0; // 通讯的超时时间，下面设置为3秒（单位ms）,.Net版本没有实现 sockIoPool.SocketTimeout = 1000 * 3; // 维护线程的间隔激活时间，下面设置为30秒（单位s），设置为0时表示不启用维护线程 sockIoPool.MaintenanceSleep = 30; // 设置SocktIO池的故障标志 sockIoPool.Failover = true; // 是否对TCP/IP通讯使用nalgle算法，.net版本没有实现 sockIoPool.Nagle = false; // socket单次任务的最大时间（单位ms），超过这个时间socket会被强行中端掉，当前任务失败。 sockIoPool.MaxBusy = 1000 * 10; sockIoPool.Initialize(); // 实例化缓存对象 _client = new MemcachedClient(); // 是否启用压缩数据：如果启用了压缩，数据压缩长于门槛的数据将被储存在压缩的形式 _client.EnableCompression = false; // 压缩设置，超过指定大小的都压缩 _client.CompressionThreshold = 1024 * 1024; } catch (Exception ex) { // 错误信息写入事务日志 throw new Exception(ex.Message); } } /// /// 获取缓存的实例对象，方法调用的时候使用 /// /// public static MemcacheHelper GetInstance() { return _instance; } /// /// 添加缓存信息(如果存在缓存信息则直接重写设置，否则添加) /// 使用：MemcacheHelper.GetInstance().Add(key,value) /// /// 需要缓存的键 /// 需要缓存的值 public void Add(string key, object value) { if (_client.KeyExists(key)) { _client.Set(key, value); } _client.Add(key, value); } /// /// 添加缓存信息 /// 使用：MemcacheHelper.GetInstance().Add(key,value,Datetime.Now()) /// /// 需要缓存的键 /// 需要缓存的值 /// 设置的缓存的过时时间 public void Add(string key, object value, DateTime expiredDateTime) { _client.Add(key, value, expiredDateTime); } /// /// 修改缓存的值 /// 使用：MemcacheHelper.GetInstance().Update(key,value) /// /// 需要修改的键 /// 需要修改的值 public void Update(string key, object value) { _client.Replace(key, value); } /// /// 修改缓存的值 /// 使用：MemcacheHelper.GetInstance().Update(key,value,Datetime.Now()) /// /// 需要修改的键 /// 需要修改的值 /// 设置的缓存的过时时间 public void Update(string key, object value, DateTime expiredDateTime) { _client.Replace(key, value, expiredDateTime); } /// /// 设置缓存 /// 使用：MemcacheHelper.GetInstance().Set(key,value) /// /// 设置缓存的键 /// 设置缓存的值 public void Set(string key, object value) { _client.Set(key, value); } /// /// 设置缓存，并修改过期时间 /// 使用：MemcacheHelper.GetInstance().Set(key,value,Datetime.Now()) /// /// 设置缓存的键 /// 设置缓存的值 /// 设置缓存过期的时间 public void Set(string key, object value, DateTime expiredTime) { _client.Set(key, value, expiredTime); } /// /// 删除缓存 /// 使用：MemcacheHelper.GetInstance().Delete(key) /// /// 需要删除的缓存的键 public void Delete(string key) { _client.Delete(key); } /// /// 获取缓存的值 /// 使用：MemcacheHelper.GetInstance().Get(key) /// /// 传递缓存中的键 /// 返回缓存在缓存中的信息 public object Get(string key) { return _client.Get(key); } /// /// 缓存是否存在 /// 使用：MemcacheHelper.GetInstance().KeyExists(key) /// /// 传递缓存中的键 /// 如果为true，则表示存在此缓存，否则比表示不存在 public bool KeyExists(string key) { return _client.KeyExists(key); } /// /// 注册Memcache缓存(在Global.asax的Application_Start方法中注册) /// 使用：MemcacheHelper.RegisterMemcache(); /// public static void RegisterMemcache() { if (_instance == null) { _instance = new MemcacheHelper(); } } } } 1.3. App.config 1.3.1. Program.cs using System; using Tdf.Memcached; namespace Tdf.MemcachedTest { class Program { static void Main(string[] args) { // 注册Memcache缓存 MemcacheHelper.RegisterMemcache(); // 添加缓存信息(如果存在缓存信息则直接重写设置，否则添加) MemcacheHelper.GetInstance().Add(\"userName\", \"Bobby\"); // 缓存是否存在 var tf = MemcacheHelper.GetInstance().KeyExists(\"userName\"); Console.WriteLine(tf); // 获取缓存的值 var s = MemcacheHelper.GetInstance().Get(\"userName\"); Console.WriteLine(s); Console.Read(); } } } 到此，我们已经完成了一个最小化的 memcached 集群读写测试Demo。但是，在实际的开发场景中，远不仅仅是存储一个字符串，更多的是存储一个自定义的类的实例对象。这就需要使用到序列化，下面我们来新加一个类Claim，让其作为可序列化的对象来存储进Memcached中。注意：需要为该类加上 [Serializable] 的特性！ using System; using Tdf.Memcached; namespace Tdf.MemcachedTest { [Serializable] public class Claim { public int UserId { get; set; } public string UserName { get; set; } } class Program { static void Main(string[] args) { // 注册Memcache缓存 MemcacheHelper.RegisterMemcache(); // 自定义对象存储 Claim claim = new Claim(); claim.UserId = 694802856; claim.UserName = \"难念的经\"; MemcacheHelper.GetInstance().Add(\"Claim\", claim); Claim newMyObj = MemcacheHelper.GetInstance().Get(\"Claim\") as Claim; Console.WriteLine(\"Hello,My UserId is {0} and UserName is {1}\", newMyObj.UserId, newMyObj.UserName); Console.Read(); } } } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/memcache/memcached分布式原理.html":{"url":"Interview/大型网站架构/memcache/memcached分布式原理.html","title":"memcached分布式原理","keywords":"","body":"1. Memcached 分布式原理1.1. Memcached 内存管理机制1.2. Memcached 算法1.2.1. 余数计算分散法1.2.2. Consistent Hashing算法1.2.3. 优化的 Consistent Hashing 算法1. Memcached 分布式原理 添加新的键值对数据 从图中可以看出，Memcached 虽然称为“分布式”缓存服务器，但服务器端并没有“分布式”功能，而是完全由客户端程序库实现的。服务端之间没有任何联系，数据存取都是通过客户端的算法实现的。当客户端要存取数据时，首先会通过算法查找自己维护的服务器哈希列表，找到对应的服务器后，再将数据存往指定服务器。例如：上图中应用程序要新增一个 的键值对，它通过 set 操作提交给 Memcached 客户端，客户端通过一定的哈希算法（比如：一般的求余函数或者强大的一致性Hash算法）从服务器列表中计算出一个要存储的服务器地址，最后将该键值对存储到计算出来的服务器里边。 获取已存在的键值对数据 上图中应用程序想要获取 Key 为 tokyo 的 Value，于是它向 Memcached 客户端提交了一个 Get 请求，Memcached 客户端还是通过算法从服务器列表查询哪台服务器存有 Key 为 tokyo 的 Value（即选择刚刚 Set 到了哪台服务器），如果查到，则向查到的服务器请求返回 Key 为 tokyo 的数据。 1.1. Memcached 内存管理机制 Memcached 通过预分配指定的内存空间来存取数据，所有的数据都保存在 memcached 内置的内存中。利用 Slab Allocation 机制来分配和管理内存。按照预先规定的大小，将分配的内存分割成特定长度的内存块，再把尺寸相同的内存块分成组，这些内存块不会释放，可以重复利用。当存入的数据占满内存空间时，Memcached 使用 LRU 算法自动删除不使用的缓存数据。Memcached 是为缓存系统设计的，因此没有考虑数据的容灾问题，和机器的内存一样，重启机器将会丢失，如果希望服务重启数据依然能保留，那么就需要 sina 网开发的 Memcached 持久性内存缓冲系统，当然还有常见的 NOSQL 服务如 redis。默认监听端口：11211 1.2. Memcached 算法 1.2.1. 余数计算分散法 余数计算分散法是 memcached 标准的分布式方法，算法如下： CRC($key)%N 求得传入键的整数哈希值（ int hashCode ）。 使用计算出的 hashCode 除以服务器台数 (N) 取余数（ C = hashCode % N ） 在 N 台服务器中选择序号为 C 的服务器。 余数计算的方法简单，数据的分散性也相当优秀，但也有其缺点。 那就是当添加或移除服务器时，缓存重组的代价相当巨大。 添加服务器后，余数就会产生巨变，这样就无法获取与保存时相同的服务器， 从而影响缓存的命中率。 1.2.2. Consistent Hashing算法 首先求出 memcached 服务器节点的哈希值，并将其分配到 0 ～ 2^32 的圆上，这个圆我们可以把它叫做值域，然后用同样的方法求出存储数据键的哈希值，并映射到圆上。然后从数据映射到的位置开始顺时针查找，将数据保存到找到的最近服务器上，如果超过 0~2^32 仍找不到，就会保存在第一台 memcached 服务器上： memcached 基本原理: 再抛出上面的问题，如果新添加或移除一台机器，在consistent Hashing算法下会有什么影响。上图中假设有四个节点，我们再添加一个节点叫 node5: 添加了node节点之后: node5 被放在了 node4 与 node2 之间，本来映射到 node2 和 node4 之间的区域都会找到 node4，当有 node5 的时候，node5 和 node4 之间的还是找到 node4，而 node5 和 node2 之间的此时会找到 node5，因此当添加一台服务器的时候受影响的仅仅是 node5 和 node2 区间。由于KEY总是顺时针查找距离其最近的节点，因此新加入的节点只影响整个环中的一部分 1.2.3. 优化的 Consistent Hashing 算法 上面可以看出使用 consistent Hashing 最大限度的抑制了键的重新分配，且有的 consistent Hashing 的实现方式还采用了虚拟节点的思想。问题起源于使用一般hash函数的话，服务器的映射地点的分布非常不均匀，从而导致数据库访问倾斜，大量的key被映射到同一台服务器上。为了避免这个问题，引入了虚拟节点的机制，为每台服务器计算出多个hash值，每个值对应环上的一个节点位置，这种节点叫虚拟节点。而key的映射方式不变，就是多了层从虚拟节点再映射到物理机的过程。这种优化下尽管物理机很少的情况下，只要虚拟节点足够多，也能够使用得key分布的相对均匀。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/redis/":{"url":"Interview/大型网站架构/redis/","title":"Interview/大型网站架构/redis","keywords":"","body":"1. TOC1. TOC 1Redis在Windows上的安装与配置 2Redis API与常用数据类型简介 3Redis作为消息队列服务场景应用案例 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/大型网站架构/redis/1Redis在Windows上的安装与配置.html":{"url":"Interview/大型网站架构/redis/1Redis在Windows上的安装与配置.html","title":"1Redis在Windows上的安装与配置","keywords":"","body":"1. Redis1.1. Redis 在 Windows上的安装与配置1.1.1. 参考文献1.1.2. 附件下载1. Redis Redis是一个开源的，使用C语言编写，面向“键/值”（Key/Value）对类型数据的分布式NoSQL数据库系统，特点是高性能、持久存储、适应高并发的应用场景。因此，可以说Redis纯粹为应用而产生，它是一个高性能的key-value数据库，并且还提供了多种语言的API。那么，也许我们会问：到底性能如何呢？以下是官方的bench-mark数据： 测试完成了50个并发执行100000个请求。 设置和获取的值是一个256字节字符串。 Linux box是运行Linux 2.6,这是X3320 Xeon 2.5 ghz。 文本执行使用loopback接口(127.0.0.1)。 结果:读的速度是110000次/s,写的速度是81000次/s 。（当然不同的服务器配置性能也有所不同）。 　　和Memcached类似，Redis 支持存储的 value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis支持各种不同方式的排序。与Memcached一样，为了保证效率，数据都是缓存在内存中。区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步（数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。）。 　　因此，Redis的出现，很大程度补偿了 Memcached 这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。 1.1. Redis 在 Windows上的安装与配置 　　前面介绍了一大堆，现在开始真刀实干！首先，肯定是安装Redis，这里我们选择比较熟悉的Windows平台来进行安装。既然是Windows平台，那么肯定要选择一个 Windows 版本的 Redis安装包（其实 NoSQL 大部分都是部署在Linux服务器上得，什么原因？大家都懂得，开源+免费=成熟的服务器方案）。 　　（1）进入GitHub的Redis相关包下载页面：https://github.com/MSOpenTech/redis 　　（2）选择相应版本，我这里选择的是2.6的版本，点击Download ZIP按钮进行下载； 　　（3）打开压缩包，可以看到我们下载的其实是一个完整的Redis-2.6的包，包含了bin、src等文件夹，src是源码，而bin则是编译好的执行文件，也是我们主要使用的东东。进入bin目录，可以看到里面又有两个目录，一个是32位操作系统使用的，另一个则是64位操作系统使用的。 　　（4）我所使用的是64位系统，所以我将redisbin64.zip拷贝出来，解压后移动至我的D:/Redis目录中，可以看到解压后的内容包含以下的一些可执行exe文件： 　　下面来看看这几个可执行exe文件都是干嘛用的？ 　　①redis-server.exe：服务程序，也是最最最核心的一个程序。说到底，Redis也就是我们服务器系统上一直运行的一个服务甚至就是一个进程而已。 　　②redis-check-dump.exe：本地数据库检查 　　③redis-check-aof.exe：更新日志检查 　　④redis-benchmark.exe：性能测试，用以模拟同时由 N个客户端发送 M个 SETs/GETs 查询。上面所提到的测试结果就是使用的该程序来进行的。 　　⑤redis-cli.exe： 服务端开启后，我们的客户端就可以输入各种命令测试了，例如GET、SET等操作； 　　另外，将刚刚下载的包里边的redis.conf默认配置文件拷贝到工作目录中（我的是D:/Redis），redis.conf主要是一些 Redis的默认服务配置，包括默认端口号（一般默认6379）啊之类的配置。 　　（5）既然我们知道了redis-server.exe是最核心的一个程序，那么我们就首先来将它开启。这里需要在Windows的命令行界面中来开启，首先在运行窗口输入cmd进入命令窗口，使用cd命令切换到指定的目录（我是将刚刚解压的文件放在了D:/Redis文件夹下） 　　（6）最后就是惊心动魄地开启Redis的服务了，输入一句简单的命令：redis-server.exe redis.conf 　　这里需要注意的是：开启Redis服务后，命令行窗口不要关闭，一旦关闭，Redis服务也会相应关闭。因此，我们一般会将其改为Windows服务，并且设置为开机自动启动，就像我们数据库服务器中的SQL Server服务和Web服务器中的IIS服务一样。 　　（7）究竟我们的Redis安装好了没呢？我们可以通过新打开（记得是新打开一个，而不是将原来那个关闭了）一个cmd窗口使用redis-cli.exe来测试一下：redis-cli.exe -h 服务器IP –p 端口 　　（8）既然每次都需要在命令窗口中开启Redis服务不爽，那我们就动手将其改为Windows服务，让它自动启动。通过在网上查找，我在CSDN找到了一个批处理文件和一个RedisService的可执行文件，并将这两个文件拷贝到指定的Redis目录（我的是D:/Redis）： 　　其中，install-service这个批处理文件的代码如下： @echo off set cur_path=%cd% sc create redis-instance binpath= \"\\\"%cur_path%\\RedisService.exe\\\" %cur_path%\\redis.conf\" start= \"auto\" DisplayName= \"Redis\" 　　意思是在我们的Windows中创建一个Redis的服务实例，指定要启动的程序路径与配置文件路径。这里需要注意的是：RedisService是另外的一个exe，不是我们刚刚下载下来就有的，这个RedisService.exe的下载地址为：http://pan.baidu.com/s/1sjrvmTf。启动模式设置为auto代表自动启动，显示的服务名称为Redis。这样，一个bat文件就做好了，点击运行之后，一个Redis的Windows服务也出现在了我们的Windows服务列表中，如下图所示： 1.1.1. 参考文献 （1）传智播客Redis公开课，王承伟主讲，http://bbs.itcast.cn/thread-26525-1-1.html （2）NoSQL百度百科，http://baike.baidu.com/view/2677528.htm （3）孙立，《NoSQL开篇—为什么使用NoSQL》，http://www.infoq.com/cn/news/2011/01/nosql-why/ （4）Redis百度百科，http://baike.baidu.com/view/4595959.htm （5）Ruthless，《Windows下安装Redis》，http://www.cnblogs.com/linjiqin/archive/2013/05/27/3101694.html （6）张善友，《在Windows上以服务方式运行Redis》，http://www.cnblogs.com/shanyou/archive/2013/01/17/redis-on-windows.html 1.1.2. 附件下载 （1）Redis-2.6服务包：http://pan.baidu.com/s/1dDEKojJ （2）Redis注册Windows服务的批处理文件：http://pan.baidu.com/s/1jGJtNXs （3）Redis注册Windows服务的启动程序（RedisServcie.exe）：http://pan.baidu.com/s/1sjrvmTf Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/redis/2Redis API与常用数据类型简介.html":{"url":"Interview/大型网站架构/redis/2Redis API与常用数据类型简介.html","title":"2Redis API与常用数据类型简介","keywords":"","body":"1. 一、Redis API For .Net1.1. 二、Redis中常用数据类型1.2. 2.1 String 字符串1.3. 2.2 Hash1.3.1. 2.3 List 链表1.3.2. 2.4 Set 集合1.3.3. 2.5 Sorted Set 有序集合1.3.4. 参考文献1.3.5. 附件下载1. 一、Redis API For .Net 　　首先，不得不说 Redis 官方提供了众多的API开发包，但是目前Redis官方版本不支持.Net直接进行连接，需要使用一些第三方的开源类库。目前最流行的就是ServiceStack.Redis这个开源项目，其在GitHub上的下载地址为：https://github.com/ServiceStack/ServiceStack.Redis 　　进入下载页面，点击“Download Zip”按钮，即可下载该API包。解压该Zip包后，其实我们所用到的只是其中的几个DLL而已，打开build/release/MonoDevelop文件夹，看到里边还有一个zip包，这里边就是我们所需的DLL了。 　　再次解压这个Zip包，可以看到其中包含如下图所示的DLL文件，这几个也是我们今天所要引入VS的DLL库，有了它们，我们就可以在程序端和Redis服务端进行对话了，是不是很赞？ 　　这时，我们就可以在VS中新建一个控制台项目，命名为RedisDemo，然后新建一个Lib文件夹用来存放我们的DLL文件，然后添加对这些DLL引用。至此，就是万事俱备只欠东风了，我们接下来会在程序中调用Redis客户端和Redis服务端进行通信，了解Redis API为我们提供的丰富的数据类型。 1.1. 二、Redis中常用数据类型 　 Redis目前提供五种数据类型：string(字符串)、list（链表）、Hash（哈希）、set（集合）及zset(sorted set) （有序集合）。现在，我们一一来看看这五种数据类型的基本使用方法。在开始介绍之前，我们先使用刚刚引入的Redis API建立一个 Redis 客户端对象，有了这个客户端对象，我们才能和Redis服务端进行通信，且看下面的一行代码。我们需要事先指定好Redis服务端的IP地址和端口号，然后根据这两个信息建立一个RedisClient的对象实例，通过这个实例所带的方法和服务端通信。 using System; using System.Collections.Generic; using ServiceStack.Redis; namespace RedisDemo.FirstStart { class Program { //Redis服务器IP地址 static string localHostIP = \"127.0.0.1\"; //Redis服务端口号 static int redisServicePort = 6379; static void Main(string[] args) { var redisClient = new RedisClient(localHostIP, redisServicePort); Console.ReadKey(); } } } 1.2. 2.1 String 字符串 　　String是最常用的一种数据类型，普通的key/value存储都可以归为此类 。一个Key对应一个Value，string类型是二进制安全的。Redis的string可以包含任何数据，比如jpg图片(生成二进制)或者序列化的对象。 static void StringTypeDemo(RedisClient redisClient) { //向Redis中添加一个Key/Value对 redisClient.Set(\"username\", \"edisonchou\"); //从Redis中读取一个Value值 string userName = redisClient.Get(\"username\"); Console.WriteLine(\"The value from Redis is {0}\", userName); } 　　运行效果如下： 1.3. 2.2 Hash 　　Hash是一个string 类型的field和value的映射表。Hash特别适合存储对象，相对于将对象的每个字段存成单个string 类型。一个对象存储在Hash类型中会占用更少的内存，并且可以更方便的存取整个对象。 　　这里借用群叔的描述，我们简单举个实例来描述下Hash的应用场景，比如我们要存储一个用户信息对象数据，包含以下信息：用户ID为查找的key，存储的value用户对象包含姓名，年龄，生日等信息，如果用普通的key/value结构来存储，主要有以下2种存储方式： 　　第一种方式将用户ID作为查找key,把其他信息封装成一个对象以序列化的方式存储，这种方式的缺点是，增加了序列化/反序列化的开销，并且在需要修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护，引入CAS等复杂问题。 　　第二种方法是这个用户信息对象有多少成员就存成多少个key-value对儿，用用户ID+对应属性的名称作为唯一标识来取得对应属性的值，虽然省去了序列化开销和并发问题，但是用户ID为重复存储，如果存在大量这样的数据，内存浪费严重的。 　　因此，基于以上两种方式的缺陷，Redis提供的Hash很好的解决了这个问题，Redis的Hash实际是内部存储的Value为一个HashMap，并提供了直接存取这个Map成员的接口。 　　也就是说，Key仍然是用户ID, value是一个Map，这个Map的key是成员的属性名，value是属性值，这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field), 也就是通过key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题，也就很好的解决了问题。 　　下面我们在VS中来看看Hash类型如何Code： static void HashTypeDemo(RedisClient redisClient) { redisClient.SetEntryInHash(\"user\", \"userinfo\", \"cool boy\"); redisClient.SetEntryInHash(\"user\", \"useraccount\", \"5000\"); List keyList = redisClient.GetHashKeys(\"user\"); foreach (string key in keyList) { Console.WriteLine(key); string value = redisClient.GetValueFromHash(\"user\", key); Console.WriteLine(\"user:{0}:{1}\", key, value); } } 　　运行结果如下图： 1.3.1. 2.3 List 链表 　　List是一个链表结构，主要功能是push与pop，获取一个范围的所有的值等，操作中key理解为链表名字。 Redis的List类型其实就是一个每个子元素都是string类型的双向链表，我们可以通过push或pop操作从链表的头部或者尾部添加删除元素，这样List既可以作为栈，又可以作为队列。它即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。 　　（1）现在我们首先来看看List作为（Stack）栈类型的使用：　 　　那么在VS中如何来Code呢？通过Push与Pop操作Stack static void StackTypeDemo(RedisClient redisClient) { redisClient.PushItemToList(\"userenname\", \"edisonchou\"); redisClient.PushItemToList(\"userenname\", \"wncudchou\"); redisClient.PushItemToList(\"userenname\", \"milkye\"); redisClient.PushItemToList(\"userenname\", \"dickgu\"); int length = redisClient.GetListCount(\"userenname\"); for (int i = 0; i 　　运行效果如下： 　　（2）下面我们来看看List作为（Queue）队列的使用： 　　那么在VS中如何Code呢？通过DeQueue和EnQueue操作Queue static void QueueTypeDemo(RedisClient redisClient) { redisClient.EnqueueItemOnList(\"account\", \"马云\"); redisClient.EnqueueItemOnList(\"account\", \"马化腾\"); redisClient.EnqueueItemOnList(\"account\", \"李彦宏\"); int length = redisClient.GetListCount(\"account\"); for (int i = 0; i 　　运行效果如下： 1.3.2. 2.4 Set 集合 　　Set是string类型的无序集合。set是通过hash table实现的，添加、删除和查找，对集合我们可以取并集、交集、差集，可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。 　　与List比较而言，set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。 　　那么在VS中我们使用Set来Code一下，先增加两个Set集合，然后对其进行交集、并集与差集运算： static void SetTypeDemo(RedisClient redisClient) { redisClient.AddItemToSet(\"a3\", \"ddd\"); redisClient.AddItemToSet(\"a3\", \"ccc\"); redisClient.AddItemToSet(\"a3\", \"tttt\"); redisClient.AddItemToSet(\"a3\", \"sssh\"); redisClient.AddItemToSet(\"a3\", \"hhhh\"); redisClient.AddItemToSet(\"a4\", \"hhhh\"); redisClient.AddItemToSet(\"a4\", \"h777\"); Console.WriteLine(\"-------------求a3集合------------\"); HashSet hashSet = redisClient.GetAllItemsFromSet(\"a3\"); foreach (string value in hashSet) { Console.WriteLine(value); } Console.WriteLine(\"-------------求并集------------\"); hashSet.Clear(); hashSet = redisClient.GetUnionFromSets(new string[] { \"a3\", \"a4\" }); foreach (string value in hashSet) { Console.WriteLine(value); } Console.WriteLine(\"-------------求交集------------\"); hashSet.Clear(); hashSet = redisClient.GetIntersectFromSets(new string[] { \"a3\", \"a4\" }); foreach (string value in hashSet) { Console.WriteLine(value); } Console.WriteLine(\"-------------求差集------------\"); hashSet.Clear(); hashSet = redisClient.GetDifferencesFromSet(\"a3\", new string[] { \"a4\" }); foreach (string value in hashSet) { Console.WriteLine(value); } } 　　运行效果如下： 1.3.3. 2.5 Sorted Set 有序集合 　　Sorted Set 是set的一个升级版本，又被称为ZSet，它在set的基础上增加了一个顺序的属性，这一属性在添加修改。元素的时候可以指定，每次指定后，zset(表示有序集合)会自动重新按新的值调整顺序。可以理解为有列的表，一列存 value，一列存顺序。操作中key理解为zset的名字。 　　sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构。此外，还可以用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 　　下面，我们在VS中编写对Sorted Set的操作代码，输出时会按字母的有序顺序输出： static void SortedSetTypeDemo(RedisClient redisClient) { redisClient.AddItemToSortedSet(\"a5\", \"ffff\"); redisClient.AddItemToSortedSet(\"a5\", \"bbbb\"); redisClient.AddItemToSortedSet(\"a5\", \"gggg\"); redisClient.AddItemToSortedSet(\"a5\", \"cccc\"); redisClient.AddItemToSortedSet(\"a5\", \"waaa\"); List list = redisClient.GetAllItemsFromSortedSet(\"a5\"); foreach (string str in list) { Console.WriteLine(str); } } 　　运行效果如下： 1.3.4. 参考文献 （1）传智播客公开课，王承伟主讲，http://bbs.itcast.cn/thread-26525-1-1.html （2）群叔，《Redis数据类型详解及Redis适用场景》，http://www.cnblogs.com/qunshu/p/3196972.html 1.3.5. 附件下载 ServiceStack.Redis：http://pan.baidu.com/s/1sjtxe5v Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/redis/3Redis作为消息队列服务场景应用案例.html":{"url":"Interview/大型网站架构/redis/3Redis作为消息队列服务场景应用案例.html","title":"3Redis作为消息队列服务场景应用案例","keywords":"","body":"1. 一、消息队列场景简介1.1. 二、使用预置类型实现异常日志队列1.2. 三、使用Redis重构异常日志队列1.3. 四、小结1.3.1. 参考文献1.3.2. 附件下载1. 一、消息队列场景简介 　　 　　在众多的实践当中，除了增加服务器数量配置服务器集群实现伸缩性架构设计之外，异步操作也被广泛采用。而异步操作中最核心的就是使用消息队列，通过消息队列，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务，改善网站系统的性能。在京东之类的电子商务网站促销活动中，合理地使用消息队列，可以有效地抵御促销活动刚开始就开始大量涌入的订单对系统造成的冲击。 　　消息队列服务器中有一个进程单独对消息队列进行处理，首先判断消息队列中是否有待处理的消息，如果有，则将其取出（出队操作，坚持“先进先出”的顺序，保证事务的准确性）进行相应地处理（比如这里是进行保存数据的操作，将数据插入到数据库服务器中的指定数据库里边，实质还是文件的IO操作）。就这样，通过消息队列将高并发用户请求进行异步操作，然后一一对消息队列进行出队的同步操作，也避免了并发控制的难题。 　　说到这里，大家可能会想到这尼玛不就是生产者消费者模式么？对的，消息队列就是生产者消费者模式的典型场景。简单地说，客户端不同用户发送的操作请求就是生产者，他们将要处理的事务存储到消息队列中，然后消息队列服务器的某个进程不停地将要处理的单个事务从消息队列中一个一个地取出来进行相应地处理，这就是消费者消费的过程。 　　下面我们将以异常日志为案例，介绍在.Net中如何采用消息队列的思想解决并发问题。当然，消息队列只是解决并发问题的其中一种方式，在实际中往往需要结合多种不同的技术方式来共同解决，比如负载均衡、反向代理、集群等方案。这里，虽然以异常日志为案例，但是“麻雀虽小五脏俱全”，日志写入文件的高并发操作也同样适用于数据库的高并发，所以，研究这个案例是具有实际意义的。 1.1. 二、使用预置类型实现异常日志队列 　　在日常的Web应用中，异常日志的记录是一个十分重要的要点。因为，人无完人，系统也一样，难免会在什么时候出一个测试阶段未能完全测试到的异常。这时候，不能将异常信息直接显示给客户，那样既不友好也不安全。所以，一般都采用将异常信息记录到日志文件中（比如某个txt文件，数据库中某个表等），然后技术支持人员通过查看异常日志，分析异常原因，改进BUG重新发布，保障系统正常运行。 　　在用户的各种操作中，如果出现异常的时间一致，那么记录异常日志的操作就会成为并发操作，而记录异常日志又属于文件的IO操作（其实数据库的读写归根结底也是对文件即对磁盘进行的IO操作），因此很有可能带来并发控制的一系列问题。在以往的编码实践中，我们可以通过给不同的IO请求进行加锁（C#中的lock），等第一个请求完成写入后释放锁，第二个请求再获得锁，进行IO操作，然后释放掉，一直到第N个请求释放后结束。这种方式，虽然解决了并发操作带来的问题，但是通过加锁延迟了用户响应请求的时间（比如第一个正在IO写入操作时，后面的均处于等待状态），并且加锁也会给服务器带来一定的性能负担，造成服务器性能的下降。 　　基于以上原因，我们采用消息队列的思想将异常日志的记录操作改为队列版，这里我们先不采用Redis，直接使用.Net为我们提供的预置类型-Queue。接下来，就让我们动手开刀，写起来。 新建一个ASP.NET MVC 4项目，选择“基本”类型，视图引擎选择“Razor”。 既然是异常日志记录，首先得有异常。这时，我们脑海中想到了那个经典的异常：DividedByZeroException。于是，在Controllers 文件夹中新建一个 Controller，取名为Home（这里因为 Global 文件中的默认路由就指向了Home控制器中的Index 这个 Action），在 HomeControlle r中修改 Index 这个 Action的代码如下： public ActionResult Index() { int a = 10; int b = 0; int c = a / b; //会抛一个DividedByZero的异常 return View(); } 在ASP.NET MVC项目中，我们需要在Global.asax 中的 Application_Start 这个事件中修改全局过滤器（主要是App_Start中的 FilterConfig 类的 RegisterGlobalFilters这个方法），让系统支持对异常的全局处理操作（我们这里主要是对异常进行记录到指定文件中）。 public class FilterConfig { public static void RegisterGlobalFilters(GlobalFilterCollection filters) { // MyExceptionFilterAttribute 继承自 HandleError，主要作用是将异常信息写入日志文件中 filters.Add(new MyExceptionFilterAttribute()); // 默认的异常记录类 filters.Add(new HandleErrorAttribute()); } } 通过改写过滤器配置，我们向全局过滤器中注册了一个异常处理的过滤器配置，那么这个MyExceptionFilterAttribute类又是如何编写的呢？ public class MyExceptionFilterAttribute : HandleErrorAttribute { //版本1：使用预置队列类型存储异常对象 public static Queue ExceptionQueue = new Queue(); public override void OnException(ExceptionContext filterContext) { //将异常信息入队 ExceptionQueue.Enqueue(filterContext.Exception); //跳转到自定义错误页 filterContext.HttpContext.Response.Redirect(\"~/Common/CommonError.html\"); base.OnException(filterContext); } } 通过使该类继承 HandlerErrorAttribute 并使其覆写 OnException这个事件，代表在异常发生时可以进行的操作。而我们在这儿主要通过一个异常队列将获取的异常写入队列，然后跳转到自定义错误页：~/Common/CommonError.html，这个错误页很简单，就是简单的显示“系统发生错误，5秒后自动跳转到首页” 错误 .timecss { color: red; font-weight: bold; } function delayJump(url) { var timeValue = parseInt(document.getElementById(\"time\").innerHTML); if (timeValue > 0) { timeValue--; document.getElementById(\"time\").innerHTML = timeValue; } else { window.location.href = url; } setTimeout(\"delayJump('\" + url + \"')\", 1000); } 抱歉，处理您的请求时出错。将会在5秒后自动跳转到首页，请耐心等候。 var destUrl = \"/Home/NoError\"; delayJump(destUrl); 走到这里，生产者消费者模式中生产者的任务已经完成了，接下来消费者就需要开始消费了。也就是说，消息队列已经建好了，我们什么时候从队列中去任务，在哪里执行？怎么样执行？通过上面的介绍，我们知道，在专门的消息队列服务器中有一个进程在始终不停地监视消息队列，如果有需要待办的任务信息，则会立即从队列中取出来执行相应的操作，直到队列为空为止。于是，思路有了，我们马上来实现以下。这个消息监视的操作也是一个全局操作，在系统启动时就会一直运行，于是它也应该写在Application_Start这个全局起始事件里边，于是按照标准的配置写法，我们在Application_Start中添加了如下代码： protected void Application_Start() { AreaRegistration.RegisterAllAreas(); WebApiConfig.Register(GlobalConfiguration.Configuration); FilterConfig.RegisterGlobalFilters(GlobalFilters.Filters); RouteConfig.RegisterRoutes(RouteTable.Routes); BundleConfig.RegisterBundles(BundleTable.Bundles); //自定义事件注册 MessageQueueConfig.RegisterExceptionLogQueue(); } 那么，这个MessageQueueConfig.RegisterExceptionLogQueue()又是怎么写的呢？ public class MessageQueueConfig { public static void RegisterExceptionLogQueue() { string logFilePath = HttpContext.Current.Server.MapPath(\"/App_Data/\"); //通过线程池开启线程，不停地从队列中获取异常信息并将其写入日志文件 ThreadPool.QueueUserWorkItem(o => { while (true) { try { if (MyExceptionFilterAttribute.ExceptionQueue.Count > 0) { Exception ex = MyExceptionFilterAttribute.ExceptionQueue.Dequeue(); //从队列中出队，获取异常对象 if (ex != null) { //构建完整的日志文件名 string logFileName = logFilePath + DateTime.Now.ToString(\"yyyy-MM-dd\") + \".txt\"; //获得异常堆栈信息 string exceptionMsg = ex.ToString(); //将异常信息写入日志文件中 File.AppendAllText(logFileName, exceptionMsg, Encoding.Default); } } else { Thread.Sleep(1000); //为避免CPU空转，在队列为空时休息1秒 } } catch (Exception ex) { MyExceptionFilterAttribute.ExceptionQueue.Enqueue(ex); } } }, logFilePath); } } 现在，让我们来看看这段代码： ①首先定义Log文件存放的文件夹目录，这里我们一般放到App_Data里边，因为放到这里边外网是无法访问到的，可以防止下载操作； ②其次通过线程池ThreadPool开启一个线程，不停地监听消息队列里边的待办事项个数，如果个数>0，则进行出队（FIFO，先入队的先出队）操作。这里主要是取出具体的异常实例对象，并将异常的具体堆栈信息追加写入到指定命名格式的文件中。 许多应用程序创建的线程都要在休眠状态中消耗大量时间，以等待事件发生。其他线程可能进入休眠状态，只被定期唤醒以轮询更改或更新状态信息。线程池通过为应用程序提供一个由系统管理的辅助线程池使您可以更为有效地使用线程。关于线程池的更多信息请访问：http://msdn.microsoft.com/zh-cn/library/system.threading.threadpool(v=VS.90).aspx.aspx) ③如果该线程检测到消息队列中无待办事项，则使用Thread.Sleep使线程“休息”一会，避免了CPU空转（从理论上来说，CPU资源是很珍贵的，应该尽量提高CPU的利用率）。 最后，我们来看看效果如何？ ①首先，高大上的VS捕捉到了异常-DividedByZeroException： ②按照我们的全局异常处理过滤器，会将此异常记入队列中，并返回HTTP 302重定向跳转到自定义错误页面 ③最后，打开App_Data文件夹，查看日志文件： 到这里时，我们已经借助消息队列的思想完成了一个自定义的异常日志队列服务。但也许有朋友会说，这个跟Redis有关系么？异常日志不都是用Log4Net么？不要着急，后边我们就会使用Redis+Log4Net来重构这个异常日志队列服务。 1.2. 三、使用Redis重构异常日志队列 开启Redis的服务，这里我们使用命令开启Redis服务（之前已经将 Redis 注册到了Windows系统服务中了嘛，么么嗒）：net start redis-instance，当然，也可以通过在Windows服务列表中开启。 在刚刚的版本1的Demo中新建一个文件夹，命名为Lib，将ServiceStack.Redis的dll和Log4Net的dll都拷贝进去。然后，在引用中添加对Lib文件夹中所有dll的引用。 重写MyExceptionFilterAttribute这个全局异常信息过滤器。这里使用到了Redis的客户端连接池，每次连接时都是从池中取，不需要每次都创建，节省了时间和资源，提高了资源利用率。对于，多台Redis服务器组成的集群而言，这里需要指定多个形如 IP地址:端口号 的字符串数组。 public class MyExceptionFilterAttribute : HandleErrorAttribute { //版本2：使用Redis的客户端管理器（对象池） public static IRedisClientsManager redisClientManager = new PooledRedisClientManager(new string[] { //如果是Redis集群则配置多个{IP地址:端口号}即可 //例如: \"10.0.0.1:6379\",\"10.0.0.2:6379\",\"10.0.0.3:6379\" \"127.0.0.1:6379\" }); //从池中获取Redis客户端实例 public static IRedisClient redisClient = redisClientManager.GetClient(); public override void OnException(ExceptionContext filterContext) { //将异常信息入队 redisClient.EnqueueItemOnList(\"ExceptionLog\", filterContext.Exception.ToString()); //跳转到自定义错误页 filterContext.HttpContext.Response.Redirect(\"~/Common/CommonError.html\"); base.OnException(filterContext); } } 在Web.config 中加入 Log4Net 的详细配置 --> Log4Net是用来记录日志的一个常用组件（Log4J的移植版本），可以将程序运行过程中的信息输出到一些地方（文件、数据库、EventLog等）。由于Log4Net不是本篇博文介绍的重点，所以对Log4Net不熟悉的朋友，请在博客园首页搜索：Log4Net，浏览其详细的介绍。 其次，在App_Start文件夹中添加一个类，取名为LogConfig，定义一个静态方法：RegisterLog4NetConfigure，具体代码只有一行，实现了Log4Net配置的初始化操作。 public class LogConfig { public static void RegisterLog4NetConfigure() { //获取Log4Net配置信息(配置信息定义在Web.config文件中) log4net.Config.XmlConfigurator.Configure(); } } 最后，在Global.asax中的Application_Start方法中添加一行代码，注册Log4Net的配置： protected void Application_Start() { AreaRegistration.RegisterAllAreas(); WebApiConfig.Register(GlobalConfiguration.Configuration); FilterConfig.RegisterGlobalFilters(GlobalFilters.Filters); RouteConfig.RegisterRoutes(RouteTable.Routes); BundleConfig.RegisterBundles(BundleTable.Bundles); //自定义事件注册 MessageQueueConfig.RegisterExceptionLogQueue(); LogConfig.RegisterLog4NetConfigure(); } 改写 MessageQueueConfig 中的 RegisterExceptionLogQueue方法。这里就不再需要从预置类型Queue中取任务了，而是Redis中取出任务出队进行相应处理。这里，我们使用了Log4Net进行异常日志的记录工作。注意在代码顶部添加对log4net的引用：using log4net; public static void RegisterExceptionLogQueue() { //通过线程池开启线程，不停地从队列中获取异常信息并将其写入日志文件 ThreadPool.QueueUserWorkItem(o => { while (true) { try { if (MyExceptionFilterAttribute.redisClient.GetListCount(\"ExceptionLog\") > 0) { //从队列中出队，获取异常对象 string errorMsg = MyExceptionFilterAttribute.redisClient.DequeueItemFromList(\"ExceptionLog\"); if (!string.IsNullOrEmpty(errorMsg)) { //使用Log4Net写入异常日志 ILog logger = LogManager.GetLogger(\"Log\"); logger.Error(errorMsg); } } else { Thread.Sleep(1000); //为避免CPU空转，在队列为空时休息1秒 } } catch (Exception ex) { MyExceptionFilterAttribute.redisClient.EnqueueItemOnList(\"ExceptionLog\", ex.ToString()); } } }); } 调试验证是否能正常写入App_Data文件的日志中，发现写入的异常日志如下，格式好看，信息详细，圆满完成了我们的目的。 1.3. 四、小结 　　使用消息队列将调用异步化，可以改善网站系统的性能：消息队列具有很好的削峰作用，即通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。在电商网站的促销活动中，合理使用消息队列，可以有效地抵御促销活动刚开始大量涌入的订单对系统造成的冲击。本文使用消息队列的思想，借助Redis+Log4Net完成了一个超简单的异常日志队列的应用案例，可以有效地解决在多线程操作中对日志文件的并发操作带来的一些问题。同样地，借助消息队列的思想，我们也可以完成对数据库的高并发的消息队列方案。所以，麻雀虽小五脏俱全，理解好了这个案例，相信对我们这些菜鸟码农是有所裨益的。同样，也请大牛们一笑而过，多多指教菜鸟们一步一步地提高，谢谢了！后边，我们会探索一下Redis的集群、主从复制，以及在VMWare中建立几台虚拟机来构建主从结构，并使用Redis记录网站中重要的Session会话对象，或者是电商项目中常见的商品类目信息等。但是，本人资质尚浅，并且都是一些初探性质的学习，如有错误和不当，还请各位园友多多指教！ 1.3.1. 参考文献 （1）传智播客.Net学院王承伟，数据优化技术之Redis公开课，http://bbs.itcast.cn/thread-26525-1-1.html （2）Sanfilippo/贾隆译，《几点建议，让Redis在你的系统中发挥更大作用》，http://database.51cto.com/art/201107/276333.htm （3）NoSQLFan，《Redis作者谈Redis应用场景》，http://blog.nosqlfan.com/html/2235.html （4）善心如水，《C#中使用Log4Net记录日志》，http://www.cnblogs.com/wangsaiming/archive/2013/01/11/2856253.html （5）逆心，《ServiceStack.Redis之IRedisClient》，http://www.cnblogs.com/kissdodog/p/3572084.html （6）李智慧，《大型网站技术架构-核心原理与案例分析》，http://item.jd.com/11322972.html 1.3.2. 附件下载 （1）版本1：使用预置类型的异常日志队列Demo，http://pan.baidu.com/s/1nt5G7Fj （2）版本2：使用Redis+Log4Net的异常日志队列Demo，http://pan.baidu.com/s/1i3gMnnJ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/Web系统大规模并发——电商秒杀与抢购.html":{"url":"Interview/大型网站架构/Web系统大规模并发——电商秒杀与抢购.html","title":"Web系统大规模并发——电商秒杀与抢购","keywords":"","body":"一、大规模并发带来的挑战 在过去的工作中，我曾经面对过5w每秒的高并发秒杀功能，在这个过程中，整个Web系统遇到了很多的问题和挑战。 1. 请求接口的合理设计 一个秒杀或者抢购页面，通常分为2个部分，一个是静态的HTML等内容，另一个就是参与秒杀的Web后台请求接口。 通常静态HTML等内容，是通过CDN的部署，一般压力不大，核心瓶颈实际上在后台请求接口上。这个后端接口，必须能够支持高并发请求，同时，非常重要的一点，必须尽可能“快”，在最短的时间里返回用户的请求结果。为了实现尽可能快这一点，接口的后端存储使用内存级别的操作会更好一点。仍然直接面向MySQL之类的存储是不合适的，如果有这种复杂业务的需求，都建议采用异步写入。 当然，也有一些秒杀和抢购采用“滞后反馈”，就是说秒杀当下不知道结果，一段时间后才可以从页面中看到用户是否秒杀成功。但是，这种属于“偷懒”行为，同时给用户的体验也不好，容易被用户认为是“暗箱操作”。 2. 高并发的挑战：一定要“快” 通常衡量一个 Web 系统的吞吐率的指标是 QPS（Query Per Second，每秒处理请求数），解决每秒数万次的高并发场景，这个指标非常关键。举个例子，我们假设处理一个业务请求平均响应时间为100ms，同时，系统内有20台 Apache 的Web服务器，配置 MaxClients 为500个（表示Apache的最大连接数目）。 那么，Web 系统的理论峰值 QPS 为（理想化的计算方式）：20*500/0.1 = 100000 （10万QPS） 咦？我们的系统似乎很强大，1秒钟可以处理完10万的请求，5w/s的秒杀似乎是“纸老虎”哈。实际情况，当然没有这么理想。在高并发的实际场景下，机器都处于高负载的状态，在这个时候平均响应时间会被大大增加。 就Web服务器而言，Apache打开了越多的连接进程，CPU需要处理的上下文切换也越多，额外增加了CPU的消耗，然后就直接导致平均响应时间增加。因此上述的MaxClient数目，要根据CPU、内存等硬件因素综合考虑，绝对不是越多越好。可以通过 Apache 自带的 abench 来测试一下，取一个合适的值。然后，我们选择内存操作级别的存储的Redis，在高并发的状态下，存储的响应时间至关重要。网络带宽虽然也是一个因素，不过，这种请求数据包一般比较小，一般很少成为请求的瓶颈。负载均衡成为系统瓶颈的情况比较少，在这里不做讨论哈。 那么问题来了，假设我们的系统，在5w/s的高并发状态下，平均响应时间从100ms变为 250ms（实际情况，甚至更多）： 20*500/0.25 = 40000 （4万QPS） 于是，我们的系统剩下了4w 的 QPS，面对5w每秒的请求，中间相差了1w。 同理，某一个秒内，20*500个可用连接进程都在满负荷工作中，却仍然有1万个新来请求，没有连接进程可用，系统陷入到异常状态也是预期之内。 其实在正常的非高并发的业务场景中，也有类似的情况出现，某个业务请求接口出现问题，响应时间极慢，将整个Web请求响应时间拉得很长，逐渐将Web服务器的可用连接数占满，其他正常的业务请求，无连接进程可用。 更可怕的问题是，是用户的行为特点，系统越是不可用，用户的点击越频繁，恶性循环最终导致“雪崩”（其中一台Web机器挂了，导致流量分散到其他正常工作的机器上，再导致正常的机器也挂，然后恶性循环），将整个Web系统拖垮。 3. 重启与过载保护 如果系统发生“雪崩”，贸然重启服务，是无法解决问题的。最常见的现象是，启动起来后，立刻挂掉。这个时候，最好在入口层将流量拒绝，然后再将重启。如果是redis/memcache 这种服务也挂了，重启的时候需要注意“预热”，并且很可能需要比较长的时间。 秒杀和抢购的场景，流量往往是超乎我们系统的准备和想象的。这个时候，过载保护是必要的。如果检测到系统满负载状态，拒绝请求也是一种保护措施。在前端设置过滤是最简单的方式，但是，这种做法是被用户“千夫所指”的行为。更合适一点的是，将过载保护设置在CGI入口层，快速将客户的直接请求返回。 二、作弊的手段：进攻与防守 秒杀和抢购收到了“海量”的请求，实际上里面的水分是很大的。不少用户，为了“抢”到商品，会使用“刷票工具”等类型的辅助工具，帮助他们发送尽可能多的请求到服务器。还有一部分高级用户，制作强大的自动请求脚本。这种做法的理由也很简单，就是在参与秒杀和抢购的请求中，自己的请求数目占比越多，成功的概率越高。 这些都是属于“作弊的手段”，不过，有“进攻”就有“防守”，这是一场没有硝烟的战斗哈。 1. 同一个账号，一次性发出多个请求 部分用户通过浏览器的插件或者其他工具，在秒杀开始的时间里，以自己的账号，一次发送上百甚至更多的请求。实际上，这样的用户破坏了秒杀和抢购的公平性。 这种请求在某些没有做数据安全处理的系统里，也可能造成另外一种破坏，导致某些判断条件被绕过。例如一个简单的领取逻辑，先判断用户是否有参与记录，如果没有则领取成功，最后写入到参与记录中。这是个非常简单的逻辑，但是，在高并发的场景下，存在深深的漏洞。多个并发请求通过负载均衡服务器，分配到内网的多台Web服务器，它们首先向存储发送查询请求，然后，在某个请求成功写入参与记录的时间差内，其他的请求获查询到的结果都是“没有参与记录”。这里，就存在逻辑判断被绕过的风险。 应对方案： 在程序入口处，一个账号只允许接受1个请求，其他请求过滤。不仅解决了同一个账号，发送N个请求的问题，还保证了后续的逻辑流程的安全。实现方案，可以通过Redis这种内存缓存服务，写入一个标志位（只允许1个请求写成功，结合watch的乐观锁的特性），成功写入的则可以继续参加。 或者，自己实现一个服务，将同一个账号的请求放入一个队列中，处理完一个，再处理下一个。 2. 多个账号，一次性发送多个请求 很多公司的账号注册功能，在发展早期几乎是没有限制的，很容易就可以注册很多个账号。因此，也导致了出现了一些特殊的工作室，通过编写自动注册脚本，积累了一大批“僵尸账号”，数量庞大，几万甚至几十万的账号不等，专门做各种刷的行为（这就是微博中的“僵尸粉“的来源）。举个例子，例如微博中有转发抽奖的活动，如果我们使用几万个“僵尸号”去混进去转发，这样就可以大大提升我们中奖的概率。 这种账号，使用在秒杀和抢购里，也是同一个道理。例如，iPhone官网的抢购，火车票黄牛党。 应对方案： 这种场景，可以通过检测指定机器IP请求频率就可以解决，如果发现某个IP请求频率很高，可以给它弹出一个验证码或者直接禁止它的请求： 弹出验证码，最核心的追求，就是分辨出真实用户。因此，大家可能经常发现，网站弹出的验证码，有些是“鬼神乱舞”的样子，有时让我们根本无法看清。他们这样做的原因，其实也是为了让验证码的图片不被轻易识别，因为强大的“自动脚本”可以通过图片识别里面的字符，然后让脚本自动填写验证码。实际上，有一些非常创新的验证码，效果会比较好，例如给你一个简单问题让你回答，或者让你完成某些简单操作（例如百度贴吧的验证码）。 直接禁止IP，实际上是有些粗暴的，因为有些真实用户的网络场景恰好是同一出口IP的，可能会有“误伤“。但是这一个做法简单高效，根据实际场景使用可以获得很好的效果。 3. 多个账号，不同IP发送不同请求 所谓道高一尺，魔高一丈。有进攻，就会有防守，永不休止。这些“工作室”，发现你对单机IP请求频率有控制之后，他们也针对这种场景，想出了他们的“新进攻方案”，就是不断改变IP。 有同学会好奇，这些随机IP服务怎么来的。有一些是某些机构自己占据一批独立IP，然后做成一个随机代理IP的服务，有偿提供给这些“工作室”使用。还有一些更为黑暗一点的，就是通过木马黑掉普通用户的电脑，这个木马也不破坏用户电脑的正常运作，只做一件事情，就是转发IP包，普通用户的电脑被变成了IP代理出口。通过这种做法，黑客就拿到了大量的独立IP，然后搭建为随机IP服务，就是为了挣钱。 应对方案： 说实话，这种场景下的请求，和真实用户的行为，已经基本相同了，想做分辨很困难。再做进一步的限制很容易“误伤“真实用户，这个时候，通常只能通过设置业务门槛高来限制这种请求了，或者通过账号行为的”数据挖掘“来提前清理掉它们。 僵尸账号也还是有一些共同特征的，例如账号很可能属于同一个号码段甚至是连号的，活跃度不高，等级低，资料不全等等。根据这些特点，适当设置参与门槛，例如限制参与秒杀的账号等级。通过这些业务手段，也是可以过滤掉一些僵尸号。 4. 火车票的抢购** 看到这里，同学们是否明白你为什么抢不到火车票？如果你只是老老实实地去抢票，真的很难。通过多账号的方式，火车票的黄牛将很多车票的名额占据，部分强大的黄牛，在处理验证码方面，更是“技高一筹“。 高级的黄牛刷票时，在识别验证码的时候使用真实的人，中间搭建一个展示验证码图片的中转软件服务，真人浏览图片并填写下真实验证码，返回给中转软件。对于这种方式，验证码的保护限制作用被废除了，目前也没有很好的解决方案。 因为火车票是根据身份证实名制的，这里还有一个火车票的转让操作方式。大致的操作方式，是先用买家的身份证开启一个抢票工具，持续发送请求，黄牛账号选择退票，然后黄牛买家成功通过自己的身份证购票成功。当一列车厢没有票了的时候，是没有很多人盯着看的，况且黄牛们的抢票工具也很强大，即使让我们看见有退票，我们也不一定能抢得过他们哈。 最终，黄牛顺利将火车票转移到买家的身份证下。 解决方案： 并没有很好的解决方案，唯一可以动心思的也许是对账号数据进行“数据挖掘”，这些黄牛账号也是有一些共同特征的，例如经常抢票和退票，节假日异常活跃等等。将它们分析出来，再做进一步处理和甄别。 三、高并发下的数据安全 我们知道在多线程写入同一个文件的时候，会存现“线程安全”的问题（多个线程同时运行同一段代码，如果每次运行结果和单线程运行的结果是一样的，结果和预期相同，就是线程安全的）。如果是MySQL数据库，可以使用它自带的锁机制很好的解决问题，但是，在大规模并发的场景中，是不推荐使用MySQL的。秒杀和抢购的场景中，还有另外一个问题，就是“超发”，如果在这方面控制不慎，会产生发送过多的情况。我们也曾经听说过，某些电商搞抢购活动，买家成功拍下后，商家却不承认订单有效，拒绝发货。这里的问题，也许并不一定是商家奸诈，而是系统技术层面存在超发风险导致的。 超发的原因 假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是99个，然后都通过了这一个余量判断，最终导致超发。（同文章前面说的场景） 在上面的这个图中，就导致了并发用户B也“抢购成功”，多让一个人获得了商品。这种场景，在高并发的情况下非常容易出现。 1. 悲观锁思路 解决线程安全的思路很多，可以从“悲观锁”的方向开始讨论。 悲观锁，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待。 虽然上述的方案的确解决了线程安全的问题，但是，别忘记，我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，这种请求就会死在那里。同时，这种请求会很多，瞬间增大系统的平均响应时间，结果是可用连接数被耗尽，系统陷入异常。 2. FIFO队列思路 那好，那么我们稍微修改一下上面的场景，我们直接将请求放入队列中的，采用FIFO（First Input First Output，先进先出），这样的话，我们就不会导致某些请求永远获取不到锁。看到这里，是不是有点强行将多线程变成单线程的感觉哈。 然后，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态。或者设计一个极大的内存队列，也是一种方案，但是，系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说，队列内的请求会越积累越多，最终Web系统平均响应时候还是会大幅下降，系统还是陷入异常。 3. ==乐观锁思路== 这个时候，我们就可以讨论一下“乐观锁”的思路了。乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。这样的话，我们就不需要考虑队列的问题，不过，它会增大CPU的计算开销。但是，综合来说，这是一个比较好的解决方案。 有很多软件和服务都“乐观锁”功能的支持，例如 Redis 中的 watch 就是其中之一。通过这个实现，我们保证了数据的安全。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/亿级Web系统搭建——单机到分布式集群.html":{"url":"Interview/大型网站架构/亿级Web系统搭建——单机到分布式集群.html","title":"亿级Web系统搭建——单机到分布式集群","keywords":"","body":"1. Web负载均衡1.1. 1. HTTP重定向1.2. 2. 反向代理负载均衡1.3. 3. IP负载均衡1.4. 4. DNS负载均衡1. Web负载均衡 Web负载均衡（Load Balancing），简单地说就是给我们的服务器集群分配“工作任务”，而采用恰当的分配方式，对于保护处于后端的Web服务器来说，非常重要。 负载均衡的策略有很多，我们从简单的讲起哈。 1.1. 1. HTTP重定向 当用户发来请求的时候，Web服务器通过修改HTTP响应头中的Location标记来返回一个新的url，然后浏览器再继续请求这个新url，实际上就是页面重定向。通过重定向，来达到“负载均衡”的目标。例如，我们在下载PHP源码包的时候，点击下载链接时，为了解决不同国家和地域下载速度的问题，它会返回一个离我们近的下载地址。重定向的HTTP返回码是302，如下图： 如果使用PHP代码来实现这个功能，方式如下： 这个重定向非常容易实现，并且可以自定义各种策略。但是，它在大规模访问量下，性能不佳。而且，给用户的体验也不好，实际请求发生重定向，增加了网络延时。 1.2. 2. 反向代理负载均衡 反向代理服务的核心工作主要是转发HTTP请求，扮演了浏览器端和后台Web服务器中转的角色。因为它工作在HTTP层（应用层），也就是网络七层结构中的第七层，因此也被称为“七层负载均衡”。可以做反向代理的软件很多，比较常见的一种是Nginx。 Nginx是一种非常灵活的反向代理软件，可以自由定制化转发策略，分配服务器流量的权重等。反向代理中，常见的一个问题，就是Web服务器存储的session数据，因为一般负载均衡的策略都是随机分配请求的。同一个登录用户的请求，无法保证一定分配到相同的Web机器上，会导致无法找到session的问题。 解决方案主要有两种： 配置反向代理的转发规则，让同一个用户的请求一定落到同一台机器上（通过分析cookie），复杂的转发规则将会消耗更多的CPU，也增加了代理服务器的负担。 将session这类的信息，专门用某个独立服务来存储，例如redis/memchache，这个方案是比较推荐的。 反向代理服务，也是可以开启缓存的，如果开启了，会增加反向代理的负担，需要谨慎使用。这种负载均衡策略实现和部署非常简单，而且性能表现也比较好。但是，它有“单点故障”的问题，如果挂了，会带来很多的麻烦。而且，到了后期Web服务器继续增加，它本身可能成为系统的瓶颈。 1.3. 3. IP负载均衡 IP负载均衡服务是工作在网络层（修改IP）和传输层（修改端口，第四层），比起工作在应用层（第七层）性能要高出非常多。原理是，他是对IP层的数据包的IP地址和端口信息进行修改，达到负载均衡的目的。这种方式，也被称为“四层负载均衡”。常见的负载均衡方式，是LVS（Linux Virtual Server，Linux虚拟服务），通过IPVS（IP Virtual Server，IP虚拟服务）来实现。 在负载均衡服务器收到客户端的IP包的时候，会修改IP包的目标IP地址或端口，然后原封不动地投递到内部网络中，数据包会流入到实际Web服务器。实际服务器处理完成后，又会将数据包投递回给负载均衡服务器，它再修改目标IP地址为用户IP地址，最终回到客户端。 上述的方式叫LVS-NAT，除此之外，还有LVS-RD（直接路由），LVS-TUN（IP隧道），三者之间都属于LVS的方式，但是有一定的区别，篇幅问题，不赘叙。 IP负载均衡的性能要高出Nginx的反向代理很多，它只处理到传输层为止的数据包，并不做进一步的组包，然后直接转发给实际服务器。不过，它的配置和搭建比较复杂。 1.4. 4. DNS负载均衡 DNS（Domain Name System）负责域名解析的服务，域名url实际上是服务器的别名，实际映射是一个IP地址，解析过程，就是DNS完成域名到IP的映射。而一个域名是可以配置成对应多个IP的。因此，DNS也就可以作为负载均衡服务。 这种负载均衡策略，配置简单，性能极佳。但是，不能自由定义规则，而且，变更被映射的IP或者机器故障时很麻烦，还存在DNS生效延迟的问题。 5. DNS/GSLB负载均衡 我们常用的CDN（Content Delivery Network，内容分发网络）实现方式，其实就是在同一个域名映射为多IP的基础上更进一步，通过GSLB（Global Server Load Balance，全局负载均衡）按照指定规则映射域名的IP。一般情况下都是按照地理位置，将离用户近的IP返回给用户，减少网络传输中的路由节点之间的跳跃消耗。 图中的“向上寻找”，实际过程是LDNS（Local DNS）先向根域名服务（Root Name Server）获取到顶级根的Name Server（例如.com的），然后得到指定域名的授权DNS，然后再获得实际服务器IP。 CDN在Web系统中，一般情况下是用来解决大小较大的静态资源（html/Js/Css/图片等）的加载问题，让这些比较依赖网络下载的内容，尽可能离用户更近，提升用户体验。 例如，我访问了一张imgcache.gtimg.cn上的图片（腾讯的自建CDN，不使用qq.com域名的原因是防止http请求的时候，带上了多余的cookie信息），我获得的IP是183.60.217.90。 这种方式，和前面的DNS负载均衡一样，不仅性能极佳，而且支持配置多种策略。但是，搭建和维护成本非常高。互联网一线公司，会自建CDN服务，中小型公司一般使用第三方提供的CDN。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/压力性能测试.html":{"url":"Interview/大型网站架构/压力性能测试.html","title":"压力性能测试","keywords":"","body":"1. 压力测试以及性能分析1.1. 工具简单设置1.2. 压力测试1. 压力测试以及性能分析 使用Microsoft Web Application Stress Tool对web进行压力测试，Microsoft Web Application Stress Tool 是由微软的网站测试人员所开发，专门用来进行实际网站压力测试的一套工具。透过这套功能强大的压力测试工具，您可以使用少量的客户端计算机仿真大量用户上线对网站服务所可能造成的影响，在网站实际上线之前先对您所设计的网站进行如同真实环境下的测试 1.1. 工具简单设置 打开Web Application Stress Tool，很简洁的一个页面，上面是工具栏，左下方是功能选项，右下方是详细设置选项。在对目标Web服务器进行压力测试之前，先对它进行一些必要的设置。 在“settings”的功能设置中(如下图)，一个是Stress level (threads)这里是指定程序在后台用多少线程进行请求，也就是相当于模拟多少个客户机的连接，更加形象的就是说设置多少轰炸的线程数。一般填写 500～1000，因为这个线程数是根据本机的承受力来设置的，如果你对自己的机器配置有足够信心的话，那么设置的越高，轰炸的效果越好。 在“Test Run Time”中来指定一次压力测试需要持续的时间，分为天、小时、分、秒几个单位级别，你根据实际情况来设置吧!这里面设置测试时间为1分钟。 其余的选项大家可以根据自己的情况设置。 1.2. 压力测试 在工具中点右键，选择Add命令，增加了一个新的测试项目：memcache，对它进行设置，在主选项中的server中填写要测试的服务器的IP地址，这里我们是在本机上进行测试，所以填写localhost。在下方选择测试的Web连接方式，这里的方式Verb选择 get，path选择要测试的Web页面路径，这里填写/WebMemCache/memcache.aspx,即加入缓存的memcache.aspx页面(如下图)。 在“Settings”的功能设置中将Stress level (threads)线程数设置为500。完毕后，点工具中的灰色三角按钮即可进行测试(如下图)。 同理，我们在建一个nomemcach的项目用来测试nomemcache.aspx页面。Memcach和nomemcach测试完毕后，点击工具栏上的Reports按钮查看测试报告： Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/回答高并发和大型网站设计.html":{"url":"Interview/大型网站架构/回答高并发和大型网站设计.html","title":"回答高并发和大型网站设计","keywords":"","body":"1. 高并发解决，大型网站设计1. 高并发解决，大型网站设计 我想高并发问题解决方案要同时考虑硬件和应用程序优化两方面。硬件方面包括水平架构和垂直架构。 垂直架构是增强服务器硬件配置，这个只能到达一定程度，并有资金限制，一般不可取。 水平架构的话我想从小到大说出演化过程。 一台服务器，包括应用程序、数据库、文件 3台服务器：应用程序服务器（cpu 给力），数据库服务器（硬盘读写快，内存），文件服务器（硬盘大） 增加 分布式缓存服务器集群（memcached，redis） 负载均衡调度器（http 重定向、DNS域名解析、反向代理 nginx、IP、数据链路层三角传输） + 应用程序服务器集群 数据库 读写分离（主：写，从：读），主从复制 分布式文件服务器集群 + 数据库集群 CDN 服务器集群 + 反向代理服务器集群 nosql + 搜索引擎服务器 按照业务拆分：用户中心A、店铺B、订单C 划分不同的应用程序服务器集群。之间通信通过 消息队列服务器 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/多线程1.html":{"url":"Interview/大型网站架构/多线程1.html","title":"多线程1","keywords":"","body":"1. C#综合揭秘——细说多线程(上)2. 一、线程的定义3. 二、线程的基础知识4. 三、以ThreadStart方式实现多线程5. 四、CLR线程池的工作者线程1. C#综合揭秘——细说多线程(上) 2. 一、线程的定义 1.1 进程、应用程序域与线程的关系 进程(Process)是Windows系统中的一个基本概念，它包含着一个运行程序所需要的资源。进程之间是相对独立的，一个进程无法访问另一个进程的数据(除非利用分布式计算方式)，一个进程运行的失败也不会影响其他进程的运行，Windows系统就是利用进程把工作划分为多个独立的区域的。进程可以理解为一个程序的基本边界。 应用程序域(AppDomain)是一个程序运行的逻辑区域，它可以视为一个轻量级的进程，.NET的程序集正是在应用程序域中运行的，一个进程可以包含有多个应用程序域，一个应用程序域也可以包含多个程序集。在一个应用程序域中包含了一个或多个上下文context，使用上下文CLR就能够把某些特殊对象的状态放置在不同容器当中。 线程(Thread)是进程中的基本执行单元，在进程入口执行的第一个线程被视为这个进程的主线程。在.NET应用程序中，都是以Main()方法作为入口的，当调用此方法时系统就会自动创建一个主线程。线程主要是由CPU寄存器、调用栈和线程本地存储器(Thread Local Storage，TLS)组成的。CPU寄存器主要记录当前所执行线程的状态，调用栈主要用于维护线程所调用到的内存与数据，TLS主要用于存放线程的状态信息。 进程、应用程序域、线程的关系如下图，一个进程内可以包括多个应用程序域，也有包括多个线程，线程也可以穿梭于多个应用程序域当中。但在同一个时刻，线程只会处于一个应用程序域内。 由于本文是以介绍多线程技术为主题，对进程、应用程序域的介绍就到此为止。关于进程、线程、应用程序域的技术，在“C#综合揭秘——细说进程、应用程序域与上下文”会有详细介绍。 1.2 多线程 在单CPU系统的一个单位时间(time slice)内，CPU只能运行单个线程，运行顺序取决于线程的优先级别。如果在单位时间内线程未能完成执行，系统就会把线程的状态信息保存到线程的本地存储器(TLS) 中，以便下次执行时恢复执行。而多线程只是系统带来的一个假像，它在多个单位时间内进行多个线程的切换。因为切换频密而且单位时间非常短暂，所以多线程可被视作同时运行。 适当使用多线程能提高系统的性能，比如：在系统请求大容量的数据时使用多线程，把数据输出工作交给异步线程，使主线程保持其稳定性去处理其他问题。但需要注意一点，因为CPU需要花费不少的时间在线程的切换上，所以过多地使用多线程反而会导致性能的下降。 3. 二、线程的基础知识 2.1 System.Threading.Thread类 System.Threading.Thread是用于控制线程的基础类，通过Thread可以控制当前应用程序域中线程的创建、挂起、停止、销毁。 它包括以下常用公共属性： 属性名称 说明 CurrentContext 获取线程正在其中执行的当前上下文。 CurrentThread 获取当前正在运行的线程。 ExecutionContext 获取一个 ExecutionContext 对象，该对象包含有关当前线程的各种上下文的信息。 IsAlive 获取一个值，该值指示当前线程的执行状态。 IsBackground 获取或设置一个值，该值指示某个线程是否为后台线程。 IsThreadPoolThread 获取一个值，该值指示线程是否属于托管线程池。 ManagedThreadId 获取当前托管线程的唯一标识符。 Name 获取或设置线程的名称。 Priority 获取或设置一个值，该值指示线程的调度优先级。 ThreadState 获取一个值，该值包含当前线程的状态。 2.1.1 线程的标识符 ManagedThreadId是确认线程的唯一标识符，程序在大部分情况下都是通过Thread.ManagedThreadId来辨别线程的。而Name是一个可变值，在默认时候，Name为一个空值 Null，开发人员可以通过程序设置线程的名称，但这只是一个辅助功能。 2.1.2 线程的优先级别 .NET 为线程设置了 Priority 属性来定义线程执行的优先级别，里面包含5个选项，其中Normal是默认值。除非系统有特殊要求，否则不应该随便设置线程的优先级别。 成员名称 说明 Lowest 可以将 Thread 安排在具有任何其他优先级的线程之后。 BelowNormal 可以将 Thread 安排在具有 Normal 优先级的线程之后，在具有 Lowest 优先级的线程之前。 Normal 默认选择。可以将 Thread 安排在具有 AboveNormal 优先级的线程之后，在具有 BelowNormal 优先级的线程之前。 AboveNormal 可以将 Thread 安排在具有 Highest 优先级的线程之后，在具有 Normal 优先级的线程之前。 Highest 可以将 Thread 安排在具有任何其他优先级的线程之前。 2.1.3 线程的状态 通过ThreadState可以检测线程是处于Unstarted、Sleeping、Running 等等状态，它比 IsAlive 属性能提供更多的特定信息。 前面说过，一个应用程序域中可能包括多个上下文，而通过CurrentContext可以获取线程当前的上下文。 CurrentThread是最常用的一个属性，它是用于获取当前运行的线程。 2.1.4 System.Threading.Thread的方法 Thread 中包括了多个方法来控制线程的创建、挂起、停止、销毁，以后来的例子中会经常使用。 方法名称 说明 Abort() 终止本线程。 GetDomain() 返回当前线程正在其中运行的当前域。 GetDomainId() 返回当前线程正在其中运行的当前域Id。 Interrupt() 中断处于 WaitSleepJoin 线程状态的线程。 Join() 已重载。 阻塞调用线程，直到某个线程终止时为止。 Resume() 继续运行已挂起的线程。 Start() 执行本线程。 Suspend() 挂起当前线程，如果当前线程已属于挂起状态则此不起作用 Sleep() 把正在运行的线程挂起一段时间。 2.1.5 开发实例 以下这个例子，就是通过Thread显示当前线程信息 static void Main(string[] args) { Thread thread = Thread.CurrentThread; thread.Name = \"Main Thread\"; string threadMessage = string.Format(\"Thread ID:{0}\\n Current AppDomainId:{1}\\n \" + \"Current ContextId:{2}\\n Thread Name:{3}\\n \" + \"Thread State:{4}\\n Thread Priority:{5}\\n\", thread.ManagedThreadId, Thread.GetDomainID(), Thread.CurrentContext.ContextID, thread.Name, thread.ThreadState, thread.Priority); Console.WriteLine(threadMessage); Console.ReadKey(); } 运行结果 2.2 System.Threading 命名空间 在System.Threading命名空间内提供多个方法来构建多线程应用程序,其中ThreadPool与Thread是多线程开发中最常用到的，在.NET中专门设定了一个CLR线程池专门用于管理线程的运行，这个CLR线程池正是通过ThreadPool类来管理。而Thread是管理线程的最直接方式，下面几节将详细介绍有关内容。 类　　　　 说明 AutoResetEvent 通知正在等待的线程已发生事件。无法继承此类。 ExecutionContext 管理当前线程的执行上下文。无法继承此类。 Interlocked 为多个线程共享的变量提供原子操作。 Monitor 提供同步对对象的访问的机制。 Mutex 一个同步基元，也可用于进程间同步。 Thread 创建并控制线程，设置其优先级并获取其状态。 ThreadAbortException 在对 Abort 方法进行调用时引发的异常。无法继承此类。 ThreadPool 提供一个线程池，该线程池可用于发送工作项、处理异步 I/O、代表其他线程等待以及处理计时器。 Timeout 包含用于指定无限长的时间的常数。无法继承此类。 Timer 提供以指定的时间间隔执行方法的机制。无法继承此类。 WaitHandle 封装等待对共享资源的独占访问的操作系统特定的对象。 在 System.Threading 中的包含了下表中的多个常用委托，其中 ==ThreadStart、ParameterizedThreadStart 是最常用到的委托。== 由 ThreadStart 生成的线程是最直接的方式，但由 ThreadStart所生成并不受线程池管理。 而 ParameterizedThreadStart 是为异步触发带参数的方法而设的，在下一节将为大家逐一细说。 委托 说明 ContextCallback 表示要在新上下文中调用的方法。 ParameterizedThreadStart 表示在 Thread 上执行的方法。 ThreadExceptionEventHandler 表示将要处理 Application 的 ThreadException 事件的方法。 ThreadStart 表示在 Thread 上执行的方法。 TimerCallback 表示处理来自 Timer 的调用的方法。 WaitCallback 表示线程池线程要执行的回调方法。 WaitOrTimerCallback 表示当 WaitHandle 超时或终止时要调用的方法。 2.3 线程的管理方式 ==通过 ThreadStart 来创建一个新线程是最直接的方法，但这样创建出来的线程比较难管理，如果创建过多的线程反而会让系统的性能下载。== 有见及此，.NET 为线程管理专门设置了一个 CLR 线程池，使用 CLR 线程池系统可以更合理地管理线程的使用。所有请求的服务都能运行于线程池中，当运行结束时线程便会回归到线程池。通过设置，能控制线程池的最大线程数量，在请求超出线程最大值时，线程池能按照操作的优先级别来执行，让部分操作处于等待状态，待有线程回归时再执行操作。 4. 三、以ThreadStart方式实现多线程 3.1 使用ThreadStart委托 这里先以一个例子体现一下多线程带来的好处，首先在 Message 类中建立一个方法 ShowMessage()，里面显示了当前运行线程的Id，并使用 Thread.Sleep 方法模拟部分工作。在 main() 中通过 ThreadStart 委托绑定 Message 对象的 ShowMessage 方法，然后通过 Thread.Start 执行异步方法。 public class Message { public void ShowMessage() { string message = string.Format(\"Async threadId is :{0}\", Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); for (int n = 0; n 请注意运行结果，在调用Thread.Start()方法后，系统以异步方式运行Message.ShowMessage()，而主线程的操作是继续执行的，在Message.ShowMessage()完成前，主线程已完成所有的操作。 3.2 使用 ParameterizedThreadStart 委托 ParameterizedThreadStart 委托与 ThreadStart 委托非常相似，但 ParameterizedThreadStart 委托是面向带参数方法的。注意 ParameterizedThreadStart 对应方法的参数为 object，此参数可以为一个值对象，也可以为一个自定义对象。 public class Person { public string Name { get; set; } public int Age { get; set; } } public class Message { public void ShowMessage(object person) { if (person != null) { Person _person = (Person) person; string message = string.Format(\"\\n{0}'s age is {1}!\\nAsync threadId is:{2}\", _person.Name, _person.Age, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); } for (int n = 0; n 运行结果： 3.3 前台线程与后台线程 注意以上两个例子都没有使用Console.ReadKey(),但系统依然会等待异步线程完成后才会结束。这是因为使用Thread.Start()启动的线程默认为前台线程，而系统必须等待所有前台线程运行结束后，应用程序域才会自动卸载。 在第二节曾经介绍过线程Thread有一个属性 IsBackground，通过把此属性设置为true，就可以把线程设置为后台线程！这时应用程序域将在主线程完成时就被卸载，而不会等待异步线程的运行。 3.4 挂起线程 为了等待其他后台线程完成后再结束主线程，就可以使用Thread.Sleep()方法。 public class Message { public void ShowMessage() { string message = string.Format(\"\\nAsync threadId is:{0}\", Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); for (int n = 0; n 运行结果如下，此时应用程序域将在主线程运行5秒后自动结束 但系统无法预知异步线程需要运行的时间，所以用通过Thread.Sleep(int)阻塞主线程并不是一个好的解决方法。有见及此，.NET专门为等待异步线程完成开发了另一个方法thread.Join()。把上面例子中的最后一行Thread.Sleep(5000)修改为 thread.Join() 就能保证主线程在异步线程thread运行结束后才会终止。 3.5 Suspend 与 Resume (慎用) Thread.Suspend()与 Thread.Resume()是在Framework1.0 就已经存在的老方法了，它们分别可以挂起、恢复线程。但在Framework2.0中就已经明确排斥这两个方法。这是因为一旦某个线程占用了已有的资源，再使用Suspend()使线程长期处于挂起状态，当在其他线程调用这些资源的时候就会引起死锁！所以在没有必要的情况下应该避免使用这两个方法。 3.6 终止线程 若想终止正在运行的线程，可以使用Abort()方法。在使用Abort()的时候，将引发一个特殊异常 ThreadAbortException 。 若想在线程终止前恢复线程的执行，可以在捕获异常后 ,在catch(ThreadAbortException ex){...} 中调用Thread.ResetAbort()取消终止。 而使用Thread.Join()可以保证应用程序域等待异步线程结束后才终止运行。 static void Main(string[] args) { Console.WriteLine(\"Main threadId is:\" + Thread.CurrentThread.ManagedThreadId); Thread thread = new Thread(new ThreadStart(AsyncThread)); thread.IsBackground = true; thread.Start(); thread.Join(); } //以异步方式调用 static void AsyncThread() { try { string message = string.Format(\"\\nAsync threadId is:{0}\", Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); for (int n = 0; n = 4) { Thread.CurrentThread.Abort(n); } Thread.Sleep(300); Console.WriteLine(\"The number is:\" + n.ToString()); } } catch (ThreadAbortException ex) { //输出终止线程时n的值 if (ex.ExceptionState != null) Console.WriteLine(string.Format(\"Thread abort when the number is: {0}!\", ex.ExceptionState.ToString())); //取消终止，继续执行线程 Thread.ResetAbort(); Console.WriteLine(\"Thread ResetAbort!\"); } //线程结束 Console.WriteLine(\"Thread Close!\"); } 运行结果如下 5. 四、CLR线程池的工作者线程 4.1 关于CLR线程池 ==使用 ThreadStart 与 ParameterizedThreadStart 建立新线程非常简单，但通过此方法建立的线程难于管理，若建立过多的线程反而会影响系统的性能。== 有见及此，.NET引入CLR线程池这个概念。CLR线程池并不会在CLR初始化的时候立刻建立线程，而是在应用程序要创建线程来执行任务时，线程池才初始化一个线程。线程的初始化与其他的线程一样。在完成任务以后，该线程不会自行销毁，而是以挂起的状态返回到线程池。直到应用程序再次向线程池发出请求时，线程池里挂起的线程就会再度激活执行任务。这样既节省了建立线程所造成的性能损耗，也可以让多个任务反复重用同一线程，从而在应用程序生存期内节约大量开销。 注意：通过CLR线程池所建立的线程总是默认为后台线程，优先级数为ThreadPriority.Normal。 4.2 工作者线程与I/O线程 CLR线程池分为工作者线程(workerThreads)与I/O线程 (completionPortThreads) 两种，工作者线程是主要用作管理CLR内部对象的运作，I/O(Input/Output) 线程顾名思义是用于与外部系统交换信息，IO线程的细节将在下一节详细说明。 通过ThreadPool.GetMax(out int workerThreads,out int completionPortThreads )和 ThreadPool.SetMax( int workerThreads, int completionPortThreads)两个方法可以分别读取和设置CLR线程池中工作者线程与I/O线程的最大线程数。在Framework2.0中最大线程默认为25CPU数，在Framewok3.0、4.0中最大线程数默认为250CPU数，在近年 I3,I5,I7 CPU出现后，线程池的最大值一般默认为1000、2000。 若想测试线程池中有多少的线程正在投入使用，可以通过ThreadPool.GetAvailableThreads( out int workerThreads,out int completionPortThreads ) 方法。 使用CLR线程池的工作者线程一般有两种方式，一是直接通过 ThreadPool.QueueUserWorkItem() 方法，二是通过委托，下面将逐一细说。 4.3 通过 QueueUserWorkItem 启动工作者线程 ThreadPool 线程池中包含有两个静态方法可以直接启动工作者线程： 一为 ThreadPool.QueueUserWorkItem(WaitCallback) 二为 ThreadPool.QueueUserWorkItem(WaitCallback, Object) 先把WaitCallback委托指向一个带有Object参数的无返回值方法，再使用 ThreadPool.QueueUserWorkItem(WaitCallback) 就可以异步启动此方法，此时异步方法的参数被视为null 。 class Program { static void Main(string[] args) { //把CLR线程池的最大值设置为1000 ThreadPool.SetMaxThreads(1000, 1000); //显示主线程启动时线程池信息 ThreadMessage(\"Start\"); //启动工作者线程 ThreadPool.QueueUserWorkItem(new WaitCallback(AsyncCallback)); Console.ReadKey(); } static void AsyncCallback(object state) { Thread.Sleep(200); ThreadMessage(\"AsyncCallback\"); Console.WriteLine(\"Async thread do work!\"); } //显示线程现状 static void ThreadMessage(string data) { string message = string.Format(\"{0}\\n CurrentThreadId is {1}\", data, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); } } 运行结果 使用 ThreadPool.QueueUserWorkItem(WaitCallback, Object) 方法可以把 object 对象作为参数传送到回调函数中。 下面例子中就是把一个 string 对象作为参数发送到回调函数当中。 class Program { static void Main(string[] args) { //把线程池的最大值设置为1000 ThreadPool.SetMaxThreads(1000, 1000); ThreadMessage(\"Start\"); ThreadPool.QueueUserWorkItem(new WaitCallback(AsyncCallback), \"Hello Elva\"); Console.ReadKey(); } static void AsyncCallback(object state) { Thread.Sleep(200); ThreadMessage(\"AsyncCallback\"); string data = (string) state; Console.WriteLine(\"Async thread do work!\\n\" + data); } //显示线程现状 static void ThreadMessage(string data) { string message = string.Format(\"{0}\\n CurrentThreadId is {1}\", data, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); } } 运行结果 ==通过 ThreadPool.QueueUserWorkItem 启动工作者线程虽然是方便，但WaitCallback委托指向的必须是一个带有Object参数的无返回值方法，这无疑是一种限制。== 若方法需要有返回值，或者带有多个参数，这将多费周折。有见及此，.NET提供了另一种方式去建立工作者线程，那就是委托。 4.4 委托类 使用CLR线程池中的工作者线程，最灵活最常用的方式就是使用委托的异步方法，在此先简单介绍一下委托类。 当定义委托后，.NET就会自动创建一个代表该委托的类，下面可以用反射方式显示委托类的方法成员(对反射有兴趣的朋友可以先参考一下“.NET基础篇——反射的奥妙”) class Program { delegate void MyDelegate(); static void Main(string[] args) { MyDelegate delegate1 = new MyDelegate(AsyncThread); //显示委托类的几个方法成员 var methods = delegate1.GetType().GetMethods(); if (methods != null) foreach(MethodInfo info in methods) Console.WriteLine(info.Name); Console.ReadKey(); } } 委托类包括以下几个重要方法 public class MyDelegate: MulticastDelegate { public MyDelegate(object target, int methodPtr); //调用委托方法 public virtual void Invoke(); //异步委托 public virtual IAsyncResult BeginInvoke(AsyncCallback callback, object state); public virtual void EndInvoke(IAsyncResult result); } 当调用 Invoke() 方法时，对应此委托的所有方法都会被执行。而 BeginInvoke 与 EndInvoke 则支持委托方法的异步调用，由BeginInvoke启动的线程都属于CLR线程池中的工作者线程，在下面将详细说明。 4.5 利用 BeginInvoke 与 EndInvoke 完成异步委托方法 首先建立一个委托对象，通过 IAsyncResult BeginInvoke(string name,AsyncCallback callback,object state) 异步调用委托方法，BeginInvoke 方法除最后的两个参数外，其它参数都是与方法参数相对应的。通过 BeginInvoke 方法将返回一个实现了 System.IAsyncResult 接口的对象，之后就可以利用 EndInvoke(IAsyncResult) 方法就可以结束异步操作，获取委托的运行结果。 class Program { delegate string MyDelegate(string name); static void Main(string[] args) { ThreadMessage(\"Main Thread\"); //建立委托 MyDelegate myDelegate = new MyDelegate(Hello); //异步调用委托，获取计算结果 IAsyncResult result = myDelegate.BeginInvoke(\"Leslie\", null, null); //完成主线程其他工作 ............. //等待异步方法完成，调用EndInvoke(IAsyncResult)获取运行结果 string data = myDelegate.EndInvoke(result); Console.WriteLine(data); Console.ReadKey(); } static string Hello(string name) { ThreadMessage(\"Async Thread\"); Thread.Sleep(2000); //虚拟异步工作 return \"Hello \" + name; } //显示当前线程 static void ThreadMessage(string data) { string message = string.Format(\"{0}\\n ThreadId is:{1}\", data, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); } } 运行结果 4.6 善用IAsyncResult 在以上例子中可以看见，如果在使用myDelegate.BeginInvoke后立即调用myDelegate.EndInvoke，那在异步线程未完成工作以前主线程将处于阻塞状态，等到异步线程结束获取计算结果后，主线程才能继续工作，这明显无法展示出多线程的优势。此时可以好好利用IAsyncResult 提高主线程的工作性能，IAsyncResult有以下成员： public interface IAsyncResult { object AsyncState { get; } //获取用户定义的对象，它限定或包含关于异步操作的信息。 WailHandle AsyncWaitHandle { get; } //获取用于等待异步操作完成的 WaitHandle。 bool CompletedSynchronously { get; } //获取异步操作是否同步完成的指示。 bool IsCompleted { get; } //获取异步操作是否已完成的指示。 } 通过轮询方式，使用IsCompleted属性判断异步操作是否完成，这样在异步操作未完成前就可以让主线程执行另外的工作。 class Program { delegate string MyDelegate(string name); static void Main(string[] args) { ThreadMessage(\"Main Thread\"); //建立委托 MyDelegate myDelegate = new MyDelegate(Hello); //异步调用委托，获取计算结果 IAsyncResult result = myDelegate.BeginInvoke(\"Leslie\", null, null); //在异步线程未完成前执行其他工作 while (!result.IsCompleted) { Thread.Sleep(200); //虚拟操作 Console.WriteLine(\"Main thead do work!\"); } string data = myDelegate.EndInvoke(result); Console.WriteLine(data); Console.ReadKey(); } static string Hello(string name) { ThreadMessage(\"Async Thread\"); Thread.Sleep(2000); return \"Hello \" + name; } static void ThreadMessage(string data) { string message = string.Format(\"{0}\\n ThreadId is:{1}\", data, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); } } 运行结果： 除此以外，也可以使用WailHandle完成同样的工作，WaitHandle里面包含有一个方法WaitOne(int timeout)，它可以判断委托是否完成工作，在工作未完成前主线程可以继续其他工作。运行下面代码可得到与使用 IAsyncResult.IsCompleted 同样的结果，而且更简单方便 。 namespace Test { class Program { delegate string MyDelegate(string name); static void Main(string[] args) { ThreadMessage(\"Main Thread\"); //建立委托 MyDelegate myDelegate = new MyDelegate(Hello); //异步调用委托，获取计算结果 IAsyncResult result = myDelegate.BeginInvoke(\"Leslie\", null, null); while (!result.AsyncWaitHandle.WaitOne(200)) { Console.WriteLine(\"Main thead do work!\"); } string data = myDelegate.EndInvoke(result); Console.WriteLine(data); Console.ReadKey(); } static string Hello(string name) { ThreadMessage(\"Async Thread\"); Thread.Sleep(2000); return \"Hello \" + name; } static void ThreadMessage(string data) { string message = string.Format(\"{0}\\n ThreadId is:{1}\", data, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); } } } 当要监视多个运行对象的时候，使用IAsyncResult.WaitHandle.WaitOne可就派不上用场了。 幸好.NET为WaitHandle准备了另外两个静态方法：WaitAny(waitHandle[], int)与WaitAll (waitHandle[] , int)。 其中WaitAll在等待所有waitHandle完成后再返回一个bool值。 而WaitAny是等待其中一个waitHandle完成后就返回一个int，这个int是代表已完成waitHandle在waitHandle[]中的数组索引。 下面就是使用WaitAll的例子，运行结果与使用 IAsyncResult.IsCompleted 相同。 class Program { delegate string MyDelegate(string name); static void Main(string[] args) { ThreadMessage(\"Main Thread\"); //建立委托 MyDelegate myDelegate = new MyDelegate(Hello); //异步调用委托，获取计算结果 IAsyncResult result = myDelegate.BeginInvoke(\"Leslie\", null, null); //此处可加入多个检测对象 WaitHandle[] waitHandleList = new WaitHandle[] { result.AsyncWaitHandle,........ }; while (!WaitHandle.WaitAll(waitHandleList, 200)) { Console.WriteLine(\"Main thead do work!\"); } string data = myDelegate.EndInvoke(result); Console.WriteLine(data); Console.ReadKey(); } static string Hello(string name) { ThreadMessage(\"Async Thread\"); Thread.Sleep(2000); return \"Hello \" + name; } static void ThreadMessage(string data) { string message = string.Format(\"{0}\\n ThreadId is:{1}\", data, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(message); } } 4.7 回调函数 使用轮询方式来检测异步方法的状态非常麻烦，而且效率不高，有见及此，.NET为 IAsyncResult BeginInvoke(AsyncCallback , object)准备了一个回调函数。使用 AsyncCallback 就可以绑定一个方法作为回调函数，回调函数必须是带参数 IAsyncResult 且无返回值的方法： void AsycnCallbackMethod(IAsyncResult result) 。在BeginInvoke方法完成后，系统就会调用AsyncCallback所绑定的回调函数,最后回调函数中调用 XXX EndInvoke(IAsyncResult result) 就可以结束异步方法，它的返回值类型与委托的返回值一致。 class Program { delegate string MyDelegate(string name); static void Main(string[] args) { ThreadMessage(\"Main Thread\"); //建立委托 MyDelegate myDelegate = new MyDelegate(Hello); //异步调用委托，获取计算结果 myDelegate.BeginInvoke(\"Leslie\", new AsyncCallback(Completed), null); //在启动异步线程后，主线程可以继续工作而不需要等待 for (int n = 0; n 可以看到，主线在调用BeginInvoke方法可以继续执行其他命令，而无需再等待了，这无疑比使用轮询方式判断异步方法是否完成更有优势。 在异步方法执行完成后将会调用AsyncCallback所绑定的回调函数，注意一点，回调函数依然是在异步线程中执行，这样就不会影响主线程的运行，这也使用回调函数最值得青昧的地方。 在回调函数中有一个既定的参数IAsyncResult,把IAsyncResult强制转换为AsyncResult后，就可以通过 AsyncResult.AsyncDelegate 获取原委托，再使用EndInvoke方法获取计算结果。 运行结果如下： 如果想为回调函数传送一些外部信息，就可以利用BeginInvoke(AsyncCallback,object)的最后一个参数object,它允许外部向回调函数输入任何类型的参数。只需要在回调函数中利用 AsyncResult.AsyncState 就可以获取object对象。 class Program { public class Person { public string Name; public int Age; } delegate string MyDelegate(string name); static void Main(string[] args) { ThreadMessage(\"Main Thread\"); //建立委托 MyDelegate myDelegate = new MyDelegate(Hello); //建立Person对象 Person person = new Person(); person.Name = \"Elva\"; person.Age = 27; //异步调用委托，输入参数对象person, 获取计算结果 myDelegate.BeginInvoke(\"Leslie\", new AsyncCallback(Completed), person); //在启动异步线程后，主线程可以继续工作而不需要等待 for (int n = 0; n 运行结果: Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/多线程2.html":{"url":"Interview/大型网站架构/多线程2.html","title":"多线程2","keywords":"","body":"1. 五、CLR线程池的I/O线程2. 六、异步 SqlCommand3. 七、并行编程与PLINQ1. 五、CLR线程池的I/O线程 在前一节所介绍的线程都属于CLR线程池的工作者线程，这一节开始为大家介绍一下 CLR 线程池的I/O线程 I/O 线程是.NET专为访问外部资源所设置的一种线程，因为访问外部资源常常要受到外界因素的影响，为了防止让主线程受影响而长期处于阻塞状态，.NET为多个I/O操作都建立起了异步方法，例如：FileStream、TCP/IP、WebRequest、WebService等等，而且每个异步方法的使用方式都非常类似，都是以BeginXXX为开始，以EndXXX结束，下面为大家一一解说。 5.1 异步读写 FileStream 需要在 FileStream 异步调用 I/O线程，必须使用以下构造函数建立 FileStream 对象，并把useAsync设置为 true。 FileStream stream = new FileStream ( string path, FileMode mode, FileAccess access, FileShare share, int bufferSize,bool useAsync ) ; 其中 path 是文件的相对路径或绝对路径; mode 确定如何打开或创建文件; access 确定访问文件的方式; share 确定文件如何进程共享; bufferSize 是代表缓冲区大小,一般默认最小值为8，在启动异步读取或写入时，文件大小一般大于缓冲大小; userAsync代表是否启动异步I/O线程。 注意：当使用 BeginRead 和 BeginWrite 方法在执行大量读或写时效果更好，但对于少量的读/写，这些方法速度可能比同步读取还要慢，因为进行线程间的切换需要大量时间。 5.1.1 异步写入 FileStream中包含BeginWrite、EndWrite 方法可以启动I/O线程进行异步写入。 public override IAsyncResult BeginWrite (byte[] array, int offset, int numBytes, AsyncCallback userCallback, Object stateObject) public override void EndWrite (IAsyncResult asyncResult) BeginWrite 返回值为IAsyncResult, 使用方式与委托的BeginInvoke方法相似，最好就是使用回调函数，避免线程阻塞。在最后两个参数中，参数AsyncCallback用于绑定回调函数; 参数Object用于传递外部数据。要注意一点：AsyncCallback所绑定的回调函数必须是带单个 IAsyncResult 参数的无返回值方法。 在例子中，把FileStream作为外部数据传递到回调函数当中，然后在回调函数中利用IAsyncResult.AsyncState 获取FileStream对象，最后通过FileStream.EndWrite（IAsyncResult）结束写入。 class Program { static void Main(string[] args) { //把线程池的最大值设置为1000 ThreadPool.SetMaxThreads(1000, 1000); ThreadPoolMessage(\"Start\"); //新立文件File.sour FileStream stream = new FileStream(\"File.sour\", FileMode.OpenOrCreate, FileAccess.ReadWrite,FileShare.ReadWrite,1024,true); byte[] bytes = new byte[16384]; string message = \"An operating-system ThreadId has no fixed relationship........\"; bytes = Encoding.Unicode.GetBytes(message); //启动异步写入 stream.BeginWrite(bytes, 0, (int)bytes.Length,new AsyncCallback(Callback),stream); stream.Flush(); Console.ReadKey(); } static void Callback(IAsyncResult result) { //显示线程池现状 Thread.Sleep(200); ThreadPoolMessage(\"AsyncCallback\"); //结束异步写入 FileStream stream = (FileStream)result.AsyncState; stream.EndWrite(result); stream.Close(); } //显示线程池现状 static void ThreadPoolMessage(string data) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"{0}\\n CurrentThreadId is {1}\\n \"+ \"WorkerThreads is:{2} CompletionPortThreads is :{3}\", data, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 由输出结果可以看到，在使用FileStream.BeginWrite方法后，系统将自动启动CLR线程池中I/O线程。 5.1.2 异步读取 FileStream 中包含 BeginRead 与 EndRead 可以异步调用I/O线程进行读取。 public override IAsyncResult BeginRead (byte[] array,int offset,int numBytes, AsyncCallback userCallback,Object stateObject) public override int EndRead(IAsyncResult asyncResult) 其使用方式与BeginWrite和EndWrite相似，AsyncCallback用于绑定回调函数; Object用于传递外部数据。在回调函数只需要使用IAsyncResut.AsyncState就可获取外部数据。EndWrite 方法会返回从流读取到的字节数量。 首先定义 FileData 类，里面包含FileStream对象，byte[] 数组和长度。然后把FileData对象作为外部数据传到回调函数，在回调函数中，把IAsyncResult.AsyncState强制转换为FileData，然后通过FileStream.EndRead（IAsyncResult）结束读取。最后比较一下长度，若读取到的长度与输入的数据长度不一至，则抛出异常。 class Program { public class FileData { public FileStream Stream; public int Length; public byte[] ByteData; } static void Main(string[] args) { //把线程池的最大值设置为1000 ThreadPool.SetMaxThreads(1000, 1000); ThreadPoolMessage(\"Start\"); ReadFile(); Console.ReadKey(); } static void ReadFile() { byte[] byteData=new byte[80961024]; FileStream stream = new FileStream(\"File1.sour\", FileMode.OpenOrCreate, FileAccess.ReadWrite, FileShare.ReadWrite, 1024, true); //把FileStream对象,byte[]对象，长度等有关数据绑定到FileData对象中，以附带属性方式送到回调函数 FileData fileData = new FileData(); fileData.Stream = stream; fileData.Length = (int)stream.Length; fileData.ByteData = byteData; //启动异步读取 stream.BeginRead(byteData, 0, fileData.Length, new AsyncCallback(Completed), fileData); } static void Completed(IAsyncResult result) { ThreadPoolMessage(\"Completed\"); //把AsyncResult.AsyncState转换为FileData对象，以FileStream.EndRead完成异步读取 FileData fileData = (FileData)result.AsyncState; int length=fileData.Stream.EndRead(result); fileData.Stream.Close(); //如果读取到的长度与输入长度不一致，则抛出异常 if (length != fileData.Length) throw new Exception(\"Stream is not complete!\"); string data=Encoding.ASCII.GetString(fileData.ByteData, 0, fileData.Length); Console.WriteLine(data.Substring(2,22)); } //显示线程池现状 static void ThreadPoolMessage(string data) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"{0}\\n CurrentThreadId is {1}\\n \"+ \"WorkerThreads is:{2} CompletionPortThreads is :{3}\", data, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 由输出结果可以看到，在使用FileStream.BeginRead方法后，系统将自动启动CLR线程池中I/O线程。 注意：如果你看到的测试结果正好相反：工作者线程为999，I/O线程为1000，这是因为FileStream的文件容量小于缓冲值1024所致的。此时文件将会一次性读取或写入，而系统将启动工作者线程而非I/O线程来处理回调函数。** 5.2 异步操作TCP/IP套接字 在介绍 TCP/IP 套接字前先简单介绍一下 NetworkStream 类，它是用于网络访问的基础数据流。 NetworkStream 提供了好几个方法控制套接字数据的发送与接收, 其中BeginRead、EndRead、BeginWrite、EndWrite 能够实现异步操作，而且异步线程是来自于CLR线程池的I/O线程。 public override int ReadByte () public override int Read (byte[] buffer,int offset, int size) public override void WriteByte (byte value) public override void Write (byte[] buffer,int offset, int size) public override IAsyncResult BeginRead (byte [] buffer, int offset, int size, AsyncCallback callback, Object state ) public override int EndRead(IAsyncResult result) public override IAsyncResult BeginWrite (byte [] buffer, int offset, int size, AsyncCallback callback, Object state ) public override void EndWrite(IAsyncResult result) 若要创建 NetworkStream，必须提供已连接的 Socket。而在.NET中使用TCP/IP套接字不需要直接与Socket打交道，因为.NET把Socket的大部分操作都放在System.Net.TcpListener和System.Net.Sockets.TcpClient里面，这两个类大大地简化了Socket的操作。一般套接字对象Socket包含一个Accept（）方法，此方法能产生阻塞来等待客户端的请求，而在TcpListener类里也包含了一个相似的方法 public TcpClient AcceptTcpClient（）用于等待客户端的请求。此方法将会返回一个TcpClient 对象，通过 TcpClient 的 public NetworkStream GetStream（）方法就能获取NetworkStream对象，控制套接字数据的发送与接收。 下面以一个例子说明异步调用TCP/IP套接字收发数据的过程。 首先在服务器端建立默认地址127.0.0.1用于收发信息，使用此地址与端口500新建TcpListener对象，调用TcpListener.Start 侦听传入的连接请求，再使用一个死循环来监听信息。 在ChatClient类包括有接收信息与发送信息两个功能：当接收到客户端请求时，它会利用 NetworkStream.BeginRead 读取客户端信息，并在回调函数ReceiveAsyncCallback中输出信息内容，若接收到的信息的大小小于1时，它将会抛出一个异常。当信息成功接收后，再使用 NetworkStream.BeginWrite 方法回馈信息到客户端 class Program { static void Main(string[] args) { //设置CLR线程池最大线程数 ThreadPool.SetMaxThreads(1000, 1000); //默认地址为127.0.0.1 IPAddress ipAddress = IPAddress.Parse(\"127.0.0.1\"); TcpListener tcpListener = new TcpListener(ipAddress, 500); tcpListener.Start(); //以一个死循环来实现监听 while (true) { //调用一个ChatClient对象来实现监听 ChatClient chatClient = new ChatClient(tcpListener.AcceptTcpClient()); } } } public class ChatClient { static TcpClient tcpClient; static byte[] byteMessage; static string clientEndPoint; public ChatClient(TcpClient tcpClient1) { tcpClient = tcpClient1; byteMessage = new byte[tcpClient.ReceiveBufferSize]; //显示客户端信息 clientEndPoint = tcpClient.Client.RemoteEndPoint.ToString(); Console.WriteLine(\"Client's endpoint is \" + clientEndPoint); //使用NetworkStream.BeginRead异步读取信息 NetworkStream networkStream = tcpClient.GetStream(); networkStream.BeginRead(byteMessage, 0, tcpClient.ReceiveBufferSize, new AsyncCallback(ReceiveAsyncCallback), null); } public void ReceiveAsyncCallback(IAsyncResult iAsyncResult) { //显示CLR线程池状态 Thread.Sleep(100); ThreadPoolMessage(\"\\nMessage is receiving\"); //使用NetworkStream.EndRead结束异步读取 NetworkStream networkStreamRead = tcpClient.GetStream(); int length=networkStreamRead.EndRead(iAsyncResult); //如果接收到的数据长度少于1则抛出异常 if (length 而在客户端只是使用简单的开发方式，利用TcpClient连接到服务器端，然后调用NetworkStream.Write方法发送信息，最后调用NetworkStream.Read方法读取回馈信息 static void Main(string[] args) { //连接服务端 TcpClient tcpClient = new TcpClient(\"127.0.0.1\", 500); //发送信息 NetworkStream networkStream = tcpClient.GetStream(); byte[] sendMessage = Encoding.UTF8.GetBytes(\"Client request connection!\"); networkStream.Write(sendMessage, 0, sendMessage.Length); networkStream.Flush(); //接收信息 byte[] receiveMessage=new byte[1024]; int count=networkStream.Read(receiveMessage, 0,1024); Console.WriteLine(Encoding.UTF8.GetString(receiveMessage)); Console.ReadKey(); } 注意观察运行结果，服务器端的异步操作线程都是来自于CLR线程池的I/O线程 5.3 异步WebRequest System.Net.WebRequest 是 .NET 为实现访问 Internet 的 “请求/响应模型” 而开发的一个 abstract 基类， 它主要有三个子类：FtpWebRequest、HttpWebRequest、FileWebRequest。当使用WebRequest.Create（string uri）创建对象时，应用程序就可以根据请求协议判断实现类来进行操作。FileWebRequest、FtpWebRequest、HttpWebRequest 各有其作用：FileWebRequest 使用 “file://路径” 的URI方式实现对本地资源和内部文件的请求/响应、FtpWebRequest 使用FTP文件传输协议实现文件请求/响应、HttpWebRequest 用于处理HTTP的页面请求/响应。由于使用方法相类似，下面就以常用的HttpWebRequest为例子介绍一下异步WebRequest的使用方法。 在使用ASP.NET开发网站的时候，往往会忽略了HttpWebRequest的使用，因为开发都假设客户端是使用浏览器等工具去阅读页面的。但如果你对REST开发方式有所了解，那对 HttpWebRequest 就应该非常熟悉。它可以在路径参数、头文件、页面主体、Cookie 等多处地方加入请求条件，然后对回复数据进行适当处理。HttpWebRequest 包含有以下几个常用方法用于处理请求/响应： public override Stream GetRequestStream () public override WebResponse GetResponse () public override IAsyncResult BeginGetRequestStream ( AsyncCallback callback, Object state ) public override Stream EndGetRequestStream ( IAsyncResult asyncResult ) public override IAsyncResult BeginGetResponse ( AsyncCallback callback, Object state ) public override WebResponse EndGetResponse ( IAsyncResult asyncResult ) 其中BeginGetRequestStream、EndGetRequestStream 用于异步向HttpWebRequest对象写入请求信息; BeginGetResponse、EndGetResponse 用于异步发送页面请求并获取返回信息。使用异步方式操作Internet的“请求/响应”，避免主线程长期处于等待状态，而操作期间异步线程是来自CLR线程池的I/O线程。 请求与响应不能使用同步与异步混合开发模式，即当请求写入使用GetRequestStream同步模式，即使响应使用BeginGetResponse异步方法，操作也与GetRequestStream方法在于同一线程内。 下面以简单的例子介绍一下异步请求的用法。 首先为Person类加上可序列化特性，在服务器端建立Hanlder.ashx，通过Request.InputStream 获取到请求数据并把数据转化为String对象，此实例中数据是以 “Id：1” 的形式实现传送的。然后根据Id查找对应的Person对象，并把Person对象写入Response.OutStream 中返还到客户端。 在客户端先把 HttpWebRequird.Method 设置为 \"post\"，使用异步方式通过BeginGetRequireStream获取请求数据流，然后写入请求数据 “Id:1”。再使用异步方法BeginGetResponse 获取回复数据，最后把数据反序列化为Person对象显示出来。 HttpWebRequire.Method默认为get，在写入请求前必须把HttpWebRequire.Method设置为post,否则在使用BeginGetRequireStream 获取请求数据流的时候，系统就会发出 “无法发送具有此谓词类型的内容正文\" 的异常。 Model namespace Model { [Serializable] public class Person { public int ID { get; set; } public string Name { get; set; } public int Age { get; set; } } } 服务器端 public class Handler : IHttpHandler { public void ProcessRequest(HttpContext context) { //把信息转换为String，找出输入条件Id byte[] bytes=new byte[1024]; int length=context.Request.InputStream.Read(bytes,0,1024); string condition = Encoding.Default.GetString(bytes); int id = int.Parse(condition.Split(new string[] { \":\" }, StringSplitOptions.RemoveEmptyEntries)[1]); //根据Id查找对应Person对象 var person = GetPersonList().Where(x => x.ID == id).First(); //所Person格式化为二进制数据写入OutputStream BinaryFormatter formatter = new BinaryFormatter(); formatter.Serialize(context.Response.OutputStream, person); } //模拟源数据 private IList GetPersonList() { var personList = new List(); var person1 = new Person(); person1.ID = 1; person1.Name = \"Leslie\"; person1.Age = 30; personList.Add(person1); ........... return personList; } public bool IsReusable { get { return true;} } } 客户端 class Program { static void Main(string[] args) { ThreadPool.SetMaxThreads(1000, 1000); Request(); Console.ReadKey(); } static void Request() { ThreadPoolMessage(\"Start\"); //使用WebRequest.Create方法建立HttpWebRequest对象 HttpWebRequest webRequest = (HttpWebRequest)WebRequest.Create( \"http://localhost:5700/Handler.ashx\"); webRequest.Method = \"post\"; //对写入数据的RequestStream对象进行异步请求 IAsyncResult result=webRequest.BeginGetRequestStream( new AsyncCallback(EndGetRequestStream),webRequest); } static void EndGetRequestStream(IAsyncResult result) { ThreadPoolMessage(\"RequestStream Complete\"); //获取RequestStream HttpWebRequest webRequest = (HttpWebRequest)result.AsyncState; Stream stream=webRequest.EndGetRequestStream(result); //写入请求条件 byte[] condition = Encoding.Default.GetBytes(\"Id:1\"); stream.Write(condition, 0, condition.Length); //异步接收回传信息 IAsyncResult responseResult = webRequest.BeginGetResponse( new AsyncCallback(EndGetResponse), webRequest); } static void EndGetResponse(IAsyncResult result) { //显出线程池现状 ThreadPoolMessage(\"GetResponse Complete\"); //结束异步请求，获取结果 HttpWebRequest webRequest = (HttpWebRequest)result.AsyncState; WebResponse webResponse = webRequest.EndGetResponse(result); //把输出结果转化为Person对象 Stream stream = webResponse.GetResponseStream(); BinaryFormatter formatter = new BinaryFormatter(); var person=(Person)formatter.Deserialize(stream); Console.WriteLine(string.Format(\"Person Id:{0} Name:{1} Age:{2}\", person.ID, person.Name, person.Age)); } //显示线程池现状 static void ThreadPoolMessage(string data) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"{0}\\n CurrentThreadId is {1}\\n \" + \"WorkerThreads is:{2} CompletionPortThreads is :{3}\\n\", data, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 从运行结果可以看到，BeginGetRequireStream、BeginGetResponse方法是使用CLR线程池的I/O线程。 5.4 异步调用WebService 相比TCP/IP套接字，在使用WebService的时候，服务器端需要更复杂的操作处理，使用时间往往会更长。为了避免客户端长期处于等待状态，在配置服务引用时选择 “生成异步操作”，系统可以自动建立异步调用的方式。 以.NET 2.0以前，系统都是使用ASMX来设计WebService，而近年来WCF可说是火热登场，下面就以WCF为例子简单介绍一下异步调用WebService的例子。 由于系统可以自动生成异步方法，使用起来非常简单，首先在服务器端建立服务ExampleService，里面包含方法Method。客户端引用此服务时，选择 “生成异步操作”。然后使用 BeginMethod 启动异步方法， 在回调函数中调用EndMethod结束异步调用。 服务端 [ServiceContract] public interface IExampleService { [OperationContract] string Method(string name); } public class ExampleService : IExampleService { public string Method(string name) { return \"Hello \" + name; } } class Program { static void Main(string[] args) { ServiceHost host = new ServiceHost(typeof(ExampleService)); host.Open(); Console.ReadKey(); host.Close(); } } 客户端 class Program { static void Main(string[] args) { //设置最大线程数 ThreadPool.SetMaxThreads(1000, 1000); ThreadPoolMessage(\"Start\"); //建立服务对象，异步调用服务方法 ExampleServiceReference.ExampleServiceClient exampleService = new ExampleServiceReference.ExampleServiceClient(); exampleService.BeginMethod(\"Leslie\",new AsyncCallback(AsyncCallbackMethod), exampleService); Console.ReadKey(); } static void AsyncCallbackMethod(IAsyncResult result) { Thread.Sleep(1000); ThreadPoolMessage(\"Complete\"); ExampleServiceReference.ExampleServiceClient example = (ExampleServiceReference.ExampleServiceClient)result.AsyncState; string data=example.EndMethod(result); Console.WriteLine(data); } //显示线程池现状 static void ThreadPoolMessage(string data) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"{0}\\n CurrentThreadId is {1}\\n \" + \"WorkerThreads is:{2} CompletionPortThreads is :{3}\\n\", data, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 注意观察运行结果，异步调用服务时，回调函数都是运行于CLR线程池的I/O线程当中。 2. 六、异步 SqlCommand 从ADO.NET 2.0开始，SqlCommand就新增了几个异步方法执行SQL命令。相对于同步执行方式，它使主线程不需要等待数据库的返回结果，在使用复杂性查询或批量插入时将有效提高主线程的效率。使用异步SqlCommand的时候，请注意把ConnectionString 的 Asynchronous Processing 设置为 true 。 SqlCommand异步操作的特别之处在于线程并不依赖于CLR线程池，而是由Windows内部提供，这比使用异步委托更有效率。但如果需要使用回调函数的时候，回调函数的线程依然是来自于CLR线程池的工作者线程。 SqlCommand有以下几个方法支持异步操作： public IAsyncResult BeginExecuteNonQuery (......) public int EndExecuteNonQuery(IAsyncResult) public IAsyncResult BeginExecuteReader(......) public SqlDataReader EndExecuteReader(IAsyncResult) public IAsyncResult BeginExecuteXmlReader (......) public XmlReader EndExecuteXmlReader(IAsyncResult） 由于使用方式相似，此处就以 BeginExecuteNonQuery 为例子，介绍一下异步SqlCommand的使用。首先建立connectionString,注意把Asynchronous Processing设置为true来启动异步命令，然后把SqlCommand.CommandText设置为 WAITFOR DELAY \"0:0:3\" 来虚拟数据库操作。再通过BeginExecuteNonQuery启动异步操作，利用轮询方式监测操作情况。最后在操作完成后使用EndExecuteNonQuery完成异步操作。 class Program { //把Asynchronous Processing设置为true static string connectionString = \"Data Source=LESLIE-PC;Initial Catalog=Business;\"+ \"Integrated Security=True;Asynchronous Processing=true\"; static void Main(string[] args) { //把CLR线程池最大线程数设置为1000 ThreadPool.SetMaxThreads(1000, 1000); ThreadPoolMessage(\"Start\"); //使用WAITFOR DELAY命令来虚拟操作 SqlConnection connection = new SqlConnection(connectionString); SqlCommand command = new SqlCommand(\"WAITFOR DELAY '0:0:3';\", connection); connection.Open(); //启动异步SqlCommand操作，利用轮询方式监测操作 IAsyncResult result = command.BeginExecuteNonQuery(); ThreadPoolMessage(\"BeginRead\"); while (!result.AsyncWaitHandle.WaitOne(500)) Console.WriteLine(\"Main thread do work........\"); //结束异步SqlCommand int count= command.EndExecuteNonQuery(result); ThreadPoolMessage(\"\\nCompleted\"); Console.ReadKey(); } //显示线程池现状 static void ThreadPoolMessage(string data) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"{0}\\n CurrentThreadId is {1}\\n \"+ \"WorkerThreads is:{2} CompletionPortThreads is :{3}\\n\", data, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 注意运行结果，SqlCommand的异步执行线程并不属于CLR线程池。 如果觉得使用轮询方式过于麻烦，可以使用回调函数，但要注意当调用回调函数时，线程是来自于CLR线程池的工作者线程。 class Program { //把Asynchronous Processing设置为true static string connectionString = \"Data Source=LESLIE-PC;Initial Catalog=Business;\"+ \"Integrated Security=True;Asynchronous Processing=true\"; static void Main(string[] args) { //把CLR线程池最大线程数设置为1000 ThreadPool.SetMaxThreads(1000, 1000); ThreadPoolMessage(\"Start\"); //使用WAITFOR DELAY命令来虚拟操作 SqlConnection connection = new SqlConnection(connectionString); SqlCommand command = new SqlCommand(\"WAITFOR DELAY '0:0:3';\", connection); connection.Open(); //启动异步SqlCommand操作，并把SqlCommand对象传递到回调函数 IAsyncResult result = command.BeginExecuteNonQuery( new AsyncCallback(AsyncCallbackMethod),command); Console.ReadKey(); } static void AsyncCallbackMethod(IAsyncResult result) { Thread.Sleep(200); ThreadPoolMessage(\"AsyncCallback\"); SqlCommand command = (SqlCommand)result.AsyncState; int count=command.EndExecuteNonQuery(result); command.Connection.Close(); } //显示线程池现状 static void ThreadPoolMessage(string data) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"{0}\\n CurrentThreadId is {1}\\n \"+ \"WorkerThreads is:{2} CompletionPortThreads is :{3}\\n\", data, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 运行结果： 3. 七、并行编程与PLINQ 要使用多线程开发，必须非常熟悉Thread的使用，而且在开发过程中可能会面对很多未知的问题。为了简化开发，.NET 4.0 特别提供一个并行编程库System.Threading.Tasks，它可以简化并行开发，你无需直接跟线程或线程池打交道，就可以简单建立多线程应用程序。此外，.NET还提供了新的一组扩展方法PLINQ，它具有自动分析查询功能，如果并行查询能提高系统效率，则同时运行，如果查询未能从并行查询中受益，则按原顺序查询。下面将详细介绍并行操作的方式。 7.1 泛型委托 使用并行编程可以同时操作多个委托,在介绍并行编程前先简单介绍一下两个泛型委托System.Func<>与System.Action<>。 Func<>是一个能接受多个参数和一个返回值的泛型委托，它能接受0个到16个输入参数, 其中 T1,T2,T3,T4......T16 代表自定的输入类型，TResult为自定义的返回值。 public delegate TResult Func（） public delegate TResult Func（T1 arg1） public delegate TResult Func（T1 arg1,T2 arg2） public delegate TResult Func（T1 arg1,T2 arg2,T3 arg3） public delegate TResult Func（T1 arg1,T2 arg2,T3 arg3,T4 arg4） .............. public delegate TResult Func（T1 arg1,T2 arg2,T3 arg3,T4 arg4，...... ,T16 arg16） Action<>与Func<>十分相似，不同在于Action<>的返回值为void，Action能接受0~16个参数 public delegate void Action（） public delegate void Action（T1 arg1,T2 arg2） public delegate void Action（T1 arg1,T2 arg2, T3 arg3） ............. public delegate void Action（T1 arg1,T2 arg2,T3 arg3,T4 arg4，...... ,T16 arg16） 7.2 任务并行库（TPL） System.Threading.Tasks中的类被统称为任务并行库（Task Parallel Library，TPL），TPL使用CLR线程池把工作分配到CPU，并能自动处理工作分区、线程调度、取消支持、状态管理以及其他低级别的细节操作，极大地简化了多线程的开发。 TPL比Thread更具智能性，当它判断任务集并没有从并行运行中受益，就会选择按顺序运行。但并非所有的项目都适合使用并行开发，创建过多并行任务可能会损害程序的性能，降低运行效率。 TPL包括常用的数据并行与任务并行两种执行方式： 7.2.1 数据并行 数据并行的核心类就是System.Threading.Tasks.Parallel，它包含两个静态方法 Parallel.For 与 Parallel.ForEach, 使用方式与for、foreach相仿。通过这两个方法可以并行处理System.Func<>、System.Action<>委托。 以下一个例子就是利用 public static ParallelLoopResult For( int from, int max, Action) 方法对List进行并行查询。 假设使用单线程方式查询3个Person对象，需要用时大约6秒，在使用并行方式，只需使用2秒就能完成查询，而且能够避开Thread的繁琐处理。 class Program { static void Main(string[] args) { //设置最大线程数 ThreadPool.SetMaxThreads(1000, 1000); //并行查询 Parallel.For(0, 3,n => { Thread.Sleep(2000); //模拟查询 ThreadPoolMessage(GetPersonList()[n]); }); Console.ReadKey(); } //模拟源数据 static IList GetPersonList() { var personList = new List(); var person1 = new Person(); person1.ID = 1; person1.Name = \"Leslie\"; person1.Age = 30; personList.Add(person1); ........... return personList; } //显示线程池现状 static void ThreadPoolMessage(Person person) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"Person ID:{0} Name:{1} Age:{2}\\n\" + \" CurrentThreadId is {3}\\n WorkerThreads is:{4}\" + \" CompletionPortThreads is :{5}\\n\", person.ID, person.Name, person.Age, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 观察运行结果，对象并非按照原排列顺序进行查询，而是使用并行方式查询。 若想停止操作，可以利用ParallelLoopState参数，下面以ForEach作为例子。 public static ParallelLoopResult ForEach( IEnumerable source, Action action) 其中source为数据集，在Action委托的ParallelLoopState参数当中包含有Break（）和 Stop（）两个方法都可以使迭代停止。Break的使用跟传统for里面的使用方式相似，但因为处于并行处理当中，使用Break并不能保证所有运行能立即停止，在当前迭代之前的迭代会继续执行。若想立即停止操作，可以使用Stop方法，它能保证立即终止所有的操作，无论它们是处于当前迭代的之前还是之后。 class Program { static void Main(string[] args) { //设置最大线程数 ThreadPool.SetMaxThreads(1000, 1000); //并行查询 Parallel.ForEach(GetPersonList(), (person, state) => { if (person.ID == 2) state.Stop(); ThreadPoolMessage(person); }); Console.ReadKey(); } //模拟源数据 static IList GetPersonList() { var personList = new List(); var person1 = new Person(); person1.ID = 1; person1.Name = \"Leslie\"; person1.Age = 30; personList.Add(person1); .......... return personList; } //显示线程池现状 static void ThreadPoolMessage(Person person) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"Person ID:{0} Name:{1} Age:{2}\\n\" + \" CurrentThreadId is {3}\\n WorkerThreads is:{4}\" + \" CompletionPortThreads is :{5}\\n\", person.ID, person.Name, person.Age, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 观察运行结果，当Person的ID等于2时，运行将会停止。 当要在多个线程中调用本地变量，可以使用以下方法： public static ParallelLoopResult ForEach(IEnumerable, Func, Func, Action) 其中第一个参数为数据集; 第二个参数是一个Func委托，用于在每个线程执行前进行初始化; 第 三个参数是委托Func,它能对数据集的每个成员进行迭代，当中T1是数据集的成员，T2是一个ParallelLoopState对 象，它可以控制迭代的状态，T3是线程中的本地变量; 第四个参数是一个Action委托，用于对每个线程的最终状态进行最终操作。 在以下例子中，使用ForEach计算多个Order的总体价格。在ForEach方法中，首先把参数初始化为0f，然后用把同一个Order的多个OrderItem价格进行累加，计算出Order的价格，最后把多个Order的价格进行累加，计算出多个Order的总体价格。 public class Order { public int ID; public float Price; } public class OrderItem { public int ID; public string Goods; public int OrderID; public float Price; public int Count; } class Program { static void Main(string[] args) { //设置最大线程数 ThreadPool.SetMaxThreads(1000, 1000); float totalPrice = 0f; //并行查询 var parallelResult = Parallel.ForEach(GetOrderList(), () => 0f, //把参数初始值设为0 (order, state, orderPrice) => { //计算单个Order的价格 orderPrice = GetOrderItem().Where(item => item.OrderID == order.ID) .Sum(item => item.Price * item.Count); order.Price = orderPrice; ThreadPoolMessage(order); return orderPrice; }, (finallyPrice) => { totalPrice += finallyPrice;//计算多个Order的总体价格 } ); while (!parallelResult.IsCompleted) Console.WriteLine(\"Doing Work!\"); Console.WriteLine(\"Total Price is:\" + totalPrice); Console.ReadKey(); } //虚拟数据 static IList GetOrderList() { IList orderList = new List(); Order order1 = new Order(); order1.ID = 1; orderList.Add(order1); ............ return orderList; } //虚拟数据 static IList GetOrderItem() { IList itemList = new List(); OrderItem orderItem1 = new OrderItem(); orderItem1.ID = 1; orderItem1.Goods = \"iPhone 4S\"; orderItem1.Price = 6700; orderItem1.Count = 2; orderItem1.OrderID = 1; itemList.Add(orderItem1); ........... return itemList; } //显示线程池现状 static void ThreadPoolMessage(Order order) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"OrderID:{0} OrderPrice:{1}\\n\" + \" CurrentThreadId is {2}\\n WorkerThreads is:{3}\" + \" CompletionPortThreads is:{4}\\n\", order.ID, order.Price, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 运行结果 7.2.2 任务并行 在TPL当中还可以使用Parallel.Invoke方法触发多个异步任务,其中 actions 中可以包含多个方法或者委托，parallelOptions用于配置Parallel类的操作。 public static void Invoke(Action[] actions ) public static void Invoke(ParallelOptions parallelOptions, Action[] actions ) 下面例子中利用了Parallet.Invoke并行查询多个Person，actions当中可以绑定方法、lambda表达式或者委托，注意绑定方法时必须是返回值为void的无参数方法。 class Program { static void Main(string[] args) { //设置最大线程数 ThreadPool.SetMaxThreads(1000, 1000); //任务并行 Parallel.Invoke(option, PersonMessage, ()=>ThreadPoolMessage(GetPersonList()[1]), delegate(){ ThreadPoolMessage(GetPersonList()[2]); }); Console.ReadKey(); } static void PersonMessage() { ThreadPoolMessage(GetPersonList()[0]); } //显示线程池现状 static void ThreadPoolMessage(Person person) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"Person ID:{0} Name:{1} Age:{2}\\n\" + \" CurrentThreadId is {3}\\n WorkerThreads is:{4}\" + \" CompletionPortThreads is :{5}\\n\", person.ID, person.Name, person.Age, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } //模拟源数据 static IList GetPersonList() { var personList = new List(); var person1 = new Person(); person1.ID = 1; person1.Name = \"Leslie\"; person1.Age = 30; personList.Add(person1); .......... return personList; } } 运行结果 7.3 Task简介 以Thread创建的线程被默认为前台线程，当然你可以把线程IsBackground属性设置为true，但TPL为此提供了一个更简单的类Task。 Task存在于System.Threading.Tasks命名空间当中，它可以作为异步委托的简单替代品。 通过Task的Factory属性将返回TaskFactory类，以TaskFactory.StartNew（Action）方法可以创建一个新线程，所创建的线程默认为后台线程。 class Program { static void Main(string[] args) { ThreadPool.SetMaxThreads(1000, 1000); Task.Factory.StartNew(() => ThreadPoolMessage()); Console.ReadKey(); } //显示线程池现状 static void ThreadPoolMessage() { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"CurrentThreadId is:{0}\\n\" + \"CurrentThread IsBackground:{1}\\n\" + \"WorkerThreads is:{2}\\nCompletionPortThreads is:{3}\\n\", Thread.CurrentThread.ManagedThreadId, Thread.CurrentThread.IsBackground.ToString(), a.ToString(), b.ToString()); Console.WriteLine(message); } } 运行结果 若要取消处理，可以利用CancellationTakenSource对象，在TaskFactory中包含有方法 public Task StartNew( Action action, CancellationToken cancellationToken ) 在方法中加入CancellationTakenSource对象的CancellationToken属性，可以控制任务的运行，调用CancellationTakenSource.Cancel时任务就会自动停止。下面以图片下载为例子介绍一下TaskFactory的使用。 服务器端页面 private static List url=new List(); protected void Page_Load(object sender, EventArgs e) { if (!Page.IsPostBack) { url.Clear(); Application[\"Url\"] = null; } } protected void CheckBox_CheckedChanged(object sender, EventArgs e) { CheckBox checkBox = (CheckBox)sender; if (checkBox.Checked) url.Add(checkBox.Text); else url.Remove(checkBox.Text); Application[\"Url\"]= url; } 首先在服务器页面中显示多个*.jpg图片，每个图片都有对应的CheckBox检测其选择情况。 所选择图片的路径会记录在Application[\"Url\"]当中传递到Handler.ashx当中。 Application是一个全局变量，此处只是为了显示Task的使用方式，在ASP.NET开发应该慎用Application。 Handler.ashx 处理图片的下载，它从 Application[\"Url\"] 当中获取所选择图片的路径，并把图片转化成byte[]二进制数据。 再把图片的数量，每副图片的二进制数据的长度记录在OutputStream的头部。 最后把图片的二进制数据记入 OutputStream 一并输出。 public class Handler : IHttpHandler { public void ProcessRequest(HttpContext context) { //获取图片名，把图片数量写OutputStream List urlList = (List)context.Application[\"Url\"]; context.Response.OutputStream.Write(BitConverter.GetBytes(urlList.Count), 0, 4); //把图片转换成二进制数据 List imageList = GetImages(urlList); //把每副图片长度写入OutputStream foreach (string image in imageList) { byte[] imageByte=Convert.FromBase64String(image); context.Response.OutputStream.Write(BitConverter.GetBytes(imageByte.Length),0,4); } //把图片写入OutputStream foreach (string image in imageList) { byte[] imageByte = Convert.FromBase64String(image); context.Response.OutputStream.Write(imageByte,0,imageByte.Length); } } //获取多个图片的二进制数据 private List GetImages(List urlList) { List imageList = new List(); foreach (string url in urlList) imageList.Add(GetImage(url)); return imageList; } //获取单副图片的二进制数据 private string GetImage(string url) { string path = \"E:/My Projects/Example/WebSite/Images/\"+url; FileStream stream = new FileStream(path, FileMode.Open, FileAccess.Read); byte[] imgBytes = new byte[10240]; int imgLength = stream.Read(imgBytes, 0, 10240); return Convert.ToBase64String(imgBytes,0,imgLength); } public bool IsReusable { get{ return false;} } } 客户端 建立一个WinForm窗口，里面加入一个WebBrowser连接到服务器端的Default.aspx页面。 当按下Download按键时，系统就会利用TaskFactory.StartNew的方法建立异步线程，使用WebRequest方法向Handler.ashx发送请求。 接收到回传流时，就会根据头文件的内容判断图片的数量与每副图片的长度，把二进制数据转化为*.jpg文件保存。 系统利用TaskFactory.StartNew(action,cancellationToken) 方式异步调用GetImages方法进行图片下载。 当用户按下Cancel按钮时，异步任务就会停止。值得注意的是，在图片下载时调用了CancellationToken.ThrowIfCancellationRequested方法，目的在检查并行任务的运行情况，在并行任务被停止时释放出OperationCanceledException异常，确保用户按下Cancel按钮时，停止所有并行任务。 public partial class Form1 : Form { private CancellationTokenSource tokenSource = new CancellationTokenSource(); public Form1() { InitializeComponent(); ThreadPool.SetMaxThreads(1000, 1000); } private void downloadToolStripMenuItem_Click(object sender, EventArgs e) { Task.Factory.StartNew(GetImages,tokenSource.Token); } private void cancelToolStripMenuItem_Click(object sender, EventArgs e) { tokenSource.Cancel(); } private void GetImages() { //发送请求，获取输出流 WebRequest webRequest = HttpWebRequest.Create(\"Http://localhost:5800/Handler.ashx\"); Stream responseStream=webRequest.GetResponse().GetResponseStream(); byte[] responseByte = new byte[81960]; IAsyncResult result=responseStream.BeginRead(responseByte,0,81960,null,null); int responseLength = responseStream.EndRead(result); //获取图片数量 int imageCount = BitConverter.ToInt32(responseByte, 0); //获取每副图片的长度 int[] lengths = new int[imageCount]; for (int n = 0; n 7.4 并行查询（PLINQ） 并行 LINQ (PLINQ) 是 LINQ 模式的并行实现，主要区别在于 PLINQ 尝试充分利用系统中的所有处理器。 它利用所有处理器的方法，把数据源分成片段，然后在多个处理器上对单独工作线程上的每个片段并行执行查询， 在许多情况下，并行执行意味着查询运行速度显著提高。但这并不说明所有PLINQ都会使用并行方式，当系统测试要并行查询会对系统性能造成损害时，那将自动化地使用同步执行。 在System.Linq.ParallelEnumerable类中，包含了并行查询的大部分方法。 方法成员　 说明 AsParallel PLINQ 的入口点。 指定如果可能，应并行化查询的其余部分。 AsSequential(Of TSource) 指定查询的其余部分应像非并行 LINQ 查询一样按顺序运行。 AsOrdered 指定 PLINQ 应保留查询的其余部分的源序列排序，直到例如通过使用 orderby（在 Visual Basic 中为 Order By）子句更改排序为止。 AsUnordered(Of TSource) 指定查询的其余部分的 PLINQ 不需要保留源序列的排序。 WithCancellation(Of TSource) 指定 PLINQ 应定期监视请求取消时提供的取消标记和取消执行的状态。 WithDegreeOfParallelism(Of TSource) 指定 PLINQ 应当用来并行化查询的处理器的最大数目。 WithMergeOptions(Of TSource) 提供有关 PLINQ 应当如何（如果可能）将并行结果合并回到使用线程上的一个序列的提示。 WithExecutionMode(Of TSource) 指定 PLINQ 应当如何并行化查询（即使默认行为是按顺序运行查询）。 ForAll(Of TSource) 多线程枚举方法，与循环访问查询结果不同，它允许在不首先合并回到使用者线程的情况下并行处理结果。 Aggregate 重载 对于 PLINQ 唯一的重载，它启用对线程本地分区的中间聚合以及一个用于合并所有分区结果的最终聚合函数。 7.4.1 AsParallel 通常想要实现并行查询，只需向数据源添加 AsParallel 查询操作即可。 class Program { static void Main(string[] args) { var personList=GetPersonList().AsParallel() .Where(x=>x.Age>30); Console.ReadKey(); } //模拟源数据 static IList GetPersonList() { var personList = new List(); var person1 = new Person(); person1.ID = 1; person1.Name = \"Leslie\"; person1.Age = 30; personList.Add(person1); ........... return personList; } } 7.4.2 AsOrdered 若要使查询结果必须保留源序列排序方式，可以使用AsOrdered方法。 AsOrdered依然使用并行方式，只是在查询过程加入额外信息，在并行结束后把查询结果再次进行排列。 class Program { static void Main(string[] args) { var personList=GetPersonList().AsParallel().AsOrdered() .Where(x=>x.Age GetPersonList() {......} } 7.4.3 WithDegreeOfParallelism 默认情况下，PLINQ 使用主机上的所有处理器，这些处理器的数量最多可达 64 个。 通过使用 WithDegreeOfParallelism(Of TSource) 方法，可以指示 PLINQ 使用不多于指定数量的处理器。 class Program { static void Main(string[] args) { var personList=GetPersonList().AsParallel().WithDegreeOfParallelism(2) .Where(x=>x.Age GetPersonList() {.........} } 7.4.4 ForAll 如果要对并行查询结果进行操作，一般会在for或foreach中执行，执行枚举操作时会使用同步方式。 有见及此，PLINQ中包含了ForAll方法，它可以使用并行方式对数据集进行操作。 class Program { static void Main(string[] args) { ThreadPool.SetMaxThreads(1000, 1000); GetPersonList().AsParallel().ForAll(person =>{ ThreadPoolMessage(person); }); Console.ReadKey(); } static IList GetPersonList() {.......} //显示线程池现状 static void ThreadPoolMessage(Person person) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"Person ID:{0} Name:{1} Age:{2}\\n\" + \" CurrentThreadId is {3}\\n WorkerThreads is:{4}\" + \" CompletionPortThreads is :{5}\\n\", person.ID, person.Name, person.Age, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 运行结果 7.4.5 WithCancellation 如果需要停止查询，可以使用 WithCancellation(Of TSource) 运算符并提供 CancellationToken 实例作为参数。 与第三节Task的例子相似，如果标记上的 IsCancellationRequested 属性设置为 true，则 PLINQ 将会注意到它，并停止所有线程上的处理，然后引发 OperationCanceledException。这可以保证并行查询能够立即停止。 class Program { static CancellationTokenSource tokenSource = new CancellationTokenSource(); static void Main(string[] args) { Task.Factory.StartNew(Cancel); try { GetPersonList().AsParallel().WithCancellation(tokenSource.Token) .ForAll(person => { ThreadPoolMessage(person); }); } catch (OperationCanceledException ex) { } Console.ReadKey(); } //在10~50毫秒内发出停止信号 static void Cancel() { Random random = new Random(); Thread.Sleep(random.Next(10,50)); tokenSource.Cancel(); } static IList GetPersonList() {......} //显示线程池现状 static void ThreadPoolMessage(Person person) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"Person ID:{0} Name:{1} Age:{2}\\n\" + \" CurrentThreadId is {3}\\n WorkerThreads is:{4}\" + \" CompletionPortThreads is :{5}\\n\", person.ID, person.Name, person.Age, Thread.CurrentThread.ManagedThreadId, a.ToString(), b.ToString()); Console.WriteLine(message); } } 八、定时器与锁 8.1定时器 若要长期定时进行一些工作，比如像邮箱更新，实时收听信息等等，可以利用定时器Timer进行操作。 在System.Threading命名空间中存在Timer类与对应的TimerCallback委托，它可以在后台线程中执行一些长期的定时操作，使主线程不受干扰。 Timer类中最常用的构造函数为 public Timer( timerCallback , object , int , int ) timerCallback委托可以绑定执行方法，执行方法必须返回void，它可以是无参数方法，也可以带一个object参数的方法。 第二个参数是为 timerCallback 委托输入的参数对象。 第三个参数是开始执行前等待的时间。 第四个参数是每次执行之间的等待时间。 开发实例 class Program { static void Main(string[] args) { ThreadPool.SetMaxThreads(1000, 1000); TimerCallback callback = new TimerCallback(ThreadPoolMessage); Timer t = new Timer(callback,\"Hello Jack! \", 0, 1000); Console.ReadKey(); } //显示线程池现状 static void ThreadPoolMessage(object data) { int a, b; ThreadPool.GetAvailableThreads(out a, out b); string message = string.Format(\"{0}\\n CurrentThreadId is:{1}\\n\" + \" CurrentThread IsBackground:{2}\\n\" + \" WorkerThreads is:{3}\\n CompletionPortThreads is:{4}\\n\", data + \"Time now is \" + DateTime.Now.ToLongTimeString(), Thread.CurrentThread.ManagedThreadId, Thread.CurrentThread.IsBackground.ToString(), a.ToString(), b.ToString()); Console.WriteLine(message); } } 注意观察运行结果，每次调用Timer绑定的方法时不一定是使用同一线程，但线程都会是来自工作者线程的后台线程。 8.2 锁 在使用多线程开发时，存在一定的共用数据，为了避免多线程同时操作同一数据，.NET提供了lock、Monitor、Interlocked等多个锁定数据的方式。 8.2.1 lock lock的使用比较简单，如果需要锁定某个对象时，可以直接使用lock(this)的方式。 private void Method() { lock(this) { //在此进行的操作能保证在同一时间内只有一个线程对此对象操作 } } 如果操作只锁定某段代码，可以事先建立一个object对象，并对此对象进行操作锁定，这也是.net提倡的锁定用法。 class Control { private object obj=new object(); public void Method() { lock(obj) {.......} } } 8.2.2 Montior Montior存在于System.Thread命名空间内，相比lock，Montior使用更灵活。 它存在 Enter, Exit 两个方法，它可以对对象进行锁定与解锁，比lock使用更灵活。 class Control { private object obj=new object(); public void Method() { Monitor.Enter(obj); try {......} catch(Excetion ex) {......} finally { Monitor.Exit(obj); } } } 使用try的方式，能确保程序不会因死锁而释放出异常！ 而且在finally中释放obj对象能够确保无论是否出现死锁状态，系统都会释放obj对象。 而且Monitor中还存在Wait方法可以让线程等待一段时间，然后在完成时使用Pulse、PulseAll等方法通知等待线程。 8.2.3 Interlocked Interlocked存在于System.Thread命名空间内，它的操作比Monitor使用更简单。 它存在CompareExchange、Decrement、Exchange、Increment等常用方法让参数在安全的情况进行数据交换。 Increment、Decrement 可以使参数安全地加1或减1并返回递增后的新值。 class Example { private int a=1; public void AddOne() { int newA=Interlocked.Increment(ref a); } } Exchange可以安全地变量赋值。 public void SetData() { Interlocked.Exchange(ref a,100); } CompareExchange使用特别方便，它相当于if的用法，当a等于1时，则把100赋值给a。 public void CompareAndExchange() { Interlocked.CompareExchange(ref a,100,1); } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/大型网站分布式设计.html":{"url":"Interview/大型网站架构/大型网站分布式设计.html","title":"大型网站分布式设计","keywords":"","body":"1. 大型网站分布式设计1.1. Web分布式系统设计准则1.2. 基本原理1.2.1. 举例：图片托管应用1.2.2. 读写分离1.2.3. 分区处理1.2.4. 冗余1.2.5. 扩容之水平扩展分区和垂直扩展1.3. 建立大型web1.3.1. 缓存1.3.2. 代理1.3.3. 索引1.3.4. 负载均衡1.3.5. 队列1. 大型网站分布式设计 http://blog.jobbole.com/58551/ 1.1. Web分布式系统设计准则 可用性 大型在线零售网站，甚至是几分钟的不可用都会导致数以千万计美元的收入损失，所以将他们的系统设计成 不间断可用和能够弹性恢复 既是一项基础业务也是一个技术需求。分布式系统的高可用性需要仔细考虑关键组件冗余，快速恢复部分有问题的系统，并且当出现问题时能够做到优雅降级。 性能 性能已成为大多数网站一个很重要的考量指标。一个网站的速度会影响到使用和用户满意度，同样也会影响到搜索引擎排名，将直接关系到网站收入和用户保持力（黏性）。因此，关键之处就在于创建一个为 快速响应、低延迟 的系统。 可靠性 一个系统需要做到可靠，这样才能使得对于 固定数据的请求始终会返回同样的数据。如果数据发生变化或者更新，那相同的请求应该返回新的数据。 用户需要知道，一旦一些数据被写入、存储到系统中，那么系统就会持久化（这些数据）并且能够让人信赖随时能够检索。 可伸缩性 对于任何大型分布式系统，系统规模只是可伸缩性需要考虑的一个方面。同样重要的是， 增加容量能够处理更大量的负载所需的工作 ，通常在系统可伸缩性方面被提及到。可伸缩性会涉及到系统的很多不同的因素：系统额外还能够处理多少流量，是否能够轻易增加存储容量，还能多处理多少事务。 可管理性 设计一个易于运维的系统是另一个重要考量点。系统的可管理型等同于操作的可伸缩性：维护和变更。可管理性需要考虑的有：当 问题发生时能够便于诊断和理解 ，便于进行变更和修改，并且系统易于操作。（比如系统是否能够进行例行操作而不带来失败或者异常？） 成本 包括硬件和软件成本，但同样还要考虑到一些其他方面来 部署、运维系统，比如构建系统所需的开发时间，运行系统所需的运维工作量，甚至所需的培训都要被考虑在内 。 小节 这些准则中的每一条都提供了在设计一个分布式web系统架构时作决定的基本原则。但是，他们也可能互相矛盾，比如达到某一目标是以牺牲另一个为代价的。一个典型的例子：专注于系统容量时，选择通过简单增加更多机器（可伸缩性）的代价是（增加了）可管理性（你需要运维更多的服务器）和成本（更多服务器价格）。当设计任何web应用时，这些关键准则都是需要考量的，即使不得不承认，一个设计可能会牺牲它们中的一个或更多。 1.2. 基本原理 对于系统架构来说，有一些事情需要考虑：什么是正确的组件，这些组件如何协作，需要做哪些正确的权衡。 大型Web应用都非常核心的因素：服务，冗余，分期和失败处理。每个因素均包含有选择和妥协。 1.2.1. 举例：图片托管应用 设想一个这样的系统：用户可以将他们的图片上传到一个中央服务器，并且图片可以通过一个web链接或者API（应用程序接口）进行请求，就像Flickr或者Picasa一样。为了简单起见，我们假定这个应用有两个关键部分：能够上传（写入）一张图片到服务器，能够查询一张图片。虽然我们希望上传能够更快速，但我们最关心的是系统能够快速分发用户请求的图片（比如图片可以被请求用于一张网页或是其他应用）。这些跟一个web服务器或者CDN（内容分发网络） edge server（CDN所使用的服务器，用于在很多位置存放内容，这样内容在地理/物理上更接近用户，起到更高性能的作用）所提供的功能非常类似。 系统其他重要的方面 对于存储的图片数量没有设限，所以就图片数量而言，需要考虑存储的可伸缩性。 对于图片的下载/请求需要做到低延迟。 如果一个用户上传了一张图片，那该图片应该总是存在的。（图片的数据可靠性） 系统需要易于管理（可管理型）。 由于图片托管不会带来很高的利润，所以系统需要做到有成本效益的。 图片1.1：图片托管应用的简化架构图 服务 可伸缩系统的设计有助于各功能解耦并且通过一个清晰定义的接口思考系统的每个部分。在实践中，这种方式的系统拥有一个面向服务的架构SOA。对于这些类型的系统，每个服务都有它们各自确切的功能上下文，并且和该上下文以外的任何交互均是与一个抽象的接口进行的，特别是另一个服务的公有接口。 将一个系统拆解为一个互补的服务集合解耦了那些相互间的操作。这种抽象有助于建立服务间明确的关系、潜在的运行环境、服务的消费者。通过这些清晰的描绘有助于隔离问题，并且允许每个部分能够相互独立地进行扩展。这种面向服务的系统设计有点类似与面向对象编程。 在我们的例子中，所有上传和获取图片的请求都是在同一服务器上处理，但是，如果系统想要达到可伸缩，那么将这两个功能拆分成各自的服务是非常明智的。 1.2.2. 读写分离 假设这些服务被大量使用，这样的场景将非常易于看到写操作会如何影响读取图片的时间（因为这两个功能会竞争共享资源）。即使上传和下载速度是一样的（对于大多数IP网络来说不一定是，因为大多数都是设计成下载速度与上传速度3:1的比例），文件通常直接从缓存中读取，而写入则最终必须到达磁盘（在最终一致的场景中可能会被写入多次）。即使所有东西都是从内存或者磁盘（比如SSD固态硬盘）读取，数据库的写入操作总还是比读取要慢。 另一个潜在的设计问题是，一个像Apache或者lighttpd的web服务器，通常有一个它可以维持并发连接数的上线（默认大约在500左右，但可以调得更高），并且在高流量下，写操作将很快消耗完所有连接资源。由于读操作可以异步进行，或者利用其它性能调优如gzip压缩或者chunked transfer encoding，web服务器可以转换为更快服务读操作、更快切换客户端，从而比最大连接数每秒服务更多的请求（Apache最大连接数设置为500，但一般都能每秒服务数千个请求）。写操作，在另一方面，倾向于在上传过程中维护一个打开状态的连接，所有上传一个1M大小的文件在大多数家庭网络上将花费超过1秒的视角，所以web服务器只能同时处理500个写操作。 图1.2: 读写分离 将图片的读、写操作拆分成各自的服务是一个应对这种瓶颈很好的解决方案，如图1.2。这样允许我们能够独立的扩展它们（通常读大于写）。这样可以分离未来的担心，可以更简单地解决像读操作缓慢的问题，并做到可伸缩。 这种方法的好处在于我们能够独立解决问题——不用担心在同一上下文中写入、读取新的图片。这两种服务仍然影响着全部的图片，但均能通过service-appropriate方法优化它们的性能，比如让请求排队，或者缓存受欢迎的图片。从一个维护和成本的视角出发，每个服务均能独立、按需伸缩是非常好的，因为如果它们被组合、混合在一起，在上面讨论的场景下，可能某一服务不经意间就会影响到其他服务的性能。 当然，当你考虑着两个不同点时，上面的例子能够工作得很好（事实上，这跟一些云存储提供商的实现方案和CDN很类似）。尽管还有很多方法来处理这些类型的瓶颈，但每个都有不同方面的权衡。 1.2.3. 分区处理 例如， Flickr通过将用户分布在不同区域的方法来解决读/写问题，比如每个分区只处理一定数量的用户，随着用户的增加，集群会更多的分区 。在第一个例子中，基于实际使用（整个系统的读写操作数量）可以更容易地伸缩硬件，然而Flickr是基于它的用户（但强制假设用户的使用率均等，所以仍有额外的容量）。对于前者来说，停电或者一个服务的问题就会降低整个系统的功能性（比如没人可以写入文件），然而Flickr的一个分区停电仅会影响到这个分区相应的用户。第一个例子易于操作整个数据集，比如升级写入服务来包含新的元数据或者搜索所有的图片元数据，然而在Flickr的架构下，每个分区均需要被更新或搜索（或者一个搜索服务需要能够整理相关元数据——事实上他们确实这么做）。 对于这些系统来说没有孰对孰错，而是帮助我们回到本章开头所说的准则，判断系统需求（读多还是写多还是两者都多，并发程度，跨数据集查询，搜索，排序等），检测不同的取舍，理解系统为什么会失败并且有可靠的计划来应对失败的发生。 1.2.4. 冗余 为了能够优雅地处理失败问题，Web架构必须做到服务和数据的冗余。比如，如果在单台服务器上仅有一份文件，那么失去那台服务器就意味着丢失那份文件。通常的解决方案是创建多个、冗余的备份。 该准则同样适用于服务。如果应用有一个核心功能，那么通过确保多个拷贝（多个同类服务实例）或者版本同时运行能够免于单点失败的情况。 在一个系统中创建冗余能够去除单点失败，并提供一个备份或在必要的紧急时刻替换功能。例如，如果在生产环境有同一服务的两个实例在运行，其中一个失败或者降级了，系统可以（启动）failover到那个健康状态的服务。Failover可以自动发生或者需要人工干预。 服务冗余的另一个关键点在于创建一个非共享的架构。通过这种架构，每个节点都能够独立操作，并且没有中央“大脑”来管理状态或者协调其他节点的活动。这对于可伸缩性非常有帮助，因为新的节点不需要特殊的条件或知识就能加入到集群。但是，最重要的是在这些系统中不会存在单点失败问题，所以它们能够更加弹性地面对失败。 例如，在我们的图片服务应用，所有的图片会在另一个地方的硬件中有冗余的备份，理想情况是在一个不同的地理位置，以防地震或者数据中心火灾这类的灾难发生，而访问图片的服务同样是冗余的，见图1.3（负载均衡器可以将其变为现实，详情请见下文） 图1.3：图片托管应用，带有冗余特性 1.2.5. 扩容之水平扩展分区和垂直扩展 单台服务器可能没法放下海量数据集。也可能是一个操作需要太多计算资源，消耗性能，使得有必要增加系统容量。无论是哪种情况，你都有两种选择：垂直扩展（scale vertically）或者水平扩展（scale horizontally）。 垂直扩展意味着在单台服务器上增加更多的资源。所以对于大数据来说，这意味着增加更多更大容量的硬盘以便让单台服务器能够容纳整个数据集。对于计算操作的场景，这意味着将计算任务交给一台拥有更快CPU或者更多内存的大型服务器。对于每种场景，垂直扩展是通过自身能够处理更多的方式来达到目标的。 垂直扩展对于应用来说无需修改，通常升级机器即可达到目的 水平扩展，就是增加更多的节点。对于大数据集，可能是用另一台服务器来存储部分数据集；而对于计算资源来说，则意味着将操作进行分解或者加载在一些额外的节点上。水平扩展要求应用架构能够支持这种方式的扩展，因为数据、服务都是分布式的，需要从软件层面来支持这一特性，从而做到数据、服务的水平可扩展。水平扩展应该被天然地包含在系统架构设计准则里，否则想要通过修改、隔离上下文来达到这一点将会相当麻烦。 对于水平扩展来说，通常方法之一就是 将你的服务打散、分区。分区可以是分布式的，这样每个逻辑功能集都是分离的；分区可通过地理边界来划分，或者其他标准如付费/未付费用户 。这些设计的好处在于它们能够使得服务或数据存储易于增加容量。 在我们的图片服务器例子中，可以将单台存储图片的服务器替换为多台文件服务器，每台保存各自单独的图片集。（见图1.4）这样的架构使得系统能够往各台文件服务器中存入图片，当磁盘快满时再增加额外的服务器。这种设计将需要一种命名机制，将图片的文件名与所在服务器关联起来。一个图片的名字可以通过服务器间一致性Hash机制来生成。或者另一种选择是，可以分配给每张图片一个增量ID，当一个客户端请求一张图片时，图片检索服务只需要维护每台服务器对应的ID区间即可（类似索引）。 图1.4：图片托管应用，加入冗余和分区特性 当然，将数据或功能分布在多台服务器上会带来很多挑战。关键问题之一是数据局部性（data locality）。在分布式系统里，数据离操作或者计算点越近，系统性能就越高。因此将数据分布在多台服务器可能是有问题的，任何需要数据的时候都可能不在本地，使得服务器必须通过网络来获取所需的信息。 1.3. 建立大型web 大多数简单的web应用随着它们的成长，会有两个主要的挑战：访问应用服务器和数据库的可伸缩性。在一个高可伸缩的应用设计中，web服务器通常会最小化并通常表现为一个非共享（无状态）架构。这样使得系统的应用服务层能够很好地进行伸缩。这样数据的结果是， 压力被向下推到了数据库服务器和相关（底层）支持服务；真正的伸缩和性能挑战就在这一层起到作用 。 假设你有数以TB计的数据并且希望能让用户随机访问这些数据的一小部分。由于很难将TB级的数据加载到内存，所以这会使得事情变得非常有挑战性。这种访问将直接变为磁盘IO操作。从磁盘读取会比从内存要慢得多。顺序访问内存的速度是访问磁盘的6倍，而在随机读方面，前者是后者的十万倍。而且，即使有唯一ID，从哪里能够找到这样一小块数据仍然是一项艰巨的任务。 幸运的是，可以通过 缓存、代理、索引、负载均衡 来解决。 1.3.1. 缓存 缓存几乎被用在计算机运行的各层：硬件，操作系统，web浏览器，web应用等等。缓存就像短期的内存：有着限定大小的空间，但通常比访问原始数据源更快，并且包含有最近最多被访问过的（数据）项。缓存可以存在于架构的各个层次，但会发现到经常更靠近前端（非web前端界面，架构上层），这样就可尽快返回数据而不用经过繁重的下层处理了。 图1.5：在请求层节点中插入缓存 每次对于一个服务的请求，节点将立即返回存在的本地、缓存的数据。如果对应的缓存不存在，请求节点将会从磁盘中查询数据。请求层节点的缓存既可以放置在内存（更快）也可以在节点本地磁盘（比通过网络快）上。 图1.6：多个缓存 当你扩展到多个节点时，会发生什么呢？正如你看到的图1.6，如果请求曾扩展到多个节点，那么每个节点都可以拥有它自身的缓存。但是，如果你的负载均衡器将请求随机分发到这些节点上，同样的请求会到达不同的节点，就会提高缓存miss率。两种克服这种困难的方法是：全局缓存和分布式缓存。 全局缓存 所有节点使用同一缓存空间。这包括增加一台服务器或是某种类型的文件存储，并且所有请求层的节点均可以访问全局缓存。这种类型的缓存机制可能会变得比较复杂，因为随着客户端和请求数量的增加，单个缓存服务器很容易被压垮，但是在一些架构中非常有效（特别是有专门定制的硬件使得访问全局缓存非常快速，或者需要缓存的数据集是固定的）。 通常有两种形式的全局缓存。 如果缓存中找不到对应的响应，那缓存自身会去从下层存储中获取丢失的数据。 当缓存中找不到相应数据时，需要请求节点自己去获取数据。 第一种方式相当于是全局缓存将查询缓存、底层获取数据、填充缓存这些操作一并做掉，理想情况下对于上层应用应该只需要提供一个获取数据的API，上层应用无需关心所请求的数据是已存在于缓存中的还是从底层存储中获取的，能够更专注于上层业务逻辑，但这就可能需要这种全局缓存设计成能够根据传入API接口的参数去获取底层存储的数据，接口签名可以简化为Object getData(String uniqueId, DataRetrieveCallback callback)，第一个参数代表与缓存约定的唯一标示一个数据的ID，第二个是一个获取数据回调接口，具体实现由调用该接口的业务端来实现，即当全局缓存中未找到uniqueId对应的缓存数据时，那就会以该callback去获取数据，并以uniqueId为key、callback获取数据为value放入全局缓存中。 图1.7：全局缓存自身负责存取 第二种方式相对来说自由一些。请求节点自行根据业务场景需求来决定查询数据的方式，以及查数据后的处理（比如缓存回收策略），全局缓存只作为一个基础组件让请求节点能够在其中存取数据。 图1.8 全局缓存，请求节点负责存取 大多数应用倾向于通过第一种方式使用全局缓存，由缓存自身来管理回收、获取数据，来应对从客户端发起的对同一数据的众多请求。但是，对于一些场景来说，第二种实现就比较有意义。比如，如果是用来缓存大型文件，那缓存低命中率将会导致缓存缓冲区被缓存miss给压垮；在这种情况下，缓存中缓存大部分数据集（或热门数据）将会有助解决这个问题。另一个例子是，一个架构中缓存的文件是静态、不应回收的。（这可能跟应用对于数据延迟的需求有关——对于大数据集来说，某些数据段需要被快速访问——这时应用的业务逻辑会比缓存更懂得回收策略或热点处理。） 分布式缓存 在一个分布式缓存中，每个节点拥有部分缓存的数据，如果将杂货店里的冰箱比作一个缓存，那么一个分布式缓存好比是将你的食物放在几个不同的地方——你的冰箱、食物柜、午餐饭盒里——非常便于取到快餐的地方而无需跑一趟商店。通常这类缓存使用 一致性Hash算法进行切分，这样一个请求节点在查询指定数据时，可以很快知道去哪里查询 ，并通过分布式缓存来判断数据可用性。这种场景下，每个节点都会拥有一部分缓存，并且会将请求传递到其他节点来获取数据，最后才到原始地方查询数据。因此，分布式缓存的一个优势就是通过往请求池里增加节点来扩大缓存空间。 分布式缓存的一个缺点在于节点丢失纠正问题。一些分布式缓存通过将复制数据多份存放在不同的节点来解决这个问题；但是，你可以想象到这样做会让逻辑迅速变得复杂，特别是当你向请求层增加或减少节点的时候。虽然一个节点丢失并且缓存失效，但请求仍然可以从源头来获取（数据）——所以这不一定是最悲剧的。 图1.8 分布式缓存 缓存是以需要维护更多存储空间为代价的，特别是昂贵的内存方式；天下没有免费的午餐。缓存让事情变得更快，同时还保证了高负载条件下系统的功能，否则系统服务可能早已降级。 一个非常受欢迎的开源缓存叫做Memcached（既可以是本地又可以是分布式缓存）。它简单来说就是一个内存key-value存储，对任意数据存储和快速查找做了优化（时间复杂度O(1)）。 Facebook使用了若干种不同类型的缓存以达到他们网站的性能要求（Facebook caching and performance）。他们在语言层面使用$GLOBALS和APC缓存（在PHP中提供的函数调用）使得中间功能调用和结果更快。Facebook使用一种全局缓存，分布在多台服务器上（Scaling memcached at Facebook），这样一个访问缓存的函数调用就会产生很多并行请求来从Memcached服务器集群获取数据。这使得他们能够在用户概况数据上获得更高的性能和吞吐量，并且有一个集中的地方去更新数据。 现在让我们来聊聊当数据不存在于缓存的时候应该做什么。 1.3.2. 代理 从基本层面来看，代理服务器是硬件/软件的一个中间层，用于接收从客户端发起的请求并传递到后端服务器。通常来说，代理是用来 过滤请求、记录请求日志或者有时对请求进行转换（增加/去除头文件，加密/解密或者进行压缩） 。 代理同样能够极大帮助协调多个服务器的请求，有机会从系统的角度来优化请求流量。使用代理来加快数据访问速度的方式之一是 将多个同种请求集中放到一个请求中，然后将单个结果返回到请求客户端。这就叫做压缩转发(collapsed forwarding) 假设在几个节点上存在对同样数据的请求（我们叫它littleB），并且这份数据不在缓存里。如果请求通过代理路由，那么这些请求可以被压缩为一个，就意味着我们只需要从磁盘读取一次littleB即可。这种设计是会带来一定的开销，因为跟不用代理相比每个请求都会产生更高的延迟，并且一些请求会因为要与相同请求合并而产生一些延迟。但这种做法在高负载的情况下提高系统性能，特别是当相同的数据重复被请求。这很像缓存，但不用像缓存那样存储数据/文件，而是优化了对那些文件的请求或调用，并且充当那些客户端的代理。 例如，在局域网（LAN）代理中，客户端不需有自己的IP来连接互联网，而局域网会将对同样内容的客户端请求进行压缩。这里可能很容易产生困惑，因为许多代理同样也是缓存（因为在这里放一个缓存很合理），但不是所有缓存都能充当代理。 图1.14：使用一个代理服务器来压缩请求 另一个使用代理的好方法是，可以用来压缩对那些在原始存储中空间上紧密联系的数据（磁盘连续块）的请求。例如，我们假设一群节点请求B的部分数据：B1、B2。我们可以对代理进行设置使其能够识别出不同请求的空间局部性，将它们压缩为单个请求并且只返回bigB，最小化对原始数据的读取操作。当你随机访问TB级的数据时，这样会大幅降低请求时间。在高负载情况下或者当你只有有限的缓存，代理是非常有帮助的，因为代理可以从根本上将若干个请求合并为一个。 图1.11：使用代理压缩空间上邻近的数据请求 你完全可以一并使用代理和缓存，但通常 最好将缓存放在代理之前使用 。这是因为缓存通过内存来提供数据非常快速，并且它也不关心多个对同样结果的请求。但如果缓存被放在代理服务器的后面，那在每个请求访问缓存前就会有额外的延迟，这会阻碍系统性能。 如果你在寻找一款代理想要加入到你的系统中，那有很多选择可供考虑；Squid和Varnish都是经过路演并广泛应用于很多网站的生产环境中。这些代理方案做了很多优化来充分使用客户端与服务端的通信。安装其中之一并在web服务器层将其作为一个反向代理（将在下面的负载均衡小节解释）可以提高web服务器性能，降低处理来自客户端的请求所消耗的工作量。 1.3.3. 索引 使用索引来加快访问数据已经是优化数据访问性能众所周知的策略。索引是以增加存储开销和减慢写入速度（因为你必须同时写入数据并更新索引）的代价来得到更快读取的好处。 就像对于传统的关系数据库，你同样可以将这种概念应用到大数据集上。索引的诀窍在于你必须仔细考虑你的用户会如何使用你的数据。对于TB级但单项数据比较小比如1KB的数据集，索引是优化数据访问非常必要的方式。在一个大数据集中寻找一个小单元是非常困难的，因为你不可能在一个可接受的时间里遍历这么大的数据。并且，像这么一个大数据集很有可能是分布在几个物理设备上——这就意味着你需要有方法能够找到所要数据正确的物理位置。索引是达到这个的最好方法。 图1.12：索引 假设你在寻找B的part2数据——你将如何知道到哪去找到它？如果你有一个按照数据类型（如A,B,C）排序好的索引，它会告诉你数据B在哪里。然后你查找到位置，然后读取你所要的部分。 这些索引通常存放在内存中，或者在更靠近客户端请求的地方。伯克利数据库（BDBs）和树形数据结构经常用来有序地存储数据，非常适合通过索引来访问。 索引经常会有很多层，类似一个map，将你从一个地方引导至另一个，以此类推，直到你获取到你所要的那份数据。 图1.13：多层索引 索引也可以用来对同样的数据创建出一些不同的视图。对于大数据集来说，通过定义不同的过滤器和排序是一个很好的方式，而不需要创建很多额外数据拷贝。 在大型可伸缩的系统中，即使索引已被压缩但仍会变得很大，不易存储。在这个系统里，我们假设世界上有很多书——100,000,000本——并且每本书仅有10页（为了便于计算），每页有250个单词，这就意味着一共有2500亿个单词。如果我们假设平均每个单词有5个字符，每个字符占用8个比特，每个单词5个字节，那么对于仅包含每个单词的索引的大小就达到TB级。所以你会发现创建像一些如词组、数据位置、出现次数之类的其他信息的索引将会增长得更快。 创建这些中间索引并且以更小的方式表达数据，将大数据的问题变得易于处理。数据可以分布在多台服务器但仍可以快速访问。索引是信息获取的基石，也是当今现代搜索引擎的基础。 1.3.4. 负载均衡 用于将负载分摊在一些列负责服务请求的节点上。这使得一个系统的多个节点能够为相同功能提供服务。它们主要目的是处理许多同时进行的连接并将这些连接路由到其中的一个请求节点上，使得系统能够可伸缩地通过增加节点来服务更多请求。 图1.14 负载均衡器 有很多不同的用于服务请求的算法，包括随机挑选一个节点、循环或给予某些标准如内存/CPU使用率选取节点。一个广泛使用的开源软件级负载均衡器是HAProxy。 在一个分布式系统中，负责均衡器通常是放置在系统很前端的地方，这样就能路由所有进入系统的请求。在一个复杂的分布式系统中，一个请求被多个负载均衡器路由也是可能的。 图1.15：多重负责均衡器 如同代理一般，一些负载均衡器也能根据不同类型的请求进行路由。（从技术上来说，就是所谓的反向代理。） 负载均衡器的挑战之一在于如何管理用户session数据。在一个电子商务网站，当你只有一个客户端时很容易让用户把东西放到他们的购物车并且在不同的访问间保存（这是很重要的，因为当用户回来时很有可能买放在购物车里的产品）。但是，如果一个用户先被路由到一个session节点，然后在他们下次访问时路由到另一个不同的节点，那将会因为新节点可能丢失用户购物车里的东西而产生不一致。解决办法之一通过粘性session机制总是将用户路由到同一节点，但这样既很难享受到一些像自动failover的可靠机制了。 上段中提到的用户session问题，实际上在很多大型网站如淘宝、支付宝，都是通过一个分布式session的中间件来解决的。原理其实很简单，比如用户登录了支付宝，那么系统会给当前用户分配一个全局唯一的sessionId并写入到浏览器的cookie中，在后台服务端也会有专门的一个分布式存储以sessionId为key开辟一个空间存放该用户session数据。虽然应用都是集群部署方式，但每个无状态应用节点都会统一连接到该分布式存储。由于用户session数据是统一保存在分布式存储上，即对session数据的存取都是发生在同一个地方，而非各个节点内部，所以不会因为不同的请求路由到不同的应用节点上导致session数据不一致的情况。同时，这一方法不会像sticky session机制那样限制了系统的可伸缩性。如果出现session存取的性能问题，那只需通过扩展后端分布式存储即可解决。 如果系统只是由少数节点构成的，那么像Round Robin DNS那样的系统就更加明智，因为负责均衡器很贵而且增加了一层不必要的复杂度。当然在大型系统里有各种各样的调度和负载均衡算法，包括简单的像随机选择或循环方式，还有更加复杂的机制如考虑系统使用率和容量的。所有这些算法都分布化了流量和请求，并且提供像自动failover或者自动去除坏节点，这类对可靠性非常有帮助的工具。但是，这些先进特性也会使得问题诊断变得复杂化。比如，在一个高负载情况下，负载均衡器会去除掉那些变慢或者超时（由于请求过多）的节点，但这样反而加重了其他节点的恶劣处境。在这些情况下，全面监控变得很重要，因为从全局来看系统的流量和吞吐量正在下降（由于各节点服务请求越来越少），但从节点个体来看正在达到极限。 负载均衡器是一个非常简单能让你提高系统容量的方法，还能用来判断一个节点的健康度，这样当一个节点失去响应或者过载时，得益于系统不同节点的冗余性，可以将其从请求处理池中去除。 1.3.5. 队列 另一个扩展数据层的重要部分是有效管理写入操作。当系统比较简单，系统处理负载很低，数据库也很小，可以预见写入操作是很快的；但是，在更加复杂的系统中，写入操作的时间可能无法确定。例如，数据需要被写入到不同服务器或索引的多个地方，或者系统负载很高。这些情况下，写操作或者任何任务都会花费很长的时间，这时需要异步化系统才能提高系统的性能和可靠性；通常的方法之一是使用队列。 在小型系统中，一台服务器可以尽快地处理客户端请求。但是，当服务器接收到超过其处理能力的请求时，那每个客户端都只能被迫等待其他客户端请求完成才能得到响应。这种同步的方式将会严重降低客户端性能，客户端被强制等待。增加额外的服务器并不能解决这个问题；即使通过有效的负载均衡，依然难以保证最大化客户端性能所需做的公平分配的工作。 图1.16：同步化请求 使用队列，当前有能力处理任务的worker去取下一个任务来做。这些任务可以是对数据库的写入操作，或是复杂一些的如生成文件的小型预览图。当一个客户端将任务的请求提交到队列后，它们不再需要被迫等待结果；取而代之的是，它们只需要确认请求被得到正确接收。 图1.17：使用队列来管理请求 队列使得客户端能够以异步的方式进行工作。另一方面，一个同步化系统不会区分请求和响应，因此就无法分开管理。在一个异步化系统里，客户端提交任务请求，后端服务反馈一个收到任务的确认信息，并且客户端可以定期地查看任务的状态，一旦完成即可取得任务结果。在客户端等待一个异步请求完成时，它可以自由地处理其他的工作，即使是发起对其他服务的异步请求。 队列还能提供对服务断供/失败的保护措施。比如，很容易创建一个健壮的队列来重试那些由于服务器短暂失败的服务请求。更好的是通过使用队列来确保服务品质，而非将客户端直接面对断断续续的服务，因为那样会需要客户端复杂且经常不一致的错误处理。 队列是管理大型可伸缩分布式应用不同部分间通信的基础，可以通过很多方式来实现。有一些开源的队列如RabbitMQ, ActiveMQ, BeanstalkD，也有一些使用像Zookeeper的服务，还有像Redis那样的数据存储。 正如大家所知的双十一、双十二，这两天用户的请求可谓超级海量。拿支付宝来说，核心系统如支付、账务，即使使用了很多技术方案来确保高性能、高可用，但面对数倍于平时的请求量依然捉急。在开发了一套分布式队列基础中间件后，网站的吞吐量、可用性得到了很大的提高。同时，对于队列来说，除了将客户端请求与服务端处理分离外，通过对队列加上额外的一些特性，能够起到非常大的作用。比如，在队列上加入限流特性，当请求量大大超过后端服务处理能力时，可以采取丢弃请求的方式来保证系统、队列不至于被海量请求压垮；当请求量回到一定水平，再将限流放开。这种做法，正好满足了系统对可用性、性能、可伸缩性、可管理性的要求。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/大型网站架构.html":{"url":"Interview/大型网站架构/大型网站架构.html","title":"大型网站架构","keywords":"","body":"1. 大型分布式网站架构技术总结1. 大型分布式网站架构技术总结 http://www.10tiao.com/html/357/201701/2247484785/1.html 一、特点 用户多，分布广泛 大流量，高并发 海量数据，服务高可用 安全环境恶劣，易受网络攻击 功能多，变更快，频繁发布 从小到大，渐进发展 以用户为中心 免费服务，付费体验 二、架构目标 高性能：提供快速的访问体验。 高可用：网站服务一直可以正常访问。 可伸缩：通过硬件增加/减少，提高/降低处理能力。 安全性：提供网站安全访问和数据加密，安全存储等策略。 扩展性：方便的通过新增/移除方式，增加/减少新的功能/模块。 敏捷性：随需应变，快速响应 三、架构模式 分层：一般可分为，应用层，服务层，数据层，管理层，分析层； 分割：一般按照业务/模块/功能特点进行划分，比如应用层分为首页，用户中心。 分布式：将应用分开部署（比如多台物理机），通过远程调用协同工作。 集群：一个应用/模块/功能部署多份（如：多台物理机），通过负载均衡共同提供对外访问。 缓存：将数据放在距离应用或用户最近的位置，加快访问速度。 异步：将同步的操作异步化。客户端发出请求，不等待服务端响应，等服务端处理完毕后，使用通知或轮询的方式告知请求方。一般指：请求——响应——通知 模式。 冗余：增加副本，提高可用性，安全性，性能。 安全：对已知问题有有效的解决方案，对未知/潜在问题建立发现和防御机制。 自动化：将重复的，不需要人工参与的事情，通过工具的方式，使用机器完成。 敏捷性：积极接受需求变更，快速响应业务发展需求。 四、高性能架构 以用户为中心，提供快速的网页访问体验。主要参数有较短的响应时间，较大的并发处理能力，较高的吞吐量，稳定的性能参数。 可分为前端优化，应用层优化，代码层优化，存储层优化。 前端优化：网站业务逻辑之前的部分； 浏览器优化：减少Http请求数，使用浏览器缓存，启用压缩，Css Js位置，Js异步，减少Cookie传输； CDN加速，反向代理； 应用层优化：处理网站业务的服务器。使用缓存，异步，集群 代码优化：合理的架构，多线程，资源复用（对象池，线程池等），良好的数据结构，JVM调优，单例，Cache等； 存储优化：缓存，固态硬盘，光纤传输，优化读写，磁盘冗余，分布式存储（HDFS），NOSQL等； 五、高可用架构 大型网站应该在任何时候都可以正常访问。正常提供对外服务。因为大型网站的复杂性，分布式，廉价服务器，开源数据库，操作系统等特点。要保证高可用是很困难的，也就是说网站的故障是不可避免的。 如何提高可用性，就是需要迫切解决的问题。首先，需要从架构级别，在规划的时候，就考虑可用性。行业内一般用几个9表示可用性指标。比如四个9（99.99），一年内允许的不可用时间是53分钟。 不同层级使用的策略不同，一般采用冗余备份和失效转移解决高可用问题。 应用层：一般设计为无状态的，对于每次请求，使用哪一台服务器处理是没有影响的。一般使用负载均衡技术（需要解决Session同步问题），实现高可用。 服务层：负载均衡，分级管理，快速失败（超时设置），异步调用，服务降级，幂等设计等。 数据层：冗余备份（冷，热备[同步，异步]，温备），失效转移（确认，转移，恢复）。数据高可用方面著名的理论基础是CAP理论（持久性，可用性，数据一致性[强一致，用户一致，最终一致]） 六、可伸缩架构 伸缩性是指在不改变原有架构设计的基础上，通过添加/减少硬件（服务器）的方式，提高/降低系统的处理能力。 应用层：对应用进行垂直或水平切分。然后针对单一功能进行负载均衡（DNS,HTTP[反向代理],IP,链路层）。 服务层：与应用层类似； 数据层：分库，分表，NOSQL等；常用算法Hash，一致性Hash。 七、可扩展架构 可以方便的进行功能模块的新增/移除，提供代码/模块级别良好的可扩展性。 模块化，组件化：高内聚，内耦合，提高复用性，扩展性。 稳定接口：定义稳定的接口，在接口不变的情况下，内部结构可以“随意”变化。 设计模式：应用面向对象思想，原则，使用设计模式，进行代码层面的设计。 消息队列：模块化的系统，通过消息队列进行交互，使模块之间的依赖解耦。 分布式服务：公用模块服务化，提供其他系统使用，提高可重用性，扩展性。 八、安全架构 对已知问题有有效的解决方案，对未知/潜在问题建立发现和防御机制。对于安全问题，首先要提高安全意识，建立一个安全的有效机制，从政策层面，组织层面进行保障。比如服务器密码不能泄露，密码每月更新，并且三次内不能重复；每周安全扫描等。以制度化的方式，加强安全体系的建设。同时，需要注意与安全有关的各个环节。安全问题不容忽视。包括基础设施安全，应用系统安全，数据保密安全等。 基础设施安全：硬件采购，操作系统，网络环境方面的安全。一般采用，正规渠道购买高质量的产品，选择安全的操作系统，及时修补漏洞，安装杀毒软件防火墙。防范病毒，后门。设置防火墙策略，建立DDOS防御系统，使用攻击检测系统，进行子网隔离等手段。 应用系统安全：在程序开发时，对已知常用问题，使用正确的方式，在代码层面解决掉。防止跨站脚本攻击（XSS），注入攻击，跨站请求伪造（CSRF），错误信息，HTML注释，文件上传，路径遍历等。还可以使用Web应用防火墙（比如：ModSecurity），进行安全漏洞扫描等措施，加强应用级别的安全。 数据保密安全：存储安全（存在在可靠的设备，实时，定时备份），保存安全（重要的信息加密保存，选择合适的人员复杂保存和检测等），传输安全（防止数据窃取和数据篡改）； 常用的加解密算法（单项散列加密[MD5,SHA]，对称加密[DES,3DES,RC]），非对称加密[RSA]等。 九、敏捷性 网站的架构设计，运维管理要适应变化，提供高伸缩性，高扩展性。方便的应对快速的业务发展，突增高流量访问等要求。 除上面介绍的架构要素外，还需要引入敏捷管理，敏捷开发的思想。使业务，产品，技术，运维统一起来，随需应变，快速响应。 十、大型架构举例 以上采用七层逻辑架构，第一层客户层，第二层前端优化层，第三层应用层，第四层服务层，第五层数据存储层，第六层大数据存储层，第七层大数据处理层。 客户层：支持PC浏览器和手机APP。差别是手机APP可以直接访问通过IP访问，反向代理服务器。 前端层：使用DNS负载均衡，CDN本地加速以及反向代理服务； 应用层：网站应用集群；按照业务进行垂直拆分，比如商品应用，会员中心等； 服务层：提供公用服务，比如用户服务，订单服务，支付服务等； 数据层：支持关系型数据库集群（支持读写分离），NOSQL集群，分布式文件系统集群；以及分布式Cache； 大数据存储层：支持应用层和服务层的日志数据收集，关系数据库和NOSQL数据库的结构化和半结构化数据收集； 大数据处理层：通过Mapreduce进行离线数据分析或Storm实时数据分析，并将处理后的数据存入关系型数据库。（实际使用中，离线数据和实时数据会按照业务要求进行分类处理，并存入不同的数据库中，供应用层或服务层使用）。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/读写锁分离-封装ReaderWriterLockSlim.html":{"url":"Interview/大型网站架构/读写锁分离-封装ReaderWriterLockSlim.html","title":"读写锁分离-封装ReaderWriterLockSlim","keywords":"","body":"1. 读写锁分离－－封装ReaderWriterLockSlim1.1. ReaderWriterLockSlim 类1.2. 主要属性,方法1.3. 应用1.4. 封装1.5. 使用场合1.6. 使用详细说明1.7. 对比无lock1.8. 对比原始单一lock1.9. Code平台下载1. 读写锁分离－－封装ReaderWriterLockSlim 1.1. ReaderWriterLockSlim 类 表示用于管理资源访问的锁定状态，可实现多线程读取或进行独占式写入访问。 使用 ReaderWriterLockSlim 来保护由多个线程读取但每次只采用一个线程写入的资源。 ReaderWriterLockSlim 允许多个线程均处于读取模式，允许一个线程处于写入模式并独占锁定状态，同时还允许一个具有读取权限的线程处于可升级的读取模式，在此模式下线程无需放弃对资源的读取权限即可升级为写入模式。 注意 ReaderWriterLockSlim 类似于 ReaderWriterLock，只是简化了递归、升级和降级锁定状态的规则。 ReaderWriterLockSlim 可避免多种潜在的死锁情况。 此外，ReaderWriterLockSlim 的性能明显优于 ReaderWriterLock。 建议在所有新的开发工作中使用 ReaderWriterLockSlim。 1.2. 主要属性,方法 属性: IsReadLockHeld 　　获取一个值，该值指示当前线程是否已进入读取模式的锁定状态。 IsWriteLockHeld 　 获取一个值，该值指示当前线程是否已进入写入模式的锁定状态。 方法: EnterReadLock 尝试进入读取模式锁定状态。 ExitReadLock 减少读取模式的递归计数，并在生成的计数为 0（零）时退出读取模式。 EnterWriteLock 尝试进入写入模式锁定状态。 ExitWriteLock 减少写入模式的递归计数，并在生成的计数为 0（零）时退出写入模式。 当然还有其他很多方法,比如EnterUpgradeableReadLock.aspx)进入可以升级到写入模式的读取模式.. 1.3. 应用 来对比一个老式的lock写法 private object _Lock = new object(); private void Read() { lock (_Lock) { //具体方法实现 } } 读写锁分离 private ReaderWriterLockSlim _LockSlim = new ReaderWriterLockSlim(); private void Read() { try { _LockSlim.EnterReadLock(); //具体方法实现 } finally { _LockSlim.ExitReadLock(); } } private void Write() { try { _LockSlim.EnterWriteLock(); //具体方法实现 } finally { _LockSlim.ExitWriteLock(); } } 看上下2种写法: 从性能的角度来说,肯定是读写锁分离更好了，特别是大多数场合(读取操作远远多余写入操作) 从可读性和代码美观度来说，就是上面的lock要简洁的多了，维护起来也更清晰 所以我希望重新封装ReaderWriterLockSlim，当然我第一想到的就是利用using语法糖的特性封装一个新的对象 1.4. 封装 Code平台: UsingLock 由于是利用的using的语法,所以我直接取名叫UsingLock，简单好记 using System; using System.Threading; namespace blqw { /// 使用using代替lock操作的对象,可指定写入和读取锁定模式 /// public class UsingLock { #region 内部类 /// 利用IDisposable的using语法糖方便的释放锁定操作 /// 内部类 /// private struct Lock : IDisposable { /// 读写锁对象 /// private ReaderWriterLockSlim _Lock; /// 是否为写入模式 /// private bool _IsWrite; /// 利用IDisposable的using语法糖方便的释放锁定操作 /// 构造函数 /// /// 读写锁 /// 写入模式为true,读取模式为false public Lock(ReaderWriterLockSlim rwl, bool isWrite) { _Lock = rwl; _IsWrite = isWrite; } /// 释放对象时退出指定锁定模式 /// public void Dispose() { if (_IsWrite) { if (_Lock.IsWriteLockHeld) { _Lock.ExitWriteLock(); } } else { if (_Lock.IsReadLockHeld) { _Lock.ExitReadLock(); } } } } /// 空的可释放对象,免去了调用时需要判断是否为null的问题 /// 内部类 /// private class Disposable : IDisposable { /// 空的可释放对象 /// public static readonly Disposable Empty = new Disposable(); /// 空的释放方法 /// public void Dispose() { } } #endregion /// 读写锁 /// private ReaderWriterLockSlim _LockSlim = new ReaderWriterLockSlim(); /// 保存数据 /// private T _Data; /// 使用using代替lock操作的对象,可指定写入和读取锁定模式 /// 构造函数 /// public UsingLock() { Enabled = true; } /// 使用using代替lock操作的对象,可指定写入和读取锁定模式 /// 构造函数 /// 为Data属性设置初始值 public UsingLock(T data) { Enabled = true; _Data = data; } /// 获取或设置当前对象中保存数据的值 /// /// 获取数据时未进入读取或写入锁定模式 /// 设置数据时未进入写入锁定模式 public T Data { get { if (_LockSlim.IsReadLockHeld || _LockSlim.IsWriteLockHeld) { return _Data; } throw new MemberAccessException(\"请先进入读取或写入锁定模式再进行操作\"); } set { if (_LockSlim.IsWriteLockHeld == false) { throw new MemberAccessException(\"只有写入模式中才能改变Data的值\"); } _Data = value; } } /// 是否启用,当该值为false时,Read()和Write()方法将返回 Disposable.Empty /// public bool Enabled { get; set; } /// 进入读取锁定模式,该模式下允许多个读操作同时进行 /// 退出读锁请将返回对象释放,建议使用using语块 /// Enabled为false时,返回Disposable.Empty; /// 在读取或写入锁定模式下重复执行,返回Disposable.Empty; /// public IDisposable Read() { if (Enabled == false || _LockSlim.IsReadLockHeld || _LockSlim.IsWriteLockHeld) { return Disposable.Empty; } else { _LockSlim.EnterReadLock(); return new Lock(_LockSlim, false); } } /// 进入写入锁定模式,该模式下只允许同时执行一个读操作 /// 退出读锁请将返回对象释放,建议使用using语块 /// Enabled为false时,返回Disposable.Empty; /// 在写入锁定模式下重复执行,返回Disposable.Empty; /// /// 读取模式下不能进入写入锁定状态 public IDisposable Write() { if (Enabled == false || _LockSlim.IsWriteLockHeld) { return Disposable.Empty; } else if (_LockSlim.IsReadLockHeld) { throw new NotImplementedException(\"读取模式下不能进入写入锁定状态\"); } else { _LockSlim.EnterWriteLock(); return new Lock(_LockSlim, true); } } } } 方法: Read() 进入读取锁定模式 Write() 进入写入锁定模式 属性： Data UsingLock中可以保存一个数据，由当前线程中的环境判断是否可以读取或设置该对象 Enabled 是否启用当前组件..这个有妙用，下面介绍 1.5. 使用场合 /// 假设有这样一个队列系统 /// class MyQueue:IEnumerable { List _List; UsingLock _Lock; public MyQueue(IEnumerable strings) { _List = new List(strings); _Lock = new UsingLock(); } /// 获取第一个元素.并且从集合中删除 /// public string LootFirst() { using (_Lock.Write()) { if (_List.Count == 0) { _Lock.Enabled = false; return null; } var s = _List[0]; _List.RemoveAt(0); return s; } } public int Count { get { return _List.Count; } } /// 枚举当前集合的元素 /// public IEnumerator GetEnumerator() { using (_Lock.Read()) { foreach (var item in _List) { yield return item; } } } System.Collections.IEnumerator System.Collections.IEnumerable.GetEnumerator() { return GetEnumerator(); } } 我这里假设了一个队列系统，把最容易出现问题的修改集合和枚举集合2个操作公开出来，方便在多线程中测试效果 以下为测试代码: static void Main(string[] args) { //建立一个字符串集合,总数为1000 List list = new List(1000); for (int i = 0; i { Console.WriteLine(mq.LootFirst()); }); } //在主线程中不停调用mq的遍历方法,这样的操作是很容易出现线程争抢资源的,如果没有锁定访问机制,就会出现异常 while (mq.Count > 0) { foreach (var item in mq) { //如果最后一个值还在,就输出 \"还在\" if (item == last) { Console.WriteLine(\"还在\"); } } } } 测试结果 Release模式下也是很轻松就跑完了,证明访问的同步控制部分是可以正常工作的 1.6. 使用详细说明 语法上是不是跟lock比较类似了?Enabled属性的作用在这里就可见一斑了 这部分比较简单,就不多说了..... 1.7. 对比无lock 当然写完可以用,还需要和原始的方式比较一下,不然不知道优劣 对比无lock模式 将using代码注释,果然出现了异常 1.8. 对比原始单一lock 对比原始lock模式,这次需要加上时间 UsingLock VS 单一lock 1.9. Code平台下载 https://code.csdn.net/snippets/112634 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/负载均衡方法和分布式缓存.html":{"url":"Interview/大型网站架构/负载均衡方法和分布式缓存.html","title":"负载均衡方法和分布式缓存","keywords":"","body":"1. 一、网站架构的伸缩性设计1.1. 1.1 不同功能进行物理分离实现伸缩1.2. 1.2 单一功通过集群规模实现伸缩2. 二、应用服务器集群的伸缩性设计2.1. 2.1 应用服务器2.2. 2.2 负载均衡技术—网站必不可少的基础技术手段2.3. 2.3 负载均衡算法—负载均衡技术赖以生存的核心3. 三、分布式缓存集群的伸缩性设计4. 四、数据存储服务器集群的伸缩性设计5. 本章思维导图1. 一、网站架构的伸缩性设计 首先，所谓网站的伸缩性，指不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或者缩小网站的服务处理能力。在整个互联网行业的发展渐进演化中，最重要的技术就是服务器集群，通过不断地向集群中添加服务器来增强整个集群的处理能力。 1.1. 1.1 不同功能进行物理分离实现伸缩 　　（1）纵向分离：将业务处理流程上得不同部分分离部署，实现系统的伸缩性； 　　（2）横向分离：将不同的业务模块分离部署，实现系统的伸缩性； 1.2. 1.2 单一功通过集群规模实现伸缩 　　使用服务器集群，即将相同服务部署在多台服务器上构成一个集群整体对外提供服务。具体来说，集群伸缩性又分为应用服务器集群伸缩性和数据服务器集群伸缩性。这两种集群对于数据状态管理的不同，技术实现也有很大的区别。 2. 二、应用服务器集群的伸缩性设计 2.1. 2.1 应用服务器 　　（1）应用服务器应该被设计成无状态的，即应用服务器不存储请求上下文信息；构建集群后，每次用户的请求都可以发到集群中任意一台服务器上处理，任何一台服务器的处理结果都是相同的； 　　（2）HTTP本身是一个无状态的连接协议，为了支持客户端与服务器之间的交互，我们就需要通过不同的技术为交互存储状态，而这些不同的技术就是Cookie和Session了。 　　（3）HTTP请求的分发是应用服务器集群实现伸缩性的核心问题，而负载均衡服务器就是HTTP请求的分发装置，它是网站必不可少的基础手段，也被称为网站的杀手锏之一。 2.2. 2.2 负载均衡技术—网站必不可少的基础技术手段 　　负载均衡的实现方式多种多样，从硬件到软件，从商业产品到开源产品，应有尽有。但是，实现负载均衡的基础技术不外乎以下几种： 　　（1）HTTP重定向负载均衡　　评价：★★ 　　此方案的优点是简单易行，通过检测离用户较近的服务器，重定向到该服务器，缺点是： 　　①浏览器需要两次请求才能完成一次访问，性能较差； 　　②重定向服务器自身的处理能力有可能成为瓶颈，整个集群的伸缩性规模有限； 　　③使用HTTP 302重定向有可能使搜索引擎判断为SEO作弊，降低搜索排名； 　　（2）DNS域名解析负载均衡　　评价：★★★ 　　此方案要求在DNS服务器中配置多个A记录，例如： www.mysite.com IN A 114.100.80.1 www.mysite.com IN A 114.100.80.2 www.mysite.com IN A 114.100.80.3 　　此方案的优点是将负载均衡的工作转交给了DNS，省掉了网站管理维护负载均衡服务器的麻烦。而缺点是： 　　①目前的DNS是多级解析，每一级DNS都可能缓存A记录，当某台服务器下线后，即使修改了DNS的A记录，要使其生效仍然需要较长时间。这段期间，会导致用户访问已经下线的服务器造成访问失败。 　　②DNS负载均衡的控制权在域名服务商那里，网站无法对其做更多改善和管理； TIPS：事实上，大型网站总是部分使用DNS域名解析，利用域名解析作为第一级负载均衡手段，即域名解析得到的一组服务器不是实际的Web服务器，而是同样提供负载均衡的内部服务器，这组内部服务器再进行负载均衡，请求分发到真实的Web服务器上。 　　（3）反向代理负载均衡　　评价：★★★★ 　　Web服务器不需要使用外部IP地址，而反向代理服务器则需要配置双网卡和内外部两套IP地址。 　　此方案的优点是和反向代理服务器功能集成在一起，部署简单。缺点是反向代理服务器是所有请求和响应的中转站，其性能可能会成为瓶颈。 　　（4）IP负载均衡　　评价：★★★★ 　　此方案优点在于在内核进程完成数据分发，较反向代理负载均衡（在应用程序中分发数据）有更好的处理性能。缺点是由于所有请求响应都需要经过负载均衡服务器，集群的最大响应数据吞吐量不得不受制于负载均衡服务器网卡带宽。需要 ip 转换 　　（5）数据链路层负载均衡　　评价：★★★★★ 　　此种方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改mac地址，由于实际处理请求的真实物理IP地址和数据请求目的IP地址一致，所以不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。这种负载均衡方式又称作直接路由方式（DR）。 　　使用三角传输模式的链路层负载均衡是目前大型网站使用最广泛的一种负载均衡手段。在Linux平台上最好的链路层负载均衡开源产品是LVS（Linux Virutal Server）。 2.3. 2.3 负载均衡算法—负载均衡技术赖以生存的核心 　　前面的方法解决了负载均衡通过何种方式实现，而更为重要的则是如何从Web服务器列表中计算得到一台Web服务器的地址，而这正是负载均衡的核心—算法。这里简单介绍一下通常的集中负载均衡计算的算法，如果需要深入了解请自行百度。 　　（1）轮询 　　所有请求被以此分发到每台应用服务器上，即每台服务器需要处理的请求数目都相同，适合于所有服务器硬件都相同的场景。 　　（2）加权轮询 　　根据应用服务器的配置性能的情况，在轮询的基础上，按照配置的权重将请求分发到每个服务器，高性能的服务器能分配更多的请求。 　　（3）随机 　　此算法比较简单实用，请求被随机分配到各个应用服务器，因为好的随机数本身就很均衡。 　　（4）最少连接 　　记录每个应用服务器正在处理的连接数（请求数），将新到的请求分发到最少连接的服务器上，应该说，这是最符合负载均衡定义的算法。 　　（5）源地址散列 　　根据请求来源的IP地址进行Hash计算得到应用服务器，这样来自同一个IP地址的请求总在同一个服务器上处理，该请求的上下文信息可以存储在这台服务器上，在一个会话周期内重复使用，从而实现会话粘滞。 3. 三、分布式缓存集群的伸缩性设计 　　不同于应用服务器集群的伸缩性设计，分布式缓存集群的伸缩性不能使用简单的负载均衡手段来实现。因为：分布式缓存服务器集群中缓存的数据各不相同，缓存访问请求不可以在缓存服务器集群中的任意一台处理，必须先找到缓存有需要的数据的服务器，然后才能访问。 　　分布式缓存集群伸缩性设计的目标：让新上线的缓存服务器对整个分布式缓存集群影响最小，也就是说新加入缓存服务器后应使整个缓存服务器集群中已经缓存的数据尽可能还被访问到。 （1）以Memcached为代表的分布式缓存集群的访问模型 　　以上图片展示了一个典型的缓存写操作，应用程序需要写缓存数据，API将KEY（'CHENGDU'）输入路由算法模块，路由算法根据KEY和Memcached服务器集群列表计算得到一台服务器编号（如Node1），进而得到该机器的IP地址和端口（10.0.0.1:91000）。然后，API调用通信模块和编号为Node1的Memcached服务器进行通信，将数据写入该服务器，至此便完成了一次分布式缓存的写操作。 　　而读操作和写操作一样，使用同样的路由算法和服务器列表，只要提供相同的KEY（如上面提到的'CHENGDU'），Memcached客户端总是访问相通的服务器（如上面计算得到的Node1）去读取数据。 　　（2）以Memcached为代表的分布式缓存集群的伸缩性挑战 　　简单的路由算法（通过使用余数Hash）无法满足业务发展时服务器扩容的需要：缓存命中率下降。例如：当3台服务器扩容至4台时，采用普通的余数Hash算法会导致大约75%（3/4）被缓存了的数据无法正确命中，随着服务器集群规模的增大，这个比例会线性地上升。那么，可以想象，当100台服务器的急群众加入一台服务器，不能命中的概率大概是99%（N/N+1），这个结果显然是无法接受的。 　　那么，能否通过改进路由算法，使得新加入的服务器不影响大部分缓存数据的正确性呢？请看下面的一致性Hash算法。 　　（3）分布式缓存的一致性Hash算法 说明：一致性Hash算法是分布式缓存的核心理论，这里只是简单介绍一下，后续有空我会单独写一篇文章来详细介绍一致性Hash算法，以及用C#实现一致性Hash算法。 　　具体算法过程是： 　　①先构造一个长度为0~2^32 （2的32次幂）个的整数环（又称：一致性Hash环），根据节点名称的Hash值将缓存服务器节点防置在这个Hash环中，如上图中的node1，node2等； 　　②根据需要缓存的数据的KEY值计算得到其Hash值，如上图中右半部分的“键”，计算其Hash值后离node2很近； 　　③在Hash环上顺时针查找距离这个KEY的Hash值最近的缓存服务器节点，完成KEY到服务器的Hash映射查找，如上图中离右边这个键的Hash值最近的顺时针方向的服务器节点是node2，因此这个KEY会到node2中读取数据； 　　当缓存服务器集群需要扩容的时候，只需要将新加入的节点名称（如node5）的Hash值放入一致性Hash环中，由于KEY总是顺时针查找距离其最近的节点，因此新加入的节点只影响整个环中的一部分。如下图中所示，添加node5后，只影响右边逆时针方向的三个Key/Value对数据，只占整个Hash环中的一小部分。 　　因此，我们可以与之前的普通余数Hash作对比：采用一直性Hash算法时，当3台服务器扩容到4台时，可以继续命中原有缓存数据的概率为75%，远高于普通余数Hash的25%，而且随着集群规模越大，继续命中原有缓存数据的概率也会随之增大。当100台服务器增加1台时，继续命中的概率是99%。虽然，仍有小部分数据缓存在服务器中无法被读取到，但是这个比例足够小，通过访问数据库也不会对数据库造成致命的负载压力。 4. 四、数据存储服务器集群的伸缩性设计 　　首先，数据存储服务器必须保证数据的可靠存储，任何情况下都必须保证数据的可用性和正确性。因此，缓存服务器集群的伸缩性架构方案不能直接适用于数据库等存储服务器。 　　（1）关系数据库集群的伸缩性设计 　　①市场上主要的关系数据库都支持数据复制功能，使用这个功能可以对数据库进行简单伸缩。下图显示了使用数据复制的MySQL集群伸缩性方案：多台MySQL的角色有主从之分，写操作都在主服务器上，由主服务器将数据同步到集群中其他从服务器。而读操作及数据分析等离线操作都会在从服务器上完成。 　　②前面提到的业务分割模式也可以用在数据库，不同业务数据表部署在不同的数据库集群上，这就是所谓的“数据分库”；但是其有一个制约条件：跨库的表无法进行Join操作； 　　③在实际运维中，对一些单表数据仍然很大的表，例如Facebook的用户数据库、淘宝的商品数据库等，还需要进行分片，将一张表拆分开分别存储在多个数据库中，这就是所谓的“数据分片”； 　　（2）NoSQL数据库的伸缩性设计 　　首先，NoSQL主要指非关系的、分布式的数据库设计模式。也有许多专家将NoSQL解读为Not Only SQL，表示NoSQL是关系数据库的补充，而不是替代方案。一般而言，NoSQL数据库产品都放弃了关系数据库的两大重要基础：①以关系代数为基础的结构化查询语言（SQL）②事务的一致性保证（ACID）；与之对应的是强化一些大型网站更关注的特性：高可用性和可伸缩性； 　　开源社区的NoSQL产品不尽其数，其支持的数据结构和伸缩性特性也各不相同。目前看来，应用最广泛的是Apache HBase。HBase的伸缩性主要依赖于其可分裂的HRegion及可伸缩的分布式文件系统HDFS（如果您不知道HDFS又对HDFS有兴趣，可以阅读我的另一篇博文《不怕故障的海量存储—HDFS基础入门》）实现。 　　上图是HBase的整体架构图： 　　①HBase中数据以HRegion为单位进行管理，也就是说应用程序如果想要访问一个数据，必须先找到HRegion，然后将数据读写操作提交给HRegion，由HRegion完成存储层面的数据操作。 　　②每个HRegion中存储一段Key区间（例如：[Key1,Key2)）的数据，HRegionServer是物理服务器，每个HRegionServer上可以启动多个HRegion实例。当一个HRegion中写入的数据太多，达到配置的阀值时，HRegion会分裂成两个HRegion，并将HRegion在整个集群中进行迁移，以使HRegionServer的负载均衡。 　　③所有的HRegion的信息都（例如：存储的Key值区间、所在HRegionServer的IP地址和端口号等）记录在HMaster服务器上。同时为了保证高可用，HBase启动了多个HMaster，并通过ZooKeeper（一个支持分布式一致性的数据管理服务）选举出一个主服务器，通过这个主HMaster服务器获得Key值所在的HRegionServer，最后请求该HRegionServer上的HRegion实例，获得需要的数据。其具体的数据寻址访问流程如下图所示： 5. 本章思维导图 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/大型网站架构/高并发.html":{"url":"Interview/大型网站架构/高并发.html","title":"高并发","keywords":"","body":"1. 如何处理并发和同步1.1. 悲观锁(Pessimistic Locking)1.2. 乐观锁(Optimistic Locking)1.3. 常见并发同步案例分析1.3.1. 案例一：订票系统案例，某航班只有一张机票，假定有1w个人打开你的网站来订票，问你如何解决并发问题(可扩展到任何高并发网站要考虑的并发读写问题)1.3.2. 案例二、股票交易系统、银行系统，大数据量你是如何考虑的1.4. 常见的提高高并发下访问的效率的手段1.5. 总结1.6. 参考1.7. .net 高并发1. 如何处理并发和同步 一种我觉得有点老的方式是通过锁机制。 锁机制有两个层面。一种是代码层次上的，如 java 中的同步锁，典型的就是同步关键字 synchronized。.net lock 另外一种是数据库层次上的，比较典型的就是悲观锁和乐观锁。 1.1. 悲观锁(Pessimistic Locking) 对数据被外界（包括本系统当前的其他事务，以及来自 外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能 真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 一个典型的倚赖数据库的悲观锁调用： select * from account where name=\"Erica\" for update 这条 sql 语句锁定了 account 表中所有符合检索条件（ name=\"Erica\" ）的记录。本次事务提交之前（事务提交时会释放事务过程中的锁），外界无法修改这些记录。 Hibernate 的悲观锁，也是基于数据库的锁机制实现。 下面的代码实现了对查询记录的加锁： String hqlStr = \"from TUser as user where user.name='Erica'\"; Query query = session.createQuery(hqlStr); query.setLockMode(\"user\", LockMode.UPGRADE); // 加锁 List userList = query.list();// 执行查询，获取数据 query.setLockMode 对查询语句中，特定别名所对应的记录进行加锁（我们为 TUser 类指定了一个别名 “user\" ），这里也就是对返回的所有 user 记录进行加锁。 Hibernate 的加锁模式有： LockMode.NONE ： 无锁机制。 LockMode.WRITE ： Hibernate 在 Insert 和 Update 记录的时候会自动获取 LockMode.READ ： Hibernate 在读取记录的时候会自动获取。 以上这三种锁机制一般由 Hibernate 内部使用，如 Hibernate 为了保证 Update 过程中对象不会被外界修改，会在 save 方法实现中自动为目标对象加上 WRITE 锁。 LockMode.UPGRADE ：利用数据库的 for update 子句加锁。 LockMode. UPGRADE_NOWAIT ： Oracle 的特定实现，利用 Oracle 的 for update nowait 子句实现加锁。 上面这两种锁机制是我们在应用层较为常用的，加锁一般通过以下方法实现： Criteria.setLockMode Query.setLockMode Session.lock 只有在查询开始之前（也就是 Hibernate 生成 SQL 之前）设定加锁，才会真正通过数据库的锁机制进行加锁处理，否则，数据已经通过不包含 for update 子句的 Select SQL 加载进来，所谓数据库加锁也就无从谈起。 1.2. 乐观锁(Optimistic Locking) 相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依 靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库 性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。 如一个金融系统，当某个操作员读取用户的数据，并在读出的用户数据的基础上进 行修改时（如更改用户帐户余额），如果采用悲观锁机制，也就意味着整个操作过程中（从操作员读出数据、开始修改直至提交修改结果的全过程，甚至还包括操作员中途去煮咖啡的时间），数据库记录始终处于加锁状态，可以想见，如果面对几百上千个并发，这样的情况将导致怎样的后果。 乐观锁机制在一定程度上解决了这个问题。 乐观锁，大多是基于数据版本 Version 记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version\" 字段来实现。 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 对于上面修改用户帐户信息的例子而言，假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。 在操作员 A 操作的过程中，操作员 B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣 除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数 据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的 数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 提交版本必须大于记录当前版本才能执行更新 的乐观锁策略，因此，操作员 B 的提交被驳回。 这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员 A 的操作结果的可能。 从上面的例子可以看出，乐观锁机制避免了长事务中的数据库加锁开销（操作员 A 和操作员 B 操作过程中，都没有对数据库数据加锁），大大提升了大并发量下的系 统整体性能表现。 乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如 将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。 Hibernate 在其数据访问引擎中内置了乐观锁实现。如果不用考虑外部系统对数据库的更新操作，利用 Hibernate 提供的透明化乐观锁实现，将大大提升我们的生产力。Hibernate 中可以通过 class 描述符的 optimistic-lock 属性结合 version描述符指定。 1.3. 常见并发同步案例分析 1.3.1. 案例一：订票系统案例，某航班只有一张机票，假定有1w个人打开你的网站来订票，问你如何解决并发问题(可扩展到任何高并发网站要考虑的并发读写问题) 首先，1w个人来访问，票没出去前要保证大家都能看到有票，不可能一个人在看到票的时候别人就不能看了。到底谁能抢到，那得看这个人的“运气\"（网络快慢等）。其次考虑的问题，并发，1w个人同时点击购买，到底谁能成交？总共只有一张票。 我们容易想到和并发相关的几个方案 ： 锁同步同步更多指的是应用程序的层面，多个线程进来，只能一个一个的访问，java中指的是 synchronized 关键字。锁也有2个层面，一个是java中谈到的对象锁，用于线程同步；另外一个层面是数据库的锁；如果是分布式的系统，显然只能利用数据库端的锁来实现。 假定我们采用了同步机制或者数据库物理锁机制，如何保证1w个人还能同时看到有票，显然会牺牲性能，在高并发网站中是不可取的。使用hibernate后我们提出了另外一个概念：乐观锁、悲观锁（即传统的物理锁）； 采用乐观锁即可解决此问题。乐观锁意思是不锁定表的情况下，利用业务的控制来解决并发问题，这样即保证数据的并发可读性又保证保存数据的排他性，保证性能的同时解决了并发带来的脏数据问题。 hibernate中如何实现乐观锁： 前提：在现有表当中增加一个冗余字段，version版本号, long类型 原理： 只有当前版本号》=数据库表版本号，才能提交 提交成功后，版本号version ++ 实现很简单：在 ormapping 增加一属性 optimistic-lock=\"version\" 即可，以下是样例片段 1.3.2. 案例二、股票交易系统、银行系统，大数据量你是如何考虑的 首先，股票交易系统的行情表，每几秒钟就有一个行情记录产生，一天下来就有（假定行情3秒一个） 股票数量×20×60*6 条记录，一月下来这个表记录数量多大？ oracle中一张表的记录数超过100w后 查询性能就很差了，如何保证系统性能？再比如，中国移动有上亿的用户量，表如何设计？把所有用于存在于一个表么？ 所以，大数量的系统，必须考虑表拆分（表名字不一样，但是结构完全一样），通用的几种方式： 按业务分，比如 手机号的表，我们可以考虑 130开头的作为一个表，131开头的另外一张表 以此类推 利用oracle的表拆分机制做分表 如果是交易系统，我们可以考虑按时间轴拆分，当日数据一个表，历史数据弄到其它表。这里历史数据的报表和查询不会影响当日交易。 当然，表拆分后我们的应用得做相应的适配。单纯的 ORM Mapping 也许就得改动了。比如部分业务得通过存储过程等 此外，我们还得考虑缓存。这里的缓存，指的不仅仅是hibernate，hibernate本身提供了一级二级缓存。这里的缓存独立于应用，依然是内存的读取，假如我们能减少数据库频繁的访问，那对系统肯定大大有利的。比如一个电子商务系统的商品搜索，如果某个关键字的商品经常被搜，那就可以考虑这部分商品列表存放到缓存（内存中去），这样不用每次访问数据库，性能大大增加。 简单的缓存大家可以理解为自己做一个hashmap，把常访问的数据做一个key，value是第一次从数据库搜索出来的值，下次访问就可以从map里读取，而不读数据库；专业些的目前有独立的缓存框架比如 memcached 等，可独立部署成一个缓存服务器。 1.4. 常见的提高高并发下访问的效率的手段 首先要了解高并发的的瓶颈在哪里？ 可能是服务器网络带宽不够 可能web线程连接数不够 可能数据库连接查询上不去。 根据不同的情况，解决思路也不同。 第一种情况可以增加网络带宽，DNS域名解析分发多台服务器。 第二种情况：负载均衡，前置代理服务器 nginx、apache等等 第三种：数据库查询优化，读写分离，分表等等 1.5. 总结 尽量使用缓存，包括用户缓存，信息缓存等，多花点内存来做缓存，可以大量减少与数据库的交互，提高性能。 用 jprofiler 等工具找出性能瓶颈，减少额外的开销。 优化数据库查询语句，减少直接使用hibernate等工具的直接生成语句（仅耗时较长的查询做优化）。 优化数据库结构，多做索引，提高查询效率。 统计的功能尽量做缓存，或按每天一统计或定时统计相关报表，避免需要时进行统计的功能。 能使用静态页面的地方尽量使用，减少容器的解析（尽量将动态内容生成静态html来显示）。 解决以上问题后，使用服务器集群来解决单台的瓶颈问题。 1.6. 参考 http://betakoli.iteye.com/blog/2257095 1.7. .net 高并发 先还原一下 nuget 包，需要改一下redis的配置，rabbitmq 的配置以及Ef的连接字符串。另外使用的是 CodeFirst，先update-database生成数据库后再进行操作。 大量的请求，如果仅仅只有一台服务器肯定是吃不消的，通常一些公司都是一台服务器上部署了很多个网站也充当了数据库服务器、redis服务器。如果要应用高并发没有足够的硬件支持是不行的。我们需要进行 分布式集群 以及 负载均衡 这时我们还需要提高网站的吞吐量，怎么提高呢？首先我们需要针对IO密集型做异步化操作,抢单的页面不只是有抢单按钮，还有商品的介绍，图片，文字描述等。对于这些数据我们要进行缓存，一万个用户一万次请求都从数据库中取数据与只取一次剩下9999次从缓存中取效率自然是不一样的 上面说的都是为了解决一个 高 字，而并发才是我们真正需要准备的，假如两个用户同时请求，这时库存还有1，程序里先判断库存是不是1，现在都符合条件，然后进行生成订单等操作。就发生了资源共享的问题，明明只有一个订单，但是两个用户都完成了订单，那么这个商品应该给谁呢？假设现在是一个电商网站，今天要举办活动，有10个商品低价销售，但是会来抢购的人会特别多，最后只有十个人可以成功的买到商品。 假设的逻辑，我们用户进行了请求，我们把他们的信息放到库里，但是只有前十个人是可以购买商品的，因为库存只有10个 也许我们可以用锁来解决并发的问题，但是锁无疑带来的是效率的低下，用户体验也极低。我们想要的是快速返回，但是后面那一堆的逻辑怎么办呢？我们可以使用RabbitMq队列，用户的请求到达了抢单接口，我们只向队列中丢一条数据后就立即返回 这时又来了一个问题，会有同一个用户多次进行请求的情况，如果像之前的逻辑，前10条信息有二条是属于一个人的呢，（这里假设每个人只可以购买一次）我们就需要进行判断了，同一个账户发送的多次请求，我们只认为第一次请求是有效的，剩下的都请都直接返回。因为是并发，我们又怎么做到第一次请求有效呢？这时我们可以使用Redis incr存储用户的标识，Redis是单线程的，不存在并发的问题。incr返回为1那么是第一次请求，为N则是第N请求那么它就是无效的。这是请求标识。请求标识我们可以在抢单接口就进行判断，也就是先拿用户的标识去Incr，返回为1则丢到队列，不为1则不丢到队列。也可以在rabbitmq的消费端进行处理，从rabbitmq消息队列中拿到用户信息后，进行incr。再进行下一步操作。丢到了消息队列中，我们还需要去处理，consumer我们肯定是要有多个的，我们可以使用平分分发与手动交付。在这里我们把用户的信息进行入库，当然入库后我们再向Redis中存入一条入库标识 上面都是在后端，客户端这里点击了抢单按钮后可以立即导向排队界面（是不是很熟悉，某米。。。）在这个界面进行轮询五秒一次，判断当前用户在库中的位置，如果是前十，那么就进行订单操作，不是。。。那就再等，看看会不会有其他用户放弃购买资格。 其实讲到这里，已经差不多了，成功的把并行变成了串行。剩下的就是业务处理，怎么做都可以。 其实对于并发还可以有其它的处理方式，比如乐观锁也可以有效的控制并发 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/面经/":{"url":"Interview/面经/","title":"Interview/面经","keywords":"","body":"1. TOC1. TOC vmware Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/面经/vmware.html":{"url":"Interview/面经/vmware.html","title":"vmware","keywords":"","body":"1. vmware shanghai 2017-3-8 Jack (Ke Zhang)1.1. prepare Henry Chen interview1. vmware shanghai 2017-3-8 Jack (Ke Zhang) cookie, localStorage, when to use, when don't want to send to server? CORS how to set cookie expire time? (document.cookie = 'name=qiu; max-age=9999; path=/; domain=domain; secure';, max-age=0 删除) angular directives usage server rendering, client rendering real-time chat array [1,2,3,4,2], find values that appears more than once website optimization cross domain, jsonp why use oop, what is oop, benefit (encapsulation, abstraction, inheritance, polymorphism. reuse) modularization, commonjs, requirejs, es2015 will make commonjs or require away? how angular module? angular service, factory, provider, why use service? css priority, red, blue, green. bootstrap uses important? some js needs to put in front, resulting loading DOM slow, how to solve? async, defer less, sass pack tools, grunt testing: mocha, should.js, supertest, PhantomJS why not global variable, use closure benefit h5 advantage 1.1. prepare Henry Chen interview distributed systems 接口和抽象类有何区别？ 反射 单例模式吗？请实现之，并说说用在哪些情况中。 锁:有关锁的问题，读写锁的优化 多线程实现 写一个Singleton的例子 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/面经/阿里云后端/":{"url":"Interview/面经/阿里云后端/","title":"Interview/面经/阿里云后端","keywords":"","body":"1. TOC1. TOC JD云存储 三大音频网络协议 视频协议 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/面经/阿里云后端/JD云存储.html":{"url":"Interview/面经/阿里云后端/JD云存储.html","title":"JD云存储","keywords":"","body":"职位描述：阿里云存储服务团队负责阿里云统一的分布式存储系统的研发，以满足块，文件，对象，海量结构化数据等云存储产品和大数据处理产品的数据存储需求。基于阿里云分布式存储系统，我们开发了对象，文件，表格等云存储产品，提供了基于存储系统的数据处理能力、日志分析以及消息通信服务，打造了连接端与云、线下与线上以及存储与计算的基础设施，为用户提供安全、稳定，方便，高性价比的数据存储，处理与应用的云服务。 1. 针对互联网存储市场和用户进行技术咨询服务，结合阿里云存储产品和服务特性，为客户制定数据上云解决方案，并且解决迁移测试过程中的技术问题。 2. 理解、反馈用户需求，推动内部产品改进、服务提升。 3. 把握行业发展动向及技术变革方向，能够作为行业技术专家和云技术来引导用户做技术变革、确保重大项目的技术可行性、推进项目实施、并且形成可复制的案例和行业解决方案；能够针对行业做前瞻性的布局、影响云服务发展方向、与合作伙伴共建服务生态. 4. 与生态合作伙伴一起设计合理的商业合作模式，打造行业数据上云的生态链。 职位要求： 有3年以上的互联网应用开发、维护、优化经验，熟悉Java/C/C++/.net/Python/PHP中至少一种开发语言， 熟悉相应开发框架下的服务端多线程、高并发处理机制。 熟悉OpenStack，Ceph，Hadoop等开源软件，并且有成功的商业项目实践。 对互联网音视频业务常用的技术、标准、协议熟悉者优先；在视频直播、点播、语音通话等多媒体业务场景下有丰富的实战经验者优先。 对备份，容灾，数据连续保护等传统存储技术熟悉者优先。 有移动端开发经验者优先。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/面经/阿里云后端/三大音频网络协议.html":{"url":"Interview/面经/阿里云后端/三大音频网络协议.html","title":"三大音频网络协议","keywords":"","body":"1. 三大音频网络协议1. 三大音频网络协议 目前业内实用化音频网络协议有CobraNet、Dante、Ethernet AVB。 CobraNet网络 CobraNet是一种在以太网上传输专业非压缩音频信号的技术，工作在数据链路层（OSI二层）的低层传输协议，但无法穿过路由器，只能在局域网中传递，音频流不能大于8个数据包Bundle。 它可以在100M以太网下单向可以传输64个48kHz、20bit的音频信号通道（48kHz、24bit信号为56路）；除音频信号外，还可以传输RS485串口通信数据及其它非同步IP数据；开放的MIB文件，支持SNMP。一般使用星型（或连星型）网络结构。 目前，国内使用CobraNet技术搭建大规模音响传输及控制系统的工程还是凤毛麟角。 网络音视频实时传输技术—Ethernet AVB 以太网音视频桥接技术是一项新的IEEE 802 标准，其在传统以太网络的基础上，通过保障带宽，限制延迟和精确时钟同步，提供完美的服务质量，以支持各种基于音频、视频的网络多媒体应用。 Ethernet AVB致力于提供一套基于标准的方案来为演播室、影剧院、音乐会现场及娱乐系统等提供稳定可靠的音视频服务，以及提供低延时、供家庭及企业使用的同步音视频网络。 Ethernet AVB 关注于增强传统以太网的实时音视频性能，同时又保持了 100%向后兼容传统以太网，是极具发展潜力的下一代网络音视频实时传输技术。 Ethernet AVB是一种架构在以太网三层网络基础上传输专业非压缩Audio、video信号的协议技术，它能够支持目前大多数的专业视频信号格式，支持多达512通道无压缩或多路压缩数据格式音频信号，支持在以太网上传输压缩的1080i/p高清视频信号，而它的带宽占用率只有130Mbit/s。 Ethernet AVB建立的AVB网络，称之为AVB“云”（Cloud），解决了在以太网上提供同步化低延迟的实时流媒体服务。在AVB“云”内，由于延迟和服务质量得到保障，能够高质量地提供实时的流媒体服务。 同时，AVB网络保持与传统以太网的兼容，能够连接到传统的交换机、集线器和终端设备。告别直接与硬件对话的“云计算”支持用户在任意位置、使用各种终端获取应用服务，所请求的资源来自“云”，而不是固定的有形的实体。 Dante数字音频传输技术 Dante协议是一个在标准的IP网络上运行的现代化高性能数字媒体传输系统，是Audinate公司在2003年研发的，和传统的CobraNet技术一样，也是一个集硬件、软件和通信协议为一体的产品。 Dante数字音频传输技术是基于3层的IP网络技术，采用Zeroconf协议，简化了网络的运行模式。它可以通过一根普通的网线同时发送和接收许多的音频通道，完全替代一堆的多芯线缆，而且音频可以发送到所有带Dante的音频设备，并且更改路由只需要通过简单易用的软件即可完成。另外，Dante能提供1-1024个通道的音频传输，以及在其网络路由可以有无限数量的通道。 Dante技术具备自身独特的优势： 1、更小的延时、采用了IEEE1588精密时钟协议进行时钟同步、采用了zeroconf（Zero Configuration Networking）[6][7]协议、网络的高兼容特性、自愈系统、音频通道的传输模式可以是单播或是多播，这些独特的优势，成为Dante技术在专业音频领域及其他工程领域的奠基石，可广泛应用于专业音响行业、广播系统、电话会议系统、楼宇智能音频系统、大型运动会等行业。 2、Dante提供一个简化的，自配置，真正的即插即用的使用标准的互联网协议超过100 MB和/或千兆以太网的数字音频网络。 3、Dante是建立在全球网络标准，包括互联网协议-不只是以太网。借助真正的IP路由，Dante技术可以在网络上能够任由传输专业质量的音频和高清晰度的视频。 Dante技术可以在以太网（100M或者1000M）上传送高精度时钟信号以及专业音频信号并可以进行复杂的路由。与以往传统的音频传输技术相比，它继承了CobraNet与EtherSound所有的优点，网络中的音频信号，都以“标签”的形式进行标注等。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/面经/阿里云后端/视频协议.html":{"url":"Interview/面经/阿里云后端/视频协议.html","title":"视频协议","keywords":"","body":"1. 视频协议1.1. 1. RTSP/RTP/RTCP协议族1.2. 2. HTTP协议1.3. 3. RTMP1. 视频协议 1.1. 1. RTSP/RTP/RTCP协议族 本协议族是最早的视频传输协议。其中RTSP协议用于视频点播的会话控制，例如发起点播请求的SETUP请求，进行具体播放操作的PLAY、PAUSE请求，视频的跳转也是通过PLAY请求的参数支持的。而RTP协议用于具体的视频数据流的传输。RTCP协议中的C是控制的意思，用于在视频流数据之外，丢包或者码率之类的控制。 该协议族RTSP是建立在TCP之上的，RTP、RTCP建立在UDP之上。不过也可以通过interleave的方式，将RTP和RTSP一起在同一个TCP连接上传输。 RTSP协议族，是最早被提出来的，因此很多考虑的地方，都还带有早期的特征。比如使用UDP，是考虑到传输的效率，以及视频协议本身对丢包就有一定的容忍度。但是UDP协议，显然不能用于更大规模的网络，而且复杂网络下路由器的穿透也是问题。 从视频角度而言，RTSP协议族的优势，在于可以控制到视频帧，因此可以承载实时性很高的应用。这个优点是相对于HTTP方式的最大优点。H.323视频会议协议，底层一般采用RTSP协议。RTSP协议族的复杂度主要集中在服务器端，因为服务器端需要parse视频文件，seek到具体的视频帧，而且可能还需要进行倍速播放（就是老旧的DVD带的那种2倍速，4倍速播放的功能），倍速播放功能是RTSP协议独有的，其他视频协议都无法支持。 缺点，就是服务器端的复杂度也比较高，实现起来也比较复杂。 1.2. 2. HTTP协议 HTTP的视频协议，主要是在互联网普及之后。在互联网上看视频的需求下形成的。 2.1 最初的HTTP视频协议，没有任何特别之处，就是通用的HTTP文件渐进式下载。本质就是下载视频文件，而利用视频文件本身的特点，就是存在头部信息，和部分视频帧数据，就完全可以解码播放了。显然这种方式需要将视频文件的头部信息放在文件的前面。有些例如faststart工具，就是专门做这个功能的。 但是最为原始的状态下，视频无法进行快进或者跳转播放到文件尚未被下载到的部分。这个时候对HTTP协议提出了range-request的要求。这个目前几乎所有HTTP的服务器都支持了。range-request，是请求文件的部分数据，指定偏移字节数。在视频客户端解析出视频文件的头部后，就可以判断后续视频相应的帧的位置了。或者根据码率等信息，计算相应的为位置。 2.2 支持HTTP range-request的服务器，目前就可以支持我们一般网络看视频的要求了。但是，这种方式，无法支持实时视频流，或者准实时视频流。因为视频流，是不存在一个视频文件的概念的。HTTP协议播放视频的好处，就是简单。采取通用的HTTP服务器，就可以提供服务，不需要专门类型的服务器，也不需要特别的网络端口，穿过路由器防火墙一点都没有问题。而且还可以利用通用的CDN来简化视频的部署分发的工作，减少带宽的使用。 这个是目前用于PC端或者网页端，视频点播业务，最常见的解决方案。客户端的实现，一般采用flash完成，flash本是的videoplayer或者videodisplay控件就可以完成。资源一般采用flv格式，也可以使用mp4格式。 在此基础上，多家公司推出了自己的解决方法。 2.3 HLS HDS MSS DASH 苹果推出的HTTP Live Streaming，就是随着苹果设备的普及得以广泛应用的一种。从名词就可以判断出来，HLS支持Live直播式的视频传输。HTTP采用m3u8作为索引文件，视频为MPEG2-TS格式的片段文件。如果为直播视频流，则采取更新m3u8文件，从而更新视频索引列表，达到视频直播的目的。但是这种方法，因为最终视频是片段文件，所以必然存在片段视频长度的延迟。因此只可以用于对实时性要求没有那么高的准实时视频流。但是HLS方式，因为采用了较早的MPEG2-TS格式，这种格式的overhead，也就是头部信息占据总文件的比例比较大，也就是效率不够高。之所以没有使用其他格式，主要是商业竞争和版权的问题。 相应的，adobe公司，推出相似的HTTP dynamic streaming。这种方式本质和HLS的策略是类似的，就是通过索引文件+视频片段的方式。但是显然采用的索引格式和视频片段格式都不一样的。HDS采用的是视频格式是flv或者f4v，索引格式记不清楚了。 类似的，微软也推出了Microsoft Smooth Streaming，也即是mss的视频播出方式，采用的视频格式是分段mp4格式。 MPEG标准组则推出了Dynamic Adaptive Streaming over HTTP, DASH.采用的视频格式为3GPP吧。 显然，这个目前是百花齐放的状态，虽然最常用的的是HLS，谁叫苹果这么霸气呢。而安卓和苹果上面对于flash都有限制，而HDS是adobe推出在adobe平台上面的。mss，只有在少数几个地方见到过。dash，目前仅仅是论文里面的产物。 以上的协议，主要是解决一个问题，就是自适应码率切换，上面的dynamic，adaptive都是类似的意思。主要是利用索引文件中同时给出不同码率的视频文件的地址，这样播放器端，可以根据带宽情况，自适应选择不同码率的视频文件。 同时在视频直播方面，在安卓和iOS平台以外，还有很多视频服务器提供厂商，自己开发协议，一般采用方式为固定时间片段的flv文件的方式（采用flv，是因为flash上方便播放） 2.4 HTML5 同时HTML制定厂商也不寂寞，推出HTML5这种方式，这种方式本质上，和前面的HTTP视频协议没有任何区别。但是播放器端，不再依赖于特定的插件如flash，或者其他播放软件，而是可以支持浏览器的直接视频播放。采用的是html中嵌入video标签，同时直接指明视频的url。不过，不同的浏览器，对于音视频的格式支持不完全相同。比较通用的是视频H。264格式，音频AAC格式，封装格式MP4。 2.5其他 在HTTP协议的基础上，各家公司，针对自己的业务特性，也可能开发自己的专有的数据格式，或者协议。但是都是在上述的基本上做出一些细微的修改而已。毕竟国内的技术体系，还完全无法提出一个新的技术的程度。（google，就提出新的编码格式替换H.264,SPDY协议，这个国内做不到的）。 一般只会做到例如HTTP特殊字段或者特殊参数，传递到flash中做出一定的解释。或者在原有的视频文件格式基础上添加一些特殊意义的头部等等。 1.3. 3. RTMP 这个是adobe公司自己推出的视频播放协议。需要专用的服务器，如FMS，开源的有red5.这种协议也是flash默认支持的。 总体来看，视频相关的协议发展，是从专用的协议、服务器，逐渐向HTTP过渡的过程。而且逐渐适应网络的发展和需求，复杂多变的网络环境，才催生了http的视频协议。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/面试必看/":{"url":"Interview/面试必看/","title":"Interview/面试必看","keywords":"","body":"1. TOC1. TOC ask_question behavior-question me Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Interview/面试必看/ask_question.html":{"url":"Interview/面试必看/ask_question.html","title":"ask_question","keywords":"","body":"1. Questions that I can ask1. Questions that I can ask What is the ratio of testers to developers to program managers? What is the interaction like? How does project planning happen on the team? 我未来期望做项目经理，带领团队做出优秀的产品，您觉得如何才能成为一名出色的项目经理？需要掌握什么技能？ 技术总监／项目经理很忙，新技术更新很快，在没时间没精力学习这些技术的情况下如何管理和指导团队 这个职位需要做什么？你希望我未来三个月能够帮公司做什么？ 公司如何帮助新员工尽快适应职位？除此之外您建议我如何尽快适应该职位？并且很快在该职位上作出成绩？ 公司现在都用到哪些核心技术？未来考虑使用哪些新技术进行改进？ 您能介绍下你们团队规模以及如何分配任务的吗？ 公司未来三年最重要的新产品线、新策略、新市场有哪些？ 公司如何帮助我们多了解每个部门的业务（好让我们更能做出贡献）？ What are the necessary skills to do this job? What makes a successful candidate? What would make an unsuccessful candidate? Why have people left this position previously? What is the most difficult part of this job? 问HR福利 你最棒的团队成员有什么共通特质？ 同事们闲暇时间都做什么消遣？ 你们平常用英文还是中文？ 贵公司业绩成长的最关键因素是什么？ 面对即将来临的不景气，你们有什么应对的计划？ (或者该产业特有的状况) 公司创办的过程，有哪些关键的决定把公司带到今天的地位？ 最近的主管异动/人事改组/签下新客户，对公司有什么影响？ What brought you to this company? What has been most challenging for you? I'm very interested in scalability, and I'd love to learn more about it. What opportunities are there at this company to learn about this? I'm not familiar with technology X, but it sounds like a very interesting solution. Could you tell me a bit more about how it works? Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/面试必看/behavior-question.html":{"url":"Interview/面试必看/behavior-question.html","title":"behavior-question","keywords":"","body":"What was the toughest challenge you’ve ever faced? graphics editor, a very important module in project. It includes Tools, Canvas and Properties Area. You can think it as a online Photoshop. Syncing between areas, Grouping, Saving. To design a basic chat application like skype/qq. That was the first time that I made a real-time application. First, I did a research about what techniques should be used and SignalR is the one I want. Second, how to design the one to one, one to many chat mode? I researched and used group, room these concepts to implement both client and server side code. Third, what if one is online and the other one is offline. And online person sends a message to offline person. Then when offline person gets online, how can he receive the message? Fourth, how can I retrieve chat histories? Fifth, if one deletes history from his side, the other person should still be able to have the history, how to manage the history? This is more complicated for one to many. I put all possible situations into consideration and design the database. It's a tough task, when I finish this, all colleagues and manager spoke highly of me! What two or three things are most important to you in your job? I want to be happy. I want to work in a job that I am passionate about, and for a company that respects and rewards my contributions. I want to have co-workers whom I like and respect. I think these things all work together for a positive work environment — which increases productivity — resulting in happy employees and a happy employer. I also seek fulfillment. I don’t want to work in a job that I feel is below what I am capable of doing. I seek a job that will challenge me to perform at the highest levels and seek ongoing professional development so that I can be even better at my job, making an even stronger contribution to my employer. From everything I’ve researched and seen, this job that I’m interviewing for meets all my criteria. Opportunities, show my value, make me grow。个人发展空间 Respect from colleague, friendly, corporation salary, salary is flexible. Sometimes you cannot get the high expected one, it won't let you miss some good opportunities, but I have a bottom line, and i feel a great company like to find a very great employee and pay more salary to him, rather than find a normal person with low salary. Salary is a way to show your value Give me a specific Negative experience example of a time when a co-worker criticized your work in front of others. How did you respond? How has that event shaped the way you communicate with others? (SNH) I seldom get criticized since I'm usually productive and deliver satisfying solutions, but this happened once when I worked on the real-time chat functionality in SNH. One today, my scrum master, my director and I sat together, and scrum master asked why the task has not been finished. Scrum master is not good at techniques. So I have to say something that all of us can understand easily. I say, First, No one has real-time chat development experience, since I love to try some new things I pick up this difficult task by myself. I want to be responsible for company, and deliver great products. I try to think if I were the customer, what do I really want to see in the product? If I just want to stay at comfortable zone, I don't pick this task and maybe we never have this meeting. Second, It took me 3 days to filly understand the requirement since the requirement is not clear at beginning. Third, I did research and found SignalR is the best solution in .net Platform. It needs both client side and server side work. To achieve point to point chat is not hard, but it's a little difficult to achieve one to group and group to one. Fourth, the most difficult part is about database design. We want to keep chat history. If one deletes history from his side, the other one should still be able to view history. In addition, how does a online person send a message to offline person? And when that offline person gets online, he can receive the message immediately? Then I showed them the paper that lists my thoughts, drafts about database design, system design, and pseudo code etc. Finally they understand how hard it is and after I presented all these functionalities, all in the team are quite satisfied with it! So after this event, my scrum master attitude became warmer, he would talk with me to understand everything before any judgement. He think I'm responsible and capable. We respect each other. Don't you talk with other developers or scrum master everyday? We have standing up meetings every day, but probably because I talked about the same thing for several days, he thought I didn't make progress for days. Tell me about a time where you sought out perspectives other than your own to make a product/service/project better? (use other peoples' thought) ==ActionMenu json or web.config== Ub tahoe project there is a actionMenu dropdown list, it has icons and anchors. Based on systemId (bankerConsole, teller), the list is different. The data is dynamic so we cannot just write plain html because it's not extendable if we add a new system. So for some reasons, my manager doesn't want to load that dropdown from database. (maybe creating a table just for a dropdownList is too much) My solution is to create a json file, \"systemId\":1,\"url\":\"a-dev.com\". So I load the json and bind data to dropdownList. Whenever there is any change, I can directly work on json file. It's a good solution for many cases, but in our case, the dropdown anchor url varies like \"a-dev\", \"a-test\" based on the environment. My manager suggests we use web.config and transform the url based on environment. I feel this solution works better in this case. later instead of web.config, it's actionMenu.config and third-party lib to do transform Tell me about a time when you had to analyze facts quickly, define key issues, and respond immediately to a situation. What was the outcome? UnitOfWork, when transactions are more, slow Give me an example of a time you used customer feedback to drive improvement or innovation. What was the situation and what action did you take? UPMC mapQuest: map shows different offices, under the map there are names of offices. mouse hover on the office icon in map, name will pop up. The customer feedback is is there anyway that we know the all offices' names without hovering mouse to each, or if we want to find a office named \"A\", where is it in map without trying to hover every icon? since some offices name are long, i cannot display names along with the icon in map. What I did was to set identity number 1 2 3 4 for each of office under map, and on the map, the icon has corresponding number. Customer is very glad to have this solution. Tell me about a goal that you set that took a long time to achieve or that you are still working towards. How do you keep focused on the goal given the other priorities you have? a long-term goal: be a technical leader in 5 years. I seldom set big goal without smaller short-term goals because it may take too long to get there, and there're some uncertain things before going that far. If I don't get there I may lose confidence. I tend to set small goals and once I finish one, I encourage myself and am excited to set next one. But to be a leader is a target I'm pretty sure I will be there. To achieve that, I dig into techniques everyday, review technical news, blogs, books, videos, etc. Also I learn from my manager and teammates. Talk with friends, mentor. Learn from books. The tasks my leader assigned have first priorities, I like to finish these tasks efficiently with hight quality. And then I use some spare time to work on my goals. I'm curious. When I see an app working in a different way, I will think how it is working like this under the hood (frontend animation i.e.). When I wait bus in station, I will check how the advertise designed. What if I design it? Tell me about a time when you linked two or more problems together and identified an underlying issue? Were you able to find a solution? mPower: worked on error log using log4net. But when multiple threads throw error together, lock will decrease performance because other threads have to wait. I thought that I worked on message queue before, so I use both log4net and queue to improve the performance. And finally use redis. What three things you are you working on to improve your overall effectiveness? newest techniques, recently ES2015. Read blogs, news, videos, etc. Talk with mentors create helper functions, like AjaxHelper, CacheHelper, build my code library (frontend plugins), write notes, blogs to share to deepen my skills read books to build emotional intelligence learn from mistake treat people right Give me an example of when you took an unpopular stance in a meeting with peers and your leader and you were the outlier. What was it, why did you feel strongly about it, and what did you do? This only happened to me in the first few weeks when I joined a new company. I'm new, I'm not familiar with everything. I feel it's quite normal. What I did is listen to what they say carefully and try my best to understand how things are going, how I can get used to this new environment quickly? And after meeting I also ask my manager and peers for help. But after 2 or 3 month, I usually take a popular stance. Tell me about a time you wouldn’t compromise on achieving a great outcome when others felt something was good enough. What was the situation? log4net + queue, can use log4net + redis Tell me about a time you made a hard decision to sacrifice short term gain for a longer term goal. Before working with UnionBank, I received another offer from a small company, they give more salary, more vacations. But I feel my capability is beyond their need. I stay at my comfort zone and won't make big progress. My long-term goal is to be a technical lead, working in this company, I will get more salary, but it makes me hard to become an excellent leader. I give up that offer and go with UnionBank. How do you drive adoption for your vision/ideas? How do you know how well your idea or vision has been adopted by other teams or partners? Give a specific example highlighting one of your ideas. ES2015, coding style, name convention. Everyone started to follow rules. Tell me about a time when you realized you needed to have a deeper level of subject matter expertise to do your job well? When I started to work on Avendas in SNH, I just knew basics of angular. Although I mainly worked on backend, knowing how angular send ajax call to server is better for me to understand how frontend and backend work together. I felt I need to learn more about angular. Now I'm at middle level of angular 1, and I haven't studied angular 2. I know I need to work on angular 2 or 4 so if next project uses them, I will be more confident. Leadership skills? give others opportunities to shine think big assign tasks accordingly motivate team listen from different opinions and make best decision considering long-term goal understand what is most important I am a leader who likes to give the people I am leading the ability to shine. I think it is important to take everyone’s opinion into consideration and be willing to listen to what they have to say. I think my job as a leader is to organize things and keep them in order. Being the leader does not mean I know everything there is to know because I cannot possibly know more than everyone else about every topic. It is just not plausible. creativity or efficiency, Which is more important? I think that the key is a balance between the two, with efficiency being the most important. You could have an extremely creative piece, but if the message of the piece is not clear then it is not efficient and a waste of resources. How has college changed you as a person? I have grown up during my college years. I am able to communicate better, think strategically, and multitask more than ever before. I can handle an appropriate level of stress and still get things done. Some people work best as part of a group — others prefer the role of individual contributor. How would you describe yourself? I like a mix of both. I like to work in a group and get group input. I think a lot of good ideas come from talking things out with other people. I also like to work by myself on some projects because I think there are some projects that are just done better if one person is working on them. When given an important assignment, how do you approach it? I like to make a todo list, a timeline of how and by when things need to be done. I really like to get started on the assignment immediately because I’ve found that once I get started on a project I tend to get gradually more excited about it and involved in it, and I want to expand the project more and more as I go on. By getting started earlier, I can get the most out of the project and maximize it as much as possible while providing time to give it that extra review. a shortcoming/weakness As a engineer, I'm not strong at history, politics, art, music, etc. Sometimes when I talk with friends, they know a lot of stuff which doesn't relate to work. I feel kind of guilty. They can use very proper words, poetry to express things, but my words are just plain words. I think I might focus more on work sometimes, and forget how to balance work and life. I realized this, and I'm working on it. A excellent person should not just do well in work, but should have a broad knowledge, work for a happy life rather than just for work itself. And from a long run, it's also good for the company. 团队合作意见分歧： 处理很多问题的方式很大程度上取决于你的职位、环境等因素。如果我是管理者，每个人在团队中都应该可以自由坦诚地发表意见，我会非常认真的聆听，分析；但对于自己的意见我不会没有原则的轻易放弃。民主过后还需要集中。我的理念是：Meeting 不等于Voting，完全不需要少数服从多数；我是负责人，我相信自己有能力采取最佳方案；假如失败了，我也会承担主要责任。而如果我是团队的普通一员，我会保留自己的意见，但还是认真执行管理者已经做出的决策。只要遵循“对事不对人”的原则，目的是合理高效解决问题。反问面试官你是如何处理意见分歧的呢？ 在人际沟通上是否曾经有过不和谐？ 有，生活中遇到过，工作暂时没遇到。其实我这个人很容易和别人相处，因为我会换位思考，以此来理解他人。但是！如果遇到价值观和我有抵触的人，我会无法容忍，可能会不能进行有效沟通。有几类人不太欣赏：说话言而无信；做事虎头蛇尾；妄想不劳而获。这种人已经触犯到我的原则底线。当然，我不会拂袖而去，但实在不愿敷衍。也许这就是还不够世故圆滑吧。我很矛盾，不知道该做怎样的拿捏与平衡。 为什么回国发展？ 情。人在一些快乐的时候很容易迷失自己，忘记自己曾经最真实的、发自内心的想法。我会这样问自己，当所有的职业工资水平一样多，职位不分高低，我会选择什么职业？ Give me a specific example of a time when you sold your supervisor or professor on an idea or concept. How did you proceed? What was the result? (assertiveness) When I worked in UnionBank tahoe project, I saw many javascript files include global variable. Naming convention, coding style varies. So I talked with my manager about it. Global variable may raise conflicts and give an example it will increase the development efficiency and easier to maintain if we have a unique naming convention and coding style To make this happen, I gave several solutions, like modularization, self-closure, ESLint, ES2015. And then I told the benefits for each of these techniques. My manger loves my thoughts, and in a meeting I introduced how to make code better. Describe the system you use for keeping track of multiple projects. How do you track your progress so that you can meet deadlines? How do you stay focused? (commitment to task) I used TFS. TFS has my work, workItems. So in workItems, I can see how many tasks are pending. Each task has start day and release day, task description, etc. So by using TFS, I can keep track of my tasks. In addition, to finish a task, I probably needs to do it step by step, so I will write a todo list in my editor Atom, sublime. It includes the start day, end day, priority. I will mark it solved foreach small task. Tell me about a time when you came up with an innovative solution to a challenge your company or class was facing. What was the challenge? What role did others play? (creativity and imagination) UnionBank Unity T4 Describe a specific problem you solved for your employer or professor. How did you approach the problem? What role did others play? What was the outcome? (decision making) UnionBank MPower project log4net + redis Initially, tahoe project uses ExceptionFilter to write errors/exceptions into database. When there is an error in test, developers have to look up the error in test db, but some developers don't have access to test db. And it's not convenient to find errors, because you have to open sql client, find that table, and query errors. So I suggest, why not record errors in txt file? Another developer implemented this feature. One day, I wanted to check the error log, but when I see that log file, it's about 100 megabyte, I don't dare to open it... I immediately talked with team and pointed out that we cannot record all errors in only one file. We need to control the biggest size of one file, maybe 10mb. My manager decided to let me do it. Then I used Log4net the solve the problem since it can log errors in several files in a reasonable size. One day, I was pretty sure that an exception was not recorded in our log file. I found the reason is when errors happen in different threads, there will be a problem for multiple threads to access one file. So I added \"lock\" to solve this issue. Then I tested my code by generating multiple errors in multiple threads. The bad thing happens, when a thread writes error to file, the other threads have to wait, the performance is so bad. Then I used put all errors into queue, and start a new thread, which is responsible to get errors and write them into file. Finally, I used redis instead of traditional queue, so errors are push into distributed queues. 多线程操作同一个文件时会出现并发问题。解决的一个办法就是给文件加锁(lock)，但是这样的话，一个线程操作文件时，其它的都得等待，这样的话性能非常差。另外一个解决方案，就是先将数据放在队列中，然后开启一个线程，负责从队列中取出数据，再写到文件中。 Describe a time when you got co-workers or classmates who dislike each other to work together. How did you accomplish this? What was the outcome? (teamwork) Raya kept asking Sathish questions every day. Rajini complaint this to me because their discussion always interrupts her thoughts. One friday I invites them to have lunch together. One of my friend in another company had the same problem before the lunch. we talked about many interesting things at first, at last I said, my friend in another company feels their development is not efficient because they sometimes talk a lot of funny things during work. The environment is comfortable but sometimes they didn't finish tasks within deadline. What do you think to solve this kind of issue? Rajini said maybe they can work hard in the morning, and talk something funny during lunch or a small break. Maybe we can do the same, during standup meetings in the morning, we told any block we had. Then we work relatively independently unless there is a big issue one doesn't have any idea. If there are some small issues, we can talk between 2-3 pm everyday. So every one in the team thinks how to solve their tasks and did some research online before asking questions. There is less interruption and everyone tries their best to solve before asking for help. Tell me about a time when you failed to meet a deadline. What things did you fail to do? What were the repercussions? What did you learn? (time management) union bank layout SPA change. Describe a time when you put your needs aside to help a co-worker or classmate understand a task. How did you assist them? What was the result? (flexibility) Sathish, css layout, arrow navigation bar, div:after/before. My task is not urgent, offer help actively Describe two specific goals you set for yourself and how successful you were in meeting them. What factors led to your success in meeting your goals? (goal setting) one goal was I should at least be middle level of angular 1 in June 2016. I set this goal in December 2015. I tend to make smaller goals which can be easily achieved. I feel very glad to finish one and it makes me very excited to set another goal. I'd say I did finish this goal at that time. To get there, I tried to solve every task every efficiently. Once there is a new task, I immediately understand the requirement and start to work on it. I don't like to work close to the deadline. Once I finishes the task earlier, I use this spare time to learn new techniques. I love to learn new things. Another goal is too finishing a chinese history book. I want to be a leader in future, and I feel an excellent leader should not just focus on the techniques. I prefer one should have a very strong knowledge in one and a few fields, but one should also have a broad view, have interest in many different things. So when a new issue comes up, you can have many different ways to solve it. History may not directly help me about coding, but it indirectly gives me an idea that if there is any other way I can communicate with others. How to make the team work more efficiently, etc. factors: passion, motivation, aspiration, I want to be successful. I want to have a wonderful life. I want to share my knowledge and contribute. How do you ensure that someone understands what you are saying? meeting, ES2015, naming convention, code style, ppt lists demo with picture. Code review and double check. From listener eye, expression Tell me about a time when you had to present complex information. Real-time chat history Tell me about a time in which you had to use your written communication skills in order to get across an important point. Jay ui-controller and func-controller Give me an example of a time you had to make a difficult decision. Smaller company with high salary, before UnionBank, because of long-term goal--technical leader Give me an example of when taking your time to make a decision paid off. Unity xml, Unity pragmatically, Unity xml with T4 Give me an example of a situation that could not have happened successfully without you being there. Unity xml with T4, Log4net queue How do you determine priorities in scheduling your time? Give me an example. I have a sense. And ask manager what is important. List all steps to finish that task and find which is most important and what may block me. Tell me about a time when you influenced the outcome of a project by taking a leadership role. ES2015, naming convention, code style; Log4net queue Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Interview/面试必看/me.html":{"url":"Interview/面试必看/me.html","title":"me","keywords":"","body":"1. Self Introduction1. Self Introduction 现在在一家中小型公司做技术经理，主要负责前端，搭建框架（yeoman）、封装公共组件、最近开始负责重量级模块--图形化创建。 对 react 比较熟悉。曾经用过 angular1, 今年美国交流之后学习过 angular2。 对前沿技术很感兴趣，如 web components, custom elements, shadow dom, css variables 等。 我是中途接手一个项目，发现了很多问题，我负责帮助团队不断改进推动项目 react 状态管理混乱，早起项目只用 react State，大家觉得一层一层传递 state 麻烦。我接手后发现 redux 和 react state 混用导致不清晰，帮助大家从 react state 过度到 redux，完成路由模块、首页等公共模块 80% 提取相似组件，封装成公共组件，提高复用性 改进 Modal, Select 等组件，原来 Modal 里面没有状态控制，是通过引用该 Modal 的组件状态决定开关，现在在 Modal 里面有 state 控制。职责单一 图形化创建的撘建，老师学生端。canvas，fabrics，svg 制作的网页版 sketch、ps。介绍下功能。 eslint 工具，editorConfig 加入测试、mock-server、持续集成 下一步改进： css 模块化 I have involved in system development life cycle for 7 years, especially web development. I'm working as CTO in a startup company. Before I was a technical lead in UnionBank, US. College: I'm interested in designing web application for a long time, but I don't choose computer science as my major because I don't want exams, classes ruin my interest, and I learnt computer science class by myself in Dalian University of Technology. I did part-time job to learn and strengthen my programming skills during college life. Post College & Onwards: After college, I worked in several companies in US. Most of my work is about how to build web application. my skill sets include frontend(html,css,js and latest frameworks and libraries like angular, React + redux, jquery), backend(.net latest MVC core, WebForm, MVC, nodejs), database(mongodb, MSSQL). Current Role [Details]: Now I'm leading both frontend and backend teams. I designed system architecture, do some coding, code review and some managements. I give free time every to team so everybody can share and learn what they want if they finish tasks very efficiently. Everyday I go over some blogs and technical websites to learn new techniques, and understand what is popular, what will be popular in future. And I also like to learn these new stuff from video tutorials(youtube, codeSchool) and buy books online. Anyway, I'm self-motivated, and I love what I'm doing. I used to stand on the top in college life, now I want to an excellent leader. I'm making a progress everyday to make it happen! 我有7年软件开发经验，包括 windows application 和 web application。我更倾向于web开发。现任联合银行任技术指导。 我很早就对网站开发产生兴趣，但是我在大学时代并没选择相关专业，因为我不想找考试、强制性的课程毁掉我的兴趣。我在大连理工通过自学和兼职工作去提高自己的编程水平。 在迈阿密大学结束后我在美国3家公司工作过，大部分工作内容都是网站开发，包括前端、后端和数据库开发。前端方面主要是html css js 和一些框架 angular jquery，后端.net mvc, nodejs，数据库主要 MSSQL 和 mongodb。 半年前由于我的贡献和能力得到认可，升为技术指导，领导前端和后端开发。我主要负责重新设计系统架构、code review、还有管理方面的工作。每周我都会给团队一些自由时间，大家可以互相分享和学习他们想学的内容，前提是高质量高效完成任务。 每天我会查看浏览一些技术博客、网站去了解最新技术以及未来发展趋势。我也通过一些视频教程和看书去提高自己的水平。总之，我是个主动性很强、对这个行业充满热情的人。我期望以后能够带领团队创造出优秀的产品，为此我每天都在努力，去实现自己的价值！若干年后问心无愧 my projects 对公司现有的系统的优化和重构: 项目没有 lint 工具导致大家代码不统一，使用 ESLint。 react state 管理问题，react state 和 redux store 混合使用 react 不可变性理解不到位，有些人在 setState 里面修改了状态。还有得 deepClone 后赋值。我推荐 immutability-helper 每个 component 都是用 class 的方式去定义。我推荐了 functional/stateless component。 改进： webpack tree-shaking 和 bundle splitting。 Modal、select 组件库的优化和扩展 HighChart 配置统一、可拖拽配置。 Stylus 缩进不方便。 难点： 需要增加图形化创建，数据保存，团队多人协作。 redux 源码 applyMiddleware 等觉得难。 common questions Ub tahoe, MPower SNH Avendas UPMC panelAccess challenges Optimization: SPA, unitOfWork, Cache, Thread; Unity: T4; MPower: log4net+redis real-time chat mapQuest, chart.js, pdf Mistake A link click error after SPA NA NA Leadership ESLint, naming convention, coding style Conflicts not mine: Raya asks too much; opinion conflicts: Jay ui-controller/func-controller scrum master real-time chat task slow What do you do differently high-level architecture refactor, cacheHelper(memcache,regular) real-time chat mapQuest, chart.js, pdf UnionBank challenges 1: Performance, UnitOfWork, CacheHelper with memcache As the application get larger and we have more and more data, the system response time increased. My goal/challenge is to find the bottleneck and speed up the whole system. You know, there're too many things that need to be considered when we talk about performance (frontend, application, and database). For frontend part, we already used CDN, and js minification/compress, and some other techniques before. But to improve user experience, instead of redirecting from one page to another, I discussed with my manager and suggested to make our application a SPA. I found backend c# code makes system run slow, especially when there are multiple transactions. One reason is that the system doesn't use UnitOfWork, so this means when we are operating multiple tables, we may created dbContext many times, connect to db many times and generate multiple sql queries. So I added UnitOfWork to application and one big advantage is that the CRUD logic can be executed in the business logic layer rather than database layer. Business layer has more control about the data flow. Second, I wrote a CacheHelper and use it whenever it is possible. The CacheHelper can uses both traditional Cache and Memcache (amazon: dynamo). There're some time-costly functions. I created a new thread for them, and made them work asynchronously. As a result, the response is faster. Ub challenge 2: Unity mappings, xml --> programmatically --> T4 xml We used Unity to decouple layers. Our team had a hard time about the unity object mappings. Initially we used xml files to store the mappings. But there is not any intelligence and developers can spell wrong. They cannot see it wrong until running the solution. So I suggest, why don't we give up the xml and create mappings programmatically? We are quite happy at first. But as we have more controllers, we get tired of creating mappings because every time when you creates a new controller, you have to create a mapping between this controller and the service. And sometimes developers forget to add this mapping, resulting in more debugging time. So instead of creating mapping programmatically, I wrote a T4 code template. It can generate a xml file based on the database, new controller file, and its dependent services. Thus, when developers create a new controller, they don't need to take care of the mappings, when they build the solution, the generator will refresh the mappings. Ub mistake I redesigned the layout page and make it as a SPA. I thought I checked everywhere, but there is a link in a very latent place. The link click will raise an error. It's dangerous because it's really bad if users see this error. The bad thing is that the production day was tomorrow. I immediately talked with my manager about this and told him this change can be done within 5 minutes. But We don't have enough time to push this fix to test or production. So we delayed our deployment. Thanks god, it doesn't have a serious affect since it is an early release. I took the responsibility and said sorry to my manger. He said it's no a big issue since I found it before deployment and he likes my attitude and indeed, that link is too easy to be ignored. Ub conflicts I seldom have behavior conflicts with others since I'm always nice to others. But I have some opinion conflicts. These conflicts I feel, most of time they are good because by pointing out different opinions, we can come up with better solutions, and it can improve our creativity. One conflict with my manager is that he wants to separate controllers by ui and functions while I feel controllers should be separated by modules. His thought is, any controller related to UI, which render a view should be placed into UI-controller folder, and any controller which involves many logic and data retrieving functions should be under func folder. I wrote an email and explained my ideas. First, some controllers have both UI an logic functions, so they are not clear where to but placed. Second, these changes will have to change RoutingConfig, and many ajax calls will be affected since the url changed. Third, I estimated the time how long it will take if we really want to do this. And how many files need to be changed. At last, I said something like, if you still want to implement this way, I will definitely do it within the estimated time. Please let me know. So in this conflict, I pointed out the disadvantages that it will generate. If we really do this, how things will go, what to be predicted. These results made my manager clear at this issue. He agreed on me and he was very glad that I could point it out before making that decision. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/":{"url":"Javascript/","title":"Javascript","keywords":"","body":"1. TOC1. TOC gQuery inheritance升级版composition inheritance继承 oop reduce throttle_debounce_immediate webworker XMLHttpRequest 前端知识目录 模版编译 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Javascript/ES6/":{"url":"Javascript/ES6/","title":"Javascript/ES6","keywords":"","body":"1. TOC1. TOC const地址不变 destructuring es6_getter_setter forin_vs_forof promise proxying tail_call_optimization template_string_loop_json Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Javascript/ES6/const地址不变.html":{"url":"Javascript/ES6/const地址不变.html","title":"const地址不变","keywords":"","body":"1. javascript const 理解，如何冻结对象1.1. 完全冻结对象：包含冻结对象本身和对象属性1. javascript const 理解，如何冻结对象 对于复合类型的变量，变量名不指向数据，而是指向数据所在的地址。命令只是保证变量名指向的地址不变，并不保证该地址的数据不变，所以将一个对象声明为常量必须非常小心。 const foo = {}; foo.prop = 123; foo.prop // 123 foo = {}; // TypeError: \"foo\" is read-only 上面代码中，常量储存的是一个地址，这个地址指向一个对象。不可变的只是这个地址，即不能指向另一个地址，但对象本身是可变的，所以依然可以为其添加新属性。 1.1. 完全冻结对象：包含冻结对象本身和对象属性 const constantize = (obj) => { Object.freeze(obj); Object.keys(obj).forEach((value, index) => { if (typeof obj[value] === 'object') { constantize(obj[value]); } }); }; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/ES6/destructuring.html":{"url":"Javascript/ES6/destructuring.html","title":"destructuring","keywords":"","body":"1. 对于Set结构， 也可以使用数组的解构赋值1.1. 只有 undefined 才能触发默认值1.1.1. 主要用途1. 对于Set结构， 也可以使用数组的解构赋值 let [a, b, c] = new Set([\"a\", \"b\", \"c\"]) console.log(a) // \"a\" 事实上，只要某种数据结构具有Iterator接口，都可以采用数组形式的解构赋值。 function* fibs() { var a = 0; var b = 1; while (true) { yield a; [a, b] = [b, a + b]; } } var [first, second, third, fourth, fifth, sixth] = fibs(); sixth // 5 上面代码中， fibs是一个Generator函数，原生具有Iterator接口。 解构赋值会依次从这个接口获取值。 1.1. 只有 undefined 才能触发默认值 [1, undefined, 3].map((x = 'yes') => x); // [ 1, 'yes', 3 ] 1.1.1. 主要用途 交换变量的值: [x, y] = [y, x]; 从函数返回多个值: 将它们放在数组或对象里返回 function example() { return [1, 2, 3]; } var [a, b, c] = example(); // 返回一个对象 function example() { return { foo: 1, bar: 2 }; } var { foo, bar } = example(); 函数参数的定义: 解构赋值可以方便地将一组参数与变量名对应起来。 // 参数是一组有次序的值 function f([x, y, z]) { ... } f([1, 2, 3]) // 参数是一组无次序的值 function f({x, y, z}) { ... } f({x:1, y:2, z:3}) 提取 JSON 数据 var jsonData = { id: 42, status: \"OK\", data: [867, 5309] } let { id, status, data: number } = jsonData; console.log(id, status, number) // 42, OK, [867, 5309] 函数参数的默认值 jQuery.ajax = function (url, { async = true, beforeSend = function () {}, cache = true, complete = function () {}, crossDomain = false, global = true, // ... more config }) { // ... do stuff }; 指定参数的默认值，就避免了在函数体内部再写var foo = config.foo || 'default foo'这样的语句。 遍历Map结构: 任何部署了Iterator接口的对象，都可以用for...of循环遍历。 var map = new Map(); map.set('first', 'hello'); map.set('second', 'world'); for (let [key, value] of map) { console.log(key + \" is \" + value); } // first is hello // second is world 如果只想获取键名，或者只想获取键值，可以写成下面这样。 // 获取键名 for (let [key] of map) { // ... } // 获取键值 for (let [,value] of map) { // ... } 输入模块的指定方法: 加载模块时，往往需要指定输入那些方法。解构赋值使得输入语句非常清晰。 const { SourceMapConsumer, SourceNode } = require(\"source-map\"); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/ES6/es6_getter_setter.html":{"url":"Javascript/ES6/es6_getter_setter.html","title":"es6_getter_setter","keywords":"","body":"1. ES2015 class getter setter1. ES2015 class getter setter class Rectangle { constructor (width, height) { this._width = width this._height = height } set width (width) { this._width = width } get width () { return this._width } set height (height) { this._height = height } get height () { return this._height } get area () { return this._width * this._height } } var r = new Rectangle(50, 20) r.area === 1000 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/ES6/forin_vs_forof.html":{"url":"Javascript/ES6/forin_vs_forof.html","title":"forin_vs_forof","keywords":"","body":"1. Difference between for...of and for...in1. Difference between for...of and for...in The for...in loop will iterate over all enumerable properties of an object. Note that if someone added new properties to Array.prototype, they will also be iterated over by this loop. Therefore this method is \"not\" recommended. The for...of syntax is specific to collections, rather than all objects. It will iterate in this manner over the elements of any collection that has a [Symbol.iterator] property. The following example shows the difference between a for...of loop and a for...in loop. Object.prototype.objCustom = function () {}; Array.prototype.arrCustom = function () {}; let iterable = [3, 5, 7]; iterable.foo = 'hello'; for (let i in iterable) { if (iterable.hasOwnProperty(i)) { console.log(i); // logs 0, 1, 2, \"foo\" } // console.log(i); // logs 0, 1, 2, \"foo\", \"arrCustom\", \"objCustom\" } for (let i of iterable) { console.log(i); // logs 3, 5, 7 } Using for of: for(let v of ['dog', 'cat', 'hen']) { // Do something }); Another way of iterating over an array that was added with ECMAScript 5 is forEach(): ['dog', 'cat', 'hen'].forEach(function(currentValue, index, array) { // Do something with currentValue or array[index] }); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/ES6/promise.html":{"url":"Javascript/ES6/promise.html","title":"promise","keywords":"","body":"1. Promise1.1. Promise 回调在 react 中的应用1.1.1. Promise 链1.1.2. Promise.all1.1.3. Promise.race1.1.4. demo1.2. reference1. Promise 1.1. Promise 回调在 react 中的应用 参见 React/SetStateAsync.md 在 react component 中经常需要执行一个函数去 setHigherLevelComponentState，而等到高层 component 状态更新完毕后去进行当前 component 的一些操作 高层 component： 通过 props 把该方法传给孩子 setOutlines(obj, actionType) { let outlines = [] switch (actionType) { case 'add': outlines = [...this.state.outlines, obj] break case 'edit': outlines = this.state.outlines.map(i => { if (i.id == obj.id) { return { ...i, ...obj } } else { return i } }) break case 'delete': outlines = this.state.outlines.filter(item => item.id != obj.id) break default: break } return new Promise((resolve, reject) => { this.setState({ outlines }, () => { resolve() }) }) } 低层 component： 在提交表单更新了 outlines 数据后，会 re-render，此时滚动滚动条到最低端看到刚添加的数据 submitAddForm() { this.props .setOutlines( { id: uid(), detail: this.addText.value }, 'add' ) .then(() => { console.log(this.mainBox.scrollTop, this.listBox.scrollHeight) this.mainBox.scrollTop = this.listBox.scrollHeight || 0 }) this.closeModal() } 1.1.1. Promise 链 function foo(result) { console.log(result) return result + result } let promise = new Promise((resolve, reject) => { try { setTimeout(() => { resolve('hello') }, 250) } catch (e) { reject(new Error('exception!')) } }) //手动链接 promise.then(foo).then(foo).then(foo) //控制台输出： hello // hellohello // hellohellohellohello //动态链接 var funcs = [foo, foo, foo] funcs.forEach(function(func) { promise = promise.then(func) }) //精简后的动态链接 var funcs = [foo, foo, foo] funcs.reduce(function(prev, current) { return prev.then(current) }, promise) // ----------------------- Promise 创建函数 -------------------------- let createPromise = para => new Promise((resolve, reject) => { setTimeout(function() { resolve(para) }, 250) }) //手动链接 createPromise('hello').then(foo).then(foo).then(foo) //控制台输出： hello // hellohello // hellohellohellohello //动态链接 var funcs = [foo, foo, foo] var temp = createPromise('hello') funcs.forEach(function(func) { temp = temp.then(func) }) // 精简后的动态链接 var funcs = [foo, foo, foo] funcs.reduce(function(prev, current) { return prev.then(current) }, createPromise('hello')) 1.1.2. Promise.all Promise.all([3, promise, foo]).then(res => console.log(res)).catch(reject => { console.log('err') }) // [ 3, 'hello', [Function: foo] ] 1.1.3. Promise.race Promise.race([3, promise, foo]).then(res => console.log(res)).catch(reject => { console.log('err') }) // 3 1.1.4. demo function msgAfterTimeout(msg, who, timeout) { return new Promise((resolve, reject) => { setTimeout(() => resolve(`${msg} Hello ${who}!`), timeout); }); } msgAfterTimeout('', 'Foo', 100).then((msg) => msgAfterTimeout(msg, 'Bar', 200)).then((msg) => { console.log(`done after 300ms:${msg}`); }); // done after 300ms: Hello Foo! Hello Bar! // ---Promise.all--- function fetchAsync(url, timeout, onData, onError) { // ... } let fetchPromised = (url, timeout) => { return new Promise((resolve, reject) => { fetchAsync(url, timeout, resolve, reject); }); }; Promise.all([ fetchPromised('http://backend/foo.txt', 500), fetchPromised('http://backend/bar.txt', 500), fetchPromised('http://backend/baz.txt', 500) ]).then( (data) => { let [ foo, bar, baz ] = data; console.log(`success: foo=${foo} bar=${bar} baz=${baz}`); }, (err) => { console.log(`error: ${err}`); } ); 1.2. reference 手写一个 promise：https://github.com/panyifei/Front-end-learning/blob/master/框架以及规范/Promise.md Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/ES6/proxying.html":{"url":"Javascript/ES6/proxying.html","title":"proxying","keywords":"","body":"1. Proxying1. Proxying // Meta-Programming // Hooking into runtime-level object meta-operations. let target = { foo: 'Welcome, foo' }; let proxy = new Proxy(target, { get(receiver, name) { return name in receiver ? receiver[name] : `Hello, ${name}`; } }); proxy.foo === 'Welcome, foo'; // true proxy.world === 'Hello, world'; // true Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/ES6/tail_call_optimization.html":{"url":"Javascript/ES6/tail_call_optimization.html","title":"tail_call_optimization","keywords":"","body":"1. 尾调优化 Tail call optimization (TCO)1.1. 尾递归1.1.1. 两个案例1.1.2. 编译器是怎样优化尾递归的1.2. 尾调用1. 尾调优化 Tail call optimization (TCO) 1.1. 尾递归 使用一个 accumulator 参数来保存之前的计算的结果。这样计算到 N 的时候，之前栈计算的内容，都是可以抛弃不用保存的。这就解决一个递归很重要的问题，即栈溢出。在尾递归中，之前计算的结果都已经积累并以参数的形式交给下一次操作了，之前的函数留存在栈上的数据都可以清空。 尾递归使递归在调用堆栈上不会产生堆积 。 缺点: 将思路转换为循环的思路导致可读性的下降，而可读性是传统递归最大的优点。 1.1.1. 两个案例 传统递归： // This is just a short reminder of this great explanation: // http://www.2ality.com/2015/06/tail-call-optimization.html // not TCO function factorial(n) { if (n factorial(6) 6 * factorial(5) 5 * factorial (4) 4 * factorial(3) 3 * factorial(2) 2 * factorial(1) 1 * factorial(0) 1 (resuming previous execution) 1 * 1 = 1 (resuming…) 2 * 1 = 2 (…) 3 * 2 = 6 … 4 * 6 = 24 5 * 24 = 120 6 * 120 = 720 factorial(6) = 720 call stack needs to keep the previous result for calculating the next. 每次重复的过程调用都使得调用链条不断加长，系统不得不使用栈进行数据保存和恢复。 尾递归： // TCO function factorial(n) { var result = recursiveFactorial(n, 1); console.log(result); } function recursiveFactorial(n, accumulator) { if (n factorial(6) inner anonymous function (recursiveFactorial) gets called with (n = 6, res = 1) recursiveFactorial(5, 1 * 6) recursiveFactorial(4, 6 * 5) recursiveFactorial(3, 30 * 4) recursiveFactorial(2, 120 * 3) recursiveFactorial(1, 360 * 2) recursiveFactorial(0, 720) 720 720 720 720 720 720 720 recursiveFactorial(6, 1) = 720 factorial(6) = 720 以 f(6) 为例，以上尾递归类似： var res = 1; var n = 6; while (n > 1) { res = res * n; n--; } 案例2： // 然后再用最著名的Fibonacci数列来举例，传统的递归是: function FibonacciRecursively(n) { return n 1.1.2. 编译器是怎样优化尾递归的 我们知道递归调用是通过栈来实现的，每调用一次函数，系统都将函数当前的变量、返回地址等信息保存为一个栈帧压入到栈中，那么一旦要处理的运算很大或者数据很多，有可能会导致很多函数调用或者很大的栈帧，这样不断的压栈，很容易导致栈的溢出。 尾递归的特性：函数在递归调用之前已经把所有的计算任务已经完毕了，他只要把得到的结果全交给子函数就可以了，无需保存什么，子函数其实可以不需要再去创建一个栈帧，直接在当前栈帧上把原先的数据覆盖即可。相对的，如果是普通的递归，函数在递归调用之前并没有完成全部计算，还需要调用递归函数完成后才能完成运算任务。比如return n * factorial(n - 1); 这句话，factorial(n) 在算完 factorial(n-1) 之后才能得到 n * factorial(n - 1) 的运算结果然后才能返回。 综上所述，尾递归的时候，不会去不断创建新的栈帧，而是在当前的栈帧上不断的去更新覆盖，一来防止栈溢出，二来节省了调用函数时创建栈帧的开销。 1.2. 尾调用 尾调用为 tail-call。尾递归也是一种尾调用，但是尾调用并不一定是尾递归。尾调用更广。 尾调用是指 一个函数的最后一个动作是一个函数调用 的情形。称这个调用位置为 尾位置 。如果尾位置调用这个函数自己，那才可以称为 尾递归 。 尾调用的重要性，在于它可以不在调用栈上面添加一个新的堆栈帧 call stack frame – 而是更新它。 当一个函数调用时，电脑必须记住调用函数的位置，即返回位置，才可以在调用结束时带着返回值回到该位置，返回位置一般存在调用栈上。在尾调用的情况下，电脑不需要记住尾调用的位置而是可以从被调用的函数直接带着返回值返回到调用函数的返回位置。尾调用消除即是在不改变当前调用栈的情况下调到新函数的一种优化。 尾调用优化就是以对尾调用这种情况，进行尾调用的消除，以不用添加新的堆栈，只是更新它，来提高效率。只有当某个函数的最后一个操作仅仅是调用其它函数，而不会将其函数返回值另作他用的情况下，进行尾调用优化。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/ES6/template_string_loop_json.html":{"url":"Javascript/ES6/template_string_loop_json.html","title":"template_string_loop_json","keywords":"","body":"1. ES6 模版字符串遍历 json 数据生成 table1. ES6 模版字符串遍历 json 数据生成 table // 上面代码中，模板字符串的变量之中，又嵌入了另一个模板字符串，使用方法如下。 const table = addresses => ` ${addresses.map(addr => ` ${addr.first} ${addr.last} `).join('') } ` const data = [ { first: 'Jane', last: 'Bond' }, { first: 'Lars', last: 'Croft' }, ]; console.log(table(data)); 最终生成： Jane Bond Lars Croft Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/gQuery.html":{"url":"Javascript/gQuery.html","title":"gQuery","keywords":"","body":"1. gQuery1. gQuery jquery原理 源码 核心架构 事件委托 插件机制：http://www.zhangxinxu.com/wordpress/2013/07/jquery-%E5%8E%9F%E7%90%86-%E6%9C%BA%E5%88%B6/ 原型上 有对于 string、array、math 工具方法。选择器。模板引擎。extend。通过 extend 又扩充了对事件的封装。 //定义一个对象 - 名字是$$ var $$ = function () {}; $$.prototype = { constructor: $$, init: function () { this.stringExtend(); this.MathExtend(); this.arrayExtend(); }, stringExtend: function () { String.prototype.formatString = function (data) { return this.replace(/@\\((\\w+)\\)/g, function (match, key) { return typeof data[key] === \"undefined\" ? '' : data[key]; }); }; /*trim是 ES5 新增的*/ String.prototype.trim = function () { return this.replace(/(^\\s*)|(\\s*$)/g, \"\"); }; /*字符串-去掉前空白字符 */ String.prototype.ltrim = function () { return this.replace(/(^\\s*)/g, \"\"); }; String.prototype.rtrim = function () { return this.replace(/(\\s*$)/g, \"\"); }; /* 将一个字符串的首字母大写，其它字符小写 */ String.prototype.capitalize = function () { return this .trim() .replace(/^(\\w{1})(.*)/g, function (match, g1, g2) { return g1.toUpperCase() + g2.toLowerCase(); }); }; /* 将字符串中的下划线转换成中划线 */ String.prototype.dashString = function () { return this.replace(/\\_/g, '-'); }; /* 检测字符串是否是空串 */ String.prototype.isEmpty = function () { return this.length === 0; }; /* 找到一个字符串中所有数字 console.log('a55fdaf455454sfdsfaf'.findNum()); */ String.prototype.findNum = function () { return this.match(/\\d+/g); }; /* 检测字符串是否包含特定的字符串 */ String.prototype.includes = function (target) { return this.indexOf(target) !== -1; }; /* 对字符串中的特殊字符进行转义，避免XSS */ String.prototype.escapeHTML = function () { // 转义后的字符是可以直接设置成innerHTML的值。 replace(/&/g, // '&amp;')这条replace()调用一定要写在所有的特殊字符转义的前面，不然转换后有&符号的会再被转一次 return this .replace(/&/g, '&amp;') .replace(/\\/g, '&gt;') .replace(/\\'/g, '&#39;') .replace(/\\\"/g, '&quot;'); /*var strArr = this.split(''); for(var pos = 0, l = strArr.length, tmp; pos ': replaceArr(strArr, pos, '&gt;'); break; case '\\'': replaceArr(strArr, pos, '&#39;'); break; case '\\\"': replaceArr(strArr, pos, '&quot;'); break; case '&': replaceArr(strArr, pos, '&amp;'); break; default:; } } return strArr.join(''); function replaceArr(arr, pos, item) { return arr.splice(pos, 1, item); }*/ }; /* 对字符串进行反转义 */ String.prototype.unescapeHTML = function () { return this .replace(/&amp;/, '&') .replace(/&lt;/g, '') .replace(/&#39;/g, '\\'') .replace(/&quot;/g, '\\\"') .replace(/&#(\\d+)/g, function ($0, $1) { return String.formCharCode(parseInt($1, 10)); }); }; String.prototype.reverse = function () { return (this.toString()) .split('') .reverse() .join(''); }; }, arrayExtend: function () { /* 将数组清空，并返回这个数组的引用*/ Array.prototype.clear = function () { this.length = 0; return this; }; /* 返回数组第一项*/ Array.prototype.first = function () { return this[0]; }; /* 返回数组最后一项*/ Array.prototype.last = function () { return this[this.length - 1]; }; /*计算类*/ function calc(arr, callback) { var ret; for (var i = 0; i item)) { return item; } else { return max; } }); }; Array.prototype.min = function () { return calc(this, function (item, min) { if (!(min = 0; --i) { callbackRet = callback.call(null, callbackRet, this[i], i, this); } return callbackRet; }; /** * 返回目标值在数组中第一次出现的位置，搜索从左向右进行。 * 如果目标值在数组中不存在，则返回-1。可以指定一个搜索起始位置。默认为0 */ Array.prototype.indexOf = function (target, start) { var l = this.length, start = ~~start; //可以指定一个搜索起始位置。默认为0。start不传，默认为undefined,~~undefined -> 0 if (start = 0; --start) { if (this[start] === target) return start; } return -1; }; /** * 对于单一类型的数组，可以使用此方法去重。 * 但这类数组：[ 'ff', 1, '1' ]会去重失败 */ Array.prototype.enhanceUnique = function () { var ret = [], tempMap = {}, temp, i = 0, l = this.length, undef = void 0; for (; i 1 Math.ceil():向上取整。Math.ceil(1.1) -> 2 v // = Math.random() * n:会产生一个 0 = 200 && xhr.status data[time].找到以@开头的字符串，然后用数据替换@之后同名数据 var user // = { \"name\": \"guanghui\" }; console.log(formateString(\"欢迎@(name)来到百度世界\", // user)); formatString: function (str, json) { return str.replace(/@\\((\\w+)\\)/g, function (match, key) { return typeof json[key] === \"undefined\" ? '' : json[key]; }); }, //arttemplate语法 bindTemplate: function (json, renderContainerId, tempId) { document.getElementById(renderContainerId).innerHTML = template(tempId, json); }, artTemplate: function (id, html, json) { var render = template.compile(html); document.getElementById(id).innerHTML = render(json); }, //给一个对象扩充功能 extendMany: function () { var key, i = 0, len = arguments.length, target = null, copy; if (len === 0) { return; } else if (len === 1) { target = this; } else { i++; target = arguments[0]; } for (; i Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/inheritance升级版composition.html":{"url":"Javascript/inheritance升级版composition.html","title":"inheritance升级版composition","keywords":"","body":"1. aggregation composition 组合1. aggregation composition 组合 组合比继承好啊。下面的例子，生成了一个三维的带颜色的立方体。如果用继承做，需在继承类中写三维和颜色代码，但三维和颜色并没有抽离出来。如果又有个圆形希望变成三维和带颜色，又要在继承类中写三维和颜色代码。和立方体的代码不方便维护。 // npm install aggregation var aggregation = require('aggregation/es6'); var aggregation = (baseClass, ...mixins) => { let base = class _Combined extends baseClass { constructor(...args) { super(...args); mixins.forEach((mixin) => { mixin.prototype.initializer.call(this); }); } }; let copyProps = (target, source) => { Object.getOwnPropertyNames(source).concat(Object.getOwnPropertySymbols(source)).forEach((prop) => { if (prop.match(/^(?:constructor|prototype|arguments|caller|name|bind|call|apply|toString|length)$/)) return; Object.defineProperty(target, prop, Object.getOwnPropertyDescriptor(source, prop)); }); }; mixins.forEach((mixin) => { copyProps(base.prototype, mixin.prototype); copyProps(base, mixin); }); return base; }; 具体使用： class Colored { initializer() { this._color = 'white'; } get color() { return this._color; } set color(v) { this._color = v; } } class ZCoord { initializer() { this._z = 0; } get z() { return this._z; } set z(v) { this._z = v; } } // base class class Shape { constructor(x, y) { this._x = x; this._y = y; } get x() { return this._x; } set x(v) { this._x = v; } get y() { return this._y; } set y(v) { this._y = v; } } // Shape is base. Colored, ZCoord are features class Rectangle extends aggregation(Shape, Colored, ZCoord) {} var rect = new Rectangle(7, 42); rect.z = 1000; rect.color = 'red'; console.log(rect.x, rect.y, rect.z, rect.color); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/inheritance继承.html":{"url":"Javascript/inheritance继承.html","title":"inheritance继承","keywords":"","body":"1. Inheritance(继承)1.1. Compose Inheritance1.1.1. example 11.1.2. example 21.1.3. example 31.1.4. ES2015 class extends1. Inheritance(继承) 1.1. Compose Inheritance 1.1.1. example 1 prop in function, method in prototype // Base var Person = function(name, age) { this.name = name; this.age = age; }; Person.prototype = { constructor: Person, say: function() { console.log('Hello Everyone!'); } }; // 学生类,继承自人 var Student = function(name, age, lesson) { Person.call(this, name, age); //继承了构造器属性 // Person.apply(this, arguments); this.lesson = lesson; }; Student.prototype = new Person(); //继承了Person.prototype Student.prototype.getTeacher = function() { console.log('Mr Zhang'); }; //使用 var xiaoWang = new Student('wang', 20, 'javascript'); var xiaoLi = new Student('li', 30, 'javascript'); console.log(xiaoWang.name); //wang console.log(xiaoWang.age); //20 console.log(xiaoWang.lesson); //javascript console.log(xiaoLi.name); //li xiaoWang.say(); //'Hello Everyone!' xiaoLi.say(); //'Hello Everyone!' console.log(xiaoWang.say === xiaoLi.say); //true console.log(xiaoWang.getTeacher === xiaoLi.getTeacher); //true 1.1.2. example 2 // 教师类,继承自人 var Teacher = function(name, age, subject) { Person.call(this, name, age); this.subject = subject; }; Teacher.prototype = new Person(); Teacher.prototype.giveLecture = function() { console.log('网页平面'); }; //使用 var tc = new Teacher('zhang', 25, 'javascript'); console.log(tc.name); //zhang console.log(tc.age); //25 console.log(tc.subject); //javascript tc.giveLecture(); //网页平面 tc.say(); //'Hello Everyone!' console.log(tc.say === xiaoWang.say); //true 1.1.3. example 3 //定义产品对象 function Base() { /*产品名称*/ this.name = ''; /*普通价格*/ this.normalPrice = 144; /*团购价格*/ this.youhuijia = 120; /*已经购买的人数*/ this.buySum = 100; /*轮播图片列表*/ this.images = []; } Base.prototype = { Constructor: Base, /*普通购买*/ buy: function () {}, /*绑定图片列表*/ bindDOMImage: function () { var str = ''; for (var i = 0, len = this.images.length; i '; str += ''; str += ''; str += ''; } $('#etalage').html(str); /*jquery插件实现的幻灯片特效*/ $('#etalage').etalage({thumb_image_width: 250, thumb_image_height: 300}); }, /*绑定详细信息*/ bindDOMDetail: function () {}, /*绑定事件*/ bindEvents: function () {}, /*团购*/ groupBuy: function () {}, /*添加到购物车*/ addCart: function () {} }; //继承的固定格式 /*构造函数中写法*/ var Book = function () { Base.call(this, arguments); this.author = '糖葫芦'; this.publisher = '清华大学出版社'; this.pages = 333; this.publishTimes = 2; this.type = 'IT教育'; this.publishTime = '2016-09-09'; }; /*原型写法*/ Book.prototype = new Base(); /*重写 覆盖基类方法*/ Book.prototype.bindDOMDetail = function () { var str = ''; str += '' + this.name + ''; str += ''; str += '' + this.buySum + '人购买'; str += ''; str += ''; str += ''; str += '$' + this.normalPrice + ''; str += '$' + this.youhuijia + ''; str += '优惠价'; str += ''; str += '作者:'; str += '' + this.author + ''; str += '出版日期:'; str += '' + this.publishTime + ''; str += '出版社:'; str += '' + this.publisher + ''; str += '页数:'; str += '' + this.pages + ''; str += '分类:'; str += '' + this.type + ''; $('.bookdetail').html(str); }; //Book.prototype.constructor = Book; Book.prototype.readTry = function () {}; Book.prototype.readAll = function () {}; /*不能使用如下写法，因为这个写法相当于重新定义一个原型对象*/ //Book.prototype = {} 1.1.4. ES2015 class extends // es6 class Point { constructor(x, y) { this.x = x; this.y = y; } } class ColorPoint extends Point { constructor(x, y, color) { // this.color = color; // ReferenceError super(x, y); this.color = color; // 正确 } } // 子类的 constructor 方法没有调用 super 之前就使用 this 关键字会报错，而放在 super 方法之后就是正确的。 // 下面是生成子类实例的代码。 let cp = new ColorPoint(25, 8, 'green'); console.log(cp.x); console.log(cp.y); console.log(cp.color); 原文地址 http://es6.ruanyifeng.com/ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/oop.html":{"url":"Javascript/oop.html","title":"oop","keywords":"","body":"1. OOP(面向对象)1. OOP(面向对象) function ClassName() { this.doms = { lastOnline: document.querySelector('.lastOnline'), indicator: document.querySelector('.indicator'), indicatorModal: document.querySelector('.indicator-modal') }; this.doms.indicatorTable = this.doms.indicatorModal.querySelector('table'); this.doms.thead = this.doms.indicatorTable.tHead; this.doms.tbody = this.doms.indicatorTable.tBodies[0]; this.init(); } ClassName.prototype = { constructor: ClassName, init: function() { this.loadData(); this.bindEvents(); }, setModalPosition: function(dom) { var indicatorPosition = getPosition(dom.indicator); dom.indicatorModal.style.left = indicatorPosition.left - dom.indicatorModal.offsetWidth + dom.indicator.offsetWidth + 'px'; dom.indicatorModal.style.top = indicatorPosition.top + dom.indicator.offsetHeight + 10 + 'px'; }, setIndicatorColor: function(date) {}, loadData: function() { var instance = this; var href = location.href; // load modal window detail ajax('get', href.slice(0, href.lastIndexOf('/')) + '/data/indicator.json', '', function(data) { instance.bindIndicatorModalDOM(data); }); }, bindIndicatorModalDOM: function(data) { var instance = this; var strHead = ''; var strBody = ''; strHead += '' + data.head[0] + '' + data.head[1] + '' + data.head[2] + ''; for (var i = 0; i ' + data.body[i].product + '' + data.body[i].lastActiveDate + ''; } instance.doms.thead.innerHTML = strHead; instance.doms.tbody.innerHTML = strBody; this.bindToolip(); }, bindEvents: function() { var indicatorTimer = null; var indicatorModalTimer = null; var instance = this; var dom = this.doms; dom.indicator.onmouseenter = function() { //hold on .5s to display indicatorTimer = setTimeout(function() { dom.indicatorModal.style.display = 'block'; instance.setModalPosition(dom); }, 500); }; dom.indicator.onmouseleave = function() { clearTimeout(indicatorTimer); indicatorModalTimer = setTimeout(function() { dom.indicatorModal.style.display = 'none'; }, 500); }; dom.indicatorModal.onmouseenter = function() { //fast move from icon to modal window, keep modal open clearTimeout(indicatorModalTimer); dom.indicatorModal.style.display = 'block'; }; dom.indicatorModal.onmouseleave = function() { clearTimeout(indicatorModalTimer); dom.indicatorModal.style.display = 'none'; }; }, bindToolip: function() { var activityTR = this.doms.indicatorModal.querySelectorAll('.activity'); for (var i = 0; i Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/plugins/":{"url":"Javascript/plugins/","title":"Javascript/plugins","keywords":"","body":"1. TOC1. TOC Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Javascript/plugins/pagination/":{"url":"Javascript/plugins/pagination/","title":"Javascript/plugins/pagination","keywords":"","body":"1. TOC1. TOC pagination分页 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Javascript/plugins/pagination/pagination分页.html":{"url":"Javascript/plugins/pagination/pagination分页.html","title":"pagination分页","keywords":"","body":"1. 分页1.1. pagination code1.2. pagination css1.3. pagination usage1.4. pagination html1.5. pagination test data1. 分页 1.1. pagination code // 求得页码总数，需要Math.ceil(totalCount/pageSize) /*使用方法： window.onload = function() { pagination({ id: 'pagination', pageIndex: 1, // 当前要显示页面，1开始 pageSize: 4, // 每页显示条数 totalCount: data.length, // 总数据个数， 总页码pageCount = Math.ceil(totalCount/pageSize) callBack: function(currentPageIndex, pageSize, totalPageCount) { //分页标签加载完毕后执行 // alert('当前页:' + currentPageIndex + ',总共页:' + totalPageCount); loadData(currentPageIndex, pageSize); }， aClick: function(targetA) { //点击某个a执行 targetA.style.opacity = 0.1; }, delayTime: 500 //点击某个a后延迟500ms，再重新call page() }); }; */ /* 首页 上一页 [2] [3] 4 [5] [6] 下一页 尾页 */ function pagination(pageInfo) { if (!pageInfo.id) { return false; } // -------------------------分页链接生成 开始----------------------------------- var paginationObj = document.getElementById(pageInfo.id); paginationObj.innerHTML = ''; // 清空 var pageIndex = pageInfo.pageIndex || 1; var pageSize = pageInfo.pageSize || 5; var pageCount = Math.ceil(pageInfo.totalCount / pageSize); var callBack = pageInfo.callBack || function () {}; var aClick = pageInfo.aClick || function () {}; var delayTime = pageInfo.delayTime || 0; if (pageIndex >= 4 && pageCount >= 6) { var oA = document.createElement('a'); oA.href = '#1'; oA.innerHTML = '首页'; paginationObj.appendChild(oA); } if (pageIndex >= 2) { var oA = document.createElement('a'); oA.href = '#' + (pageIndex - 1); oA.innerHTML = '上一页'; paginationObj.appendChild(oA); } if (pageCount = 1) { var oA = document.createElement('a'); oA.href = '#' + (pageIndex + 1); oA.innerHTML = '下一页'; paginationObj.appendChild(oA); } if (pageCount - pageIndex >= 3 && pageCount >= 6) { var oA = document.createElement('a'); oA.href = '#' + pageCount; oA.innerHTML = '尾页'; paginationObj.appendChild(oA); } // --------------------------------分页链接生成 结束------------------------------ // 加载完分页表前后执行函数 callBack(pageIndex, pageSize, pageCount, paginationObj); /* 添加点击事件（传统） var aA = paginationObj.getElementsByTagName('a'); for (var i = 0; i Pasted from https://bitbucket.org/snippets/wghglory/7j6px/js_pagination 1.2. pagination css #pagination { line-height: 36px; display: flex; height: 36px; border-radius: 4px; background-color: #fff; box-shadow: 0 6px 10px rgba(0, 0, 0, 0.1); justify-content: center; align-items: center; } #pagination a { line-height: 24px; height: 24px; margin: 0 4px; padding: 0 10px; border-radius: 2px; background: linear-gradient(to bottom, #f0ece6, #e5ddda) no-repeat #d5ccc8; box-shadow: 0 1px 0 rgba(111, 89, 79, 0.4); color: #5a5a5a; text-decoration: none; } #pagination a.active { color: #fff; background-image: none; /* remove gradient and use #d5ccc8*/ box-shadow: inset 0 1px 3px rgba(111, 89, 79, .4), 0 1px 0 rgba(111, 89, 79, 0.4); } Pasted from https://bitbucket.org/snippets/wghglory/7j6px/js_pagination 1.3. pagination usage function loadData(pageIndex, pageSize) { //click first page, pageIndex = 1, not 0 based var messageListHtml = ''; var pageSize = pageSize || 5; var startIndex = (pageIndex - 1) * pageSize; //starting data var endIndex = startIndex + pageSize; //ending data endIndex = endIndex > data.length ? data.length : endIndex; for (var i = startIndex; i ' + data[i].post.username + '[' + formatDate(data[i].post.time) + ']' + data[i].post.content + ''; for (var r in data[i].replies) { messageListHtml += '' + data[i].replies[r].username + '[' + formatDate(data[i].replies[r].time) + ']' + data[i].replies[r].content + ''; } messageListHtml += ''; } messageUl.innerHTML = messageListHtml; } Pasted from https://bitbucket.org/snippets/wghglory/7j6px/js_pagination 1.4. pagination html pagination demo 用封装的分页控件 分页先入场，然后li入场。点击分页，分页先隐藏，li消失，分页入场，li入场 留言回复 You're very busying![2016-07-18 20:48:22] 学习课程 管理员回复[2016-07-14 17:57:49] 我不受si~~ 管理员回复2[2016-07-16 18:16:43] this is good --> 首页 上一页 1 2 3 4 5 6 下一页 末页 --> pagination({ id: 'pagination', pageIndex: 1, // 当前要显示页面，1开始 pageSize: 6, // 每页显示条数 totalCount: data.length, // 总数据个数， 总页码pageCount = Math.ceil(totalCount/pageSize) callBack: function(currentPageIndex, pageSize, totalPageCount, paginationObj) { // alert('当前页:' + currentPageIndex + ',总共页:' + totalPageCount); // for (var i = 0; i Pasted from https://bitbucket.org/snippets/wghglory/7j6px/js_pagination 1.5. pagination test data var data = [{ \"post\": { \"id\": 5, \"username\": \"different user name\", \"title\": \"this will be title\", \"time\": new Date(\"July 17, 2016 14:10:05\"), \"content\": \"First DATA...\" }, \"replies\": [] }, { \"post\": { \"id\": 1, \"username\": \"different user name\", \"title\": \"this will be title\", \"time\": new Date(\"July 17, 2016 14:10:05\"), \"content\": \"学习课程，学习js\" }, \"replies\": [{ \"id\": 2, \"username\": \"different user name\", \"title\": \"this will be title\", \"time\": new Date(\"July 17, 2016 14:10:05\"), \"content\": \"好好学习，天天做出好东西\" }, { \"id\": 1, \"username\": \"different user name\", \"title\": \"this will be title\", \"time\": new Date(\"July 17, 2016 14:10:05\"), \"content\": \"又回复\" } ] } ]; Pasted from https://bitbucket.org/snippets/wghglory/7j6px/js_pagination Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/reduce.html":{"url":"Javascript/reduce.html","title":"reduce","keywords":"","body":"1. javascript array.reduce1.1. map is 阉割版的 reduce1. javascript array.reduce We often need to take a list of things and convert that into just one item - whether an integer, an object, or another array. var scores = [89, 76, 47, 95] var initialValue = 0 var reducer = function (accumulator, item) { return accumulator + item } var total = scores.reduce(reducer, initialValue) var average = total / scores.length You'll notice .reduce takes in two values, a callback function and an initial value. The callback (reducer) function has two parameters. The first time the reducer function is called, it's going to be passed the initialValue you gave it (the 2nd argument to .reduce) and the first item in the actual array. So in our example above the first time that our reducer function runs, accumulator is going to be 0 and item is going to be 89. Remember, the goal is to transform an array into a single value. We currently have two numbers, 0 and 89, and are goal is to get that to one value. Because we're wanting to find the sum of every item in the array, we'll add 89 + 0 to get 89. That brings up a very important step. The thing that gets returned from the reducer function will then be passed as the accumulator the next time the function runs. So when reducer runs again, accumulator will be 89 and item will now be the second item in the array, 76. This pattern continues until we have no more items in the array and we get the summation of all of our reducer functions, which is 307. .reduce can be used for more than transforming an array of numbers. It's all about that initialValue that you pass to reduce. If you want the end result to be an object (therefore converting an array into an object), have the initialValue be an object and add properties to that object as you go. Here's an example of how you would do that below. You have an array of foods and you want to transform that to an object whose keys are the food itself and whose values are how many votes that food received. var votes = [ 'tacos', 'pizza', 'pizza', 'tacos', 'fries', 'ice cream', 'ice cream', 'pizza' ]; var initialValue = {} var reducer = function(tally, vote) { if (!tally[vote]) { tally[vote] = 1; } else { tally[vote] = tally[vote] + 1; } return tally; } var result = votes.reduce(reducer, initialValue) // {tacos: 2, pizza: 3, fries: 1, ice cream: 2} In our api.js, getStarCount will sum up each repo's star: function getStarCount(repos) { return repos.data.reduce(function (count, repo) { return count + repo.stargazers_count }, 0); } 1.1. map is 阉割版的 reduce // map const keys = arr.map((p) => p.key); //reduce const keys = arr.reduce((accu, current) => { return [...accu, current.key]; }, []); 现在 arr 里面有个 categoryId，在他 =1 的时候我不想获取值，希望进行下次循环 const keys = products[0].analysis.reduce((accu, current) => { if (current.categoryId === 1) return accu else { return [...accu, current.key] } }, []) const values = product.analysis.reduce((accu, current, index) => { if (current.categoryId === 1) return accu return [ ...accu, { analysisId: current.analysisId, yaosu: current.key, y: current.value, productId: product.id, productName: product.name } ] }, []) Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/throttle_debounce_immediate.html":{"url":"Javascript/throttle_debounce_immediate.html","title":"throttle_debounce_immediate","keywords":"","body":"1. throttle debounce 两种优化技巧1.1. 总结1. throttle debounce 两种优化技巧 resize 当节点尺寸发生变化时，触发这个事件。通常用在 window 上，这样可以监听浏览器窗口的变化。通常用在复杂布局和响应式上。出于对性能的考虑，你可以使用函数 throttle 或者 debounce 技巧来进行优化。 throttle: 某一段时间内无论多次调用，只执行一次函数，到达时间就执行。预先设定一个执行周期，当调用动作的时刻大于等于执行周期则执行该动作，然后进入下一个新周期。好比一台自动的饮料机，按拿铁按钮，在出饮料的过程中，不管按多少这个按钮，都不会连续出饮料，中间按钮的响应会被忽略，必须要等这一杯的容量全部出完之后，再按拿铁按钮才会出下一杯。 debounce: 某一段时间内等待是否还会重复调用，如果不会再调用，就执行函数；如果还有重复调用，则不执行继续等待。如果用手指一直按住一个弹簧，它将不会弹起直到你松手为止。也就是说当调用动作n毫秒后，才会执行该动作，若在这n毫秒内又调用此动作则将重新计算执行时间。一部电梯停在某一个楼层，当有一个人进来后，20秒后自动关门，这20秒的等待期间，又一个人按了电梯进来，这20秒又重新计算，直到电梯关门那一刻才算是响应了事件。 1.1. 总结 当有持续性动作的时候，Throttle 降低频率持续性触发，而 Debounce 和 Immediate 只会触发一次，且 Debounce 在动作之后触发，Immediate 在动作之前触发。 /* 每次清除之前的定时器，开启新的定时任务，如果规定时间 delta 内再次运行，继续清计时器。直到时间超过规定时间，执行任务 */ function debounce(fn, delta, context) { var timeoutID = null; return function () { clearTimeout(timeoutID); var args = arguments; timeoutID = setTimeout(function () { fn.apply(context, args); }, delta); }; } function immediate(fn, delta, context) { var timeoutID = null; var safe = true; return function () { var args = arguments; if (safe) { fn.call(context, args); safe = false; } clearTimeout(timeoutID); timeoutID = setTimeout(function () { safe = true; }, delta); }; } /* 首次执行，且立马标记 safe = false。开启定时器，规定时间到了后标记重置，所以规定时间内又想执行无效 */ function throttle(fn, delta, context) { var safe = true; return function () { var args = arguments; if (safe) { fn.call(context, args); safe = false; setTimeout(function () { safe = true; }, delta); } }; } // alternate implementation function throttleRender(fn, delta, context) { return function () { var args = arguments; var then = 0; function repeat(now) { requestAnimationFrame(repeat); if (now - then >= delta) { then = now; fn.call(context, args); } } requestAnimationFrame(repeat); }; } /** * 具体使用： */ document.addEventListener( \"mousemove\", throttle(() => console.log(\"throttle\"), 1000) ); document.addEventListener( \"mousemove\", debounce(() => console.log(\"debounce\"), 1000) ); document.addEventListener( \"mousemove\", immediate(() => console.log(\"immediate\"), 1000) ); https://zhirzh.github.io/2016/10/20/timing-controls-3 https://css-tricks.com/debouncing-throttling-explained-examples/ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/webworker.html":{"url":"Javascript/webworker.html","title":"webworker","keywords":"","body":"1. Web Worker1.1. Web worker demo1.2. reference1. Web Worker A web worker is a JavaScript that runs in the background, independently of other scripts, without affecting the performance of the page. You can continue to do whatever you want: clicking, selecting things, etc., while the web worker runs in the background. 1.1. Web worker demo // demo_workers.js var i = 0; function timedCount() { i = i + 1; postMessage(i); setTimeout(timedCount, 500); } timedCount(); Count numbers: Start Worker Stop Worker var w; function startWorker() { if(typeof(Worker) !== \"undefined\") { if(typeof(w) == \"undefined\") { w = new Worker(\"demo_workers.js\"); } w.onmessage = function(event) { document.getElementById(\"result\").innerHTML = event.data; }; } else { document.getElementById(\"result\").innerHTML = \"Sorry! No Web Worker support.\"; } } function stopWorker() { w.terminate(); w = undefined; // can reuse the Web Worker when calling startWorker() again } 1.2. reference https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/XMLHttpRequest.html":{"url":"Javascript/XMLHttpRequest.html","title":"XMLHttpRequest","keywords":"","body":"1. XMLHttpRequest1.1. 接收响应1.2. 解码响应1.3. 对请求正文进行编码1.3.1. Form-encoded 请求1.3.2. JSON编码的请求1.3.3. 上传文件1.3.4. multipart/form-data 请求1.4. HTTP 进度事件1.5. 上传进度事件1.6. 放弃请求与超时1. XMLHttpRequest readyState: 表示请求状态的整数，取值: UNSENT（0）: 对象已创建 OPENED（1）: open()成功调用，在这个状态下，可以为xhr设置请求头，或者使用send()发送请求 HEADERS_RECEIVED(2): 所有重定向已经自动完成访问，并且最终响应的HTTP头已经收到 LOADING(3): 响应体正在接收 DONE(4): 数据传输完成或者传输产生错误 onreadystatechange: readyState改变时调用的函数 status: 服务器返回的HTTP状态码（如，200， 404） statusText: 服务器返回的HTTP状态信息（如，OK，No Content） responseText: 作为字符串形式的来自服务器的完整响应 responseXML: Document对象，表示服务器的响应解析成的XML文档 abort(): 取消异步HTTP请求 getAllResponseHeaders(): 返回一个字符串，包含响应中服务器发送的全部HTTP报头。每个报头都是一个用冒号分隔开的名/值对，并且使用一个回车/换行来分隔报头行 getResponseHeader(headerName): 返回headName对应的报头值 open(method, url, asynchronous [, user, password]): 初始化准备发送到服务器上的请求。method 是 HTTP 方法，不区分大小写；url 是请求发送的相对或绝对 URL；asynchronous表示请求是否异步；user 和 password 提供身份验证 setRequestHeader(name, value): 设置HTTP报头 send(body): 对服务器请求进行初始化。参数body包含请求的主体部分，对于POST请求为键值对字符串；对于GET请求，为null XMLHttpRequest 是用于 HTTP 协议的，因此 FTP 或 file: 协议不能使用 XMLHttpRequest。 setRequestHeader 有一些请求头是你不能指定的。XMLHttpRequest 会帮你设定。不能通过 setRequestHeader() 指定的头有: Accept-Charset Accept-Encoding Connection Content-Length Cookie Cookie2 Content-Transfer-Encoding TE Date Trailer Expect Transfer-Encoding Host Upgrade Keep-Alive User-Agent Referer Via function postMessage(msg) { var request = new XMLHttpRequest(); // New request request.open(\"POST\", \"/log.php\"); request.setRequestHeader(\"Content-Type\", \"text/plain;charset=UTF-8\"); // 必须在 `open()` 后、 `send()` 之前调用 request.send(msg); // The request is done. We ignore any response or any error. } 1.1. 接收响应 通过 XMLHttpRequest 对象的属性或方法获取响应的信息: status 和 statusText 分别以数字和文本形式返回 HTTP 状态，如 200 和 “OK”。 响应头可以通过 getResponseHeader() 和 getAllResponseHeaders() 获取。 XMLHttpRequest 会自动处理 cookies，因此当你传 “Set-Cookie” 或 “Set-Cookie2” 给 getResponseHeader() 得到的是 null。 responseText 是响应的字符串形式，responseXML 是文档形式。 XMLHttpRequest 一般是异步的。send() 方法调用后立即返回。表示响应的属性和方法要等到收到响应后才有效。要判断响应是否就绪，需要监听 readystatechange 事件（或 XHR2 progress 事件）。 readyState 属性是一个整数，表示 HTTP 请求的状态。规范定义了一些常量，但老的浏览器，包括 IE8 未定义，因此很多时候直接使用数字。 UNSENT 或 0:open() 尚未被调用 OPENED 或 1:open() 已经被调用 HEADERS_RECEIVED 或 2:头部已经收到 LOADING 或 3:响应正文正在被接收 DONE 或 4:响应完成 理论上，每当 readyState 属性改变都会触发 readystatechange 事件。实际中，readyState 变到 0 或 1 可能不触发。send() 调用后一般会触发一次，即使 readyState 仍为 OPENED。一些浏览器在 LOADING 状态会触发多个事件，算进度反馈。所有浏览器当状态变为 4 时都会触发 readystatechange。 监听 readystatechange 事件的方法是设置 XMLHttpRequest 对象的 onreadystatechange 属性。也可以用 addEventListener()。 function getText(url, callback) { var request = new XMLHttpRequest(); request.open(\"GET\", url); request.onreadystatechange = function() { if (request.readyState === 4 && request.status === 200) { var type = request.getResponseHeader(\"Content-Type\"); if (type.match(/^text/)) callback(request.responseText); } }; request.send(null); // Send the request now } 1.2. 解码响应 响应若是文本，可以通过 responseText 属性获取。 如果服务器发送的是 XML 或 XHTML 文档，你可以通过 responseXML 属性获取解析后的版本。该属性的值是一个 Document 对象。 服务器还可以响应结构化的数据，如 JSON 编码的字符串。只能用 JSON.parse() 解析 responseText 了。 服务器可能响应二进制数据（如图片）。responseText 属性只用于文本，不能用于处理二进制响应。XHR2 定义了一种处理二进制响应的方法，但目前尚没有浏览器支持。 如果服务器响应未设置正确的 MIME 类型，XMLHttpRequest 对象不会解析并设置 responseXML 属性。如果服务器错误的设置了 content-type 的 charset 参数， XMLHttpRequest 解码会出错。为此，XHR2 定义了一个 overrideMimeType() 方法，你如果你知道响应的 MIME，在调用 send() 前调用 overrideMimeType()，让 XMLHttpRequest 忽略响应的 content-type 头。 // Don't process the response as an XML document request.overrideMimeType(\"text/plain; charset=utf-8\") 1.3. 对请求正文进行编码 1.3.1. Form-encoded 请求 编码表单数据的方法是:对每个表单项的键与值分别进行正常的 URI 编码（特殊字符由十六进制字符替代），用等号分割键值、用 & 分割表单项: find=pizza&zipcode=02134&radius=1km 这种格式的数据的 MIME 为:application/x-www-form-urlencoded。当你发送这类数据时，必须将请求头 Content-Type 设为该值。 把一个对象按表单编码: function encodeFormData(data) { if (!data) return ''; var pairs = []; for (var name in data) { if (!data.hasOwnProperty(name)) continue; if (typeof data[name] === 'function') continue; var value = data[name].toString(); name = encodeURIComponent(name.replace(' ', '+')); value = encodeURIComponent(value.replace(' ', '+')); pairs.push(name + '=' + value); } return pairs.join('&'); } 表单编码的数据还可以用于 GET 请求，附加到 GET 请求的查询串上: request.open(\"GET\", url + \"?\" + encodeFormData(data)); 1.3.2. JSON编码的请求 request.send(JSON.stringify(data)); 1.3.3. 上传文件 HTTP 表单总是能发送文件。但直到最近，XHR2 API 才允许通过传 File 对象到 send() 方法上传文件。 获得 File 对象的方法。 元素有一个 files 属性，是一个类数组的对象，含有 File 对象。拖放 API 通过 dataTransfer.files 属性提供类似结构。 File 类型是 Blob 的子类型。XHR2 实际允许通过 send() 方法发送任何 Blob 对象。若你不显式设置，Blob 的 type 属性会被用于设置 Content-Type。如果你要上传二进制数据，可以将其转换为 Blob 后上传。 1.3.4. multipart/form-data 请求 若表单既有文件又有其他元素，浏览器无法使用普通的表单编码，要使用一种特殊的 Content-Type: multipart/form-data。这种编码使用一个较长的边界字符串将请求分割成多个部分。 XHR2 定义了一个新的 FormData API，使得发送 multipart 请求变得简单。首先通过 FormData() 构造器创建 FormData 对象。然后通过 append() 方法添加一个个 “parts”，可以是字符串、File 或 Blob 对象。最后将 FormData 对象传入 send() 方法。 1.4. HTTP 进度事件 XHR2 草案定义了一个新的事件模型。多数现代浏览器支持。使用新的事件模型后就不必再使用 readyState 属性判断请求状态了。 触发顺序如下。当 send() 被调用，触发 loadstart 事件。在服务器响应下载的过程中 而不是上传过程中！！， XMLHttpRequest 触发多个 progress 事件，一般每 50 毫秒一次。请求完成后，触发 load 事件。 完成的请求不一定成功。load 事件的处理器需要检查返回的状态码。有三种可能的错误。若请求超时，触发 timeout 事件。若请求被放弃，触发 abort 事件。其他错误，如“太多重定向），触发 error 事件。 对于一个请求，load、 abort、 timeout 和 error 这四个事件，浏览器只会触发其中一个。XHR2 草案规定上述四个事件触发后，要再触发一个 loadend 事件。 可以通过 XMLHttpRequest 的 addEventListener() 方法注册这些事件的处理器。若只需要一个处理器，可以设置相应的处理器属性，如 onprogress、 onload 等。 进度事件的事件对象，除了一般 Event 对象的属性，如 type、timestamp。 loaded 属性是已传输的字节数。 total 属性是要传输的总的字节数，来自 Content-Length 头。若响应没有该头，该值为 0。lengthComputable 属性，布尔，用于判断到底知不知道响应的长度。 上述是下载的传输，而不是指上传的传输 这几个属性对于计算已加载的百分比: request.onprogress = function(e) { if (e.lengthComputable) progress.innerHTML = Math.round(100*e.loaded/e.total) + \"% Complete\"; } 1.5. 上传进度事件 XHR2 允许监控上传 HTTP 请求的进度。XMLHttpRequest 的 upload 属性是一个对象，有自己的 addEventListener() 方法，以及进度事件属性，如 onprogress 和 onload。 例如，对于一个 XMLHttpRequest 对象 x，设置 x.onprogress 属性监听响应的下载进度。设置 x.upload.onprogress 监听请求的上传进度。 1.6. 放弃请求与超时 调用 XMLHttpRequest 对象的 abort() 方法可以取消正在进行的请求。并且在 XHR2 中调用 abort() 方法会触发 abort 事件。 XHR2 定义了一个 timeout 属性，指定超时（毫秒）后自动放弃请求，并触发 timeout 事件。目前还没有浏览器支持这一点。但我们可以通过 setTimeout() 和 abort() 自己模拟。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/前端知识目录.html":{"url":"Javascript/前端知识目录.html","title":"前端知识目录","keywords":"","body":"1. 前端知识1.1. 0. 前端自动化(Workflow)1.2. 1. 前端框架(Frameworks)1.3. 2. JavaScript 框架汇总1.4. 3. 前端游戏框架1.5. 4. ui组件库1.6. 5. 基础模版1.7. 6. 排版1.8. 7. 网格系统1.9. 8. HTML5 API 应用1.10. 9. UA 识别1.11. 10. 表单处理1.11.1. 10.1 表单验证(Form Validator)1.11.2. 10.2 相关1.11.3. 10.3 单选框/复选框相关1.11.4. 10.4 上传组件1.11.5. 10.5 日期选择1.11.6. 10.6 取色1.11.7. 10.7 标签插件(Tag)1.11.8. 10.8 自动完成插件1.11.9. 10.9 样式修正1.12. 11. 图表绘制1.13. 12. 日期格式化1.14. 13. 页面交互1.14.1. 13.1 Slider1.14.2. 13.2 瀑布流1.14.3. 13.3 图片懒加载/加载监听1.14.4. 13.4 图片轮播/展示1.14.5. 13.5 图片剪裁/处理1.14.6. 13.6 进度条1.14.7. 13.7 侧滑插件(offcancas)1.14.8. 13.8 菜单(Menu)1.14.9. 13.9 滚动侦测(ScrollSpy)1.14.10. 13.10 滚动加载更多1.14.11. 13.11 平滑滚动插件(Smooth Scroll)1.14.12. 13.12 全屏滚动1.14.13. 13.13 分屏滚动1.14.14. 13.14 转场效果1.14.15. 13.15 固定元素(Sticky)1.14.16. 13.16 触控事件1.14.17. 13.17 拖拽组件1.14.18. 13.18 隐藏或展示页面元素1.14.19. 13.19 滚动条1.14.20. 13.20 视差滚动(Parallax Scrolling)1.15. 14. 代码高亮插件/代码编辑器1.16. 15. UI Icon 组件1.17. 16. 动画1.18. 17. 本地存储1.19. 18. 模板引擎1.20. 19. 通知组件/弹框组件1.21. 20. 提示控件(Tooltips)1.22. 21. 对话框/弹出层(lightbox)1.23. 22. 文档/表格1.24. 23. 目录树插件1.25. 24. Ajax模块1.26. 25. 音频/视频1.27. 26. 按钮1.28. 27. 富文本编辑器/Markdown编辑器/Markdown解析器1.29. 28. 内容提取(Readability)1.30. 29. 颜色(CSS Colors)/SVG1.31. 30. 实用工具/其他插件1.32. 前端参考集1. 前端知识 1.1. 0. 前端自动化(Workflow) 前端构建工具 Yeoman – a set of tools for automating development workflow gulp – The streaming build system grunt – the JavaScript Task Runner F.I.S – 前端集成解决方案 前端模块管理器 Bower – A package manager for the web Browserify Component Duo RequireJS Sea.js css预处理器 Less – Less is More , Than CSS Sass – Syntactically Awesome Style Sheets Stylus – Expressive, dynamic, robust CSS 1.2. 1. 前端框架(Frameworks) Bootstrap Foundation Amaze UI Semantic UI Pure CSS topcoat UIkit Material UI Framework7 mui ionic framework Fries jQuery Mobile 1.3. 2. JavaScript 框架汇总 JavaScript 框架 react Angular jQuery Backbone.js Ractive.js KISSY Zepto.js Vanilla JS Avalon 轻量级JavaScript框架 Min.js – Super minimal selector and event library skel.js – A lightweight responsive framework JavaScript 工具库 underscore.js Way.js – 双向数据绑定库 Keys.js – 应用快捷键 1.4. 3. 前端游戏框架 cocos2d-html5 Egret Engine LimeJS EaselJS three.js AlloyStick The-Best-JS-Game-Framework CanvasEngine Quintus 1.5. 4. ui组件库 GMU NEC NEJ Pure CSS Components magic-of-css 1.6. 5. 基础模版 HTML5 BOILERPLATE Modernizr Normalize.css Responsive – 响应式布局 1.7. 6. 排版 yue.css typo.css chinese-copywriting-guidelines – 中文文案排版指南 1.8. 7. 网格系统 grid Flexbox Grid 1.9. 8. HTML5 API 应用 History.js – gracefully supports the HTML5 History/State APIs jquery-pjax – pushState+ajax jquery-address – Deep Linking Notify.js(Web Notifications API) 1.10. 9. UA 识别 detector 1.11. 10. 表单处理 1.11.1. 10.1 表单验证(Form Validator) Validator Parsley jquery.form.js – jQuery Form Plugin Validform validator.js formvalidator.js Fort.js – 表单填写进度提示 1.11.2. 10.2 相关 Chosen Select2 bootstrap-select 1.11.3. 10.3 单选框/复选框相关 iCheck – 增强复选框和单选按钮 1.11.4. 10.4 上传组件 jQuery File Upload Plugin 百度 Web Uploader Uploadify Plupload arale-upload – 轻量级 iframe and html5 file uploader Dropzone.js – drag’n’drop library拖拽上传 flow.js 1.11.5. 10.5 日期选择 Both Date and Time picker widget based on twitter bootstrap GMU 日历组件 Mobiscroll 1.11.6. 10.6 取色 Colorpicker plugin for Twitter Bootstrap 1.11.7. 10.7 标签插件(Tag) TaggingJS – 可以灵活定制的 jQuery 标签系统插件 1.11.8. 10.8 自动完成插件 At.js – 一个Twitter/微博样式的@自动完成插件 jquery-textcomplete – 智能搜索提示框/自动补全 1.11.9. 10.9 样式修正 autosize – 使文本框自动适应所输入的内容 1.12. 11. 图表绘制 Highcharts Chart.js – Simple HTML5 Charts using Canvas 百度 ECharts Chartist.js D3.js – A JavaScript visualization library for HTML and SVG.intro-to-d3 – a D3.js tutorial 1.13. 12. 日期格式化 Moment.js Smart Time Ago – 显示相对时间 1.14. 13. 页面交互 1.14.1. 13.1 Slider slick – the last carousel you’ll ever need Swipe – the most accurate touch slider Swiper – Most modern mobile touch slider iscroll – Smooth scrolling for the web OwlCarousel – create beautiful responsive carousel slider jquery-mousewheel – jQuery鼠标滚轮滚动侦测插件 1.14.2. 13.2 瀑布流 Masonry Isotope – Filter & sort magical layouts 1.14.3. 13.3 图片懒加载/加载监听 imagesLoaded Echo.js lazySizes jquery_lazyload lazyload.js waitForImages – 图片加载监听库 1.14.4. 13.4 图片轮播/展示 FlexSlider unslider – 小而美的轮播库 prettyPhoto 1.14.5. 13.5 图片剪裁/处理 croppic – an image cropping jquery plugin jQuery.eraser – 图像擦除插件 1.14.6. 13.6 进度条 NProgress.js progress.js Pace – Automatic page load progress bar jquery-ajax-progress 1.14.7. 13.7 侧滑插件(offcancas) pushy – a responsive off-canvas navigation menu 1.14.8. 13.8 菜单(Menu) SuperFish – 基于jQuery的级联下拉菜单 Responsive Nav – 响应式导航 1.14.9. 13.9 滚动侦测(ScrollSpy) jquery-scrollspy(1) jquery-scrollspy(2) Waypoints 1.14.10. 13.10 滚动加载更多 jScroll 1.14.11. 13.11 平滑滚动插件(Smooth Scroll) jquery-smooth-scroll jquery.scrollTo – 平滑滚动到页面指定位置 1.14.12. 13.12 全屏滚动 pagePiling.js – 全屏滚动效果 1.14.13. 13.13 分屏滚动 multiscroll.js – 分屏滚动效果 1.14.14. 13.14 转场效果 Animsition – 页面切换时的过渡效果 1.14.15. 13.15 固定元素(Sticky) sticky – jQuery Plugin for Sticky Objects jquery.pin – 固定页面元素 1.14.16. 13.16 触控事件 Hammer.js jquery.event.move.js 1.14.17. 13.17 拖拽组件 Draggabilly – 专注于拖拽功能的 JS 库 1.14.18. 13.18 隐藏或展示页面元素 Headroom.js – 在不需要页头时将其隐藏 Readmore.js – 内容显示与隐藏插件 1.14.19. 13.19 滚动条 jScrollPane 1.14.20. 13.20 视差滚动(Parallax Scrolling) parallax.js jparallax 1.15. 14. 代码高亮插件/代码编辑器 google-code-prettify highlight.js Rainbow ACE CodeMirror Crayon Syntax Highlighter prism – Lightweight, robust, elegant syntax highlighting. 1.16. 15. UI Icon 组件 Font Awesome Glyphter: The SVG Font Machine Perfect Icons iconizr Cikonss – 纯CSS实现的响应式Icon Simple Icons 1.17. 16. 动画 animate.css – A cross-browser library of CSS animations. Transit – CSS transitions and transformations for jQuery Move.js – 简化CSS3动画的JS库 ScrollMe – 在网页中加入各种滚动动画效果 Effeckt.css – A Performant Transitions and Animations Library NEC动画库 csshake – CSS classes to move your DOM magic – CSS3 Animations with special effects Hover.css css-loaders SpinKit 1.18. 17. 本地存储 cross-storage – Cross domain local storage localForage pouchdb basil.js 1.19. 18. 模板引擎 mustache.js Handlebars.js artTemplate baiduTemplate JSRender EJS – JavaScript Templates Juicer – A Light Javascript Templete Engine. Tempo json2html 1.20. 19. 通知组件/弹框组件 alertify.js AlertifyJS SweetAlert Messenger – 非常酷的弹框组件 PNotify Notify.js – A simple, versatile notification library 1.21. 20. 提示控件(Tooltips) qTip2 – Pretty powerful tooltips tooltip – CSS Tooltips tooltipster – A jQuery tooltip plugin grumble.js – 气泡形状的提示（Tooltip）控件 Ouibounce – 离站提示控件 1.22. 21. 对话框/弹出层(lightbox) fancyBox – Fancy jQuery lightbox jquery-lightbox – The popular lightbox script, ported to jQuery Colorbox – a jQuery lightbox artDialog – 经典的网页对话框组件 DialogEffects 1.23. 22. 文档/表格 handsontable – 在线可编辑excel表格 jQuery Bootgrid – 用于ajax生成动态表格 DataTables – Table plug-in for jQuery 1.24. 23. 目录树插件 zTree_v3 – jQuery Tree Plugin jstree – jQuery Tree Plugin fancytree – Tree plugin for jQuery 1.25. 24. Ajax模块 fetch – A window.fetch JavaScript polyfill reqwest – browser asynchronous http requests minAjax.js 1.26. 25. 音频/视频 jPlayer – HTML5 Audio & Video for jQuery video.js – HTML5 & Flash video player Accessible HTML5 Video Player – PayPal 开源的 HTML5 视频播放器 Clappr – 开源的Web视频播放器 Plyr – A simple HTML5 media player FitVids.js – A lightweight, easy-to-use jQuery plugin for fluid width video embeds. BigVideo.js – The jQuery Plugin for Big Background Video BigScreen – A simple library for using the JavaScript Full Screen API Vide – 视频背景 winamp2-js 1.27. 26. 按钮 Buttons – A CSS button library ButtonComponentMorph ProgressButtonStyles CreativeButtons CSS3 buttons jquery.onoff – Interactive, accessible toggle switches for the web. 1.28. 27. 富文本编辑器/Markdown编辑器/Markdown解析器 Simditor – 简单快速的富文本编辑器 BachEditor – 一个有情怀的编辑器 bootstrap-markdown marked – markdown解析器 1.29. 28. 内容提取(Readability) Readability json.human.js – Json Formatting for Human Beings 1.30. 29. 颜色(CSS Colors)/SVG CSS Colours SVGeneration 1.31. 30. 实用工具/其他插件 jquery-cookie FastClick – 处理移动端 click 事件 300 毫秒延迟 screenfull.js – 全屏切换 Async.js – 异步操作 html2canvas – 实现纯JS网页截图 jquery.qrcode.js – 生成二维码的 jQuery 插件 FocusPoint.js 实现图片的响应式裁剪 DD_belatedPNG.js – 让IE6支持透明PNG图片 nakedpassword – 用脱衣女帮助检测密码强度 PDF.js – 一个 JavaScript 编写的 PDF 阅读器 1.32. 前端参考集 frontend-guidelines – Some HTML, CSS and JS best practices. Codrops – Useful resources Front-end Code Standards & Best Practices frontend-dev-bookmarks Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/":{"url":"Javascript/工具类/","title":"Javascript/工具类","keywords":"","body":"1. TOC1. TOC code_common code_cookie code_dom code_Event code_Internationalization_localization code_money code_queryString code_random code_time code_view Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Javascript/工具类/code_common.html":{"url":"Javascript/工具类/code_common.html","title":"code_common","keywords":"","body":"1. Common1. Common /** * 判断一个对象是否是数组，参数不是对象或者不是数组，返回false * * @param {Object} obj 需要测试是否为数组的对象 * @return {Boolean} 传入参数是数组返回true，否则返回false */ // 如果浏览器支持 Array.isArray() 可以直接判断否则需进行必要判断 function isArray(obj) { if (typeof obj === 'object') { return Object.prototype.toString.call(obj) === '[object Array]'; } return false; // return obj instanceof Array; //method 2 // return obj.constructor == Array; //method 3 } /** * 判断对象是否为函数，如果当前运行环境对可调用对象（如正则表达式）的 typeof 返回' function'，采用通用方法，否则采用优化方法 * * @param {Any} arg 需要检测是否为函数的对象 * @return {boolean} 如果参数是函数，返回true，否则false */ function isFunction(arg) { if (arg) { if (typeof /./ !== 'function') { return typeof arg === 'function'; } else { return Object.prototype.toString.call(arg) === '[object Function]'; } } return false; } /** * 解析一个 url 并生成 window.location 对象中包含的域 * console.log(parseUrl('http://google.com?s=fdf&g=guang')); * * location: * { * href: '包含完整的url', * origin: '包含协议到pathname之前的内容', * protocol: 'url使用的协议，包含末尾的:', * username: '用户名', // 暂时不支持 * password: '密码', // 暂时不支持 * host: '完整主机名，包含:和端口', * hostname: '主机名，不包含端口' * port: '端口号', * pathname: '服务器上访问资源的路径/开头', * search: 'query string，?开头', * hash: '#开头的fragment identifier' * } * * @param {string} url 需要解析的url * @return {Object} 包含url信息的对象 */ function parseUrl(url) { var result = {}; var keys = ['href', 'origin', 'protocol', 'host', 'hostname', 'port', 'pathname', 'search', 'hash']; var i, len; var regexp = /(([^:]+:)\\/\\/(([^:\\/\\?#]+)(:\\d+)?))(\\/[^?#]*)?(\\?[^#]*)?(#.*)?/; var match = regexp.exec(url); if (match) { for (i = keys.length - 1; i >= 0; --i) { result[keys[i]] = match[i] ? match[i] : ''; } } return result; } /** * 忽略大小写后的安字符串名字排序。在 node 读取文件夹中文件时，排序忽略英文大小写 * @param {array} arr */ export function sortByAlphaIgnoreCase(arr) { arr.sort((a, b) => { return a.localeCompare(b, undefined /* Ignore language */, { sensitivity: 'base' }); }); } /** * 深拷贝 deepClone，也可以用 lodash 里面的 */ function deepClone(obj) { let temp = Array.isArray(obj) ? [] : {}; for (let key in obj) { //是否有嵌套对象 temp[key] = typeof obj[key] === 'object' ? deepClone(obj[key]) : obj[key]; } return temp; } /** * var a = { name: 'qiu', birth: new Date(), pattern: /qiu/gim, container: document.body, hobbys: ['book', new Date(), /aaa/gim, 111] }; var b = deepClone(a) * @param {object} obj */ function deepClone(obj) { var _toString = Object.prototype.toString; // null, undefined, non-object, function if (!obj || typeof obj !== 'object') { return obj; } // DOM Node if (obj.nodeType && 'cloneNode' in obj) { return obj.cloneNode(true); } // Date if (_toString.call(obj) === '[object Date]') { return new Date(obj.getTime()); } // RegExp if (_toString.call(obj) === '[object RegExp]') { var flags = []; if (obj.global) { flags.push('g'); } if (obj.multiline) { flags.push('m'); } if (obj.ignoreCase) { flags.push('i'); } return new RegExp(obj.source, flags.join('')); } var result = Array.isArray(obj) ? [] : obj.constructor ? new obj.constructor() : {}; for (var key in obj) { result[key] = deepClone(obj[key]); } return result; } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_cookie.html":{"url":"Javascript/工具类/code_cookie.html","title":"code_cookie","keywords":"","body":"1. Cookie1. Cookie var cookieUtil = (function(window, undefined) { var doc = window.document; var cookieUtil = { /** * 根据 opt 中设置的值设置cookie * * @param {Object} opt 包含cookie信息的对象，选项如下 * key {string} 需要设置的名字 * value {string} 需要设置的值 * maxAge {number} 有效期 * domain {string} domain * path {string} path * secure {boolean} secure * * @return {string} opt 对应的设置 cookie的字符串 */ setItem: function(opt) { var result = []; var str; if (opt.key) { result.push(encodeURIComponent(opt.key) + '=' + encodeURIComponent(opt.value)); if ('maxAge' in opt) { result.push('max-age=' + opt.maxAge); } if ('domain' in opt) { result.push('domain=' + opt.domain); } if ('path' in opt) { result.push('path=' + opt.path); } if (opt.secure) { result.push('secure'); } str = result.join('; '); doc.cookie = str; } return str; }, /** * 从 cookie 读取指定 key 的值，如果key有多个值，返回数组，如果没有 * 对应key，返回undefined * * @param {string} key 需要从 cookie 获取值得 key * @return {string|Array|undefined} 根据cookie数据返回不同值 */ getItem: function(key) { key = encodeURIComponent(key); var result; var pairs = doc.cookie.split('; '); var i, len, item, value; for (i = 0, len = pairs.length; i Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_dom.html":{"url":"Javascript/工具类/code_dom.html","title":"code_dom","keywords":"","body":"1. DOM1. DOM /** * 获取某个 DOM 元素的某个属性 * @param {*} obj * @param {*} attr */ export function getStyle(obj, attr) { if (attr == 'rotate') { return obj.rotate; } let i = parseFloat( obj.currentStyle ? obj.currentStyle[attr] : document.defaultView.getComputedStyle(obj, false)[attr] ); let val = i ? i : 0; if (attr == 'opacity') { val *= 100; } return val; } function getStyle(obj, attr) { if (obj.currentStyle) { return obj.currentStyle[attr]; // IE } else { return getComputedStyle(obj, false)[attr]; // standard } } /** * 编写一个函数实现form的序列化(即将一个表单中的键值序列化为可提交的字符串) * aaa bbb qiu de qing description Football Basketball Female Male var form = document.getElementById('target'); console.log(serializeForm(form)); * @param {FormElement} form 需要序列化的表单元素 * @return {string} 表单序列化后的字符串 */ function serializeForm(form) { if (!form || form.nodeName.toUpperCase() !== 'FORM') { return; } var result = []; var i, len; var field, fieldName, fieldType; for (i = 0, len = form.length; i div*4. 2nd div index should be 1 * @method getIndex * @param {[type]} obj [description] * @return {[type]} [description] */ function getIndex(obj) { // var siblingsAndSelf = getChildren(obj.parentNode); var siblingsAndSelf = obj.parentNode.children; for (var i = 0; i = 0; i--) { //if (eles[i].className == classname) { //if (eles[i].className.search(classname) != -1) { //也不行，比如有个class叫largebox。 if (reg.test(eles[i].className)) { //单词边界\\b result.push(eles[i]); } } return result; } //not useful function getByParent(obj, tagname, classname) { // 通过父级的className以及tagName获取元素 var re = new RegExp('(^|\\\\s)' + classname + '(\\\\s|$)'); while (obj.parentNode) { if (obj.parentNode.tagName != tagname) { obj = obj.parentNode; } else { if (re.test(obj.parentNode.className)) { return obj.parentNode; } else { obj = obj.parentNode; } } } } */ Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_Event.html":{"url":"Javascript/工具类/code_Event.html","title":"code_Event","keywords":"","body":"1. Event1. Event /** * 请实现一个MyEvent类, 继承自此类的对象都会拥有两个方法on, off, once, trigger; */ function MyEvent() { if (!(this instanceof MyEvent)) { return new MyEvent(); } this._callbacks = {}; } MyEvent.prototype.on = function(type, handler) { this_callbacks = this._callbacks || {}; this._callbacks[type] = this.callbacks[type] || []; this._callbacks[type].push(handler); return this; }; MyEvent.prototype.off = function(type, handler) { var list = this._callbacks[type]; if (list) { for (var i = list.length; i >= 0; --i) { if (list[i] === handler) { list.splice(i, 1); } } } return this; }; MyEvent.prototype.trigger = function(type, data) { var list = this._callbacks[type]; if (list) { for (var i = 0, len = list.length; i Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_Internationalization_localization.html":{"url":"Javascript/工具类/code_Internationalization_localization.html","title":"code_Internationalization_localization","keywords":"","body":"1. 国际化 本地化 internationalization localization1. 国际化 本地化 internationalization localization var l10nEN = new Intl.NumberFormat('en-US'); var l10nDE = new Intl.NumberFormat('de-DE'); l10nEN.format(1234567.89) === '1,234,567.89'; l10nDE.format(1234567.89) === '1.234.567,89'; var l10nUSD = new Intl.NumberFormat('en-US', { style: 'currency', currency: 'USD' }); var l10nGBP = new Intl.NumberFormat('en-GB', { style: 'currency', currency: 'GBP' }); var l10nEUR = new Intl.NumberFormat('de-DE', { style: 'currency', currency: 'EUR' }); l10nUSD.format(100200300.4) === '$100,200,300.40'; l10nGBP.format(100200300.4) === '£100,200,300.40'; l10nEUR.format(100200300.4) === '100.200.300,40 €'; var l10nEN = new Intl.DateTimeFormat('en-US'); var l10nDE = new Intl.DateTimeFormat('de-DE'); l10nEN.format(new Date('2015-01-02')) === '1/2/2015'; l10nDE.format(new Date('2015-01-02')) === '2.1.2015'; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_money.html":{"url":"Javascript/工具类/code_money.html","title":"code_money","keywords":"","body":"1. Money1. Money /** * 如何将浮点数点左边的数每三位添加一个逗号，如12000000.11转化为『12,000,000.11』? * @param {Number} num */ function commafy(num) { return ( num && num.toString().replace(/(\\d)(?=(\\d{3})+\\.)/g, function($1, $2) { return $2 + ','; }) ); } /** * 数字转换成金钱，每三位加\",\"。并且控制小数点保留位数 * @param {Number} number 数字 * @param {Number} digit 小数点后保留位数 * toMoney(12345435.34, 2) */ function toMoney(number, digit) { digit = digit > 0 && digit Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_queryString.html":{"url":"Javascript/工具类/code_queryString.html","title":"code_queryString","keywords":"","body":"1. queryString1. queryString /** * @param {object} data * 表单数据装配成 queryString */ function encodeFormData(data) { if (!data) return ''; var pairs = []; for (var name in data) { if (!data.hasOwnProperty(name)) continue; if (typeof data[name] === 'function') continue; var value = data[name].toString(); name = encodeURIComponent(name.replace(' ', '+')); value = encodeURIComponent(value.replace(' ', '+')); pairs.push(name + '=' + value); } return pairs.join('&'); } /** * usage: * query string: ?foo=lorem&bar=&baz var foo = getParameterByName('foo'); // \"lorem\" var bar = getParameterByName('bar'); // \"\" (present with empty value) var baz = getParameterByName('baz'); // \"\" (present with no value) var qux = getParameterByName('qux'); // null (absent) Note: If a parameter is present several times (?foo=lorem&foo=ipsum), you will get the first value (lorem). method 2: `URLSearchParams` var searchParams = new URLSearchParams(window.location.search); //?anything=123 console.log(searchParams.get(\"anything\")) //123 method 3: import queryString from 'query-string'; queryString.parse('?playerOneName=wghglory&playerTwoName=ff'); // {playerOneName: \"wghglory\", playerTwoName: \"ff\"} * @param {string} name * @param {string} url */ function getParameterByName(name, url) { if (!url) url = window.location.href; name = name.replace(/[\\[\\]]/g, '\\\\$&'); var regex = new RegExp('[?&]' + name + '(=([^&#]*)|&|#|$)'), results = regex.exec(url); if (!results) return null; if (!results[2]) return ''; return decodeURIComponent(results[2].replace(/\\+/g, ' ')); } /** * 解析query string转换为对象，一个key有多个值时生成数组 * * @param {String} query 需要解析的query字符串，开头可以是?， * console.log(parseQuery('sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8')); * 按照application/x-www-form-urlencoded编码 * @return {Object} 参数解析后的对象 */ function parseQuery(query) { var result = {}; // 如果不是字符串返回空对象 if (typeof query !== 'string') { return result; } // 去掉字符串开头可能带的? if (query.charAt(0) === '?') { query = query.substring(1); } var pairs = query.split('&'); var pair; var key, value; var i, len; for (i = 0, len = pairs.length; i Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_random.html":{"url":"Javascript/工具类/code_random.html","title":"code_random","keywords":"","body":"1. 如何实现数组的随机排序？1. 如何实现数组的随机排序？ // 方法一：随意交换某个随机位置和 i 的位置 var arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]; function randSort1(arr) { for (var i = 0, len = arr.length; i 0) { var randomIndex = parseInt(Math.random() * arr.length); mixedArray.push(arr[randomIndex]); arr.splice(randomIndex, 1); } return mixedArray; } console.log(randSort2(arr)); // 方法三： var arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]; arr.sort(function() { return Math.random() - 0.5; }); console.log(arr); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_time.html":{"url":"Javascript/工具类/code_time.html","title":"code_time","keywords":"","body":"1. Time Helper1.1. Declaratively Programming Demo(functional programming)1.2. 多久之前发布评论1. Time Helper 参考 moment.js export function formatDate(date) { let day = date.getDate(); if (day 1.1. Declaratively Programming Demo(functional programming) /** * compose * @param {functions} fns a list of functions * reduce first para: function second para: initial value cb first para is initial value(arg in this case) cb second para is a item(one item of fns in this case) 目的是执行第一个函数，得到结果再交给第二个函数执行 compose(f1, f2) 是构建传入 function，compose(f1, f2)(initialValue) 是返回最终结果 */ const compose = (...fns) => (arg) => fns.reduce((accu, f) => f(accu), arg); /** Clock Demo */ const oneSecond = () => 1000; const getCurrentTime = () => new Date(); const clear = () => console.clear(); const log = (message) => console.log(message); const abstractClockTime = (date) => ({ hours: date.getHours(), minutes: date.getMinutes(), seconds: date.getSeconds() }); const civilianHours = (clockTime) => ({ ...clockTime, hours: clockTime.hours > 12 ? clockTime.hours - 12 : clockTime.hours }); const appendAMPM = (clockTime) => ({ ...clockTime, ampm: clockTime.hours >= 12 ? 'PM' : 'AM' }); const display = (target) => (time) => target(time); const formatClock = (format) => (time) => format.replace('hh', time.hours).replace('mm', time.minutes).replace('ss', time.seconds).replace('tt', time.ampm); const prependZero = (key) => (clockTime) => ({ ...clockTime, [key]: clockTime[key] (arg) => fns.reduce((accu, f) => f(accu), arg); // clockTime 作为 arg，初始值。先 appendAMPM(clockTime)，返回的对象作为 civilianHours 的参数，执行 civilianHours const convertToCivilianTime = (clockTime) => compose(appendAMPM, civilianHours)(clockTime); const doubleDigits = (civilianTime) => compose(prependZero('hours'), prependZero('minutes'), prependZero('seconds'))(civilianTime); const startTicking = () => setInterval( compose( clear, getCurrentTime, abstractClockTime, convertToCivilianTime, doubleDigits, formatClock('hh:mm:ss tt'), display(log) ), oneSecond() ); startTicking(); 1.2. 多久之前发布评论 const second = 1000, minute = 60 * second, hour = 60 * minute, day = 24 * hour, timeframe = { second, minute, hour, day }, breakpoints = { second: 60, minute: 60, hour: 24, day: 30 }; const toDate = timeStampString => new Date(timeStampString); const getDiff = (timestamp, now) => toDate(now) - toDate(timestamp); const isUnderTime = (diff, timeframe, time) => diff / timeframe Math.floor(diff / timeframe); const printResult = (result, timeframeName) => `${result} ${timeframeName + ((result > 1) ? \"s\" : \"\")}`; const checkDate = (diff, timeframeName, underTime, timeframe) => (isUnderTime(diff, timeframe[timeframeName], underTime)) ? printResult(diffOverTimeframe(diff, timeframe[timeframeName]), timeframeName) : null; const printFullDate = dateTime => `${dateTime.getMonth() + 1}/${dateTime.getDate()}/${dateTime.getFullYear()}`; const lessThanAMinute = timeString => (timeString.match(/seconds/)) ? \"less than a minute\" : timeString + ' ago'; const _checkNext = (result, callback) => (result) ? lessThanAMinute(result) : callback(); const checkNext = ([tfName, ...rest], timeframe, timestamp, now) => _checkNext( checkDate(getDiff(timestamp, now), tfName, breakpoints[tfName], timeframe), () => howLongAgo(rest, timeframe, timestamp, now) ); const howLongAgo = (remainingTimeframe, timeframe, timestamp, now) => (!remainingTimeframe.length) ? printFullDate(toDate(timestamp)) : checkNext(remainingTimeframe, timeframe, timestamp, now); export const ago = (timestamp, now = new Date().toString()) => howLongAgo(Object.keys(timeframe), timeframe, timestamp, now); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/工具类/code_view.html":{"url":"Javascript/工具类/code_view.html","title":"code_view","keywords":"","body":"1. 页面展示相关 Helper1. 页面展示相关 Helper /** * 获取元素左上角 相对浏览器左上角（0，0）元素的坐标 * @param {object} element * * @return {object} 元素左上角相对浏览器（0，0）坐标和元素宽高(包括 padding，border) */ function getPosition(element) { var rect = element.getBoundingClientRect(); return { x: rect.left, y: rect.top, width: rect.width, height: rect.height }; // let top = 0; // let left = 0; // while (element) { // top += element.offsetTop; // left += element.offsetLeft; // element = element.offsetParent; // } // return { // top, // left // }; } /** * 查询指定窗口的视口尺寸，如果不指定窗口，查询当前窗口尺寸 **/ function getViewportSize(w) { w = w || window; // IE9及标准浏览器中可使用此标准方法 if ('innerHeight' in w) { return { width: w.innerWidth, height: w.innerHeight }; } var d = w.document; // IE 8及以下浏览器在标准模式下 if (document.compatMode === 'CSS1Compat') { return { width: d.documentElement.clientWidth, height: d.documentElement.clientHeight }; } // IE8及以下浏览器在怪癖模式下 return { width: d.body.clientWidth, height: d.body.clientHeight }; } /** * 获取指定window中滚动条的偏移量，如未指定则获取当前 window 滚动条偏移量 * * @param {window} w 需要获取滚动条偏移量的窗口 * @return {Object} obj.x为水平滚动条偏移量,obj.y为竖直滚动条偏移量 */ function getScrollOffset(w) { w = w || window; // 如果是标准浏览器 if (w.pageXOffset != null) { return { x: w.pageXOffset, y: w.pageYOffset }; } // 老版本IE，根据兼容性不同访问不同元素 var d = w.document; if (d.compatMode === 'CSS1Compat') { return { x: d.documentElement.scrollLeft, y: d.documentElement.scrollTop }; } return { x: d.body.scrollLeft, y: d.body.scrollTop }; } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/效果/":{"url":"Javascript/效果/","title":"Javascript/效果","keywords":"","body":"1. TOC1. TOC Tween 图片加载 滚动坐标宽高 滚动条自动滑动到底 鼠标进入div方向 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Javascript/效果/Tween.html":{"url":"Javascript/效果/Tween.html","title":"Tween","keywords":"","body":"1. Tween1. Tween /* * Tween.js * t: current time（当前时间）； * b: beginning value（初始值）； * c: change in value（变化量）； * d: duration（持续时间）。 * you can visit 'http://easings.net/zh-cn' to get effect */ var Tween = { Linear: function(t, b, c, d) { return c*t/d + b; }, Quad: { easeIn: function(t, b, c, d) { return c * (t /= d) * t + b; }, easeOut: function(t, b, c, d) { return -c *(t /= d)*(t-2) + b; }, easeInOut: function(t, b, c, d) { if ((t /= d / 2) Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/效果/图片加载.html":{"url":"Javascript/效果/图片加载.html","title":"图片加载","keywords":"","body":"1. 图片加载1.1. 一张张加载1.2. 图片按需、延迟加载 (Lazy-loading) 三种实现方式1.2.1. 第一种1.3. 第二种 使用 throttle 优化 scroll1.4. 第三种： 使用 IntersectionObserver API1.5. 预加载1. 图片加载 1.1. 一张张加载 // 首先html中的图片不要加路径。src为空 var imgArr = [ 'a1.png', 'a2.png', 'a3.png', 'a4.png' ]; var imgElements = document.getElementsByTagName('img'); var i = 0; function loadImage(n) { if (n > imgArr.length - 1) return; imgElements[n].src = imgArr[n]; imgElements[n].onload = function() { loadImage(++i); }; } loadImage(i); 1.2. 图片按需、延迟加载 (Lazy-loading) 三种实现方式 定义：延迟加载也称为惰性加载，即在长网页中延迟加载图像。用户滚动到它们之前，视口外的图像不会加载。这与图像预加载相反，在长网页上使用延迟加载将使网页加载更快。在某些情况下，它还可以帮助减少服务器负载。举个例子来说明，当打开淘宝首页的时候，只有在浏览器窗口里的图片才会被加载，当你滚动首页向下滑的时候，进入视口内的图片才会被加载，而其它从未进入视口的图像不会也不会加载。 那么延迟加载有什么好处： 提升用户的体验，试想一下，如果打开页面的时候就将页面上所有的图片全部获取加载，如果图片数量较大，对于用户来说简直就是灾难，会出现卡顿现象，影响用户体验。 有选择性地请求图片，这样能明显减少了服务器的压力和流量，也能够减小浏览器的负担。 1.2.1. 第一种 首先将页面上的图片的 src 属性设为 loading.gif，而图片的真实路径则设置在 data-src 属性中，页面滚动的时候计算图片的位置与滚动的位置，当图片出现在浏览器视口内时，将图片的 src 属性设置为 data-src 的值，这样，就可以实现延迟加载。 https://github.com/craigbuckler/progressive-image.js https://codepen.io/craigbuckler/pen/dNpaWp .item { width: 300px; display: inline-block; } .item .itemtitle { font-weight: bold; font-size: 2em; } .hidden { display: none; } Amalgam Comics Characters Dark Claw Super Soldier Spider Boy View more Iron Lantern Amazon Hawkeye var lazy = []; registerListener('load', setLazy); registerListener('load', lazyLoad); registerListener('scroll', lazyLoad); registerListener('resize', lazyLoad); function setLazy() { document.getElementById('listing').removeChild(document.getElementById('viewMore')); document.getElementById('nextPage').removeAttribute('class'); lazy = document.getElementsByClassName('lazy'); console.log('Found ' + lazy.length + ' lazy images'); } function lazyLoad() { for (var i = 0; i = 0 && rect.right >= 0 && rect.top Lazyload 1 img { display: block; margin-bottom: 50px; height: 200px; } function lazyload() { var images = document.getElementsByTagName('img'); var len = images.length; var n = 0; //存储图片加载到的位置，避免每次都从第一张图片开始遍历 return function () { var seeHeight = document.documentElement.clientHeight; var scrollTop = document.documentElement.scrollTop || document.body.scrollTop; for (var i = n; i 比较 image 的 offsetTop 与 seeHeight + scrollTop 的大小，当小于时则说明图片已经出现过在视口中，这时候继续判断图片是否已经替换过，如果没有替换过，则进行替换。 需要提及的是变量 n 是用来保存已经加载的图片数量，避免每次都从第一张图片开始遍历，提升性能。 1.3. 第二种 使用 throttle 优化 scroll 上面的代码是没什么问题，但是性能偏差。如果直接将函数绑定在 scroll 事件上，当页面滚动时，函数会被高频触发，这非常影响浏览器的性能。我粗略地估计一下，当简单地滚动一下页面，函数至少触发了十来次，这显然是十分没必要的。所以在做事件绑定的时候，可以对 lazyload 函数进行函数节流（throttle）与函数去抖（debounce）处理。 Debounce：一部电梯停在某一个楼层，当有一个人进来后，20秒后自动关门，这20秒的等待期间，又一个人按了电梯进来，这20秒又重新计算，直到电梯关门那一刻才算是响应了事件。 Throttle：好比一台自动的饮料机，按拿铁按钮，在出饮料的过程中，不管按多少这个按钮，都不会连续出饮料，中间按钮的响应会被忽略，必须要等这一杯的容量全部出完之后，再按拿铁按钮才会出下一杯。 下面就是经过 throttle 处理后的代码： Lazyload 2 img { display: block; margin-bottom: 50px; height: 200px; } function throttle(fn, delay, atleast) { var timeout = null, startTime = new Date(); return function () { var curTime = new Date(); clearTimeout(timeout); if (curTime - startTime >= atleast) { fn(); startTime = curTime; } else { timeout = setTimeout(fn, delay); } } } function lazyload() { var images = document.getElementsByTagName('img'); var len = images.length; var n = 0; //存储图片加载到的位置，避免每次都从第一张图片开始遍历 return function () { var seeHeight = document.documentElement.clientHeight; var scrollTop = document.documentElement.scrollTop || document.body.scrollTop; for (var i = n; i 设置了 500ms 的延迟，和 1000ms 的间隔，当超过 1000ms 未触发该函数，则立即执行该函数，不然则延迟 500ms 执行该函数。 1.4. 第三种： 使用 IntersectionObserver API 目前有一个新的 IntersectionObserver API，可以自动”观察”元素是否可见，只有 IE 不支持 这里不过多介绍 IntersectionObserver API 的详细使用，感兴趣可以另外阅读下面的文章： IntersectionObserver API 使用教程 Intersection Observer API Lazyload 3 img { display: block; margin-bottom: 50px; width: 800px; } var io = new IntersectionObserver(function (items) { items.forEach(function (item) { var target = item.target; if (target.getAttribute('src') == 'images/loading.gif') { target.src = target.getAttribute('data-src'); } }) }); Array.from(document.querySelectorAll('img')).forEach(function (item) { io.observe(item); }); IntersectionObserver 传入一个回调函数，当其观察到元素集合出现时候，则会执行该函数。 io.observe 即要观察的元素，要一个个添加才可以。 io 管理的是一个数组，当元素出现或消失的时候，数组添加或删除该元素，并且执行该回调函数。 1.5. 预加载 看漫画，提前加载下一张 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/效果/滚动_坐标_宽高.html":{"url":"Javascript/效果/滚动_坐标_宽高.html","title":"滚动坐标宽高","keywords":"","body":"1. 布局-JavaScript1.1. 大小1.1.1. JavaScript 读取宽高1.1.2. JavaScript 设置尺寸1.1.3. JavaScript 间接尺寸读写1.1.4. 元素的右 padding 和下 padding 在内盒边缘还是内容盒子边缘的问题1.1.5. 浏览器视口大小1.2. 位置1.2.1. 文档坐标与视口坐标1.2.2. 相对于 offsetParent 的 offsetTop 和 offsetLeft1.2.3. getBoundingClientRect()1.2.4. clientLeft 和 clientTop1.2.5. 利用 scrollTop 和 scrollLeft 读写1.2.6. 主滚动条位置1.3. 利用 elementFromPoint() 获知在某个点最上面的元素1.4. 利用 scrollIntoView() 将元素滚动到视野内1.5. 精确滚动1.6. jQuery 相关方法1. 布局-JavaScript 1.1. 大小 1.1.1. JavaScript 读取宽高 1、clientWidth 和 clientHeight 内盒大小 + padding 大小，不包含滚动条。对于内联元素 clientWidth clientHeight 总是返回 0。 2、offsetHeight 和 offsetWidth 内盒大小 + padding 大小 + 滚动条大小 + border 大小。getBoundingClientRect() 返回的对象的 height 和 width 与这两个属性等价。 内联元素可能跨多行，因此可能包含多个矩形。如第一行末尾的矩形和第二个开头的矩形。调用内联元素的 getBoundingClientRect() 返回的是包围所有这些矩形的矩形。例如对于换行的内联元素，矩形包含两个行的全部宽度。 3、scrollWidth 和 scrollHeight 该属性会被取整。如果想要小数，使用 element.getBoundingClientRect()。 有滚动条时 子元素的外盒仍然在父元素的内盒内。只是子元素的右 margin 和父元素的右 padding 会被丢弃。上下和左 padding / margin 正常。 scrollWidth 包括子元素的 CSS width 、两侧 padding、两侧 border、左侧 margin，加自身的左侧 padding。即子元素的右侧 margin 和自身的右侧 padding 不包括在 scrollWidth 中。 scrollHeight 包括子元素的 CSS height 、两侧 padding、两侧 border、两侧 margin，加自身的两侧 padding。算法与 scrollWidth 不同。 例子： 外层 div 的 scrollWidth 为 124，scrollHeight 为 258。（Chrome 测试） 无滚动条时（子元素外盒小于父元素内盒） 元素的 scrollWidth 等于其 clientWidth，scrollHeight 等于其 clientHeight；与子元素无关。 4、getComputedStyle() getComputedStyle(element) 返回的对象表示元素计算出的样式属性。width 和 height 返回一个字符串，px 结尾。这两个值的含义取决于浏览器： Chrome 浏览器为内盒的宽高。即 CSS 的 width / height 减去滚动条。 对于其他浏览器，等于 CSS 的 width / height，即内盒大小 + 滚动条。 5、style.width 和 style.height 元素的 style 属性的子属性 width 和 height，它们返回元素内联样式中设置的 width 和 height。若没有设置内联样式返回空。若设置了返回设置了的字符串，设置什么单位就返回什么单位。因此基本上读取这两个属性是没有意义的。 1.1.2. JavaScript 设置尺寸 通过 JavaScript 设置元素个组件大小，只能通过元素的 style 属性，如 div.style.width = \"10px\"。本质上设置的是元素的内联样式。可以设置所有内联样式允许的属性，如 width padding borderTopWidth marginBottom 等。 1.1.3. JavaScript 间接尺寸读写 1、读取滚动条宽度/高度 滚动条宽度 = offsetWidth - clientWidth - pxToNumber(computedStyle.borderLeftWidth) - pxToNumber(computedStyle.borderRightWidth) 滚动条高度类似。 2、读取外盒宽度/高度 外盒宽度 = offsetWidth + pxToNumber(computedStyle.marginLeft) + pxToNumber(computedStyle.marginRight) 外盒高度亦然。 3、设置外盒宽度/高度 思路：我们只能设置内联 CSS 的 width，因此要把外盒宽度转换为此宽度。 style.width = numberToPx(outerWidth - horizontalPBM(computedStyle)) 高度亦然。 4、读取内盒宽度/高度 稳定的方法是用 clientWidth 减去 padding。注意仅在 Chome 下 computedStyle.width 等于内盒宽度。 4、设置内盒宽度/高度 我们想确保内盒为指定尺寸，为了设置 CSS 的宽高时要在指定尺寸基础上加滚动条宽度。 style.width = numberToPx(innerWidth + scrollBarWidth) 1.1.4. 元素的右 padding 和下 padding 在内盒边缘还是内容盒子边缘的问题 参见：http://stackoverflow.com/a/33672058 1.1.5. 浏览器视口大小 与滚动条位置一样，IE8 不支持标准做法，IE 中的可行方法取决于浏览器处于 quirks 模式还是标准模式。下面给出获取视口大小的通用方法： // Return the viewport size as w and h properties of an object function getViewportSize(w) { // Use the specified window or the current window if no argument w = w || window; // This works for all browsers except IE8 and before if (w.innerWidth != null) return {w: w.innerWidth, h:w.innerHeight}; // For IE (or any browser) in Standards mode var d = w.document; if (document.compatMode == \"CSS1Compat\") return { w: d.documentElement.clientWidth, h: d.documentElement.clientHeight }; // For browsers in Quirks mode return { w: d.body.clientWidth, h: d.body.clientWidth }; } 1.2. 位置 1.2.1. 文档坐标与视口坐标 X 轴向右，Y 轴向下。坐标系统原点可以有两个：可以相对于文档的左上角，或文档所在的视口的左上角。定义在 Frame 中的文档，视口 元素。（有时视口坐标也被称为窗口（window）坐标）。 通过 CSS 指定元素位置时使用的是文档坐标。但查询元素位置最简单的方法返回的是视口坐标。在鼠标事件中，鼠标指针的坐标是视口坐标。 1.2.2. 相对于 offsetParent 的 offsetTop 和 offsetLeft offsetTop 和 offsetLeft 是元素节点相对于 offsetParent 的偏移像素。偏移是元素的 border 外边缘到 offsetParent 的 border 内边缘偏移。 offsetParent 是定位祖先：最近的 position 值不为 static 的元素。如果找不到选 元素（或其他 document）。寻找过程中遇到 则选这些元素，即使它们的 position 值为 static。 当 offsetParent 是 ， 且 或 有 margin/padding/border，多数浏览器会把相对于“边框外”改成“边框内”。 1.2.3. getBoundingClientRect() getBoundingClientRect() 返回一个对象，带有 top right bottom left x y width height 8个属性，表示元素的 border 外边缘相对于浏览器视口左边和顶边的距离。注意 right 是元素右 border 外边缘相对于视口左边而不是右边的距离。bottom 类似。 If you want to query the individual rectangles of inline elements, call the getClientRects() method to obtain a read-only array-like object whose elements are rectangle objects like those returned by getBoundingClientRect(). 1.2.4. clientLeft 和 clientTop clientLeft 和 clientTop 属性返回 padding 外缘和 border 外缘之间的距离，多数情况下就是左边和上边边框的宽度。如果元素有滚动条且滚动条在左面或上边（很少见）clientLeft、clientTop 也包含滚动条宽度。对于内联元素 clientLeft 和 clientTop 总是 0。 没有 clientRight 和 clientBottom。 1.2.5. 利用 scrollTop 和 scrollLeft 读写 scrollTop 和 scrollLeft 表示已被滚动了距离。这两个属性是可写的。 1.2.6. 主滚动条位置 function getScrollOffsets(w) { // Use the specified window or the current window if no argument w = w || window; // 除了 IE8 if (w.pageXOffset != null) return {x: w.pageXOffset, y:w.pageYOffset}; // For IE (or any browser) in Standards mode var d = w.document; if (document.compatMode == \"CSS1Compat\") return {x:d.documentElement.scrollLeft, y:d.documentElement.scrollTop}; // For browsers in Quirks mode return { x: d.body.scrollLeft, y: d.body.scrollTop }; } 1.3. 利用 elementFromPoint() 获知在某个点最上面的元素 利用 document 的 elementFromPoint(left, top) 获知在某个点最上面的元素。其中 left、top 是相对于是视口左边与顶边的距离。 如果指定点超出视口，elementFromPoint() 将返回 null，即使这个点转换成文档坐标后是有效的。 elementFromPoint() 看似很有用，如判断当前鼠标经过的元素。但实际鼠标事件已经通过 target 属性包含了这个信息。 elementFromPoint() 很少在实际中使用。 1.4. 利用 scrollIntoView() 将元素滚动到视野内 若一个节点在一个可滚动的容器内，可以让该节点滚动到视野内。 document.querySelector('content').children[4].scrollIntoView(true); 默认尝试令元素上边接近视口上边。如果传入一个 false。则尝试令元素下边接近视口下边。如果需要浏览器还会水平滚动视口让元素可见。 1.5. 精确滚动 scrollTo() 和 scrollBy() 都是 window 对象的方法。 除了设置 scrollTop 或 scrollLeft，还可以使用 scrollTo()（或 scroll()）。传入一个文档坐标，令这个点滚到视口的左上角。如果位置太接近底边或右边，则尽可能滚的远。 例子，滚到文档底部： // 获取文档和视口的高度 var documentHeight = document.documentElement.offsetHeight; var viewportHeight = window.innerHeight; window.scrollTo(0, documentHeight - viewportHeight); scrollBy() 则是增量的。例子： // 每200毫秒滚10像素 javascript:void setInterval(function() {scrollBy(0, 10)}, 200); 1.6. jQuery 相关方法 offset() offset() 方法返回元素的文档坐标。返回的对象包含 left 和 top 两个属性。 传入含有这两个属性的对象可以设置元素位置。如果需要会自动设置 CSS 的 position 属性。 var elt = $(\"#sprite\"); var position = elt.offset(); position.top += 100; elt.offset(position); // Move all elements to the right by a distance that depends on their // position in the document $(\"h1\").offset(function(index, curpos) { return {left: curpos.left + 25 * index, top: curpos.top}; }); position() position() 方法是只读的，返回的位置相对于 offset parent。 offsetParent() 返回元素的定位祖先。 大小 有三组查询元素宽度高度的方法。 width() 和 height() 返回内盒宽高（不包含 padding, border, margin） innerWidth() 和 innerHeight() 返回的宽度和高度中含 padding。 outerWidth() 和 outerHeight() 返回的大小中含有 padding 和 border。调用时传入 true，则同时包含元素的 margin。 var body = $(\"body\"); var contentWidth = body.width(); var paddingWidth = body.innerWidth(); var borderWidth = body.outerWidth(); var marginWidth = body.outerWidth(true); var padding = paddingWidth-contentWidth; var borders = borderWidth-paddingWidth; var margins = marginWidth-borderWidth; 对于 Window， width() 和 height() 返回窗口的视口大小。对于 Document，width() 和 height() 返回窗口的文档大小。其他方法只能对元素调用。 width() 和 height() 还可以设置元素的宽高。若只传入数字，单位取像素。如果传入字符串，会被当成 CSS 宽度高度值，可以任意单位。 如果元素使用了 box-sizing: border-box，则设置的值中含 border 和 padding。 滚动 scrollTop() 和 scrollLeft() 用于读取、设置元素滚动条位置。两个方法能用于 Window 对象或 Document 元素。如果对 Document 调用，则返回或设置包含文档的 Window 对象的滚动条位置。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/效果/滚动条自动滑动到底.html":{"url":"Javascript/效果/滚动条自动滑动到底.html","title":"滚动条自动滑动到底","keywords":"","body":"1. 滚动条自动滑动到底1. 滚动条自动滑动到底 有一个 div，里面是一个 input，下面创建按钮。点击创建按钮后在按钮上面创建新的 input。这样可以添加多个 input。div 高度固定，overflow auto。我想在添加新的 input 后 scroll 到底部，这样能一直看到新添加的 input 和创建按钮。 let newInput = document.createElement('input') newInput.type = 'text' newInput.classList.add('form-control') newInput.placeholder = '请输入要素' parentDiv.insertBefore(newInput, createButtonElement) newInput.focus() parentDiv.scrollTop = divEle.scrollHeight Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/效果/鼠标进入div方向.html":{"url":"Javascript/效果/鼠标进入div方向.html","title":"鼠标进入div方向","keywords":"","body":"1. 判断鼠标进入 div 的方向1. 判断鼠标进入 div 的方向 .demo { width: 400px; height: 300px; background-color: pink; margin: 100px auto; } $(function () { $('div').on('mouseenter mouseleave', function (e) { var w = $(this).width(); // 得到盒子宽度 var h = $(this).height(); // 得到盒子高度 var x = (e.pageX - this.offsetLeft - (w / 2)) * (w > h ? (h / w) : 1); var y = (e.pageY - this.offsetTop - (h / 2)) * (h > w ? (w / h) : 1); var direction = Math.round((((Math.atan2(y, x) * (180 / Math.PI)) + 180) / 90) + 3) % 4; //direction的值为“0,1,2,3”分别对应着“上，右，下，左” // 将点的坐标对应的弧度值换算成角度度数值 var dirName = new Array('上方', '右侧', '下方', '左侧'); if (e.type == 'mouseenter') { $(this).html(dirName[direction] + '进入'); } else { $(this).html(dirName[direction] + '离开'); } }); }) Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Javascript/模版编译.html":{"url":"Javascript/模版编译.html","title":"模版编译","keywords":"","body":"1. 模板编译1. 模板编译 一个通过模板字符串生成正式模板的实例: var template = ` `; 该模板使用放置 JavaScript 代码，使用输出JavaScript表达式。将其转换为JavaScript表达式字符串。 echo(''); for(var i=0; i '); echo(data.supplies[i]); echo(''); }; echo(''); 这个转换使用正则表达式就行了。 function compile(template) { var outputExpression = //g; var expr = //g; template = template .replace(outputExpression, '`); \\n echo( $1 ); \\n echo(`') .replace(expr, '`); \\n $1 \\n echo(`'); template = 'echo(`' + template + '`);'; console.log(template); /* echo(``); for(var i=0; i `); echo( data.supplies[i] ); echo(``); } echo(``); */ var script = `(function parse(data){ var output = \"\"; function echo(html){ output += html; } ${template} return output; })`; return script; } compile函数的用法如下: var template = ` `; var parse = eval(compile(template)); console.log(parse); console.log(parse({ supplies: [\"broom\", \"mop\", \"cleaner\"] })); // div.innerHTML = parse({ supplies: [\"broom\", \"mop\", \"cleaner\"] }); // // broom // mop // cleaner // Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/":{"url":"ProjectConfig/","title":"ProjectConfig","keywords":"","body":"1. TOC1. TOC Mock npm_scripts_over_gulp webpack Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"ProjectConfig/Javacript-Starter/":{"url":"ProjectConfig/Javacript-Starter/","title":"ProjectConfig/Javacript-Starter","keywords":"","body":"1. TOC1. TOC 01_Consideration 02_Editors_Configuration 03_package_managers 04_devServer 05_automation 06_transpiling 07_bundle_webpack_rollup 08_linting 09_testing_CI 10_httpcalls 11_structure 12_production_build 13_deployment Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"ProjectConfig/Javacript-Starter/01_Consideration.html":{"url":"ProjectConfig/Javacript-Starter/01_Consideration.html","title":"01_Consideration","keywords":"","body":"1. Things to be considered1.1. What belongs in Starter Kit1. Things to be considered Editor Which one? Which plugins? Use built in terminal? Editor config Module format ES6 Modules, CommonJS... HTML generation Minify? Use plugin? Inject prod only concerns? Templating language? Transpiling Native ES or diff language? Use experimental features? Which plugins? Production vs dev config Bundler Webpack, Browserify, Rollup... Linting Which linter? Enable which rules? Warning or error? Which plugins? Use a preset? Testing Framework? Assertion Library? Helpers? Test file location? File naming? What environment? Mocking? Code Coverage Continuous Integration Project structure By file type or feature? Centralize API? Allow Inline JS? Extract to POJOs? HTTP Library Mock schema format Mock data generation Mock server Production build Minification Sourcemaps Bundle splitting Cache busting Error logging 1.1. What belongs in Starter Kit Package Management Bundling Minification Sourcemaps Transpiling Dynamic HTML Generation Centralized HTTP Mock API framework Component libraries Development Webserver Linting Automated testing Continuous Integration Automated build Automated deployment Working example app Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/02_Editors_Configuration.html":{"url":"ProjectConfig/Javacript-Starter/02_Editors_Configuration.html","title":"02_Editors_Configuration","keywords":"","body":"1. Editors, Configuration1.1. Editor (Vscode, atom, webstorm, brackets)1.2. Automated Consistency via EditorConfig1. Editors, Configuration 1.1. Editor (Vscode, atom, webstorm, brackets) Strong ES2015+ support Autocompletion Parse ES6 imports Report unused imports Automated refactoring Framework intelligence Built in terminal 1.2. Automated Consistency via EditorConfig .editorconfig: # editorconfig.org root = true [*] indent_style = space # hit tab, editorconfig converts it into 2 spaces indent_size = 2 end_of_line = lf # line feed, \\n charset = utf-8 trim_trailing_whitespace = true insert_final_newline = true [*.md] trim_trailing_whitespace = false Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/03_package_managers.html":{"url":"ProjectConfig/Javacript-Starter/03_package_managers.html","title":"03_package_managers","keywords":"","body":"1. Package Managers1.1. Security Scanning1.1.1. Usage of node security platform1. Package Managers npm, bower, jspm, jam, volo npm is best, because it offers everything, like linting, transpiling, etc. 1.1. Security Scanning Anyone can creates npm package, so we need to security scanning. retire.js node security platform (better) 1.1.1. Usage of node security platform npm install -g nsp cd your-project nsp check # result usually: (+) No known vulnerabilities found When to Run Security Check Manually - Easy to forget npm install - May be issue later production build - Expensive to change pull request - Expensive to change npm start - Slows start slightly Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/04_devServer.html":{"url":"ProjectConfig/Javacript-Starter/04_devServer.html","title":"04_devServer","keywords":"","body":"1. Development Web Servers1.1. Express setup1.2. Sharing work-in-progress1.2.1. localtunnel (great!)1.2.2. ngrok1.2.3. now1.2.4. Surge1. Development Web Servers http-server: Ultra -simple, Single command serves current directory live-server: Lightweight, Support live-reloading Express: Comprehensive, Highly Configurable, Production grade, Can run it everywhere budo: Integrates with Browserify, Includes hot reloading Webpack dev server: Built in to Webpack, Serves from memory, Includes hot reloading Browsersync: Dedicated IP for sharing work on LAN. ==All interactions remain in sync!== Great for cross-device testing. Integrates with Webpack, Browserify, Gulp 1.1. Express setup /** express dev server */ let express = require('express') let path = require('path') let open = require('open') let port = 3000 let app = express() app.get('/', (req, res) => { res.sendFile(path.join(__dirname, '../src/index.html')) }) app.listen(port, (err) => { if (err) { console.log(err); } else { open(`http://localhost:${port}`) } }) 1.2. Sharing work-in-progress localtunnel ngrok Surge now 1.2.1. localtunnel (great!) Easiest setup Ultra-versatile. Easily share work on your local machine. 让内网服务器暴露到公网上的开源项目 Setup: 1. `npm install localtunnel -g` 2. Start your app, if port is 3000 3. `lt --port 3000` or `lt --port 3000 --subdomain wghglory` Result is like: your url is: https://pgerjpkszz.localtunnel.me or https://wghglory.localtunnel.me Note: multiple devices, use browserSync and localtunnel together 1.2.2. ngrok Easy setup Secure. Secure tunnel to your local machine Sign up Install ngrok Install authtoken Start your app ./ngrok http 80 1.2.3. now No firewall hole Hosting persists. Quickly deploy Node.js to the cloud npm install -g now Create start script now 1.2.4. Surge No firewall hole Hosting persists. Quickly host static files to public URL npm install -g surge surge Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/05_automation.html":{"url":"ProjectConfig/Javacript-Starter/05_automation.html","title":"05_automation","keywords":"","body":"1. Automation1.1. Why npm Scripts1.1.1. Usage1. Automation Grunt The \"original\" Configuration over code Writes intermediary (中间的) files between steps Large plugin ecosystem Gulp In-memory streams Fast Code over configuration Large plugin ecosystem npm Scripts Declared in package.json Leverage your OS command line Directly use npm packages Call separate Node scripts Convention-based pre/post hooks Leverage world's largest package manager 1.1. Why npm Scripts Use tools directly No need for separate plugins Simpler debugging Better docs Easy to learn Simple Previous project I used gulp, gulp-eslint. There is a strange bug when I stop watching files once I have a certain number of files. I have to figure out was the bug in gulp? Eslint? gulp-eslint? my gulp config? I have to wait the author to update their plugins. 1.1.1. Usage Run concurrently: \"start\": \"npm-run-all --parallel security-check start:server\", \"start2\": \"npm run security-check & npm run start:server\", Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/06_transpiling.html":{"url":"ProjectConfig/Javacript-Starter/06_transpiling.html","title":"06_transpiling","keywords":"","body":"1. Transpiling1.1. Babel for nodejs1. Transpiling Babel Standardized JS Leverage full JS Ecosystem experimental features earlier No type defs, annotations required Test, lint, great libs Typescript Superset of Javascript Enhanced AutoCompletion Safer refactoring Clearer intent Additional non-standard features like interface Elm Compiles down to JS Clean Syntax Immutable data structures Friendly errors All errors are compile-time errors Interops with JS 1.1. Babel for nodejs .babelrc: { \"presets\": [ // \"env\", // \"react\" \"latest\" ] } Use babel-node buildScripts/startMessage instead of node buildScripts/startMessage so node.js can use import new features. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/07_bundle_webpack_rollup.html":{"url":"ProjectConfig/Javacript-Starter/07_bundle_webpack_rollup.html","title":"07_bundle_webpack_rollup","keywords":"","body":"1. Why bundling1.1. Module Format1.2. Why Use ES6 Modules1.3. Bundler1.3.1. Browserify1.3.2. Webpack1.3.3. Rollup1.3.4. JSPM1.4. Sourcemaps1. Why bundling CommonJS doesn't work in web browsers Package project into file(s) Improve Node performance 1.1. Module Format IIFE Asynchronous Module Definition (AMD) CommonJS (CJS) Universal Module Definition (UMD) ES6 Modules 1.2. Why Use ES6 Modules Standardized Statically analyzable Improved autocomplete Intelligent refactoring Fails fast Tree shaking Easy to read Named imports Default exports 1.3. Bundler require.js (old) Browserify Webpack Rollup JSPM 1.3.1. Browserify The first bundler to reach mass adoption Bundle npm packages for the web Large plugin ecosystem 1.3.2. Webpack loaders, plugins Bundles more than just JS Import CSS, images, etc like JS Bundle splitting Built in hot-reloading web server Webpack 2 offers tree shaking: using ES6 import so tree shaking will be ready for you 1.3.3. Rollup Tree shaking Faster loading production code Quite new Great for library authors No hot reloading and code splitting yet 1.3.4. JSPM Uses SystemJS, a universal module loader Can load modules at runtime Has its own package manager Can install from npm, git Uses Rollup 1.4. Sourcemaps To debug. Map code back to original source Part of our build downloaded only if you open developer tools write debugger in code Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/08_linting.html":{"url":"ProjectConfig/Javacript-Starter/08_linting.html","title":"08_linting","keywords":"","body":"1. Linting1.1. ESLint1.1.1. Warnings vs Errors1.1.2. Plugins1.1.3. preset1.1.4. Issue1.2. Why Lint via an Automated Build Process1.2.1. Usage1. Linting Enforce Consistency Curly brace position confirm / alert Trailing commas Globals eval Avoid Mistakes Extra parenthesis Overwriting function Assignment in conditional Missing default case in switch debugger / console.log 1.1. ESLint 1.1.1. Warnings vs Errors Warning Can continue development Can be ignored Team must agree: Fix warnings Error Breaks the build Cannot be ignored Team is forced to comply 1.1.2. Plugins eslint-plugin-react, eslint-plugin-angular, eslint-plugin-node 1.1.3. preset from scratch recommended presets: airbnb 1.1.4. Issue ESLint doesn't watch files eslint-loader if using webpack Re-lints all files upon save. eslint-watch is a npm package (better solution) ESLint wrapper that adds file watch Not tied to webpack Better warning/error formatting Displays clean message Easily lint tests and build scripts too ESLint doesn't support many experimental JavaScript features Run ESLint directly Supports ES6 and ES7 natively Also supports object spread use Babel-eslint Also lints stage 0 - 4 features 1.2. Why Lint via an Automated Build Process One place to check Universal configuration Part of continuous integration 1.2.1. Usage npm scripts: \"lint\": \"esw webpack.config.* src buildScripts --color\", // tell which files or folders to lint \"lint:watch\": \"npm run lint -- --watch\" dependencies: \"eslint\": \"4.6.1\", \"eslint-watch\": \"3.1.2\", .eslintrc.json { \"root\": true, \"extends\": [ \"eslint:recommended\" // \"plugin:react/recommended\" ], \"parserOptions\": { \"ecmaVersion\": 7, \"sourceType\": \"module\" }, \"env\": { \"browser\": true, \"node\": true, \"mocha\": true }, \"rules\": { \"no-console\": 1 } } disable linting for individual file: /* eslint-disable no-console */ console.log('111') disable linting for a specific line console.log('111') // eslint-disable-line no-console Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/09_testing_CI.html":{"url":"ProjectConfig/Javacript-Starter/09_testing_CI.html","title":"09_testing_CI","keywords":"","body":"1. Testing 测试 for Javascript1.1. JavaScript testing styles1.1.1. Unit Tests vs Integration Tests1.2. 6 key testing decisions1.2.1. Frameworks1.2.2. Assertion Library1.2.3. Helper library1.2.4. Where to run tests1.2.5. Where do test files belong1.2.6. Naming Convention1.2.7. When should unit tests run1.3. Configure testing and write test1.3.1. Test setup1.3.2. watch tests1.4. Continuous integration1.4.1. Why CI?1.4.2. What does a CI server do?1.4.3. CI server1. Testing 测试 for Javascript 1.1. JavaScript testing styles Style Focus Unit Single function or module Integration Interactions between modules UI Automate interactions with UI 1.1.1. Unit Tests vs Integration Tests Unit Tests Integration Tests Test a small unit Test multiple units Often single function Often involves clicking and making calls to a webApi using automation tool like Selenium Fast Slow Run upon save Often run on demand, or in QA 1.2. 6 key testing decisions Framework Assertion Library Helper Libraries Where to run tests Where to place tests When to run tests 1.2.1. Frameworks Mocha: highly configurable, large ecosystem, No Assertion Jasmine: large ecosystem, built-in assertion library Jest: wrapper for jasmine by facebook, popular among react developers Tape: simple QUnit: jquery creator writes AVA: run test parallel Choose any of these just like choosing a gym. 1.2.2. Assertion Library Declare what you expect. expect(2 + 2).to.equal(4) assert(2 + 2).equals(4) Chai Should.js expect 1.2.3. Helper library JSDOM Simulate the browser's DOM Run DOM-related tests without a browser Cheerio jQuery for the server Query virtual DOM using jQuery selectors 1.2.4. Where to run tests Browser(slower, not good) Karma, Testem Headless Browser PhantomJS (great) In-memory DOM JSDOM (great): https://github.com/tmpvar/jsdom 1.2.5. Where do test files belong Centralized (✘) Less \"noise\" in src folder (they are important source, asset. not liability) Deployment confusion (deploy won't be an issue for alongside way) Inertia 惯性 (backend test prefers Centralized test, not frontend) import file from '../../src/long/path' // file.test.js Alongside (✔️ more suitable for javascript test) Easy imports Clear visibility Convenient to open No recreating folder structure Easy file moves Path to file under test is always ./filename: import file from './file' // file.test.js 1.2.6. Naming Convention fileName.spec.js fileName.test.js 1.2.7. When should unit tests run Rapid feedback: run every time you hit save Facilitates TDD Automatic = Low friction 摩擦 Increases test visibility For integration test, admittedly slow, you should run separately. 1.3. Configure testing and write test I'm using below skills for unit tests Framework: Mocha Assertion Library: Chai Helper Libraries: JSDOM Where to run tests: Node Where to place tests: Alongside When to run tests: Upon save 1.3.1. Test setup npm scripts: using \"progress reporter\" because of clean output \"test\": \"mocha --reporter progress buildScripts/testSetup.js src/**/*.test.js\" create buildScripts/testSetup.js // This file isn't transpilied, so must use CommonJS and ES5 // register babel to transpile before our tests run require('babel-register'); // disable webpack features that Mocha doesn't understand // import 'index.css', webpack understands, but not mocha require.extensions['.css'] = function() {}; // mocha, treat it as a empty function create src/index.test.js import { expect } from 'chai'; describe('our first test', () => { it('should pass', () => { expect(true).to.equal(true); }); }); DOM testing by JSDOM v11 import { expect } from 'chai'; import { JSDOM } from 'jsdom'; import fs from 'fs'; describe('index.html', () => { it('should say hello', () => { const index = fs.readFileSync('./src/index.html', 'utf-8'); const dom = new JSDOM(index); const h1 = dom.window.document.querySelector('h1'); expect(h1.textContent).to.equal('hello world'); }); }); 1.3.2. watch tests \"scripts\": { \"start\": \"npm-run-all --parallel security-check start:server lint:watch test:watch\", \"test\": \"mocha --reporter progress buildScripts/testSetup.js src/**/*.test.js\", \"test:watch\": \"npm run test -- -w\" // or \"npm run test -- --watch\" } 1.4. Continuous integration The code is working on my machine, but it breaks on the CI server. 1.4.1. Why CI? Forgot to commit new file Forgot to update package.json commit doesn't run cross-platform node version conflicts bad merge didn't run tests 1.4.2. What does a CI server do? Run automated build Run your tests Check code coverage automate deployment 1.4.3. CI server Travis CI(linux) Jenkins Appveyor (windows) CircleCI Semaphore SnapCI Travis CI for unix Sign in by github and you should see all repositories. Turn on \"wghglory/javascript-starter-kit\". Create .travis.yml language: node_js node_js: - \"7\" If I intently change index.html h1 from 'hello world' to 'hello' and then commit to github. Note our test watching task only watches js now, so html changes won't be reflected in terminal unless restarting. After commit and push to github. Travis will build and give us the build result. Appveyor for windows appveyor.yml: # test against this version of node.s environment: matrix: # node.js - nodejs_version: \"7\" # install scripts. (runs after repo cloning) install: # get the latest stable version of node.js or io.js - ps: Install-Product node $env:nodejs_version # install modules - npm install # post-install test scripts test_script: # output useful info for debugging - node --version - npm --version # run tests - npm test # don't actually build build: off Usage is same with Travis. Sign in by github, add the project. When push commits to github, appveyor will build. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/10_httpcalls.html":{"url":"ProjectConfig/Javacript-Starter/10_httpcalls.html","title":"10_httpcalls","keywords":"","body":"1. Http call1.1. Http call approaches1.1.1. Fetch1.1.2. Axios1.2. Why centralize API calls1.3. Mock1.3.1. Why Mock HTTP?1.3.2. How to Mock HTTP (also review interview/frontend/Mock.md)1.3.3. Our Plan for Mocking HTTP1.3.4. Mocking Libraries1.3.5. Demo1. Http call 1.1. Http call approaches Node http request (✅) Browser XMLHttpRequest jQuery Framework-based (Angular http service) Fetch (✅ polyfill for both regular version or isomorphic-fetch) Node & Browser (any below is good) isomorphic-fetch xhr superAgent axios (great) 1.1.1. Fetch You can find compatibility for fetch: https://caniuse.com/#search=fetch Fetch cannot be cancelled at this time. const request = new Request('http://your-api.com/user', { method: 'GET', mode: 'cors', headers: new Headers({ 'Content-Type': 'text/html; charset=UTF-8' }) }); fetch(request).then(onSuccess, onError); 1.1.2. Axios axios({ url: 'http://your-api.com/user', method: 'post', headers: { 'Content-type': 'text/html; charset=UTF-8' }, data: 'text' }).then(onSuccess, onError); 1.2. Why centralize API calls Configure all calls Handle preloader logic Handle errors Single seam(缝合；接合) for mocking create src/api/userApi.js import 'whatwg-fetch'; // let browser that hasn't supported fetch work with fetch const onSuccess = response => response.json(); const onError = error => console.log(error); //eslint-disable-line no-console const get = url => fetch(url).then(onSuccess, onError); export const getUsers = () => get('users'); So in index.js, I can call this api: import { getUsers } from './api/userApi'; getUsers().then(result => {}) Only send polyfill to those who need it: 1.3. Mock 1.3.1. Why Mock HTTP? Unit Testing Instant response Keep working when services are down Rapid prototyping Avoid inter-team bottlenecks Work offline 1.3.2. How to Mock HTTP (also review interview/frontend/Mock.md) Nock (mock http calls in unit test) Static JSON Create development webserver api-mock JSON server JSON Schema faker(random data) Browsersync Express, etc. 1.3.3. Our Plan for Mocking HTTP Declare our schema: JSON Schema Faker Generate Random Data: faker.js chance.js randexp.js Serve Data via API JSON Server 1.3.4. Mocking Libraries Json Schema Json Schema Faker 1.3.5. Demo 1. create Schema: buildScripts/mockDataSchema.js export const schema = { \"type\": \"object\", \"properties\": { \"users\": { \"type\": \"array\", \"minItems\": 3, \"maxItems\": 5, \"items\": { \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"number\", \"unique\": true, \"minimum\": 1 }, \"firstName\": { \"type\": \"string\", \"faker\": \"name.firstName\" }, \"lastName\": { \"type\": \"string\", \"faker\": \"name.lastName\" }, \"email\": { \"type\": \"string\", \"faker\": \"internet.email\" } }, \"required\": [\"id\", \"firstName\", \"lastName\", \"email\"] } } }, \"required\": [\"users\"] }; 2. generate Mock Data: buildScripts/generateMockData.js import jsf from 'json-schema-faker'; import { schema } from './mockDataSchema'; import fs from 'fs'; import chalk from 'chalk'; const json = JSON.stringify(jsf(schema)); fs.writeFile('./src/api/db.json', json, err => { if (err) { return console.log(chalk.red(err)); } else { console.log(chalk.green('Mock data generated.')); } }); npm scripts: \"generate-mock-data\": \"babel-node buildScripts/generateMockData\" Run npm run generate-mock-data and you should see src/api/db.json. 3. serving mock data via json server npm scripts: \"start-mockapi\": \"json-server --watch src/api/db.json --port 3001\" npm run start-mockapi and access http://localhost:3001/users, you should see the data I prefer to change data every time when restarting the app. Randomized data is helpful. empty lists long lists long value testing filtering sorting To change data, follow below: npm scripts: \"start\": \"npm-run-all --parallel security-check start:server lint:watch test:watch start-mockapi\", \"generate-mock-data\": \"babel-node buildScripts/generateMockData\", \"prestart-mockapi\": \"npm run generate-mock-data\", \"start-mockapi\": \"json-server --watch src/api/db.json --port 3001\" Targeting mock api or production api by environment Assume srcServer.js's app.get('/users') is called only for production, while in dev mode, we should hit Json-server port 3001. So when requesting localhost:3000/, we know it's development environment and call getUsers api which hosting in port 3001 by Json-server. When request http://production, we call production api. api/baseUrl.js export default function getBaseUrl() { const inDevelopment = window.location.hostname === 'localhost'; return inDevelopment ? 'http://localhost:3001/' : '/'; // first is json-server address, second is production api address } api/userApi.js import getBaseUrl from './baseUrl'; const baseUrl = getBaseUrl(); const get = url => fetch(baseUrl + url).then(onSuccess, onError); delete user for Json-server index.js const deleteLinks = document.querySelectorAll('.deleteUser'); Array.from(deleteLinks, link => { link.onclick = e => { const ele = e.target; e.preventDefault(); deleteUser(ele.dataset.id); const row = ele.parentNode.parentNode; // tr row.parentNode.removeChild(row); }; }); userApi.js const del = url => { const request = new Request(baseUrl + url, { method: 'delete' }); return fetch(request).then(onSuccess, onError); }; export const deleteUser = id => del(`users/${id}`); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/11_structure.html":{"url":"ProjectConfig/Javacript-Starter/11_structure.html","title":"11_structure","keywords":"","body":"1. Project Structure1.1. Why Include a Demo App?1.2. Tips1. Project Structure 1.1. Why Include a Demo App? Examples of: Automated deployment Directory structure and file naming Framework usage Testing Mock API Codifies decisions Interactive example of working with starter 1.2. Tips Cannot put js in html. Put js in a .js file // slap code here... Test this? Lint this? Reuse this? Transpile this? Import explicit dependencies? Consider organizing by feature Organize by file type (MVC) /components /data /models /views Organize by Feature (larger app) /authors /courses Extract logic into \"POJOs\" (plain old javascript object, no framework-specific code) Put utils to utils folder, this doesn't have any relationship with react. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/12_production_build.html":{"url":"ProjectConfig/Javacript-Starter/12_production_build.html","title":"12_production_build","keywords":"","body":"1. Production1.1. Minification1.1.1. How Does Minification Work?1.1.2. Switching Api by queryString1.1.3. Production build npm scripts1.1.4. Why Manipulate HTML for Production?1.1.5. Why Bundle/Code Splitting1.1.6. Cache Busting1.1.7. Separate CSS1.1.8. Error Logging1. Production 1.1. Minification 1.1.1. How Does Minification Work? Shortens variable and function names Removes comments Removes whitespace and new lines Dead code elimination / Tree-shaking Debug via sourcemap 1.1.2. Switching Api by queryString baseUrl.js: /** this determines api address */ export default function getBaseUrl() { return getQueryStringParameterByName('useMockApi') ? 'http://localhost:3001/' // mockapi address : '/'; // production api } function getQueryStringParameterByName(name, url) { if (!url) url = window.location.href; name = name.replace(/[[\\]]/g, '\\\\$&'); var regex = new RegExp('[?&]' + name + '(=([^&#]*)|&|#|$)'), results = regex.exec(url); if (!results) return null; if (!results[2]) return ''; return decodeURIComponent(results[2].replace(/\\+/g, ' ')); } http://localhost:3000/?useMockApi=true will use Mock Data. Otherwise, without useMockApi, will hit production Api. 1.1.3. Production build npm scripts Create build.js and distServer.js \"clean-dist\": \"rimraf ./dist && mkdir dist\", \"prebuild\": \"npm-run-all clean-dist test lint\", \"build\": \"babel-node buildScripts/build.js\", \"postbuild\": \"babel-node buildScripts/distServer.js\" 1.1.4. Why Manipulate HTML for Production? Reference bundles automatically Handle dynamic bundle names Inject production only resources Minify Best way is to use html-webpack-plugin since we use webpack. 1.1.5. Why Bundle/Code Splitting Important for larger application Speed initial page load Avoid re-downloading all libraries vendor.js /* eslint-disable no-unused-vars */ import fetch from 'whatwg-fetch'; webpack.config.prod.js entry: { + vendor: path.resolve(__dirname, 'src/vendor'), + main: path.resolve(__dirname, 'src/index') }, output: { path: path.resolve(__dirname, 'dist'), publicPath: '/', + filename: '[name].js' }, plugins: [ + // Use CommonsChunkPlugin to create a separate bundle + // of vendor libraries so that they're cached separately. + new webpack.optimize.CommonsChunkPlugin({ + name: 'vendor' + }) ] 1.1.6. Cache Busting Save HTTP Requests Force request for latest version Setup Cache busting Hash bundle filename. If no code changes, no filename changes. Generate HTML dynamically import WebpackMd5Hash from 'webpack-md5-hash'; export default { output: { path: path.resolve(__dirname, 'dist'), publicPath: '/', filename: '[name].[chunkhash].js' }, plugins: [ // Hash the files using MD5 so that their names change when the content changes. new WebpackMd5Hash() ] } 1.1.7. Separate CSS import ExtractTextPlugin from 'extract-text-webpack-plugin'; export default { plugins: [ // Generate an external css file with a hash in the filename new ExtractTextPlugin('[name].[contenthash].css'), ], module: { rules: [ { test: /\\.css$/, use: ExtractTextPlugin.extract({ fallback: \"style-loader\", use: \"css-loader\", publicPath: \"/dist\" }) } ] } }; 1.1.8. Error Logging TrackJS(✅) Sentry New Relic Raygun Things to be considered: Error Metadata Browser Stack trace Previous actions Custom API for enhanced tracking Notifications & integrations Analytics and filtering Pricing Track.js Install the Tracker Library The Tracker library lives in your web application. Paste this snippet before your other scripts in the of your page. window._trackJs = { token: '7a7c1c686a66488c8bd4b229de471250' }; Track an Error Tracker logs errors automatically, but to verify it's working let's try it manually. You can track an error from anywhere in your application, or in your developer console: trackJs.track('ahoy trackjs!'); 手动错误上报：(interview/frontend/错误监控.md） window.addEventListener('error', function (e) { console.log('捕获', e); (new Image()).src = 'http://baidu.com/tesjk?r=tksjk'; }, true); Now the error logging happened both development and production environment. Actually we only want to monitor production. We can extend HtmlWebpackPlugin property and its default template ejs to update index.html // webpack.config.prod.js plugins: [ new HtmlWebpackPlugin({ template: 'src/index.html', inject: true, minify: { removeComments: true, collapseWhitespace: true, removeRedundantAttributes: true, useShortDoctype: true, removeEmptyAttributes: true, removeStyleLinkTypeAttributes: true, keepClosingSlash: true, minifyJS: true, minifyCSS: true, minifyURLs: true }, // Properties you define here are available in index.html // using htmlWebpackPlugin.options.varName trackJSToken: '7a7c1c686a66488c8bd4b229de471250' }) ] index.html window._trackJs = { token: '7a7c1c686a66488c8bd4b229de471250' }; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Javacript-Starter/13_deployment.html":{"url":"ProjectConfig/Javacript-Starter/13_deployment.html","title":"13_deployment","keywords":"","body":"1. Deployment1.1. Why Separate the UI and API?1.2. Cloud hosting1.3. Hosting javascript-starter-kit-api(API) to Heroku1.4. Deploy static files(UI) to Surge1.4.1. Reference1. Deployment 1.1. Why Separate the UI and API? Simple, low-risk, UI only deploys Separates concerns Separate teams Less to understand Scale back-end separately Cheap UI hosting (hosting only static files) Serve UI via a content delivery network Use the API tech you like 1.2. Cloud hosting amazon web services microsoft azure Heroku firebase google cloud platform github (static files only) Surge (static files only) 1.3. Hosting javascript-starter-kit-api(API) to Heroku We separate API and UI. The repository is at https://github.com/wghglory/javascript-starter-kit-api. See some configurations needed there for heroku. This api repository will be hosted in heroku. app.json - describe app to heroku Procfile - command that heroku should run 1.4. Deploy static files(UI) to Surge package.json: \"deploy\": \"surge ./dist\" npm run build -s npm run deploy 1.4.1. Reference React starter: http://andrewhfarmer.com/starter-project/ Angular starter: https://github.com/gianarb/awesome-angularjs Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/Mock.html":{"url":"ProjectConfig/Mock.html","title":"Mock","keywords":"","body":"1. 前端数据 mock1.1. Json Server 创建本地 json 文件作为数据库1.2. Faker.js 产生数据1.3. 具体步骤1.3.1. 1. Declare Schema1.3.2. 2. Generate Random Data1.3.3. 3.  Serve Random Data1. 前端数据 mock 1.1. Json Server 创建本地 json 文件作为数据库 https://github.com/typicode/json-server https://coligo.io/create-mock-rest-api-with-json-server 1.2. Faker.js 产生数据 Faker graphql-js 1.3. 具体步骤 1.3.1. 1. Declare Schema Test schema at http://json-schema-faker.js.org install packages: npm i json-schema-faker json-server --save-dev // create buildScripts/mockDataSchema.js var schema = { \"type\": \"object\", \"properties\": { \"users\": { \"type\": \"array\", \"minItems\": 3, \"maxItems\": 5, \"items\": { \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"number\", \"unique\": true, \"minimum\": 1 }, \"firstName\": { \"type\": \"string\", \"faker\": \"name.firstName\" }, \"lastName\": { \"type\": \"string\", \"faker\": \"name.lastName\" }, \"email\": { \"type\": \"string\", \"faker\": \"internet.email\" } }, \"required\": [\"id\", \"type\", \"lastname\", \"email\"] } } }, \"required\": [\"users\"] }; module.exports = schema; 1.3.2. 2. Generate Random Data // create buildScripts/generateMockData.js /* This script generates mock data for local development. This way you don't have to point to an actual API, but you can enjoy realistic, but randomized data, and rapid page loads due to local, static data. */ var jsf = require('json-schema-faker'); var mockDataSchema = require('./mockDataSchema'); var fs = require('fs'); var json = JSON.stringify(jsf(mockDataSchema)); fs.writeFile('./src/api/db.json', json, function(err) { if (err) { return console.log(err); } else { console.log('Mock data generated.'); } }); in package.json \"generate-mock-data\": \"node buildScripts/generateMockData\" 1.3.3. 3.  Serve Random Data package.json: if prestart-mockapi is used, data will be regenerated everytime npm run start-mockapi. \"generate-mock-data\": \"node buildScripts/generateMockData\", \"prestart-mockapi\": \"npm run generate-mock-data\", \"start-mockapi\": \"json-server --watch src/api/db.json --port 3001\" run the mock server: npm run start-mockapi Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/nginx/":{"url":"ProjectConfig/nginx/","title":"ProjectConfig/nginx","keywords":"","body":"1. TOC1. TOC Nginx 创狐Nginx配置 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"ProjectConfig/nginx/Nginx.html":{"url":"ProjectConfig/nginx/Nginx.html","title":"Nginx","keywords":"","body":"1. Nginx1.1. 安装并启动 Nginx1.2. Nginx配置不完全详解1.3. Nginx配置最佳实践1.4. default配置解析1.5. 配置反向代理1.6. 配置临时跳转1.7. 配置限制访问1.8. default-ssl 配置解析1.9. 小结1.10. 反向代理1. Nginx http://www.jianshu.com/p/e24d676060c1 Nginx(发音：engine X)是一款轻量级的HTTP服务器（相比于Apache、Lighttpd而言），同时是一个高性能的HTTP和反向代理服务器，如今国内主流网站基本搭建于Nginx之上，诸如新浪、腾讯、网易、豆瓣。 Nginx主要以事件驱动的方式编写，有兴趣可以移步这里看他们的源码，这让它拥有非常好的性能，同时也是一个非常高效的反向代理、负载均衡。 官方站点也指出了Nginx作为HTTP服务器的几项基本特性： 处理静态文件，索引文件以及自动索引；打开文件描述符缓冲 无缓存的反向代理加速，简单的负载均衡和容错 FastCGI，简单的负载均衡和容错 模块化的结构，包括 gzipping, byte ranges, chunked responses 以及 SSI-filter 等 filter。 支持 SSL 和 TLSSNI. 1.1. 安装并启动 Nginx 由于我是用Mac办公的，所以安装Nginx是采用brew进行的，在终端输入下面命令安装好Nginx： # 强烈建议每次 brew 安装软件的时候先执行 rew update 保持软件依赖包都是最新的 brew install nginx 安装后 path：/usr/local/etc/nginx/nginx.conf 紧接着就可以用浏览器打开http://localhost:8080看到Nginx的欢迎信息。 跟Linux系统有些不同，在Mac下面Nginx默认监听了8080端口号，若强迫症（比如我）不希望每次打开网页都要输入端口号的话，那么请在终端执行下面命令： # 下面的1.12.0请根据最新安装版本号对应修改 sudo chown root:wheel /usr/local/Cellar/nginx/1.12.0/bin/nginx sudo chmod u+s /usr/local/Cellar/nginx/1.12.0/bin/nginx # 用vi编辑器打开nginx配置文件，找到server字段的listen字段并将其值修改为80 vi /usr/local/etc/nginx/nginx.conf 修改完上面配置信息之后，执行下面命令检查配置文件语法是否有误并且重新加载配置： nginx -t && nginx -s reload 如果遇到问题nginx: [emerg] open() \"/usr/local/Cellar/nginx/1.12.1/logs/access.log\" failed (2: No such file or directory) 手动创建 logs 文件夹和 access.log 文件 更多关于Nginx命令的帮助可以输入nginx -h查看，若想每次开机自动开启Nginx，在终端执行下面命令即可： ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents launchctl load ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist 1.2. Nginx配置不完全详解 下面是我机器上的Nginx的配置文件： 强烈建议大家先打开自己的默认Nginx配置跟我的对比来看 可以在终端执行 cat /usr/local/etc/nginx/nginx.conf.default 查看默认配置文件 # user字段表明了Nginx服务是由哪个用户哪个群组来负责维护进程的，默认是nobody # 我这里用了cainengtian用户，staff组来启动并维护进程 # 查看当前用户命令： whoami # 查看当前用户所属组命令： groups ，当前用户可能有多个所属组，选第一个即可 user cainengtian staff; # worker_processes字段表示Nginx服务占用的内核数量 # 为了充分利用服务器性能你可以直接写你本机最高内核 # 查看本机最高内核数量命令： sysctl -n hw.ncpu worker_processes 4; # error_log字段表示Nginx错误日志记录的位置 # 模式选择：debug/info/notice/warn/error/crit # 上面模式从左到右记录的信息从最详细到最少 error_log /usr/local/var/logs/nginx/error.log debug; # Nginx执行的进程id,默认配置文件是注释了 # 如果上面worker_processes的数量大于1那Nginx就会启动多个进程 # 而发信号的时候需要知道要向哪个进程发信息，不同进程有不同的pid，所以写进文件发信号比较简单 # 你只需要手动创建，比如我下面的位置： touch /usr/local/var/run/nginx.pid pid /usr/local/var/run/nginx.pid; events { # 每一个worker进程能并发处理的最大连接数 # 当作为反向代理服务器，计算公式为： `worker_processes * worker_connections / 4` # 当作为HTTP服务器时，公式是除以2 worker_connections 2048; } http { # 关闭错误页面的nginx版本数字，提高安全性 server_tokens off; include mime.types; default_type application/octet-stream; # 日志记录格式，如果关闭了access_log可以注释掉这段 #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 关闭access_log可以让读取磁盘IO操作更快 # 当然如果你在学习的过程中可以打开方便查看Nginx的访问日志 access_log off; sendfile on; # 在一个数据包里发送所有头文件，而不是一个接一个的发送 tcp_nopush on; # 不要缓存 tcp_nodelay on; keepalive_timeout 65; gzip on; client_max_body_size 10m; client_body_buffer_size 128k; # 关于下面这段在后面紧接着来谈！ include /usr/local/etc/nginx/sites-enabled/*; } 1.3. Nginx配置最佳实践 上面的配置文件最后一行include关键词会将/usr/local/etc/nginx/sites-enabled/文件夹下面的所有文件都加载进当前的配置文件，这样子就可以将配置文件分离，nginx.conf这个配置文件修改之后以后基本不会修改，配置不同站点的时候只需要在/usr/local/etc/nginx/sites-enabled/不断增加新的文件即可，这是比较好的配置方式。 比如我在/usr/local/etc/nginx/sites-enabled/下面增加了两个文件，用来配置普通的HTTP服务还有HTTPS服务： touch /usr/local/etc/nginx/sites-enabled/default touch /usr/local/etc/nginx/sites-enabled/default-ssl 1.4. default配置解析 Nginx整个配置的结构大致如下： ... events { ... } http { ... server { ... location xxx { ... } } } 对比上面我的nginx.conf文件可以知道default文件的内容就是配置server部分的，下面先弄一份最基本的配置（带有详细说明）： server { # Nginx监听端口号 listen 80; # 服务器的名字，默认为localhost，你也可以写成 aotu.jd.com，这样子就可以通过 aotu.jd.com来访问 server_name localhost; # 代码放置的根目录 root /var/www/; # 编码 charset utf-8; location / { # index字段声明了解析的后缀名的先后顺序 # 下面匹配到/的时候默认找后缀名为php的文件，找不到再找html，再找不到就找htm index index.php index.html index.htm; # 自动索引 autoindex on; # 这里引入了解析PHP的东西 include /usr/local/etc/nginx/conf.d/php-fpm; } # 404页面跳转到404.html，相对于上面的root目录 error_page 404 /404.html; # 403页面跳转到403.html，相对于上面的root目录 error_page 403 /403.html; # 50x页面跳转到50x.html error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } 上面的配置的意思就是：访问http://localhost『80端口号可以直接省略』的时候会在/var/www/下面找index.php文件，如果没有找到就找index.html，如果再没有找到那就找index.htm，如果还是没有找到的话就404跳转到404.html，如果你刚好将/var/www/设置为root用户访问的话，那么就会直接无访问权限403跳转到403.html。 # 当用root配置的时候，root后面指定的目录是上级目录 # 并且该上级目录必须含有和location后指定的名称的同名目录，否则404 # root末尾的\"/\"加不加无所谓 # 下面的配置如果访问站点http://localhost/test1访问的就是/var/www/test1目录下的站点信息 location /test1/ { root /var/www/; } # 如果用alias配置，其后面跟的指定目录是准确的，并且末尾必须加\"/\"，否则404 # 下面的配置如果访问站点http://localhost/test2访问的就是/var/www/目录下的站点信息 location /test2/ { alias /var/www/; } 大家在实践过程中注意区分即可，配置之后要是碰到404可以先考虑是否是这个原因。 1.5. 配置反向代理 对于前端工程师而言，可能最容易成为全栈的技能就是NodeJS了，当我们用express框架写好了一个Node应用之后，比如启动的时候的访问地址是：http://localhost:3000/，但是在部署到服务器上去之后，我们当然不希望别人这样子访问，最好的情况肯定是隐藏掉端口号。 例如我有一个Node服务的名字是o2blog_wx，在启动Node的时候访问的地址是：http://localhost:3000/，但是对外网我们希望是：http://aotu.jd.com/o2blog_wx，接下来我们将通过Nginx进行配置（带有详细注释）。 server { listen 80; server_name aotu.jd.com; root /var/www/; location /o2blog_wx/ { # 反向代理我们通过proxy_pass字段来设置 # 也就是当访问http://aotu.jd.com/o2blog_wx的时候经过Nginx反向代理到服务器上的http://127.0.0.1:3000 # 同时由于解析到服务器上的时候o2blog_wx这个字段都要处理 # 所以通过rewrite字段来进行正则匹配替换 # 也就是http://aotu.jd.com/o2blog_wx/hello经过Nginx解析到服务器变成http://127.0.0.1:3000/hello proxy_pass http://127.0.0.1:3000; rewrite ^/o2blog_wx/(.*) /$1 break; } } 1.6. 配置临时跳转 有时候我们觉得一开始配置的URL不好想换掉，但又不想原先的链接失效，比如一开始对外网的链接是：http://aotu.jd.com/o2blog_wx/，后来想改成http://aotu.jd.com/wxblog，又不想原先的失效。 这个时候可以在Nginx上配置一个302临时跳转，如下（server部分跟前面的一样）： location /o2blog_wx/ { # 当匹配到http://aotu.jd.com/o2blog_wx/的时候会跳转到http://aotu.jd.com/wxblog return 302 http://aotu.jd.com/wxblog } 1.7. 配置限制访问 在一台服务器上的资源不全部都是对外开放的，这个时候就需要通过Nginx配置一个限制访问，比如查看本服务器的PHP信息，我们就可以通过下面配置来实现限制访问： # 当匹配到/info的时候只允许10.7.101.224访问，其它的全部限制 # 同时改写为/info.php location = /info { allow 10.7.101.224; deny all; rewrite (.*) /info.php } 这个时候只有IP为10.7.101.224的机器才可以访问：http://aotu.jd.com/info，其它机器都会403拒绝访问！ 当然最佳的实践是将IP抽取出来变成白名单，这样子就可以实现部分IP可以访问，其它的不能访问。 1.8. default-ssl 配置解析 我们都知道HTTP在传输的过程中都是明文的，这直接导致了在传输的任何一个过程中都容易被窃取信息，所以才有了SSL（安全套接层）以及升级版TLS（传输层安全协议）的出现，其实就是在HTTP应用层给TCP/IP传输层的中间增加了TLS/SSL层，统称为HTTPS。 那如何通过Nginx配置HTTPS站点呢，下面就是default-ssl配置文件的内容（详细解析）： server { # 默认情况下HTTPS监听443端口 listen 443 ssl; server_name localhost; root /var/www/; # 下面这些都是配置SSL需要的 ssl on; # 下面两个字段需要的crt利用openssl生成，具体可以看[这里](http://nginx.org/en/docs/http/configuring_https_servers.html) ssl_certificate ssl/localhost.crt; ssl_certificate_key ssl/localhost.key; ssl_session_timeout 10m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location = /info { allow 127.0.0.1; deny all; rewrite (.*) /info.php; } location /phpmyadmin/ { root /usr/local/share/phpmyadmin; index index.php index.html index.htm; } location / { include /usr/local/etc/nginx/conf.d/php-fpm; } error_page 403 /403.html; error_page 404 /404.html; } 上面配置之后，就可以通过https://localhost/访问我们的Nginx首页了。 当然若要在对外网使用，必须购买第三方信任证书才行，有兴趣的童鞋可以谷歌了解，这里不细谈。 1.9. 小结 写到这里，最基本的Nginx配置就基本介绍完了，若按照我上面的配置一步步跟着改，基本上都可以跑起来Nginx服务了吧，若想更加深入学习Nginx的配置，强烈建议看官方文档，写得很清晰明了，还是那句老话：授之以鱼不如授之以渔。 1.10. 反向代理 提到反向代理，必然先提到正向代理，正向代理(forward)是一个位于客户端【用户A】和原始服务器(origin server)【服务器B】之间的服务器【代理服务器Z】，为了从原始服务器取得内容，用户A向代理服务器Z发送一个请求并指定目标(服务器B),然后代理服务器Z向服务器B转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。 正向代理示意图 从上图可以看出，所谓的正向代理就是代理服务器替代访问方【用户A】去访问目标服务器【服务器B】，在现实中的例子就是『翻墙』！但如果代理服务器Z被完全控制（或不完全控制），就变成了『肉鸡』了。 而反向代理与正向代理相反，对客户端而言代理服务器就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间（name-space）中的内容发送普通请求，接着反向代理将判断向何处（原始服务器）转交请求，并将获得的内容返回给客户端。 使用反向代理服务器主要核心作用如下： 保护和隐藏原始资源服务器 反向代理原理图 从上图可以看出，用户A始终认为它访问的是原始服务器B而不是代理服务器Z，但实际上反向代理服务器接受用户A的应答，从原始资源服务器B中取得用户A的需求资源，然后发送给用户A。由于防火墙的作用，只允许代理服务器Z访问原始资源服务器B。尽管在这个虚拟的环境下，防火墙和反向代理的共同作用保护了原始资源服务器B，但用户A并不知情。 负载均衡 反向代理负载均衡示例图 当反向代理服务器不止一个的时候，我们甚至可以把它们做成集群，当更多的用户访问资源服务器B的时候，让不同的代理服务器Z（x）去应答不同的用户，然后发送不同用户需要的资源。 当然反向代理服务器像正向代理服务器一样拥有CACHE的作用，它可以缓存原始资源服务器B的资源，而不是每次都要向原始资源服务器B请求数据，特别是一些静态的数据，比如图片和文件，如果这些反向代理服务器能够做到和用户X来自同一个网络，那么用户X访问反向代理服务器X，就会得到很高质量的速度。这正是CDN技术的核心。如下图： CDN原理图 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/nginx/创狐Nginx配置.html":{"url":"ProjectConfig/nginx/创狐Nginx配置.html","title":"创狐Nginx配置","keywords":"","body":"1. 创狐 Nginx 配置1. 创狐 Nginx 配置 mac nginx path: /usr/local/etc/nginx/nginx.conf worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; sendfile on; keepalive_timeout 65; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; #gzip_http_version 1.0; gzip_comp_level 5; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; gzip_vary off; gzip_disable \"MSIE [1-6]\\.\"; # pgc server { listen 8093; location / { #需要修改成你本地项目的build文件夹地址 root /Users/derek/Work/Hifox/ch-frontend/jc-pgc/build/; } location /api/ { proxy_pass http://106.15.179.107:7126/; proxy_set_header X-Forwarded-Host $host:8093; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location /r/ { #上传目录 alias D:\\\\dir; } } } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/npm_scripts_over_gulp.html":{"url":"ProjectConfig/npm_scripts_over_gulp.html","title":"npm_scripts_over_gulp","keywords":"","body":"1. Npm scripts instead of gulp or grunt1.1. npm tricks1.1.1. package.json1.1.2. Useful Commands1.1.3. reference1. Npm scripts instead of gulp or grunt 1.1. npm tricks \"&\": run concurrently (windows: START /B) \"&&\": chaining commands. First must pass, then run second \";\": second will execute even if first command has error \"|\": piping output, take the result of left command, pass result to terminal or next task in pipeline \"-- \": pass arguments into the underlying commands (npm test -- -w, -w is passed to npm test) \">\": redirection operator, write output to file 1.1.1. package.json { \"name\": \"basic-config\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\":{ \"noeffect2second\": \"echo 'hello'; echo 'world'\", // ; second will execute even if first command has error // \"start\": \"./node_modules/.bin/webpack-dev-server --open\", \"start\": \"node index.js\", \"start:dev\": \"node index.js 4000\", \"pretest\": \"npm run compile && npm run lint\", \"posttest\" : \"echo 'after tests are run'\", \"pretest\": \"npm run compile && npm run lint\", \"test\": \"mocha test -u bdd -R spec\", \"compile:coffee\": \"coffee --compile --output ./lib ./src/coffeescripts\", \"compile:ts\": \"tsc --outDir ./lib --module commonjs ./src/typescripts/tsCode.ts\", \"compile\": \"npm run compile:coffee && npm run compile:ts\", \"precompile\": \"npm run clean\", \"clean\": \"rimraf lib/*\", // 兼容 unix 和 windows. For mac: \"rm -rf lib/*.*\" \"build:less\": \"lessc client/less/demo.less public/css/site.css\", \"build:bundle\": \"browserify ./client/js/app.js | uglifyjs -mc > ./public/js/bundle.js\", \"build:clean\": \"rimraf public/css/*, public/js/*\", \"prebuild\": \"npm run build:clean\", \"build\": \"npm run build:less && npm run build:bundle\", // \"build\": \"NODE_ENV='production' webpack --config ./webpack.production.config.js -p\", \"watch:test\": \"npm run test -- -w -R min\", \"watch:lint\": \"watch 'npm run lint' .\", \"watch:server\": \"nodemon --ignore client --ignore public index.js\", \"watch:coffee\": \"coffee --compile -w --output ./lib ./src/coffeescripts\", \"watch:ts\": \"tsc -w --outDir ./lib --module commonjs ./src/typescripts/tsCode.ts\", \"watch:bundle\": \"watchify ./client/js/app.js -o ./public/js/bundle.js -dv\", // no minification \"watch:bundleWatcher\": \"watch 'npm run build:bundle' client\", // will minify \"watch:browser\": \"live-reload --port 9091 public/\", \"watch\": \"npm run watch:test & npm run watch:bundle & npm run watch:server & npm run watch:browser\", \"version:major\": \"npm version major\", \"version:minor\": \"npm version minor\", \"version:patch\": \"npm version patch\", \"prepush:origin\": \"echo 'Pushing code to GitHub'\", \"push:origin\": \"git push --tags origin HEAD:master\", \"prepush:heroku\": \"echo 'Pushing code to Heroku'\", \"push:heroku\": \"git push heroku master\", \"push:s3\": \"s3-cli sync ./dist/ s3://example-com/prod-site/\", \"push:azure\": \"git push azure master\", \"launch:prod\": \"heroku open\", \"launch:prod:windows\": \"start https://stupidlittlewebsite.herokuapp.com/\", \"push\": \"npm run push:origin && npm run push:heroku\", // \"deploy\": \"npm run build && firebase deploy\", \"deploy:prod\": \"npm run test:deploy -s && npm run build -s && npm run version:patch && npm run push && npm run launch:prod\", \"deploy:prod:time\": \"time(npm run deploy:prod)\", \"deploy:prod:script\": \"bash ./deployProd.sh\", // windows: bash ./deployProd.bat \"test:deploy\": \"npm t -- -R dot\", \"test:configoptions\": \"mocha test --reporter $npm_package_config_reporter\", \"fix\": \"./node_modules/.bin/eslint . --ext .js --fix\", \"lint\": \"./node_modules/.bin/eslint . --ext .js\", \"firebase-init\": \"firebase login && firebase init\" }, \"config\": { \"reporter\": \"landing\" }, // heroku needs it I guess \"engines\": { \"node\": \"~7.8.0\", \"npm\": \"~4.2.0\" }, \"repository\": { \"type\": \"git\", \"url\": \"https://wghglory@bitbucket.org/wghglory/guanghui.notebook.git\" }, \"devDependencies\": { \"browserify\": \"^14.4.0\", // \"coffee-script\": \"^1.10.0\", // \"jshint\": \"^2.8.0\", \"less\": \"^2.7.2\", \"live-reload\": \"^1.1.0\", \"mocha\": \"^3.5.3\", \"nodemon\": \"^1.12.0\", \"rimraf\": \"^2.6.2\", \"should\": \"^13.0.1\", \"supertest\": \"^3.0.0\", \"typescript\": \"^2.5.2\", \"uglifyjs\": \"^2.4.11\", \"watch\": \"^1.0.2\", \"watchify\": \"^3.9.0\" } } 1.1.2. Useful Commands npm run # show a log of the available commands in package.json npm run test npm test -s # 简略结果 short, small output npm tst npm t npm start npm install mocha should --save-dev 在运行 npm version 之前，最好把 git repository 远程连接配置好。这样 npm version patch 时，package.json version 和 git tag 会同步都更新。再通过下面命令把 tag 推送到远端。 npm version major/minor/patch # increments both package.json and sets a tag in git repository if package.json indicates repository git push --tags origin HEAD:master See installed tools: ls node_modules/.bin 1.1.3. reference https://github.com/coryhouse/react-slingshot/blob/master/package.json https://libraries.io/ https://docs.npmjs.com/misc/scripts https://www.pluralsight.com/courses/npm-build-tool-introduction Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"ProjectConfig/webpack.html":{"url":"ProjectConfig/webpack.html","title":"webpack","keywords":"","body":"1. Webpack1. Webpack Webpack is a module bundler that helps us make production and development transformations to the code we write. The reason for it to exist is that web developers shouldn’t have to transform code every time they want to test or deploy it. These transformations include but are not limited to: bundling js, bundling css, minification and uglification, jsx to js, sass/less to css, et cetera. Webpack needs the entry point for the main javascript files. It has a modules property that we use to specify all loaders (rules) that need to make a transformation on the code. It has plugins property which specifies plugins like html-webpack-config’s object in its array. It needs the template and filename in the output distribution folder. Webpack loaders allow us to preprocess files (like css, et cetera) as we require them into the root js file. While using webpack-dev-server to run a web server locally, any changes we make do not cause webpack to compile our bundle to the dist folder. However, it dynamically updates quickly because webpack saves the changes in a cache that is meant to refresh quickly rather than compiling a build bundle every time a change is made. 2 core things: Loaders, plugins Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/":{"url":"React/","title":"React","keywords":"","body":"1. TOC1. TOC caveat code_async_await code_remarkable_markdown_library code_评分 Flux Fundamentals HOF_currying_HOC immutability-helper Immutability Imperative_vs_Declarative Inheritance _vs_composition lifecycle Presentational_vs_Container_Components Pure_vs_Impure_functions react-router React面试 setStateAsync Testing Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"React/caveat.html":{"url":"React/caveat.html","title":"caveat","keywords":"","body":"1. Something you need to know about react1. Something you need to know about react 1. React is MVC's V 2. Keep your components small const LatestPostsComponent = props => ( Latest posts { props.posts.map(post => ) } ); The component itself is a , with only 2 s inside it. The first one has a heading, and second one just maps over some data, rendering a for each element. That last part, extracting the as its own component, is the important bit. 3. Write functional components class MyComponent extends React.Component { render() { return ; } } const MyComponent = props => ( ); don't use ref often: ref encourage a very imperative, almost jquery-like way of writing components, taking us away from the functional, one-way data flow philosophy for which we chose React in the first place! don't use state if possible 4. Write stateless components State makes components difficult to test When components are just functions of input props, testing is a lot easier. (More on testing later). State makes it too easy to put business logic in the component React is a view library, so while render logic in the components is OK, business logic is a massive code smell. But when so much of your application's state is right there in the component, easily accessible by this.state, it can become really tempting to start putting things like calculations or validation into the component, where it does not belong. Revisiting my earlier point, this makes testing that much harder - you can't test render logic without the business logic getting in the way, and vice versa! 6. Always use propTypes propTypes offer us a really easy way to add a bit more type safety to our components. They look like this: import PropTypes from 'prop-types' const ListOfNumbers = props => ( { props.numbers.map(number => ( {number}) ) } ); ListOfNumbers.propTypes = { className: PropTypes.string.isRequired, numbers: PropTypes.arrayOf(PropTypes.number) }; When in development (not production), if any component is not given a required prop, or is given the wrong type for one of its props, then React will log an error to let you know. This has several benefits: It can catch bugs early, by preventing silly mistakes If you use isRequired, then you don't need to check for undefined or null as often It acts as documentation, saving readers from having to search through a component to find all the props that it needs The above list looks a bit like one you might see from someone advocating for static typing over dynamic typing. Personally, I usually prefer dynamic typing for the ease and speed of development it provides, but I find that propTypes add a lot of safety to my React components, without making things any more difficult. Frankly I see no reason not to use them. One final tip is to make your tests fail on any propType errors. The following is a bit of a blunt instrument, but it's simple and it works: beforeAll(() => { console.error = error => { throw new Error(error); }; }); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/code_async_await.html":{"url":"React/code_async_await.html","title":"code_async_await","keywords":"","body":"1. React 中的 async 和 await1. React 中的 async 和 await 使用了蚂蚁金服 antd import React, { Component } from 'react'; import { Table, Pagination, Popconfirm, Button } from 'antd'; import moment from 'moment'; import { getUsers, createUser, updateUser, deleteUser } from '../../services/user'; import { getOrganizationsBatch } from '../../services/organization'; import UserEditModal from './UserEditModal'; import UserCreateModal from './UserCreateModal'; import './UserList.scss'; export default class UserList extends Component { constructor(props) { super(props); this.fetchUsers = this.fetchUsers.bind(this); this.fetchOrganizations = this.fetchOrganizations.bind(this); this.pageChangeHandler = this.pageChangeHandler.bind(this); this.createHandler = this.createHandler.bind(this); this.editHandler = this.editHandler.bind(this); this.deleteHandler = this.deleteHandler.bind(this); this.state = { loading: true, users: [], last: false, //last page totalPages: 0, totalElements: 0, first: true, //first page numberOfElements: 0, sort: null, pageSize: 0, pageIndex: 0 }; } componentDidMount() { this.fetchUsers(); } // webpack! entry: ['babel-polyfill', './src/index.js'], async fetchUsers(pageIndex, pageSize) { let res = await getUsers(pageIndex, pageSize); let formattedUsers = await this.fetchOrganizations(res.content); this.setState({ loading: false, users: formattedUsers, // added organization name last: res.last, totalPages: res.totalPages, totalElements: res.totalElements, first: res.first, numberOfElements: res.numberOfElements, sort: res.sort, pageSize: res.size, pageIndex: res.number + 1 // 后台number从0开始，pageIndex从1，展示pagination }); } /* // Promise 写法 // method 1: 2个 then 嵌套 fetchUsers(pageIndex, pageSize) { getUsers(pageIndex, pageSize).then(res => { this.fetchOrganizations(res.content).then((formattedUsers) => this.setState({ loading: false, users: formattedUsers, // added organization name last: res.last, totalPages: res.totalPages, totalElements: res.totalElements, first: res.first, numberOfElements: res.numberOfElements, sort: res.sort, pageSize: res.size, pageIndex: res.number + 1 // 后台number从0开始，pageIndex从1，展示pagination })) }) } // method 2: 没有 then 的嵌套 fetchUsers(pageIndex, pageSize) { getUsers(pageIndex, pageSize).then(res => { this.setState({ loading: false, last: res.last, totalPages: res.totalPages, totalElements: res.totalElements, first: res.first, numberOfElements: res.numberOfElements, sort: res.sort, pageSize: res.size, pageIndex: res.number + 1 // 后台number从0开始，pageIndex从1，展示pagination }) return this.fetchOrganizations(res.content) }).then(formattedUsers => this.setState({ users: formattedUsers, // added organization name })) } */ fetchOrganizations(users) { let organizationIds = new Set(); users.forEach((u) => organizationIds.add(u.organizationId)); let orgMap = new Map(); //key: organizationId, value: organizationName return getOrganizationsBatch(Array.from(organizationIds)).then((res) => { const organizations = res.content; organizations.forEach((o) => orgMap.set(o.id, o.name)); users.forEach((u) => (u.organizationName = orgMap.get(u.organizationId))); return users; }); } pageChangeHandler(pageIndex) { // 发给后台的页码从0开始 this.fetchUsers(pageIndex - 1, this.state.pageSize); } editHandler(id, model) { updateUser(id, model); } deleteHandler(id) { deleteUser(id); } createHandler(model) { createUser(model); } render() { const columns = [ { title: 'Id', dataIndex: 'id', key: 'id', width: 200 }, { title: '用户名', dataIndex: 'userName', key: 'userName', render: (text) => {text} }, { title: '邮件', dataIndex: 'email', key: 'email' }, { title: '电话', dataIndex: 'phone', key: 'phone' }, { title: '真实姓名', dataIndex: 'trueName', key: 'trueName' }, { title: '注册时间', dataIndex: 'createdOn', key: 'createdOn', render: (text) => moment(new Date(text)).format('YYYY-MM-DD HH:mm:ss') }, { title: '禁用', dataIndex: 'enable', key: 'enable', render: (text) => (text ? '正常' : '禁用') }, { title: '组织Id', dataIndex: 'organizationId', key: 'organizationId' }, { title: '组织', dataIndex: 'organizationName', key: 'organizationName' }, { title: '权限', dataIndex: 'permissions', key: 'permissions', render: (arr) => arr.join(', ') }, { title: '备注', dataIndex: 'comment', key: 'comment' }, { title: '操作', key: 'operation', render: (text, record) => ( 编辑 删除 ) } ]; const rowSelection = { onChange: (selectedRowKeys, selectedRows) => { // console.log(`selectedRowKeys: ${selectedRowKeys}`, `selectedRows: ${selectedRows}`) } }; const dataSet = this.state.users != null ? this.state.users : []; return ( 创建用户 record.id} size=\"middle\" bordered pagination={false} /> `${range[0]}-${range[1]} / ${total} 条`} showQuickJumper current={this.state.pageIndex} onChange={this.pageChangeHandler} total={this.state.totalElements} pageSize={this.state.pageSize} /> ); } } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/code_remarkable_markdown_library.html":{"url":"React/code_remarkable_markdown_library.html","title":"code_remarkable_markdown_library","keywords":"","body":"1. remarkable, an external Markdown library1. remarkable, an external Markdown library convert markdown text in real-time class MarkdownEditor extends React.Component { constructor(props) { super(props); this.handleChange = this.handleChange.bind(this); this.state = { value: 'Type some *markdown* here!' }; } handleChange(e) { this.setState({ value: e.target.value }); } getRawMarkup() { var md = new Remarkable(); return { __html: md.render(this.state.value) }; } render() { return ( Input Output ); } } ReactDOM.render(, mountNode); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/code_评分.html":{"url":"React/code_评分.html","title":"code_评分","keywords":"","body":"1. 核心react代码1. 核心react代码 /* * usage: */ import React from 'react'; import PropTypes from 'prop-types'; const Star = ({ selected = false, onClick = f => f }) => ; Star.propTypes = { selected: PropTypes.bool, onClick: PropTypes.func }; export default class StarRating extends React.Component { constructor(props) { super(props); this.state = { starsSelected: props.starsSelected }; this.change = this.change.bind(this); } change(starsSelected) { this.setState({ starsSelected }); } render() { const { totalStars } = this.props; const { starsSelected } = this.state; return ( {[...Array(totalStars)].map((n, i) => this.change(i + 1)} /> )} {starsSelected} of {totalStars} stars ); } } StarRating.propTypes = { totalStars: PropTypes.number, starsSelected: PropTypes.number }; StarRating.defaultProps = { totalStars: 5, starsSelected: 0 }; css代码： html, body, #app { height: 100%; margin: 0; padding: 0; } #app { display: flex; align-items: center; justify-content: center; } .star-rating { display: flex; flex-wrap: wrap; justify-content: space-around; } .star { cursor: pointer; width: 2em; height: 2em; background-color: grey; -webkit-clip-path: polygon(50% 0%, 63% 38%, 100% 38%, 69% 59%, 82% 100%, 50% 75%, 18% 100%, 31% 59%, 0% 38%, 37% 38%); clip-path: polygon(50% 0%, 63% 38%, 100% 38%, 69% 59%, 82% 100%, 50% 75%, 18% 100%, 31% 59%, 0% 38%, 37% 38%); } .star.selected { background-color: red; } p { flex-basis: 100%; text-align: center; } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Flux.html":{"url":"React/Flux.html","title":"Flux","keywords":"","body":"1. MVC1.1. Flux architecture1. MVC Pros: perfect for one to one mapping: 20 views 20 controllers 20 models good separation of concerns easy to maintain and test Cons: 视图变化太快，模型需要经常变动 Sometimes your view may show several kinds of models, so it's hard to manage the relationship between view and model mappings. i.e, At first, you have a product view showing only product list. When project gets larger, this view may need include user model, comment model, etc. And other views may have the same issue. These dependencies are difficult to manage, and maybe there're cyclic dependencies. In Asp.net MVC, the solution is create a viewModel. But you have to write extra code about viewModel. 1.1. Flux architecture Due to the MVC shortcomings, Facebook has a view including message list, a small message window, message indicator on right conner. They use flux to manage the message state. flux one way data flow just as react: view(jsx) --> actions --> dispatcher(singleton, make sure action is handler one by one) --> stores(read only) --> back to view Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Fundamentals.html":{"url":"React/Fundamentals.html","title":"Fundamentals","keywords":"","body":"1. React Fundamentals1.1. 思想1.2. React Benefits1.3. What is React1.4. React 优化 Optimization1.5. When to Use ref1.6. Forms1.7. Exposing DOM Refs to Parent Components1.8. React.PureComponent1.9. Setting up first React component with npm, webpack and babel1.10. this.props.children1. React Fundamentals 1.1. 思想 Composition React 是 MVC's V。组件包含了虚拟 DOM 来展示 UI Components can be used to compose other components much like functional composition Well defined components can be used between different projects Declarative A declarative solution focusses on the WHAT rather than the HOW of the problem and uses the api that abstracts the how to do so. Unidirectional Dataflow In react the state is stored in a component as opposed to the DOM (which is how it is with JQuery) Hence the state is explicitly changed and that causes the DOM to re-render The data flows from the state to the DOM and not the other way around parent components pass data to children components with the help of props Explicit Mutations Changing the state has to be done explicitly in React Since changing the state of a component with this.setState renders it to the DOM there is no need of adding event listeners or dirty checking Just JavaScript React takes advantage of the JavaScript programming language’s functionality, api and capabilities (also functional style) 1.2. React Benefits just JavaScript js 原生方法入 each、map 遍历集合，无需 ngRepeat Declarative Design simple views for each state in your application, and React will efficiently update and render just the right components when your data changes. Declarative views make your code more predictable and easier to debug. Component-Based Since component logic is written in JavaScript instead of templates, you can easily pass rich data through your app and keep state out of the DOM. No string concatenation. Reactive update 通过算法做最小改变，速度快 One way Unidirectional data flow 很容易知道数据所处的状态。Only cares about state, and UI will be updated based on state Composition Components can nest others, Using Composition instead of Inheritance. 1.3. What is React We care only about the state, once state changes, UI will be automatically updated by React. State and UI are separated a library for building user interfaces. a React element is an object representation of a DOM node. It’s important to note that a React element isn’t actually the thing you’ll see on your screen, instead, it’s just an object representation of it. There’s a few reasons for this. JavaScript objects are lightweight — React can create and destroy these elements without too much overhead. React is able to analyze the object, diff it with the previous object representation to see what changed, and then update the actual DOM only where those changes occurred. This has some performance upsides to it. virtual DOM is a JavaScript representation of the actual DOM. React can keep track of the difference between the current virtual DOM (computed after some data changes), with the previous virtual DOM (computed before some data changes). React then isolates the changes between the old and new virtual DOM and then only updates the real DOM with the necessary changes. Because manipulating the actual DOM can be complex, React is able to minimize manipulations to the actual DOM by keeping track of a virtual DOM and only updating the real DOM when necessary and with only the necessary changes. By re-rendering the virtual DOM every time any state change occurs, React makes it easier to think about what state your application is in. Signal to notify our app some data has changed -> Re-render virtual DOM -> Diff previous virtual DOM with new virtual DOM -> Only update real DOM with necessary changes. 1.4. React 优化 Optimization 1. Use the Production Build 默认情况下，React 将会在开发模式，很缓慢，不建议用于生产。要在生产模式下使用 React，设置环境变量 NODE_ENV 为 production （使用 webpack's DefinePlugin）。例如： new webpack.DefinePlugin({ \"process.env\": { NODE_ENV: JSON.stringify(\"production\") } }); 2. Profiling Components with the Chrome Performance Tab 3. Avoid Reconciliation, use shouldComponentUpdate or PureComponent but don't mutate data In some cases, your component can speed all of this up by overriding the lifecycle function shouldComponentUpdate, which is triggered before the re-rendering process starts. The default implementation of this function returns true, leaving React to perform the update. If you know that in some situations your component doesn't need to update, you can return false from shouldComponentUpdate instead, to skip the whole rendering process, including calling render() on this component and below. 4. looping thru -- add key 比如我们现在有个 listComponent，每个 item 是个 component，总共有很多10万个吧。新增一条数据时，如果不用shouldComponentUpdate 也没加 key，react 会重新渲染10万个和这个新加的数据，性能弱。 //当下一次 props 和当前不同时，return true，告诉react去更新重新渲染。注意这里逻辑必须简洁，不然可能比react自动渲染的逻辑还费时 shouldComponentUpdate(nextProps, nextState){ return this.props.name !== nextProps.name } 1.5. When to Use ref Managing focus, text selection, or media playback. Triggering imperative animations. Integrating with third-party DOM libraries. Avoid using refs for anything that can be done declaratively. For example, instead of exposing open() and close() methods on a Dialog component, pass an isOpen prop to it. 1.6. Forms Controlled Component The controlled way is when we bind the value of the input field to the state of that component So when the user types in the value, the state updates and then changes the value of the input field We can see the state change in real time as the user types in the React developer tool React docs typically recommend that we deal with forms This is called a controlled component because React is controlling the value of the specific input field Uncontrolled Component (using ref) The uncontrolled way is a little more traditional, where the user fills the input field and the state doesn’t change till he presses submit (or a similar event) 1.7. Exposing DOM Refs to Parent Components In rare cases, you might want to have access to a child's DOM node from a parent component. This is generally not recommended because it breaks component encapsulation, but it can occasionally be useful for triggering focus or measuring the size or position of a child DOM node. In such cases we recommend exposing a special prop on the child. The child would take a function prop with an arbitrary name (e.g. inputRef) and attach it to the DOM node as a ref attribute. This lets the parent pass its ref callback to the child's DOM node through the component in the middle. This works both for classes and for functional components. function CustomTextInput(props) { return ( ); } class Parent extends React.Component { render() { return ( this.inputElement = el} /> ); } } In the example above, Parent passes its ref callback as an inputRef prop to the CustomTextInput, and the CustomTextInput passes the same function as a special ref attribute to the . As a result, this.inputElement in Parent will be set to the DOM node corresponding to the element in the CustomTextInput. Note that the name of the inputRef prop in the above example has no special meaning, as it is a regular component prop. However, using the ref attribute on the itself is important, as it tells React to attach a ref to its DOM node. 1.8. React.PureComponent React.PureComponent is exactly like React.Component but implements shouldComponentUpdate() with a shallow prop and state comparison. If your React component's render() function renders the same result given the same props and state, you can use React.PureComponent for a performance boost in some cases. Note React.PureComponent's shouldComponentUpdate() only shallowly compares the objects. If these contain complex data structures, it may produce false-negatives for deeper differences. Only extend PureComponent when you expect to have simple props and state, or use forceUpdate() when you know deep data structures have changed. Or, consider using immutable objects to facilitate fast comparisons of nested data. Furthermore, React.PureComponent's shouldComponentUpdate() skips prop updates for the whole component subtree. Make sure all the children components are also \"pure\". 1.9. Setting up first React component with npm, webpack and babel A React Component may be composed of the following: ui internal data lifecycle event Every component is supposed to have a render method. The reason is that the render method returns the template for that component and it is necessary for a component to have a UI. We need to tell ReactDOM to which element the components should be rendered to. You usually have to use ReactDOM.render only once in your applications because rendering the most parent element will render all the children as well. JSX is converted to React.createElement methods which describes what you see on the screen (notice only describes, doesn’t mean that it is what we see). React.createElement returns an object representation of the DOM node. It is also called virtual DOM node. React interprets JSX and transforms it into lightweight javascript objects which are used to create a virtual DOM. Changes in the virtual dom are tracked on only the necessary updates are rendered to the DOM. React.createElement takes 3 arguments: element type: div, span, component properties object children (multiple) When React encounters a component in any of the above arguments, it replaces that with what the components React.createElement returns. Hence when rendering the most parent component using ReactDOM, the entire virtual DOM is created. This invocation of React.createElement to create a virtual DOM node only happens while using ReactDOM.render and while changing state using setState. The process looks something like this, Signal to notify our app some data has changed -> re-render virtual dom -> diff previous virtual dom with new virtual dom -> only update real dom with necessary changes. This gives react performance ups. 1.10. this.props.children props.children is whatever is between the and closing blocks of a component. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/HOF_currying_HOC.html":{"url":"React/HOF_currying_HOC.html","title":"HOF_currying_HOC","keywords":"","body":"1. Higher-Order Functions -- Functions that can manipulate other functions.1.1. Take functions as arguments1.2. return functions - currying1.3. Higher Order Component1. Higher-Order Functions -- Functions that can manipulate other functions. 3 categories: take functions in as arguments return functions both 1.1. Take functions as arguments The first category of higher-order functions are functions that expect other functions as arguments. Array.map, Array.filter, and Array.reduce all take functions as arguments. They are higher-order functions. In the following example, we create an invokeIf callback function that will test a condition and invoke on callback function when it is true and another callback function when that condition is false: const invokeIf = (condition, fnTrue, fnFalse) => (condition) ? fnTrue() : fnFalse() const showWelcome = () => console.log(\"Welcome!!!\") const showUnauthorized = () => console.log(\"Unauthorized!!!\") invokeIf(true, showWelcome, showUnauthorized) // \"Welcome\" invokeIf(false, showWelcome, showUnauthorized) // \"Unauthorized\" invokeIf expects two functions: one for true, and one for false. This is demonstrated by sending both showWelcome and showUnauthorized to invokeIf. When the condition is true, showWelcome is invoked. When it is false, showUnauthorized is invoked. 1.2. return functions - currying Higher-order functions that return other functions can help us handle the complexities associated with asynchronicity in JavaScript. They can help us create functions that can be used or reused at our convenience. Currying is a functional technique that involves the use of higher-order functions. Currying is the practice of holding on to some of the values needed to complete an operation until the rest can be supplied at a later point in time. This is achieved through the use of a function that returns another function, the curried function. The following is an example of currying. The userLogs function hangs on to some information (the username) and returns a function that can be used and reused when the rest of the information (the message) is made available. In this example, log messages will all be prepended with the associated username. Notice that we’re using the getFakeMembers function that returns a promise. const userLogs = userName => message => console.log(`${userName} -> ${message}`) const log = userLogs(\"grandpa23\") log(\"attempted to load 20 fake members\") getFakeMembers(20).then( members => log(`successfully loaded ${members.length} members`), error => log(\"encountered an error loading members\") ) // grandpa23 -> attempted to load 20 fake members // grandpa23 -> successfully loaded 20 members // grandpa23 -> attempted to load 20 fake members // grandpa23 -> encountered an error loading members userLogs is the higher-order function. The log function is produced from userLogs, and every time the log function is used, “grandpa23” is prepended to the message. 1.3. Higher Order Component This is an example in react.fundamentals /** * HOC for data fetching */ import React from 'react'; const DataComponent = (ComposedComponent, url) => (class NewComponent extends React.Component { constructor(props) { super(props); this.state = { data: [], loading: false }; this._getData = this._getData.bind(this); this.fetchByParam = this.fetchByParam.bind(this); } _getData(param = {}) { // 如果 param 传入 url 参数则根据此 url 进行查询，不然根据顶层传入 url 参数查询 if (param.url) { url = param.url; } this.setState({loading: true}); fetch(url).then(response => response.json()).then(data => { if (this._isMount) { this.setState({loading: false, data: data.items, param}); } }); } fetchByParam(param) { this._getData(param); } componentWillMount() { this._getData(); } componentDidMount() { this._isMount = true; } componentWillUnmount() { this._isMount = false; } // only for solution 4. 返回的NewComponent作为子组件，父组件状态作为props传到子组件 // 父组件状态改变的时候，自组件props发生改变，该方法触发，根据传入的param进行数据查询 componentWillReceiveProps(nextProps) { // console.log(`nextProps`, nextProps.param); // call getData only when param props changed. Other props change will enter componentWillReceiveProps too, but we don't want to fetch data if (nextProps.param) { this._getData(nextProps.param); } } render() { return ( {(this.state.loading) ? Loading... : } ); } }); export default DataComponent; Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/immutability-helper.html":{"url":"React/immutability-helper.html","title":"immutability-helper","keywords":"","body":"1. Immutability-helper 修改 nested array of objects1.1. 一次操作，只修改某个内嵌 object 的字段1.1.1. 如何根据 id 找到 对应的 index1.2. 多次操作1.2.1. 如何根据 actionArr 构建update 语句1. Immutability-helper 修改 nested array of objects 1.1. 一次操作，只修改某个内嵌 object 的字段 原数组： const products = [ { id: '111', analysis: [{ id: 1, value: 0 }, { id: 2, value: 0 }, { id: 3, value: 0 }] }, { id: '222', analysis: [{ id: 1, value: 0 }, { id: 2, value: 0 }, { id: 3, value: 0 }] } ]; 操作：根据 productId 和 analysisId 找到 nested object, 只更新他的 value const action = { id: '111', analysisId: 2, value: 99 } 处理代码：使用 immutability-helper 时需要找到要更新 object 在 array 中的 index。如上面 id=111 对应 index=0，analysisId=2 对应 index=1 const newProducts = update(products, { 0: { analysis: { 1: { $merge: { value: 99 } } // 0: { $merge: { value: 99 }} // 可以一次性更新多个操作，这里只是举例 } } }); 结果： const newProducts = [ { id: '111', analysis: [ { id: 1, value: 0 }, - { id: 2, value: 0 }, + { id: 2, value: 99 }, { id: 3, value: 0 } }, { id: '222', analysis: [ { id: 1, value: 0 }, { id: 2, value: 0 }, { id: 3, value: 0 } ] } ] 1.1.1. 如何根据 id 找到 对应的 index const targetProductIndex = products.findIndex((x) => x.id === action.id); const targetProduct = products.find((x) => x.id === action.id); const targetAnalysisIndex = targetProduct.analysis.findIndex((x) => x.id === action.analysisId); const targetAnalysis = targetProduct.analysis.find((x) => x.id === action.analysisId); const result = update(products, { [targetProductIndex]: { analysis: { [targetAnalysisIndex]: { $merge: { value: action.value } } } } }); 1.2. 多次操作 const actionArr = [ { id: '111', analysisId: 1, value: 99 }, { id: '111', analysisId: 3, value: 99 }, { id: '222', analysisId: 3, value: 99 } ]; 以上意味着3次操作。第一次找到 productId=111，再找到 analysisId=1，更新他 value 从0到99。剩下两次操作类似。 经过操作后 products 的结果： const newProducts = [ { id: '111', analysis: [ - { id: 1, value: 0 }, + { id: 3, value: 99 }, { id: 2, value: 0 }, - { id: 3, value: 0, }, + { id: 3, value: 99 } ] }, { id: '222', analysis: [ { id: 1, value: 0 }, { id: 2, value: 0 }, - { id: 3, value: 0 }, + { id: 3, value: 99, }, ] } ] 处理代码： const newProducts = update(products, { 0: { analysis: { 0: { $merge: { value: 99 } }, 2: { $merge: { value: 99 } } } }, 1: { analysis: { 2: { $merge: { value: 99 } } } } }); 1.2.1. 如何根据 actionArr 构建update 语句 思路1：每循环 actionArr 一次时，进行一次 update 操作，返回第一次操作后的结果，作为第二次 update 的对象。依次，所以用 reduce。但这样多次复制对象，不太好 多个循环积累更新： const actionArr = [ { id: '111', analysisId: 1, value: 99 }, { id: '111', analysisId: 3, value: 99 }, { id: '222', analysisId: 3, value: 99 } ]; // acc 每次操作积累的结果，cur 是 actionArr 循环中当前对象。首次 acc = products const result = actionArr.reduce((acc, cur) => { const targetIndex = acc.findIndex((x) => x.id === cur.id); const target = acc.find((x) => x.id === cur.id); const targetAnalysisIndex = target.analysis.findIndex((x) => x.id === cur.analysisId); const targetAnalysis = target.analysis.find((x) => x.id === cur.analysisId); return update(acc, { [targetIndex]: { analysis: { [targetAnalysisIndex]: { $merge: { value: cur.value } } } } }); }, products); 思路2：循环构建好 update 语句中的对象，之后一次性更新 const buildUpdateOperation = (source, actionArr) => { let result = {}; actionArr.forEach((action) => { const targetIndex = source.findIndex((x) => x.id === action.id); const target = source.find((x) => x.id === action.id); const targetAnalysisIndex = target.analysis.findIndex((x) => x.id === action.analysisId); const targetAnalysis = target.analysis.find((x) => x.id === action.analysisId); if (result[targetIndex]) { // 第二次更新同一个 product，但 analysisId 不同 result[targetIndex].analysis[targetAnalysisIndex] = { $merge: { value: action.value } }; } else { // 首次不存在 index，赋值 result[targetIndex] = { analysis: { [targetAnalysisIndex]: { $merge: { value: c.value } } } }; } }); return result; }; 生成的结果为： { 0: { analysis: { 0: { $merge: { value: 99 }}, 2: { $merge: { value: 99 }} } }, 1: { analysis: { 2: { $merge: { value: 99 }} } } } 一次行更新： const updateQuery = buildUpdateOperation(products, actionArr) const newProducts = update(products, updateQuery) Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Immutability.html":{"url":"React/Immutability.html","title":"Immutability","keywords":"","body":"1. Immutability 对象不可变性1.1. Why Immutability1.2. Immutability Use Case1.2.1. Array with simple types like number, string1.2.2. Object Change1.2.3. Array of Objects1. Immutability 对象不可变性 通过复制一个新的对象，使得新对象和老对象不引用同一个地址。这样在一个 reducer 函数中不去直接修改老对象的属性，而是创建一个新对象并根据 action 修改其属性并返回。 var player = { score: 1, name: 'Jeff' }; var newPlayer = Object.assign({}, player, {score: 2}); // Now player is unchanged, but newPlayer is {score: 2, name: 'Jeff'} // Or if you are using object spread syntax proposal, you can write: var newPlayer = { ...player, score: 2 }; 1.1. Why Immutability 因为我们知道修改之前和修改之后的状态，方便我们追踪对象改变的属性 Because shouldComponentUpdate or PureComponent does a shallow comparison of old and new values, 即只需要 === 比较引用地址是否相同。如果不遵循 不可变性，在原对象修改属性，=== 永远相同，Then UI won't change. reducer 作为一个纯函数，根据之前的 state 和 action 计算出一下个 state。纯函数不能有负效应，对象的不可改变性使得 reducer 能够输出唯一可以预测的值 immutability 要求复制对象，复制对象难道不影响性能吗？ 首先属性不多，其次并没有过分深层嵌套。比起检查每个属性是否改变更高效，而且很容易知道改变前和改变后以及改变的因素，能够方便 debug 和追踪状态改变。最后通过 !== 检测 prevStore 和当前 store 是否相等，即是否来自同一个地址，无需检测每一个属性。检测时配合 shouldComponentUpdate 1.2. Immutability Use Case 1.2.1. Array with simple types like number, string /* push a new element */ const addCounter = (arr) => { // return arr.concat([0]); // old way return [...arr, 0]; // ES6 way }; /* remove an element by index */ const removeCounter = (arr, index) => { // Old way: //return arr // .slice(0, index) // .concat(arr.slice(index + 1)); // ES6 way: return [ ...arr.slice(0, index), ...arr.slice(index + 1) ]; }; /* modify an element by index */ const incrementCounter = (arr, index) => { // Old way: // return arr // .slice(0, index) // .concat([arr[index] + 1]) // .concat(arr.slice(index + 1)); // ES6 way: return [ ...arr.slice(0, index), arr[index] + 1, ...arr.slice(index + 1) ]; }; 1.2.2. Object Change const toggleTodo = (todo) => { // return Object.assign({}, todo, { // completed: !todo.completed // }); return { ...todo, completed: !todo.completed }; }; 1.2.3. Array of Objects This mixes creating/updating individual item and array together... const reducer = (state = [], action) => { // action : { type: '', payload: obj} const obj = action.payload; switch (action.type) { case 'add': return [...state, obj]; case 'edit': return state.map(item => { if (item.id === obj.id) { return { ...item, ...obj }; // 用新对象 obj 覆盖掉老 object } else { return item; } }); case 'delete': return state.filter(item => item.id !== obj.id); default: return state; } }; reducer composition. Separate individual and array: const individualReducer = (state, action) => { // action : { type: '', payload: obj} const obj = action.payload; switch (action.type) { case 'add': return obj; case 'edit': if (state.id === obj.id) return { ...state, ...obj }; else return state; default: return state; } }; const arrayReducer = (state = [], action) => { // action : { type: '', payload: obj} const obj = action.payload; switch (action.type) { case 'add': return [...state, individualReducer(undefined, action)]; case 'edit': return state.map(item => individualReducer(item, action)); case 'delete': return state.filter(item => item.id !== obj.id); default: return state; } }; In a functional program, data is immutable. It never changes. Instead of changing the original data structures, we build changed copies of those data structures and use them instead. Consider an object that represents the color lawn: let color_lawn = { title: \"lawn\", color: \"#00FF00\", rating: 0 } We could build a function that would rate colors, and use that function to change the rating of the color object: function rateColor(color, rating) { color.rating = rating return color } console.log(rateColor(color_lawn, 5).rating) // 5 console.log(color_lawn.rating) // 5 In JavaScript, function arguments are references to the actual data. Setting the color's rating like this is bad because it changes or mutates the original color object. We can rewrite the rateColor function so that it does not harm the original goods (the color object): ==Object.assign({}, color, {rating:rating})== var rateColor = function(color, rating) { return Object.assign({}, color, {rating:rating}) } console.log(rateColor(color_lawn, 5).rating) // 5 console.log(color_lawn.rating) // 4 Here, we used Object.assign to change the color rating. Object.assign is the copy machine; it takes a blank object, copies the color to that object, and overwrites the rating on the copy. Now we can have a newly rated color object without having to change the original. We can write the same function using an ES6 arrow function along with the ES7 object spread operator. This rateColor function uses the spread operator to copy the color into a new object and then overwrite its rating: const rateColor = (color, rating) => ({ ...color, rating }) This emerging JavaScript version of the rateColor function is exactly the same as the previous one. It treats color as an immutable object, does so with less syntax, and looks a little bit cleaner. Notice that we wrap the returned object in parentheses. With arrow functions, this is a required step since the arrow can't just point to an object's curly braces. Let's consider an array of color names: let list = [ { title: \"Rad Red\"}, { title: \"Lawn\"}, { title: \"Party Pink\"} ] We could create a function that will add colors to that array using Array.push: var addColor = function(title, colors) { colors.push({ title: title }) return colors; } console.log(addColor(\"Glam Green\", list).length) // 4 console.log(list.length) // 4 However, Array.push is not an immutable function. This addColor function changes the original array by adding another field to it. In order to keep the colors array immutable, we must use Array.concat instead: const addColor = (title, array) => array.concat({title}) console.log(addColor(\"Glam Green\", list).length) // 4 console.log(list.length) // 3 Array.concat concatenates arrays. In this case, it takes a new object, with a new color title, and adds it to a copy of the original array. You can also use the ES6 spread operator to concatenate arrays in the same way it can be used to copy objects. Here is the emerging JavaScript equivalent of the previous addColor function: const addColor = (title, list) => [...list, {title}] This function copies the original list to a new array and then adds a new object containing the color's title to that copy. It is immutable. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Imperative_vs_Declarative.html":{"url":"React/Imperative_vs_Declarative.html","title":"Imperative_vs_Declarative","keywords":"","body":"1. Imperative and Declarative1.1. Building a clock declaratively1. Imperative and Declarative Functional programming is a part of a larger programming paradigm: declarative programming. Declarative programming is a style of programming where applications are structured in a way that prioritizes describing what should happen over defining how it should happen. In order to understand declarative programming, we’ll contrast it with imperative programming, or a style of programming that is only concerned with how to achieve results with code. Let’s consider a common task: making a string URL-friendly. Typically, this can be accomplished by replacing all of the spaces in a string with hyphens, since spaces are not URL-friendly. First, let’s examine an imperative approach to this task: // Imperative programming // Just looking at the code alone does not tell us much. Imperative programs require lots of comments in order to understand what is going on. var string = 'This is the midday show with Cheryl Waters'; var urlFriendly = ''; for (var i = 0; i // declarative const string = \"This is the mid day show with Cheryl Waters\" const urlFriendly = string.replace(/ /g, \"-\") console.log(urlFriendly) Here we are using string.replace along with a regular expression to replace all instances of spaces with hyphens. Using string.replace is a way of describing what is supposed to happen: spaces in the string should be replaced. The details of how spaces are dealt with are abstracted away inside the replace function. In a declarative program, the syntax itself describes what should happen and the details of how things happen are abstracted away. Declarative programs are easy to reason about because the code itself describes what is happening. For example, read the syntax in the following sample—it details what happens after members are loaded from an API: const loadAndMapMembers = compose( combineWith(sessionStorage, 'members'), save(sessionStorage, 'members'), scopeMembers(window), logMemberInfoToConsole, logFieldsToConsole('name.first'), countMembersBy('location.state'), prepStatesForMapping, save(sessionStorage, 'map'), renderUSMap ); getFakeMembers(100).then(loadAndMapMembers); The declarative approach is more readable and, thus, easier to reason about. The details of how each of these functions is implemented are abstracted away. Those tiny functions are named well and combined in a way that describes how member data goes from being loaded to being saved and printed on a map, and this approach does not require many comments. Essentially, declarative programming produces applications that are easier to reason about, and when it is easier to reason about an application, that application is easier to scale. Now, let’s consider the task of building a document object model, or DOM. An imperative approach would be concerned with how the DOM is constructed: var target = document.getElementById('target'); var wrapper = document.createElement('div'); var headline = document.createElement('h1'); wrapper.id = \"welcome\"; headline.innerText = \"Hello World\"; wrapper.appendChild(headline); target.appendChild(wrapper); This code is concerned with creating elements, setting elements, and adding them to the document. It would be very hard to make changes, add features, or scale 10,000 lines of code where the DOM is constructed imperatively. Now let’s take a look at how we can construct a DOM declaratively using a React component: const Welcome = () => ( Hello World ) ReactDOM.render( , document.getElementById('target') ) React is declarative. Here, the Welcome component describes the DOM that should be rendered. The render function uses the instructions declared in the component to build the DOM, abstracting away the details of how the DOM is to be rendered. We can clearly see that we want to render our Welcome component into the element with the ID of 'target'. 1.1. Building a clock declaratively Our challenge is to build a ticking clock. The clock needs to display hours, minutes, seconds and time of day in civilian time. Each field must always have double digits, meaning leading zeros need to be applied to single digit values like 1 or 2. The clock must also tick and change the display every second. First, let’s review an imperative solution for the clock. // Log Clock Time every Second setInterval(logClockTime, 1000); function logClockTime() { // Get Time string as civilian time var time = getClockTime(); // Clear the Console and log the time console.clear(); console.log(time); } function getClockTime() { // Get the Current Time var date = new Date(); // Serialize clock time var time = { hours: date.getHours(), minutes: date.getMinutes(), seconds: date.getSeconds(), ampm: 'AM' }; // Convert to civilian time if (time.hours == 12) { time.ampm = 'PM'; } else if (time.hours > 12) { time.ampm = 'PM'; time.hours -= 12; } // Prepend a 0 on the hours to make double digits if (time.hours It works, and the comments help us understand what is happening. However, these functions are large and complicated. Each function does a lot. They are hard to comprehend, they require comments and they are tough to maintain. Let’s see how a functional approach can produce a more scalable application. Our goal will be to break the application logic up into smaller parts, functions. Each function will be focused on a single task, and we will compose them into larger functions that we can use to create the clock. First, let’s create some functions that give us values and manage the console. We’ll need a function that gives us one second, a function that gives us the current time, and a couple of functions that will log messages on a console and clear the console. In functional programs, we should use functions over values wherever possible. We will invoke the function to obtain the value when needed. const oneSecond = () => 1000 const getCurrentTime = () => new Date() const clear = () => console.clear() const log = message => console.log(message) Next we will need some functions for transforming data. These three functions will be used to mutate the Date object into an object that can be used for our clock: serializeClockTime Takes a date object and returns a object for clock time that contains hours minutes and seconds. civilianHours Takes the clock time object and returns an object where hours are converted to civilian time. For example: 1300 becomes 1 o’clock appendAMPM Takes the clock time object and appends time of day, AM or PM, to that object. const serializeClockTime = (date) => ({ hours: date.getHours(), minutes: date.getMinutes(), seconds: date.getSeconds() }); // clockTime { hours, minutes, seconds } const civilianHours = (clockTime) => ({ ...clockTime, hours: clockTime.hours > 12 ? clockTime.hours - 12 : clockTime.hours }); const appendAMPM = (clockTime) => ({ ...clockTime, ampm: clockTime.hours >= 12 ? 'PM' : 'AM' }); These three functions are used to transform data without changing the original. They treat their arguments as immutable objects. Next we’ll need a few higher order functions: display Takes a target function and returns a function that will send a time to the target. In this example the target will be console.log. formatClock Takes a template string and uses it to return clock time formatted based upon the criteria from the string. In this example, the template is “hh:mm:ss tt”. FormatClock will replaces the placeholders with hours, minutes, seconds, and time of day. prependZero Takes an object’s key as an argument and prepends a zero to the value stored under that objects key. It takes in a key to a specific field and prepends values with a zero if the value is less than 10. // target is console.log in this case, target maybe alert etc const display = (target) => (time) => target(time); // 决定一种 format 格式，比如 const usFormat = formatClock('hh:mm:ss tt'); const formatClock = (format) => (time) => format.replace('hh', time.hours) .replace('mm', time.minutes) .replace('ss', time.seconds) .replace('tt', time.ampm); // key is hours, minutes, seconds, 决定了哪个属性需要 prepend 0 const prependZero = (key) => (clockTime) => ({ ...clockTime, [key]: clockTime[key] These higher order functions will be invoked to create the functions that will be reused to format the clock time for every tick. Both format clock and prependZero will be invoked once, initially setting up the required template or key. The inner functions that they return will be invoked once every second to format the time for display. Now that we have all of the functions required to build a ticking clock, we will need to compose them. We will use the compose function that we defined in the last section to handle composition: convertToCivilianTime A single function that will take clock time as an argument and transforms it into civilian time by using both civilian hours. doubleDigits A single function that will take civilian clock time and make sure the hours, minutes, and seconds display double digits by prepending zeros where needed. startTicking Starts the clock by setting an interval that will invoke a callback every second. The callback is composed using all of our functions. Every second the console is cleared, currentTime obtained, converted, civilianized, formatted, and displayed. // compose 从右向左执行！ const convertToCivilianTime = (clockTime) => compose( appendAMPM, civilianHours )(clockTime); const doubleDigits = (civilianTime) => compose( prependZero('hours'), prependZero('minutes'), prependZero('seconds') )(civilianTime); const startTicking = () => setInterval( compose( clear, getCurrentTime, serializeClockTime, convertToCivilianTime, doubleDigits, formatClock('hh:mm:ss tt'), display(log) ), oneSecond() ); startTicking(); This declarative version of the clock achieves the same results as the imperative version. However, there quite a few benefits to this approach. all of these functions are easily testable and reusable. They can be used in future clocks or other digital displays. this program is easily scalable. There are no side effects. There are no global variables outside of functions themselves. There could still be bugs, but they will be easier to find. Full code: const oneSecond = () => 1000; const getCurrentTime = () => new Date(); const clear = () => console.clear(); const log = (message) => console.log(message); const abstractClockTime = (date) => ({ hours: date.getHours(), minutes: date.getMinutes(), seconds: date.getSeconds() }); const civilianHours = (clockTime) => ({ ...clockTime, hours: clockTime.hours > 12 ? clockTime.hours - 12 : clockTime.hours }); const appendAMPM = (clockTime) => ({ ...clockTime, ampm: clockTime.hours >= 12 ? 'PM' : 'AM' }); const display = (target) => (time) => target(time); const formatClock = (format) => (time) => format.replace('hh', time.hours) .replace('mm', time.minutes) .replace('ss', time.seconds) .replace('tt', time.ampm); const prependZero = (key) => (clockTime) => ({ ...clockTime, [key]: clockTime[key] (arg) => fns.reduce( (accu, f) => f(accu), arg ); // clockTime 作为 arg，初始值。先 appendAMPM(clockTime)，返回的对象作为 civilianHours 的参数，执行 civilianHours const convertToCivilianTime = (clockTime) => compose(appendAMPM, civilianHours)(clockTime); const doubleDigits = (civilianTime) => compose( prependZero('hours'), prependZero('minutes'), prependZero('seconds') )(civilianTime); const startTicking = () => setInterval( compose( clear, getCurrentTime, abstractClockTime, convertToCivilianTime, doubleDigits, formatClock('hh:mm:ss tt'), display(log) ), oneSecond() ); startTicking(); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Inheritance _vs_composition.html":{"url":"React/Inheritance _vs_composition.html","title":"Inheritance _vs_composition","keywords":"","body":"1. React 推荐 composition1.1. Composition1. React 推荐 composition Inheritance is unnecessary in React, and both containment and specialization can be achieved with composition Because mostly everything that can be accomplished with Mixins (or inheritance) can also be accomplished through composition, but with less side effects. Inheritance: You have to predict the members you want to inherit carefully. IRobot(CleaningRobot, CookingRobot), IAnimal(Dog, Cat). What if in future we need a CleaningCatRobot? You have to re-struct the interface, maybe have a common IAnimalRobot. When projects get larger, it's painful to do so. Inheritance is difficult to get rid of. Composition: CleaningCatAnimal = cleaningRobot + cat, super clean. I feel, composition is better than inheritance. Inheritance is not needed. 1.1. Composition Functional programs break up their logic into small pure functions that are focused on specific tasks. Eventually, you will need to put these smaller functions together. Specifically, you may need to combine them, call them in series or parallel, or compose them into larger functions until you eventually have an application. When it comes to composition, there are a number of different implementations, patterns, and techniques. One that you may be familiar with is chaining. In JavaScript, functions can be chained together using dot notation to act on the return value of the previous function. Strings have a replace method. The replace method returns a template string which also will have a replace method. Therefore, we can chain together replace methods with dot notation to transform a string. const template = \"hh:mm:ss tt\" const clockTime = template.replace(\"hh\", \"03\") .replace(\"mm\", \"33\") .replace(\"ss\", \"33\") .replace(\"tt\", \"PM\") console.log(clockTime) // \"03:33:33 PM\" In this example, the template is a string. By chaining replace methods to the end of the template string, we can replace hours, minutes, seconds, and time of day in the string with new values. The template itself remain intact and can be reused to create more clock time displays. Chaining is one composition technique, but there are others. The goal of composition is to “generate a higher order function by combining simpler functions.” const both = date => appendAMPM(civilianHours(date)) The both function is one function that pipes a value through two separate functions. The output of civilian hours becomes the input for appendAMPM, and we can change a date using both of these functions combined into one. However, this syntax is hard to comprehend and therefore tough to maintain or scale. What happens when we need to send a value through 20 different functions? A more elegant approach is to create a higher order function we can use to compose functions into larger functions. // new Date() 作为 arg，初始值。先 appendAMPM(clockTime)，返回的对象作为 civilianHours 的参数，执行 civilianHours const both = compose( appendAMPM, civilianHours ) both(new Date()) This approach looks much better. It is easy to scale because we can add more functions at any point. This approach also makes it easy to change the order of the composed functions. The compose function is a higher order function. It takes functions as arguments and returns a single value. // very important!!! // reduce first para: function // second para: initial value // cb first para is initial value(arg in this case) // cb second para is a item(one item of fns in this case) // 目的是执行第一个函数，得到结果再交给第二个函数执行 // compose(f1, f2) 是构建传入 function，compose(f1, f2)(initialValue) 是返回最终结果 const compose = (...fns) => (arg) => fns.reduce( (composed, f) => f(composed), arg ) Compose takes in functions as arguments and returns a single function. In this implementation, the spread operator is used to turn those function arguments into an array called fns. A function is then returned that expects one argument, arg. When this function is invoked, the fns array is piped starting with the argument we want to send through the function. The argument becomes the initial value for composed and then each iteration of the reduced callback returns. Notice that the callback takes two arguments: composed and a function f. Each function is invoked with compose which is the result of the previous functions output. Eventually, the last function will be invoked and the last result returned. Other implementations of compose may use reduceRight which would compose the functions in reverse order. const composeRight = (...fns) => (arg) => fns.reverse().reduce( (composed, f) => f(composed), arg ) Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/lifecycle.html":{"url":"React/lifecycle.html","title":"lifecycle","keywords":"","body":"1. \bReact 生命周期1.1. Mounting Lifecycle1.1.1. componentWillMount1.1.2. componentDidMount, componentWillUnmount1.2. Updating Lifecycle1.2.1. componentWillReceiveProps(nextProps)1.2.2. shouldComponentUpdate(nextProps, nextState)1.2.3. componentWillUpdate(nextProps, nextState)1.2.4. componentDidUpdate(prevProps, prevState)1. \bReact 生命周期 1.1. Mounting Lifecycle When a component gets mounted to the DOM or unmounted from it. 只能在 componentDidMount 中 发送异步请求、setState The mounting lifecycle consists of methods that are invoked when a component is mounted or unmounted. In other words, these methods allow you to initially set up state, make API calls, start and stop timers, manipulate the rendered DOM, initialize third-party libraries, and more. The mounting lifecycle is slightly different depending upon whether you use ES6 class syntax or React.createClass to create components. When you use createClass, getDefaultProps is invoked first to obtain the component's properties. Next, getInitialState is invoked to initialize the state. ES6 classes do not have these methods. Instead, default props are obtained and sent to the constructor as an argument. The constructor is where the state is initialized. Both ES6 class constructors and getInitialState have access to the properties and, if required, can use them to help define the initial state. 1.1.1. componentWillMount I don't think it's good to setState in componentWillMount I don't believe the 3rd judgement. If the api is too fast and returns the data even before component get mounted, setState won't work, although this is unlikely to happen. Calling setState before the component has rendered will not kick off the updating lifecycle. Calling setState after the component has been rendered will kick off the updating lifecycle. Note: with new React, you cannot make API calls in componentWillMount 1.1.2. componentDidMount, componentWillUnmount componentDidMount is invoked just after the component has rendered componentWillUnmount is invoked just before the component is unmounted. componentDidMount is the only good place to make API requests. This method is invoked after the component has rendered, so any setState calls from this method will kick off the updating lifecycle and re-render the component. componentDidMount is also a good place to initialize any third-party JavaScript that requires a DOM. For instance, you may want to incorporate a drag-and-drop library or a library that handles touch events. Typically, these libraries require a DOM before they can be initialized. To start background processes like intervals or timers. Any processes started in componentDidMount or componentWillMount can be cleaned up in componentWillUnmount. You don't want to leave background processes running when they are not needed. 1.2. Updating Lifecycle When a component receives new data and later. The updating lifecycle is a series of methods that are invoked ==when a component's state changes or when new properties are received from the parent.== This lifecycle can be used to incorporate JavaScript before the component updates or to interact with the DOM after the update. Additionally, it can be used to improve the performance of an application because it gives you the ability to cancel unnecessary updates. The updating lifecycle kicks off every time setState is called. Calling setState within the updating lifecycle other than componentWillReceiveProps will cause an infinite recursive loop that results in a stack overflow error. Therefore, setState can only be called in componentWillReceiveProps, which allows the component to update state when its properties are updated. 1.2.1. componentWillReceiveProps(nextProps) Triggered when the component receives new props from its parent component. This is the only method where setState can be called. 当组件传入的 props 发生变化时调用.例如：父组件状态改变，给子组件传入了新的 prop 值。用于组件 props 变化后，更新 state。 1.2.2. shouldComponentUpdate(nextProps, nextState) It's the update lifecycle's gatekeeper -- a predicate that can call off the update. This method can be used to ==improve performance== by only allowing necessary updates. 1.2.3. componentWillUpdate(nextProps, nextState) Invoked just before the component updates. Similar to componentWillMount, only it is invoked before each update occurs. 1.2.4. componentDidUpdate(prevProps, prevState) Invoked just after the update takes place, after the call to render. It is invoked after each update. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Presentational_vs_Container_Components.html":{"url":"React/Presentational_vs_Container_Components.html","title":"Presentational_vs_Container_Components","keywords":"","body":"1. Presentational and Container Components1.1. presentational components1.2. container components1.2.1. Benefits of This Approach1.2.2. When to Introduce Containers?1.2.3. Other Dichotomies1. Presentational and Container Components 1.1. presentational components Are concerned with how things look. Another advantage of using stateless functional components is that we don't need to consider this May contain both presentational and container components inside, and usually have some DOM markup and styles of their own. Often allow containment via this.props.children. Have no dependencies on the rest of the app, such as Flux actions or stores. Don’t specify how the data is loaded or mutated. Receive data and callbacks exclusively via props. Rarely have their own state (when they do, it’s UI state rather than data). Are written as functional components unless they need state, lifecycle hooks, or performance optimizations. Examples: Page, Sidebar, Story, UserInfo, List. Presentational components are components that only render UI elements. They do not tightly couple with any data architecture. Instead, they receive data as props and send data to their parent component via callback function properties. They are purely concerned with the UI and can be reused across applications that contain different data. 1.2. container components Are concerned with how things work. May contain both presentational and container components inside but usually don’t have any DOM markup of their own except for some wrapping divs, and never have any styles. Provide the data and behavior to presentational or other container components. Call Flux actions and provide these as callbacks to the presentational components. Are often stateful, as they tend to serve as data sources. Are usually generated using higher order components such as connect() from React Redux, createContainer() from Relay, or Container.create() from Flux Utils, rather than written by hand. Examples: UserPage, FollowersSidebar, StoryContainer, FollowedUserList. Container components are components that connect presentational components to the data. In our case, container components will retrieve the store via context and manage any interactions with the store. They render presentational components by mapping properties to state and callback function properties to the store’s dispatch method. Container components are not concerned with UI elements; they are used to connect presentational components to data. I put them in different folders to make this distinction clear. 1.2.1. Benefits of This Approach Better separation of concerns. You understand your app and UI better by writing components this way. Better reusability. Presentational components are reusable. They are easy to swap out and easy to test. They can be composed to create the UI. Presentational components can be reused across browser applications that may use different data libraries. You can use the same presentational component with completely different state sources, and turn those into separate container components that can be further reused. Presentational components are essentially your app’s “palette”. You can put them on a single page and let the designer tweak all their variations without touching the app’s logic. You can run screenshot regression tests on that page. This forces you to extract “layout components” such as Sidebar, Page, ContextMenu and use this.props.children instead of duplicating the same markup and layout in several container components. Remember, components don’t have to emit DOM. They only need to provide composition boundaries between UI concerns. Container components are not concerned with the UI at all. Their main focus is connecting the presentation components to the data architecture. Container components can be reused across device platforms to connect native presentational components to the data. 1.2.2. When to Introduce Containers? I suggest you to start building your app with just presentational components first. Eventually you’ll realize that you are passing too many props down the intermediate components. When you notice that some components don’t use the props they receive but merely forward them down and you have to rewire all those intermediate components any time the children need more data, it’s a good time to introduce some container components. This way you can get the data and the behavior props to the leaf components without burdening the unrelated components in the middle of the tree. 1.2.3. Other Dichotomies It’s important that you understand that the distinction between the presentational components and the containers is not a technical one. Rather, it is a distinction in their purpose. By contrast, here are a few related (but different!) technical distinctions: Stateful and Stateless. Some components use React setState() method and some don’t. While container components tend to be stateful and presentational components tend to be stateless, this is not a hard rule. Presentational components can be stateful, and containers can be stateless too. Classes and Functions. Functional components are simpler to define but they lack certain features currently available only to class components. Some of these restrictions may go away in the future but they exist today. Because functional components are easier to understand, I suggest you to use them unless you need state, lifecycle hooks, or performance optimizations, which are only available to the class components at this time. Pure and Impure. People say that a component is pure if it is guaranteed to return the same result given the same props and state. Pure components can be defined both as classes and functions, and can be both stateful and stateless. Another important aspect of pure components is that they don’t rely on deep mutations in props or state, so their rendering performance can be optimized by a shallow comparison in their shouldComponentUpdate() hook. Currently only classes can define shouldComponentUpdate() but that may change in the future. Both presentational components and containers can fall into either of those buckets. In my experience, presentational components tend to be stateless pure functions, and containers tend to be stateful pure classes. However this is not a rule but an observation, and I’ve seen the exact opposite cases that made sense in specific circumstances. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Pure_vs_Impure_functions.html":{"url":"React/Pure_vs_Impure_functions.html","title":"Pure_vs_Impure_functions","keywords":"","body":"1. Pure vs impure function1. Pure vs impure function pure function 不修改外部变量包括DOM，输入参数唯一则返回值唯一，没有负效应，容易测试。 The function should take in at least one argument. The function should return a value or another function. The function should not change or mutate any of its arguments. function addToArrayImpure(array, element) { array.push(element); return array; } function addToArrayPure(array, element) { return [...array, element]; // return array.concat(element); } function addToObjImpure(obj, prop, value) { obj[prop] = value; return obj; } function addToObjPure(obj, prop, value) { return Object.assign({}, obj, { [prop]: value }); } // ES7 function addToObjPureSpread(obj, prop, value) { return { ...obj, [prop]: value }; } let person = { name: 'guanghui' }; console.log(addToObjPure(person, 'age', 20)); const frederick = { name: \"Frederick Douglass\", canRead: false, canWrite: false } const selfEducate = person => ({ ...person, canRead: true, canWrite: true }) console.log( selfEducate(frederick) ) console.log( frederick ) // {name: \"Frederick Douglass\", canRead: true, canWrite: true} // {name: \"Frederick Douglass\", canRead: false, canWrite: false} In React, the UI is expressed with pure functions. In the following sample, Header is a pure function that can be used to create heading—one elements just like in the previous example. However, this function on its own does not cause side effects because it does not mutate the DOM. This function will create a heading-one element, and it is up to some other part of the application to use that element to change the DOM: const Header = (props) => {props.title} Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/react-router.html":{"url":"React/react-router.html","title":"react-router","keywords":"","body":"1. React Router1.1. 基本使用1.2. 点击 button 跳转到新的 component1.3. 新转到的 component 获得之前 button 传递的参数1. React Router Concepts BrowserRouter as Router - is the component between which all the routes are nested. Our most parent component. Route - the component that helps specify views for each component, has many small nuances one needs to be aware of Link - just a link with prop to. NavLink - has activeClassName prop, to apply a css class when active Switch - used to make sure only one of the Routes is active at any moment (useful for showing a route without a path for paths that are not handled aka 404) instead of rendering all of the routes that are active, switch is gonna let only 1 route be active at a time Route path - prop takes string for the url path at which component should be active in the view Note: if a route has path='/first', it’s component will be active for all paths that start with /first to avoid the above, we need to prepend prop path with keyword exact component - takes a javascript expression referring to the component that one wants to link to the path render - this prop is useful when you don’t want to link the route to a component, but instead specify the JSX right there. This prop takes a value of a function that returns the JSX you wish this route to return. This is used mostly for the 404 pages I’m assuming, in a route that’s the last child of the switch component (and has no path prop value obviously). exact - prop makes sure the route is rendered/active only when the path matches exactly and not just partly Link This component is the basic anchor tag in react, except obviously it knows what component it originates in. to - prop takes the path to route to when the user clicks the link NavLink Composed of the component Link, except with additional functionality to make Links active when their path matches the current path. activeClassName - is the class that is applied to the NavLink component when the current path matches with the link’s path exact - this prop makes sure the activeClassName is applied only when the path has an exact match with the link’s path (not just partly, similar to the exact prop in routes) Query Params The to prop of the Link component of React Router accepts url path strings or an object with props: pathname: which takes a string for the link’s path search: takes a string beginning with ‘?’ for query params followed by the query param name value string React Router’s Route component passes a few props to the component it’s linked with. One of the prop is match which is an object with a property url which contains the current url’s path. The to value of a Link that routes to a sub-path of the current url should be composed of the this.props.match.url property, so that the path can be changed later without affecting the link. 1.1. 基本使用 import React, { Component } from 'react'; import { BrowserRouter, Route, Switch } from 'react-router-dom'; import Nav from './Nav'; import Home from './Home'; import Battle from './Battle'; import Result from './Result'; import Popular from './Popular'; class App extends React.Component { render() { return ( Not found} /> ); } } export default App; Nav.js import React from 'react'; import { NavLink } from 'react-router-dom'; function Nav() { return ( Home Battle Popular ); } export default Nav; 1.2. 点击 button 跳转到新的 component 返回当前 component 的 url: this.props.match.url. Link 组件中 to 定义 pathname 和 customParam import { Link } from 'react-router-dom'; Battle ; 1.3. 新转到的 component 获得之前 button 传递的参数 通过 location.customParam 获得参数，并用 queryString 转换数据 import queryString from 'query-string'; componentDidMount() { let players = queryString.parse(this.props.location.customParam); console.log(this.props.location.customParam); //?playerOneName=wghglory&playerTwoName=ff console.log(players); //{playerOneName: \"wghglory\", playerTwoName: \"ff\"} } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/React面试.html":{"url":"React/React面试.html","title":"React面试","keywords":"","body":"1. React 面试1.1. 原理，diff1.1.1. tree diff1.1.2. component diff1.1.3. element diff1.1.4. 总结1.2. 组件化思想1. React 面试 1.1. 原理，diff React diff 会帮助我们计算出 Virtual DOM 中真正变化的部分，并只针对该部分进行实际 DOM 操作，而非重新渲染整个页面，从而保证了每次操作更新后页面的高效渲染，因此 Virtual DOM 与 diff 是保证 React 性能口碑的幕后推手。而且 React 能够批处理虚拟 DOM 的刷新，在一个事件循环 (Event Loop)内的两次数据变化会被合并，例如你连续的先将节点内容从 A 变成 B，然后又从 B 变成 A，React 会认为 UI 不发生任何变化。尽管每一次都需要构造完整的虚拟 DOM 树，但是因为虚拟 DOM 是内存数据，性能是极高的，而对实际 DOM 进行操作的仅仅是 Diff 部分，因而能达到提高性能的目的。 传统 diff 算法通过循环递归对节点进行依次对比，算法复杂度达到 O(n^3)，其中 n 是树中节点的总数。 React 通过制定大胆的策略，将 O(n^3) 复杂度的问题转换成 O(n) 复杂度的问题。 diff 策略： tree diff: Web UI 中 DOM 节点跨层级的移动操作特别少，可以忽略不计。 component diff: 拥有相同类的两个组件将会生成相似的树形结构，拥有不同类的两个组件将会生成不同的树形结构。 element diff: 对于同一层级的一组子节点，它们可以通过唯一 id 进行区分。 1.1.1. tree diff 对树进行分层比较，两棵树只会对同一层次的节点进行比较。 既然 DOM 节点跨层级的移动操作少到可以忽略不计，针对这一现象，React 通过 updateDepth 对 Virtual DOM 树进行层级控制，只会对相同颜色方框内的 DOM 节点进行比较，即同一个父节点下的所有子节点。当发现节点已经不存在，则该节点及其子节点会被完全删除掉，不会用于进一步的比较。这样只需要对树进行一次遍历，便能完成整个 DOM 树的比较。 分析至此，大部分人可能都存在这样的疑问：如果出现了 DOM 节点跨层级的移动操作，React diff 会有怎样的表现呢？是的，对此我也好奇不已，不如试验一番。 如下图，A 节点 (包括其子节点)整个被移动到 D 节点下，由于 React 只会简单的考虑同层级节点的位置变换，而对于不同层级的节点，只有创建和删除操作。当根节点发现子节点中 A 消失了，就会直接销毁 A；当 D 发现多了一个子节点 A，则会创建新的 A (包括子节点)作为其子节点。此时，React diff 的执行情况：create A -> create B -> create C -> delete A。 由此可发现，当出现节点跨层级移动时，并不会出现想象中的移动操作，而是以 A 为根节点的树被整个重新创建，这是一种影响 React 性能的操作，因此 React 官方建议不要进行 DOM 节点跨层级的操作。 注意：在开发组件时，保持稳定的 DOM 结构会有助于性能的提升。例如，可以通过 CSS 隐藏或显示节点，而不是真的移除或添加 DOM 节点。 1.1.2. component diff React 是基于组件构建应用的，对于组件间的比较所采取的策略也是简洁高效。 如果是同一类型的组件，按照原策略继续比较 virtual DOM tree。 如果不是，则将该组件判断为 dirty component，从而替换整个组件下的所有子节点。 对于同一类型的组件，有可能其 Virtual DOM 没有任何变化，如果能够确切的知道这点那可以节省大量的 diff 运算时间，因此 React 允许用户通过 shouldComponentUpdate() 来判断该组件是否需要进行 diff。 如下图，当 component D 改变为 component G 时，即使这两个 component 结构相似，一旦 React 判断 D 和 G 是不同类型的组件，就不会比较二者的结构，而是直接删除 component D，重新创建 component G 以及其子节点。虽然当两个 component 是不同类型但结构相似时，React diff 会影响性能，但正如 React 官方博客所言：不同类型的 component 是很少存在相似 DOM tree 的机会，因此这种极端因素很难在实现开发过程中造成重大影响的。 1.1.3. element diff 当节点处于同一层级时，React diff 提供了三种节点操作，分别为：INSERT_MARKUP (插入)、MOVE_EXISTING (移动)和 REMOVE_NODE (删除)。 INSERT_MARKUP，新的 component 类型不在老集合里， 即是全新的节点，需要对新节点执行插入操作。 MOVE_EXISTING，在老集合有新 component 类型，且 element 是可更新的类型，generateComponentChildren 已调用 receiveComponent，这种情况下 prevChild=nextChild，就需要做移动操作，可以复用以前的 DOM 节点。 REMOVE_NODE，老 component 类型，在新集合里也有，但对应的 element 不同则不能直接复用和更新，需要执行删除操作，或者老 component 不在新集合里的，也需要执行删除操作。 如下图，老集合中包含节点：A、B、C、D，更新后的新集合中包含节点：B、A、D、C，此时新老集合进行 diff 差异化对比，发现 B != A，则创建并插入 B 至新集合，删除老集合 A；以此类推，创建并插入 A、D 和 C，删除 B、C 和 D。 React 发现这类操作繁琐冗余，因为这些都是相同的节点，但由于位置发生变化，导致需要进行繁杂低效的删除、创建操作，其实只要对这些节点进行位置移动即可。 针对这一现象，React 提出优化策略：允许开发者对同一层级的同组子节点，添加唯一 key 进行区分，虽然只是小小的改动，性能上却发生了翻天覆地的变化！ 新老集合所包含的节点，如下图所示，新老集合进行 diff 差异化对比，通过 key 发现新老集合中的节点都是相同的节点，因此无需进行节点删除和创建，只需要将老集合中节点的位置进行移动，更新为新集合中节点的位置，此时 React 给出的 diff 结果为：B、D 不做任何操作，A、C 进行移动操作，即可。 那么，如此高效的 diff 到底是如何运作的呢？让我们通过源码进行详细分析。 首先对新集合的节点进行循环遍历，for (name in nextChildren)，通过唯一 key 可以判断新老集合中是否存在相同的节点，if (prevChild === nextChild)，如果存在相同节点，则进行移动操作，但在移动前需要将当前节点在老集合中的位置与 lastIndex 进行比较，if (child._mountIndex 以上图为例，可以更为清晰直观的描述 diff 的差异对比过程： 从新集合中取得 B，判断老集合中存在相同节点 B，通过对比节点位置判断是否进行移动操作，B 在老集合中的位置 B._mountIndex = 1，此时 lastIndex = 0，不满足 child._mountIndex 从新集合中取得 A，判断老集合中存在相同节点 A，通过对比节点位置判断是否进行移动操作，A 在老集合中的位置 A._mountIndex = 0，此时 lastIndex = 1，满足 child._mountIndex 从新集合中取得 D，判断老集合中存在相同节点 D，通过对比节点位置判断是否进行移动操作，D 在老集合中的位置 D._mountIndex = 3，此时 lastIndex = 1，不满足 child._mountIndex 从新集合中取得 C，判断老集合中存在相同节点 C，通过对比节点位置判断是否进行移动操作，C 在老集合中的位置 C._mountIndex = 2，此时 lastIndex = 3，满足 child._mountIndex 以上主要分析新老集合中存在相同节点但位置不同时，对节点进行位置移动的情况，如果新集合中有新加入的节点且老集合存在需要删除的节点，那么 React diff 又是如何对比运作的呢？ 以下图为例： 从新集合中取得 B，判断老集合中存在相同节点 B，由于 B 在老集合中的位置 B._mountIndex = 1，此时lastIndex = 0，因此不对 B 进行移动操作；更新 lastIndex ＝ 1，并将 B 的位置更新为新集合中的位置B._mountIndex = 0，nextIndex++进入下一个节点的判断。 从新集合中取得 E，判断老集合中不存在相同节点 E，则创建新节点 E；更新 lastIndex ＝ 1，并将 E 的位置更新为新集合中的位置，nextIndex++进入下一个节点的判断。 从新集合中取得 C，判断老集合中存在相同节点 C，由于 C 在老集合中的位置C._mountIndex = 2，此时lastIndex = 1，因此对 C 进行移动操作；更新 lastIndex ＝ 2，并将 C 的位置更新为新集合中的位置，nextIndex++ 进入下一个节点的判断。 从新集合中取得 A，判断老集合中存在相同节点 A，由于 A 在老集合中的位置A._mountIndex = 0，此时lastIndex = 2，因此不对 A 进行移动操作；更新 lastIndex ＝ 2，并将 A 的位置更新为新集合中的位置，nextIndex++ 进入下一个节点的判断。 当完成新集合中所有节点 diff 时，最后还需要对老集合进行循环遍历，判断是否存在新集合中没有但老集合中仍存在的节点，发现存在这样的节点 D，因此删除节点 D，到此 diff 全部完成。 当然，React diff 还是存在些许不足与待优化的地方，如下图所示，若新集合的节点更新为：D、A、B、C，与老集合对比只有 D 节点移动，而 A、B、C 仍然保持原有的顺序，理论上 diff 应该只需对 D 执行移动操作，然而由于 D 在老集合的位置是最大的，导致其他节点的 _mountIndex 在此，读者们可以讨论思考：如何优化上述问题？ 建议：在开发过程中，尽量减少类似将最后一个节点移动到列表首部的操作，当节点数量过大或更新操作过于频繁时，在一定程度上会影响 React 的渲染性能。 1.1.4. 总结 React 通过制定大胆的 diff 策略，将 O(n3) 复杂度的问题转换成 O(n) 复杂度的问题； React 通过分层求异的策略，对 tree diff 进行算法优化； React 通过相同类生成相似树形结构，不同类生成不同树形结构的策略，对 component diff 进行算法优化； React 通过设置唯一 key的策略，对 element diff 进行算法优化； 建议，在开发组件时，保持稳定的 DOM 结构会有助于性能的提升； 建议，在开发过程中，尽量减少类似将最后一个节点移动到列表首部的操作，当节点数量过大或更新操作过于频繁时，在一定程度上会影响 React 的渲染性能。 1.2. 组件化思想 组件，即封装起来的具有独立功能的UI部件。React 推荐以组件的方式去重新思考 UI 构成，将UI上每一个功能相对独立的模块定义成组件，然后将小的组件通过组合或者嵌套的方式构成大的组件，最终完成整体UI的构建。 如果说 MVC 的思想让你做到 视图-数据-控制器 的分离，那么组件化的思考方式则是带来了UI功能模块之间的分离。 对于MVC开发模式来说，开发者将三者定义成不同的类，实现了表现，数据，控制的分离。对于React而言，则完全是一个新的思路，开发者从功能的角度出发，将 UI 分成不同的组件，每个组件都独立封装。在React中，你按照界面模块自然划分的方式来组织和编写你的代码，整个UI是一个通过小组件构成的大组件，每个组件只关心自己部分的逻辑，彼此独立。 React组件特征： 可组合(Composable)：一个组件易于和其它组件一起使用，或者嵌套在另一个组件内部 可重用(Reusable)：每个组件都是具有独立功能的，它可以被使用在多个UI场景 可维护(Maintainable)：每个小的组件仅仅包含自身的逻辑，更容易被理解和维护 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/setStateAsync.html":{"url":"React/setStateAsync.html","title":"setStateAsync","keywords":"","body":"1. React SetStateAsync1. React SetStateAsync We know React setState is an asynchronous function which accept a second parameter as a callback. Although Facebook recommends to write any code after setState in componentDidUpdate, sometimes we might want to write the task directly in setState. this.setState( { load: !this.state.load, count: this.state.count + 1 }, () => { console.log(this.state.count); console.log('加载完成'); } ); It's better to use Promise than callback: class AwesomeProject extends React.Component { constructor(props){ super(props) this.state = { ipAddress: '' } } setStateAsync(state) { return new Promise((resolve) => { this.setState(state, resolve) }); } async componentDidMount() { StatusBar.setNetworkActivityIndicatorVisible(true) const res = await fetch('https://api.ipify.org?format=json') const {ip} = await res.json() await this.setStateAsync({ipAddress: ip}) StatusBar.setNetworkActivityIndicatorVisible(false) } render() { return ( My IP is {this.state.ipAddress || 'Unknown'} ); } } Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"React/Testing.html":{"url":"React/Testing.html","title":"Testing","keywords":"","body":"1. Use shallow rendering1. Use shallow rendering Testing React components is still a bit of a tricky topic. Not because it's hard, but because it's still an evolving area, and no single approach has emerged as the 'best' one yet. At the moment, my go-to method is to use shallow rendering and prop assertions. Shallow rendering is nice, because it allows you to render a single component completely, but without delving into any of its child components to render those. Instead, the resulting object will tell you things like the type and props of the children. This gives us good isolation, allowing testing of a single component at a time. There are three types of component unit tests I find myself most commonly writing: Render logic Imagine a component that should conditionally display either an image, or a loading icon: const Image = props => { if (props.loading) { return ; } return ; }; We might test it like this: describe('Image', () => { it('renders a loading icon when the image is loading', () => { const image = shallowRender(); expect(image.type).toEqual(LoadingIcon); }); it('renders the image once it has loaded', () => { const image = shallowRender(); expect(image.type).toEqual('img'); }); }); Easy! I should point out that the API for shallow rendering is slightly more complicated than what I've shown. The shallowRender function used above is our own helper, which wraps the real API to make it easier to use. Revisiting our ListOfNumbers component above, here is how we might test that the map is done correctly: describe('ListOfNumbers', () => { it('renders an item for each provided number', () => { const listOfNumbers = shallowRender(); expect(listOfNumbers.props.children.length).toEqual(4); }); }); Prop transformations In the last example, we dug into the children of the component being tested, to make sure that they were rendered correctly. We can extend this by asserting that not only are the children there, but that they were given the correct props. This is particularly useful when a component does some transformation on its props, before passing them on. For example, the following component takes CSS class names as an array of strings, and passes them down as a single, space-separated string: const TextWithArrayOfClassNames = props => ( {props.text} ); describe('TextWithArrayOfClassNames', () => { it('turns the array into a space-separated string', () => { const text = 'Hello, world!'; const classNames = ['red', 'bold', 'float-right']; const textWithArrayOfClassNames = shallowRender(); const childClassNames = textWithArrayOfClassNames.props.children.props.className; expect(childClassNames).toEqual('red bold float-right'); }); }); One common criticism of this approach to testing is the proliferation of props.children.props.children... While it's not the prettiest code, personally I find that if I'm being annoyed by writing props.children too much in the one test, that's a sign that the component is too big, complex, or deeply nested, and should be split up. The other thing I often hear is that your tests become too dependent on the component's internal implementation, so that changing your DOM structure slightly causes all of your tests to break. This is definitely a fair criticism, and a brittle test suite is the last thing that anyone wants. The best way to manage this is to (wait for it) keep your components small and simple, which should limit the number of tests that break due to any one component changing. User interaction Of course, components are not just for display, they're also interactive: const RedInput = props => ( ) Here's my favorite way to test these: describe('RedInput', () => { it('passes the event to the given callback when the value changes', () => { const callback = jasmine.createSpy(); const redInput = shallowRender(); redInput.props.onChange('an event!'); expect(callback).toHaveBeenCalledWith('an event!'); }); }); It's a bit of a trivial example, but hopefully you get the idea. Integration testing So far I've only covered unit testing components in isolation, but you're also going to want some higher level tests in order to ensure that your application connects up properly and actually works. Render your entire tree of components (instead of shallow rendering). Reach into the DOM (using the React TestUtils, or jQuery, etc) to find the elements you care about the most, and then assert on their HTML attributes or contents, orsimulate DOM events and then assert on the side effects (DOM or route changes, AJAX calls, etc) On TDD In general, I don't use TDD when writing React components. When working on a component, I often find myself churning its structure quite a bit, as I try to land on the simplest HTML and CSS that looks right in whatever browsers I need to support. And because my component unit testing approach tends to assert on the component structure, TDD would cause me to be constantly fixing my tests as I tweak the DOM, which seems like a waste of time. The other factor to this is that the components should be so simple that the advantages of test-first are diminished. All of the complex logic and transformations are pulled out into action creators and reducers, which is where I can (and do) reap the benefits of TDD. Which brings me to my final point about testing. In this whole section, I've been talking about testing the components, and that's because there's no special information needed for testing the rest of a Redux-based app. As a framework, Redux has very little 'magic' that goes on behind the scenes, which I find reduces the need for excessive mocking or other test boilerplate. Everything is just plain old functions (many of them pure), which is a real breath of fresh air when it comes to testing. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/":{"url":"Redux/","title":"Redux","keywords":"","body":"1. TOC1. TOC Compose Introduction Middleware passing_store Redux入门教程1 Redux入门教程2中间件与异步操作 Redux入门教程3React-Redux的用法 数字加1 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Redux/Compose.html":{"url":"Redux/Compose.html","title":"Compose","keywords":"","body":"1. Compose1. Compose redux compose 是从右向左。跟自己用 reduce 写的相反。 Redux also comes with a compose function that you can use to compose several functions into a single function. It also composes functions from right to left as opposed to from left to right. If we just wanted to get a comma-delimited list of color titles, we could use this one crazy line of code: console.log(store.getState().colors.map((c) => c.title).join(', ')); A more functional approach would be to break this down into smaller functions and compose them into a single function: import { compose } from 'redux'; // right to left const print = compose( (list) => console.log(list), (titles) => titles.join(', '), (map) => map((c) => c.title), (colors) => colors.map.bind(colors), (state) => state.colors ); print(store.getState()); The compose function takes in functions as arguments and invokes the rightmost first. First it obtains the colors from state, then it returns a bound map function, followed by an array of color titles, which are joined as a comma-delimited list and finally logged to the console. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/Introduction.html":{"url":"Redux/Introduction.html","title":"Introduction","keywords":"","body":"1. react redux 流程1.1. Redux benefits1.2. Concepts1.2.1. Reducer1.2.2. Action1.2.3. Store1.2.4. 如何发送 action1.2.5. Container1.3. 异步操作1. react redux 流程 react: Hey Action, someone clicked this \"save\" button action: thanks react! I will dispatch an action so reducers that care can update state reducer: thanks action. I see you passed me the current state and the action to perform. I will make a new copy of the state and return it store: thanks for updating the state reducer. I'll make sure all connected components are aware react-redux: I'll determine if I should tell react about this change so that it only has to update UI when necessary react: ooo! new data has been passed down via props from the store(connect, mapStateToProps, mapDispatchToProps). I will re-render the UI to reflect this 1.1. Redux benefits reducers are pure functions, which simply do oldState + action => newState. Each reducer computes a separate piece of state, which is then all composed together to form the whole application. This makes all your business logic and state transitions easy to test. Api 简单 容易理解流程 如果按照它推荐的方式 -- 视图组件和容器组建分离，容器组件状态通过 props 传到视图组件中，职责分明，每个组件单一、小。 1.2. Concepts 1.2.1. Reducer 根据之前 state 和 action 返回新的 state 1.2.2. Action 描述请求，传递需要的数据给 Reducer，这样 Reducer 根据 action 的参数返回新的 state 1.2.3. Store redux 根据 reducer 创建 store, 传递给 Provider ... import { createStore } from 'redux' import { Provider } from 'react-redux' import App from './components/App' import reducer from './reducers' const store = createStore(reducer) render( , document.getElementById('root') ) 1.2.4. 如何发送 action 一般在初始化或者按钮点击的时候，希望能够触发 dispatch(action)。下面讲实现。 App component App.js 作为启动组件，引入所有 Container import AddTodo from '../containers/AddTodo' import VisibleTodoList from '../containers/VisibleTodoList' const App = () => ( ) export default App 1.2.5. Container container component 核心代码： connect(mapStateToProps, mapDispatchToProps)(PresentationalComponent) connect() without any parameter, means to not subscribe to the store. connect is a higher-order function that returns a function that returns a component. connect expects two arguments: mapStateToProps and mapDispatchToProps. Both are functions. It returns a function that expects a presentational component, and wraps it with a container that sends it data via props. The first function, mapStateToProps, injects state as an argument and returns an object that will be mapped to props. We set the colors property of the ColorList component to an array of sorted colors from state. The second function, mapDispatchToProps, injects the store’s dispatch function as an argument that can be used when the ColorList component invokes callback function properties. When the ColorList raises onRate or onRemove events, data about the color to rate or remove is obtained and dispatched. connect works in conjunction with the provider. The provider adds the store to the context and connect creates components that retrieve the store. When using connect, you do not have to worry about context. Container 引入需要的 Action 和视图组件。mapStateToProps 和 mapDispatchToProps 两个方法分别负责把 state 和 dispatch 映射到 props 中。connect 传递着两个方法，再 Wrap 视图组件。这样 presentational 组件就有了 active 和 onClick 两个 props，其中 onClick 执行的时候会 dispatch action。 注意，如果 connect 第二个参数 mapDispatchToProps 不传，则 dispatch 会以 props 注入到组件中！ 把 \bredux store 想象成一个 pie chart，里面有多少个 reducer 就负责有多少片 state 需要管理。mapStateToProps 可以\b暴露所需要的 state。每次 state 更新都会触发该方法。这里可能会有复杂耗时的 mapping 计算，可以用 reselect library memorizes expensive calls import { bindActionCreators } from 'redux' function mapStateToProps(state, ownProps){ return { courses: state.courses } } // method 1: manually function mapDispatchToProps(dispatch){ return ({ createCourse(course, ownProps){ dispatch(courseActions.createCourse(course)) } }) // return { // createCourse: (course) => { // dispatch(courseActions.createCourse(course)) // } // } } // method 2: bindActionCreators will find all actions in that file function mapDispatchToProps(dispatch, ownProps){ return { actions: bindActionCreators(courseActions, dispatch) } } export default connect(mapStateToProps, mapDispatchToProps)(CoursesPage) 1.3. 异步操作 redux-thunk redux-saga Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/Middleware.html":{"url":"Redux/Middleware.html","title":"Middleware","keywords":"","body":"1. Middleware1.1. Applying Middleware to the Store1. Middleware Redux also has middleware. It acts on the store’s dispatch pipeline. In Redux, middleware consists of a series of functions that are executed in a row in the process of dispatching an action. Figure 8-7. HTTP request middleware pipeline These higher-order functions allow you to insert functionality before or after actions are dispatched and state is updated. Each middleware function is executed sequentially. Each piece of middleware is a function that has access to the action, a dispatch function, and a function that will call next. next causes the update to occur. Before next is called, you can modify the action. After next, the state will have changed. Figure 8-8. Middleware functions execute sequentially 1.1. Applying Middleware to the Store In this section, we are going to create a storeFactory. A factory is a function that manages the process of creating stores. In this case, the factory will create a store that has middleware for logging and saving data. The storeFactory will be one file that contains one function that groups everything needed to create the store. Whenever we need a store, we can invoke this function: const store = storeFactory(initialData) When we create the store, we create two pieces of middleware: the logger and the saver (Example 8-9). The data is saved to localStorage with middleware instead of the store method. Example 8-9. storeFactory: ./store/index.js import { createStore, combineReducers, applyMiddleware } from 'redux'; import { colors, sort } from './reducers'; import stateData from './initialState'; const logger = (store) => (next) => (action) => { let result; console.groupCollapsed('dispatching', action.type); console.log('prev state', store.getState()); console.log('action', action); result = next(action); console.log('next state', store.getState()); console.groupEnd(); }; const saver = (store) => (next) => (action) => { let result = next(action); localStorage['redux-store'] = JSON.stringify(store.getState()); return result; }; const storeFactory = (initialState = stateData) => applyMiddleware(logger, saver)(createStore)( combineReducers({ colors, sort }), localStorage['redux-store'] ? JSON.parse(localStorage['redux-store']) : stateData ); export default storeFactory; Both the logger and the saver are middleware functions. In Redux, middleware is defined as a higher-order function: it’s a function that returns a function that returns a function. The last function returned is invoked every time an action is dispatched. When this function is invoked, you have access to the action, the store, and the function for sending the action to the next middleware. Instead of exporting the store directly, we export a function, a factory that can be used to create stores. If this factory is invoked, then it will create and return a store that incorporates logging and saving. In the logger, before the action is dispatched, we open a new console group and log the current state and the current action. Invoking next pipes the action on to the next piece of middleware and eventually the reducers. The state at this point has been updated, so we log the changed state and end the console group. In the saver, we invoke next with the action, which will cause the state to change. Then we save the new state in localStorage and return the result, as in Example 8-9. In Example 8-10 we create a store instance using the storeFactory. Since we do not send any arguments to this store, the initial state will come from state data. Example 8-10. Creating a store using the factory import storeFactory from \"./store\" const store = storeFactory(true) store.dispatch( addColor(\"#FFFFFF\",\"Bright White\") ) store.dispatch( addColor(\"#00FF00\",\"Lawn\") ) store.dispatch( addColor(\"#0000FF\",\"Big Blue\") ) Every action dispatched from this store will add a new group of logs to the console, and the new state will be saved in localStorage. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/passing_store.html":{"url":"Redux/passing_store.html","title":"passing_store","keywords":"","body":"1. Passing store1.1. Provider from react-redux ✅1.2. Explicitly Passing the Store1.3. Passing the Store via Context1. Passing store 1.1. Provider from react-redux ✅ React Redux is a library that contains some tools to help ease the complexity involved with implicitly passing the store via context. Redux does not require that you use this library. However, using React Redux reduces your code’s complexity and may help you build apps a bit faster. react-redux supplies us with a component that we can use to set up our store in the context, the provider. We can wrap any React element with the provider and that element’s children will have access to the store via context. Instead of setting up the store as a context variable in the App component, we can keep the App component stateless: import { Menu, NewColor, Colors } from './containers'; const App = () => ( ); export default App; The provider adds the store to the context and updates the App component when actions have been dispatched. The provider expects a single child component: import React from 'react'; import { render } from 'react-dom'; import { Provider } from 'react-redux'; import App from './components/App'; import storeFactory from './store'; const store = storeFactory(); render( , document.getElementById('react-container') ); The provider requires that we pass the store as a property. It adds the store to the context so that it can be retrieved by any child of the App component. Simply using the provider can save us some time and simplify our code. Once we’ve incorporated the provider, we can retrieve the store via context in child container components. However, React Redux provides us with another way to quickly create container components that work with the provider: the connect function. 1.2. Explicitly Passing the Store The first, and most logical, way to incorporate the store into your UI is to pass it down the component tree explicitly as a property. This approach is simple and works very well for smaller apps that only have a few nested components. Let’s take a look at how we can incorporate the store into the color organizer. In the ./index.js file, we will render an App component and pass it the store: import React from 'react' import ReactDOM from 'react-dom' import App from './components/App' import storeFactory from './store' const store = storeFactory() const render = () => ReactDOM.render( , document.getElementById('react-container') ) store.subscribe(render) render() This is the ./index.js file. In this file, we create the store with the storeFactory and render the App component into the document. When the App is rendered the store is passed to it as a property. Every time the store changes, the render function will be invoked, which efficiently updates the UI with new state data. Now that we have passed the store to the App, we have to continue to pass it down to the child components that need it: import AddColorForm from './AddColorForm' import SortMenu from './SortMenu' import ColorList from './ColorList' const App = ({ store }) => export default App The App component is our root component. It captures the store from props and explicitly passes it down to its child components. The store is passed to the SortMenu, AddColorForm, and ColorList components as a property. Now that we have passed the store from the App, we can use it inside the child components. Remember we can read state from the store with store.getState, and we can dispatch actions to the store with store.dispatch. From the AddColorForm component, we can use the store to dispatch ADD_COLOR actions. When the user submits the form, we collect the color and the title from refs and use that data to create and dispatch a new ADD_COLOR action: import { PropTypes, Component } from 'react' import { addColor } from '../actions' const AddColorForm = ({store}) => { let _title, _color const submit = e => { e.preventDefault() store.dispatch( addColor(_title.value, _color.value) ) _title.value = '' _color.value = '#000000' _title.focus() } return ( _title = input} type=\"text\" placeholder=\"color title...\" required/> _color = input} type=\"color\" required/> ADD ) } AddColorForm.propTypes = { store: PropTypes.object } export default AddColorForm From this component, we import the necessary action creator, addColor. When the user submits the form, we’ll dispatch a new ADD_COLOR action directly to the store using this action creator. The ColorList component can use the store’s getState method to obtain the original colors and sort them appropriately. It can also dispatch RATE_COLOR and REMOVE_COLOR actions directly as they occur: import { PropTypes } from 'react' import Color from './Color' import { rateColor, removeColor } from '../actions' import { sortFunction } from '../lib/array-helpers' const ColorList = ({ store }) => { const { colors, sort } = store.getState() const sortedColors = [...colors].sort(sortFunction(sort)) return ( {(colors.length === 0) ? No Colors Listed. (Add a Color) : sortedColors.map(color => store.dispatch( rateColor(color.id, rating) ) } onRemove={() => store.dispatch( removeColor(color.id) ) } /> ) } ) } ColorList.propTypes = { store: PropTypes.object } export default ColorList The store has been passed all the way down the component tree to the ColorList component. This component interacts with the store directly. When colors are rated or removed, those actions are dispatched to the store. The store is also used to obtain the original colors. Those colors are duplicated and sorted according to the store’s sort property and saved as sortedColors. sortedColors is then used to create the UI. This approach is great if your component tree is rather small, like this color organizer. The drawback of using this approach is that we have to explicitly pass the store to child components, which means slightly more code and slightly more headaches than with other approaches. Additionally, the SortMenu, AddColorForm, and ColorList components require this specific store. It would be hard to reuse them in another application. 1.3. Passing the Store via Context In the last section, we created a store and passed it all the way down the component tree from the App component to the ColorList component. This approach required that we pass the store through every component that comes between the App and the ColorList. Let’s say we have some cargo to move from Washington, DC, to San Francisco, CA. We could use a train, but that would require that we lay tracks through at least nine states so that our cargo can travel to California. This is like explicitly passing the store down the component tree from the root to the leaves. You have to “lay tracks” through every component that comes between the origin and the destination. If using a train is like explicitly passing the store through props, then implicitly passing the store via context is like using a jet airliner. When a jet flies from DC to San Francisco, it flies over at least nine states—no tracks required. Similarly, we can take advantage of a React feature called context that allows us to pass variables to components without having to explicitly pass them down through the tree as properties.1 Any child component can access these context variables. If we were to pass the store using context in our color organizer app, the first step would be to refactor the App component to hold context. The App component will also need to listen to the store so that it can trigger a UI update every time the state changes: import { PropTypes, Component } from 'react' import SortMenu from './SortMenu' import ColorList from './ColorList' import AddColorForm from './AddColorForm' import { sortFunction } from '../lib/array-helpers' class App extends Component { getChildContext() { return { store: this.props.store } } componentWillMount() { this.unsubscribe = store.subscribe( () => this.forceUpdate() ) } componentWillUnmount() { this.unsubscribe() } render() { const { colors, sort } = store.getState() const sortedColors = [...colors].sort(sortFunction(sort)) return ( ) } } App.propTypes = { store: PropTypes.object.isRequired } App.childContextTypes = { store: PropTypes.object.isRequired } export default App First, adding context to a component requires that you use the getChildContext lifecycle function. It will return the object that defines the context. In this case, we add the store to the context, which we can access through props. Next, you will need to specify childContextTypes on the component instance and define your context object. This is similar to adding propTypes or defaultProps to a component instance. However, for context to work, you must take this step. At this point, any children of the App component will have access to the store via the context. They can invoke store.getState and store.dispatch directly. The final step is to subscribe to the store and update the component tree every time the store updates state. This can be achieved with the mounting lifecycle functions (see “Mounting Lifecycle”). In componentWillMount, we can subscribe to the store and use this.forceUpdate to trigger the updating lifecycle, which will re-render our UI. In componentWillUnmount, we can invoke the unsubscribe function and stop listening to the store. Because the App component itself triggers the UI update, there is no longer a need to subscribe to the store from the entry ./index.js file; we are listening to store changes from the same component that adds the store to the context, App. Let’s refactor the AddColorForm component to retrieve the store and dispatch the ADD_COLOR action directly: const AddColorForm = (props, { store }) => { let _title, _color const submit = e => { e.preventDefault() store.dispatch(addColor(_title.value, _color.value)) _title.value = '' _color.value = '#000000' _title.focus() } return ( _title = input} type=\"text\" placeholder=\"color title...\" required/> _color = input} type=\"color\" required/> ADD ) } AddColorForm.contextTypes = { store: PropTypes.object } The context object is passed to stateless functional components as the second argument, after props. We can use object destructuring to obtain the store from this object directly in the arguments. In order to use the store, we must define contextTypes on the AddColorForm instance. This is where we tell React which context variables this component will use. This is a required step. Without it, the store cannot be retrieved from the context. Let’s take a look at how to use context in a component class. The Color component can retrieve the store and dispatch RATE_COLOR and REMOVE_COLOR actions directly: import { PropTypes, Component } from 'react' import StarRating from './StarRating' import TimeAgo from './TimeAgo' import FaTrash from 'react-icons/lib/fa/trash-o' import { rateColor, removeColor } from '../actions' class Color extends Component { render() { const { id, title, color, rating, timestamp } = this.props const { store } = this.context return ( {title} store.dispatch( removeColor(id) ) }> store.dispatch( rateColor(id, rating) ) } /> ) } } Color.contextTypes = { store: PropTypes.object } Color.propTypes = { id: PropTypes.string.isRequired, title: PropTypes.string.isRequired, color: PropTypes.string.isRequired, rating: PropTypes.number } Color.defaultProps = { rating: 0 } export default Color ColorList is now a component class, and can access context via this.context. Colors are now read directly from the store via store.getState. The same rules apply that do for stateless functional components. contextTypes must be defined on the instance. Retrieving the store from the context is a nice way to reduce your boilerplate, but this is not something that is required for every application. Dan Abramov, the creator of Redux, even suggests that these patterns do not need to be religiously followed. Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/Redux入门教程1.html":{"url":"Redux/Redux入门教程1.html","title":"Redux入门教程1","keywords":"","body":"1. Redux 入门教程（一）：基本用法1.1. 你可能不需要 Redux1.2. 设计思想1.3. 基本概念和 API1.3.1. Store1.3.2. State1.3.3. Action1.3.4. Action Creator1.3.5. store.dispatch()1.3.6. Reducer1.3.7. store.subscribe()1.3.8. Store 的实现1.4. Reducer 的拆分1.5. 工作流程1.6. 实例：计数器1. Redux 入门教程（一）：基本用法 React 只是 DOM 的一个抽象层，并不是 Web 应用的完整解决方案。有两个方面，它没涉及。 代码结构 组件之间的通信 对于大型的复杂应用来说，这两方面恰恰是最关键的。因此，只用 React 没法写大型应用。 为了解决这个问题，2014年 Facebook 提出了 Flux 架构的概念，引发了很多的实现。2015年，Redux 出现，将 Flux 与函数式编程结合一起，很短时间内就成为了最热门的前端架构。 本文详细介绍 Redux 架构，由于内容较多，全文分成三个部分。今天是第一部分，介绍基本概念和用法。 1.1. 你可能不需要 Redux 首先明确一点，Redux 是一个有用的架构，但不是非用不可。事实上，大多数情况，你可以不用它，只用 React 就够了。 \"如果你不知道是否需要 Redux，那就是不需要它。\" \"只有遇到 React 实在解决不了的问题，你才需要 Redux 。\" 简单说，如果你的UI层非常简单，没有很多互动，Redux 就是不必要的，用了反而增加复杂性。 用户的使用方式非常简单 用户之间没有协作 不需要与服务器大量交互，也没有使用 WebSocket 视图层（View）只从单一来源获取数据 上面这些情况，都不需要使用 Redux。 用户的使用方式复杂 不同身份的用户有不同的使用方式（比如普通用户和如普通用户和管理员） 多个用户之间可以协作 与服务器大量交互，或者使用了WebSocket View要从多个来源获取数据 上面这些情况才是 Redux 的适用场景：多交互、多数据源。 从组件角度看，如果你的应用有以下场景，可以考虑使用 Redux。 某个组件的状态，需要共享 某个状态需要在任何地方都可以拿到 一个组件需要改变全局状态 一个组件需要改变另一个组件的状态 发生上面情况时，如果不使用 Redux 或者其他状态管理工具，不按照一定规律处理状态的读写，代码很快就会变成一团乱麻。你需要一种机制，可以在同一个地方查询状态、改变状态、传播状态的变化。 总之，不要把 Redux 当作万灵丹，如果你的应用没那么复杂，就没必要用它。另一方面，Redux 只是 Web 架构的一种解决方案，也可以选择其他方案。 1.2. 设计思想 Redux 的设计思想很简单，就两句话。 Web 应用是一个状态机，视图与状态是一一对应的。 所有的状态，保存在一个对象里面。 请务必记住这两句话，下面就是详细解释。 1.3. 基本概念和 API 1.3.1. Store Store 就是保存数据的地方，你可以把它看成一个容器。整个应用只能有一个 Store。 Redux 提供 createStore 这个函数，用来生成 Store。 import { createStore } from 'redux'; const store = createStore(reducer); 上面代码中，createStore函数接受另一个函数作为参数，返回新生成的 Store 对象。 1.3.2. State Store 对象包含所有数据。如果想得到某个时点的数据，就要对 Store 生成快照。这种时点的数据集合，就叫做 State。 当前时刻的 State，可以通过 store.getState() 拿到。 import { createStore } from 'redux'; const store = createStore(reducer); const state = store.getState(); Redux 规定， 一个 State 对应一个 View。只要 State 相同，View 就相同。你知道 State，就知道 View 是什么样，反之亦然。 1.3.3. Action State 的变化，会导致 View 的变化。但是，用户接触不到 State，只能接触到 View。所以，State 的变化必须是 View 导致的。Action 就是 View 发出的通知，表示 State 应该要发生变化了。 Action 是一个对象。其中的type属性是必须的，表示 Action 的名称。其他属性可以自由设置，社区有一个规范可以参考。 const action = { type: 'ADD_TODO', payload: 'Learn Redux' }; 上面代码中，Action 的名称是ADD_TODO，它携带的信息是字符串Learn Redux。 可以这样理解，Action 描述当前发生的事情。改变 State 的唯一办法，就是使用 Action。它会运送数据到 Store。 1.3.4. Action Creator View 要发送多少种消息，就会有多少种 Action。如果都手写，会很麻烦。可以定义一个函数来生成 Action，这个函数就叫 Action Creator。 const ADD_TODO = '添加 TODO'; function addTodo(text) { return { type: ADD_TODO, text } } const action = addTodo('Learn Redux'); 上面代码中，addTodo函数就是一个 Action Creator。 1.3.5. store.dispatch() store.dispatch()是 View 发出 Action 的唯一方法。 import { createStore } from 'redux'; const store = createStore(reducer); store.dispatch({ type: 'ADD_TODO', payload: 'Learn Redux' }); 上面代码中，store.dispatch接受一个 Action 对象作为参数，将它发送出去。 结合 Action Creator，这段代码可以改写如下。 store.dispatch(addTodo('Learn Redux')); 1.3.6. Reducer Store 收到 Action 以后，必须给出一个新的 State，这样 View 才会发生变化。这种 State 的计算过程就叫做 Reducer。 Reducer 是一个函数，它接受 Action 和当前 State 作为参数，返回一个新的 State。 const reducer = function (state, action) { // ... return new_state; }; 整个应用的初始状态，可以作为 State 的默认值。下面是一个实际的例子。 const defaultState = 0; const reducer = (state = defaultState, action) => { switch (action.type) { case 'ADD': return state + action.payload; default: return state; } }; const state = reducer(1, { type: 'ADD', payload: 2 }); 上面代码中，reducer 函数收到名为 ADD 的 Action 以后，就返回一个新的 State，作为加法的计算结果。其他运算的逻辑（比如减法），也可以根据 Action 的不同来实现。 实际应用中，Reducer 函数不用像上面这样手动调用，store.dispatch 方法会触发 Reducer 的自动执行。为此，Store 需要知道 Reducer 函数，做法就是在生成 Store 的时候，将 Reducer 传入createStore方法。 import { createStore } from 'redux'; const store = createStore(reducer); 上面代码中，createStore接受 Reducer 作为参数，生成一个新的 Store。以后每当store.dispatch发送过来一个新的 Action，就会自动调用 Reducer，得到新的 State。 为什么这个函数叫做 Reducer 呢？因为它可以作为数组的reduce方法的参数。请看下面的例子，一系列 Action 对象按照顺序作为一个数组。 const actions = [ { type: 'ADD', payload: 0 }, { type: 'ADD', payload: 1 }, { type: 'ADD', payload: 2 } ]; const total = actions.reduce(reducer, 0); // 3 上面代码中，数组actions表示依次有三个 Action，分别是加0、加1和加2。数组的reduce方法接受 Reducer 函数作为参数，就可以直接得到最终的状态3。 纯函数 Reducer 函数最重要的特征是，它是一个纯函数。也就是说，只要是同样的输入，必定得到同样的输出。 纯函数是函数式编程的概念，必须遵守以下一些约束。 不得改写参数 不能调用系统 I/O 的API 不能调用Date.now()或者Math.random()等不纯的方法，因为每次会得到不一样的结果 由于 Reducer 是纯函数，就可以保证同样的 State，必定得到同样的 View。但也正因为这一点，Reducer 函数里面不能改变 State，必须返回一个全新的对象，请参考下面的写法。 // State 是一个对象 function reducer(state, action) { return Object.assign({}, state, { thingToChange }) // 或者 return { ...state, ...newState }; } // State 是一个数组 function reducer(state, action) { return [...state, newItem]; } 最好把 State 对象设成只读。你没法改变它，要得到新的 State，唯一办法就是生成一个新对象。这样的好处是，任何时候，与某个 View 对应的 State 总是一个不变的对象。 1.3.7. store.subscribe() Store 允许使用 store.subscribe 方法设置监听函数，一旦 State 发生变化，就自动执行这个函数。 import { createStore } from 'redux'; const store = createStore(reducer); store.subscribe(listener); 显然，只要把 View 的更新函数（对于 React 项目，就是组件的render方法或setState方法）放入listen，就会实现 View 的自动渲染。 store.subscribe方法返回一个函数，调用这个函数就可以解除监听。 let unsubscribe = store.subscribe(() => console.log(store.getState()) ); unsubscribe(); 1.3.8. Store 的实现 store.getState() store.dispatch() store.subscribe() import { createStore } from 'redux'; let { subscribe, dispatch, getState } = createStore(reducer); createStore 方法还可以接受第二个参数，表示 State 的最初状态。这通常是服务器给出的。 // todoApp is reducer let store = createStore(todoApp, window.STATE_FROM_SERVER) 上面代码中，window.STATE_FROM_SERVER 就是整个应用的状态初始值。注意，如果提供了这个参数，它会覆盖 Reducer 函数的默认初始值。 下面是 createStore 方法的一个简单实现，可以了解一下 Store 是怎么生成的。 const createStore = (reducer) => { let state; let listeners = []; const getState = () => state; const dispatch = (action) => { state = reducer(state, action); listeners.forEach(listener => listener()); }; const subscribe = (listener) => { listeners.push(listener); return () => { listeners = listeners.filter(l => l !== listener); } }; dispatch({}); return { getState, dispatch, subscribe }; }; 1.4. Reducer 的拆分 Reducer 函数负责生成 State。由于整个应用只有一个 State 对象，包含所有数据，对于大型应用来说，这个 State 必然十分庞大，导致 Reducer 函数也十分庞大。 请看下面的例子。 const chatReducer = (state = defaultState, action = {}) { const { type, payload } = action; switch (type) { case ADD_CHAT: return Object.assign({}, state, { chatLog: state.chatLog.concat(payload) }); case CHANGE_STATUS: return Object.assign({}, state, { statusMessage: payload }); case CHANGE_USERNAME: return Object.assign({}, state, { userName: payload }); default: return state; } }; 上面代码中，三种 Action 分别改变 State 的三个属性。 ADD_CHAT：chatLog属性 CHANGE_STATUS：statusMessage属性 CHANGE_USERNAME：userName属性 这三个属性之间没有联系，这提示我们可以把 Reducer 函数拆分。不同的函数负责处理不同属性，最终把它们合并成一个大的 Reducer 即可。 const chatReducer = (state = defaultState, action = {}) => { return { chatLog: chatLog(state.chatLog, action), statusMessage: statusMessage(state.statusMessage, action), userName: userName(state.userName, action) } }; 上面代码中，Reducer 函数被拆成了三个小函数，每一个负责生成对应的属性。 这样一拆，Reducer 就易读易写多了。而且，这种拆分与 React 应用的结构相吻合：一个 React 根组件由很多子组件构成。这就是说，子组件与子 Reducer 完全可以对应。 Redux 提供了一个combineReducers方法，用于 Reducer 的拆分。你只要定义各个子 Reducer 函数，然后用这个方法，将它们合成一个大的 Reducer。 import { combineReducers } from 'redux'; const chatReducer = combineReducers({ chatLog, statusMessage, userName }) export default chatReducer; 上面的代码通过combineReducers方法将三个子 Reducer 合并成一个大的函数。 这种写法有一个前提，就是 State 的属性名必须与子 Reducer 同名。如果不同名，就要采用下面的写法。 const reducer = combineReducers({ a: doSomethingWithA, b: processB, c: c }) // 等同于 function reducer(state = {}, action) { return { a: doSomethingWithA(state.a, action), b: processB(state.b, action), c: c(state.c, action) } } 总之，combineReducers()做的就是产生一个整体的 Reducer 函数。该函数根据 State 的 key 去执行相应的子 Reducer，并将返回结果合并成一个大的 State 对象。 下面是combineReducer的简单实现。 const combineReducers = reducers => { return (state = {}, action) => { return Object.keys(reducers).reduce( (nextState, key) => { nextState[key] = reducers[key](state[key], action); return nextState; }, {} ); }; }; 你可以把所有子 Reducer 放在一个文件里面，然后统一引入。 import { combineReducers } from 'redux' import * as reducers from './reducers' const reducer = combineReducers(reducers) 1.5. 工作流程 首先，用户发出 Action。 store.dispatch(action); 然后，Store 自动调用 Reducer，并且传入两个参数：当前 State 和收到的 Action。 Reducer 会返回新的 State 。 // todoApp is reducer let nextState = todoApp(previousState, action); State 一旦有变化，Store 就会调用监听函数。 // 设置监听函数 store.subscribe(listener); listener可以通过store.getState()得到当前状态。如果使用的是 React，这时可以触发重新渲染 View。 function listener() { let newState = store.getState(); component.setState(newState); } 1.6. 实例：计数器 下面我们来看一个最简单的实例。 const Counter = ({ value }) => ( {value} ); const render = () => { ReactDOM.render( , document.getElementById('root') ); }; store.subscribe(render); render(); 上面是一个简单的计数器，唯一的作用就是把参数value的值，显示在网页上。Store 的监听函数设置为render，每次 State 的变化都会导致网页重新渲染。 下面加入一点变化，为Counter添加递增和递减的 Action。 const Counter = ({ value }) => ( {value} + - ); const reducer = (state = 0, action) => { switch (action.type) { case 'INCREMENT': return state + 1; case 'DECREMENT': return state - 1; default: return state; } }; const store = createStore(reducer); const render = () => { ReactDOM.render( store.dispatch({type: 'INCREMENT'})} onDecrement={() => store.dispatch({type: 'INECREMENT'})} />, document.getElementById('root') ); }; render(); store.subscribe(render); 完整的代码请看这里。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/Redux入门教程2中间件与异步操作.html":{"url":"Redux/Redux入门教程2中间件与异步操作.html","title":"Redux入门教程2中间件与异步操作","keywords":"","body":"1. Redux 入门教程（二）：中间件与异步操作1.1. 中间件的概念1.2. 中间件的用法1.3. applyMiddlewares()1.4. 异步操作的基本思路1.5. redux-thunk 中间件1.6. redux-promise 中间件1. Redux 入门教程（二）：中间件与异步操作 异步操作怎么办？Action 发出以后，Reducer 立即算出 State，这叫做同步；Action 发出以后，过一段时间再执行 Reducer，这就是异步。 怎么才能 Reducer 在异步操作结束后自动执行呢？这就要用到新的工具：中间件（middleware）。 1.1. 中间件的概念 为了理解中间件，让我们站在框架作者的角度思考问题：如果要添加功能，你会在哪个环节添加？ Reducer：纯函数，只承担计算 State 的功能，不合适承担其他功能，也承担不了，因为理论上，纯函数不能进行读写操作。 View：与 State 一一对应，可以看作 State 的视觉层，也不合适承担其他功能。 Action：存放数据的对象，即消息的载体，只能被别人操作，自己不能进行任何操作。 想来想去，只有发送 Action 的这个步骤，即store.dispatch()方法，可以添加功能。举例来说，要添加日志功能，把 Action 和 State 打印出来，可以对store.dispatch进行如下改造。 let next = store.dispatch; store.dispatch = function dispatchAndLog(action) { console.log('dispatching', action); next(action); console.log('next state', store.getState()); } 上面代码中，对store.dispatch进行了重定义，在发送 Action 前后添加了打印功能。这就是中间件的雏形。 中间件就是一个函数，对store.dispatch方法进行了改造，在发出 Action 和执行 Reducer 这两步之间，添加了其他功能。 1.2. 中间件的用法 本教程不涉及如何编写中间件，因为常用的中间件都有现成的，只要引用别人写好的模块即可。比如，上一节的日志中间件，就有现成的redux-logger模块。这里只介绍怎么使用中间件。 import { applyMiddleware, createStore } from 'redux'; import createLogger from 'redux-logger'; const logger = createLogger(); const store = createStore( reducer, applyMiddleware(logger) ); 上面代码中，redux-logger提供一个生成器createLogger，可以生成日志中间件logger。然后，将它放在applyMiddleware方法之中，传入createStore方法，就完成了store.dispatch()的功能增强。 这里有两点需要注意： createStore方法可以接受整个应用的初始状态作为参数，那样的话，applyMiddleware就是第三个参数了。 const store = createStore( reducer, initial_state, applyMiddleware(logger) ); 中间件的次序有讲究。 const store = createStore( reducer, applyMiddleware(thunk, promise, logger) ); 上面代码中，applyMiddleware方法的三个参数，就是三个中间件。有的中间件有次序要求，使用前要查一下文档。比如，logger就一定要放在最后，否则输出结果会不正确。 1.3. applyMiddlewares() 看到这里，你可能会问，applyMiddlewares这个方法到底是干什么的？ 它是 Redux 的原生方法，作用是将所有中间件组成一个数组，依次执行。下面是它的源码。 export default function applyMiddleware(...middlewares) { return (createStore) => (reducer, preloadedState, enhancer) => { var store = createStore(reducer, preloadedState, enhancer); var dispatch = store.dispatch; var chain = []; var middlewareAPI = { getState: store.getState, dispatch: (action) => dispatch(action) }; chain = middlewares.map(middleware => middleware(middlewareAPI)); dispatch = compose(...chain)(store.dispatch); return {...store, dispatch} } } 上面代码中，所有中间件被放进了一个数组chain，然后嵌套执行，最后执行store.dispatch。可以看到，中间件内部（middlewareAPI）可以拿到 getState和 dispatch 这两个方法。 1.4. 异步操作的基本思路 理解了中间件以后，就可以处理异步操作了。 同步操作只要发出一种 Action 即可，异步操作的差别是它要发出三种 Action。 操作发起时的 Action 操作成功时的 Action 操作失败时的 Action 以向服务器取出数据为例，三种 Action 可以有两种不同的写法。 // 写法一：名称相同，参数不同 { type: 'FETCH_POSTS' } { type: 'FETCH_POSTS', status: 'error', error: 'Oops' } { type: 'FETCH_POSTS', status: 'success', response: { ... } } // 写法二：名称不同 { type: 'FETCH_POSTS_REQUEST' } { type: 'FETCH_POSTS_FAILURE', error: 'Oops' } { type: 'FETCH_POSTS_SUCCESS', response: { ... } } 除了 Action 种类不同，异步操作的 State 也要进行改造，反映不同的操作状态。下面是 State 的一个例子。 let state = { // ... isFetching: true, didInvalidate: true, lastUpdated: 'xxxxxxx' }; 上面代码中，State 的属性isFetching表示是否在抓取数据。didInvalidate表示数据是否过时，lastUpdated表示上一次更新时间。 现在，整个异步操作的思路就很清楚了。 操作开始时，送出一个 Action，触发 State 更新为\"正在操作\"状态，View 重新渲染 操作结束后，再送出一个 Action，触发 State 更新为\"操作结束\"状态，View 再一次重新渲染 1.5. redux-thunk 中间件 异步操作至少要送出两个 Action：用户触发第一个 Action，这个跟同步操作一样，没有问题；如何才能在操作结束时，系统自动送出第二个 Action 呢？ 奥妙就在 Action Creator 之中。 class AsyncApp extends Component { componentDidMount() { const { dispatch, selectedPost } = this.props dispatch(fetchPosts(selectedPost)) } // ... 上面代码是一个异步组件的例子。加载成功后（componentDidMount方法），它送出了（dispatch方法）一个 Action，向服务器要求数据 fetchPosts(selectedSubreddit)。这里的fetchPosts就是 Action Creator。 下面就是fetchPosts的代码，关键之处就在里面。 const fetchPosts = postTitle => (dispatch, getState) => { dispatch(requestPosts(postTitle)); return fetch(`/some/API/${postTitle}.json`) .then(response => response.json()) .then(json => dispatch(receivePosts(postTitle, json))); }; }; // 使用方法一 store.dispatch(fetchPosts('reactjs')); // 使用方法二 store.dispatch(fetchPosts('reactjs')).then(() => console.log(store.getState()) ); 上面代码中，fetchPosts是一个Action Creator（动作生成器），返回一个函数。这个函数执行后，先发出一个Action（requestPosts(postTitle)），然后进行异步操作。拿到结果后，先将结果转成 JSON 格式，然后再发出一个 Action（ receivePosts(postTitle, json)）。 上面代码中，有几个地方需要注意。 fetchPosts返回了一个函数，而普通的 Action Creator 默认返回一个对象。 返回的函数的参数是dispatch和getState这两个 Redux 方法，普通的 Action Creator 的参数是 Action 的内容。 在返回的函数之中，先发出一个 Action（requestPosts(postTitle)），表示操作开始。 异步操作结束之后，再发出一个 Action（receivePosts(postTitle, json)），表示操作结束。 这样的处理，就解决了自动发送第二个 Action 的问题。但是，又带来了一个新的问题，Action 是由store.dispatch方法发送的。而store.dispatch方法正常情况下，参数只能是对象，不能是函数。 这时，就要使用中间件redux-thunk。 import { createStore, applyMiddleware } from 'redux'; import thunk from 'redux-thunk'; import reducer from './reducers'; // Note: this API requires redux@>=3.1.0 const store = createStore( reducer, applyMiddleware(thunk) ); 上面代码使用redux-thunk中间件，改造store.dispatch，使得后者可以接受函数作为参数。 因此，异步操作的第一种解决方案就是，写出一个返回函数的 Action Creator，然后使用redux-thunk中间件改造store.dispatch。 1.6. redux-promise 中间件 既然 Action Creator 可以返回函数，当然也可以返回其他值。另一种异步操作的解决方案，就是让 Action Creator 返回一个 Promise 对象。 这就需要使用redux-promise中间件。 import { createStore, applyMiddleware } from 'redux'; import promiseMiddleware from 'redux-promise'; import reducer from './reducers'; const store = createStore( reducer, applyMiddleware(promiseMiddleware) ); 这个中间件使得store.dispatch方法可以接受 Promise 对象作为参数。这时，Action Creator 有两种写法。写法一，返回值是一个 Promise 对象。 const fetchPosts = (dispatch, postTitle) => new Promise(function (resolve, reject) { dispatch(requestPosts(postTitle)); return fetch(`/some/API/${postTitle}.json`) .then(response => { type: 'FETCH_POSTS', payload: response.json() }); }); 写法二，Action 对象的payload属性是一个 Promise 对象。这需要从redux-actions模块引入createAction方法，并且写法也要变成下面这样。 import { createAction } from 'redux-actions'; class AsyncApp extends Component { componentDidMount() { const { dispatch, selectedPost } = this.props // 发出同步 Action dispatch(requestPosts(selectedPost)); // 发出异步 Action dispatch(createAction( 'FETCH_POSTS', fetch(`/some/API/${postTitle}.json`) .then(response => response.json()) )); } 上面代码中，第二个dispatch方法发出的是异步 Action，只有等到操作结束，这个 Action 才会实际发出。注意，createAction的第二个参数必须是一个 Promise 对象。 看一下redux-promise的源码，就会明白它内部是怎么操作的。 export default function promiseMiddleware({ dispatch }) { return next => action => { if (!isFSA(action)) { return isPromise(action) ? action.then(dispatch) : next(action); } return isPromise(action.payload) ? action.payload.then( result => dispatch({ ...action, payload: result }), error => { dispatch({ ...action, payload: error, error: true }); return Promise.reject(error); } ) : next(action); }; } 从上面代码可以看出，如果 Action 本身是一个 Promise，它 resolve 以后的值应该是一个 Action 对象，会被dispatch方法送出（action.then(dispatch)），但 reject 以后不会有任何动作；如果 Action 对象的payload属性是一个 Promise 对象，那么无论 resolve 和 reject，dispatch方法都会发出 Action。 中间件和异步操作，就介绍到这里。下一篇文章将是最后一部分，介绍如何使用react-redux这个库。 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/Redux入门教程3React-Redux的用法.html":{"url":"Redux/Redux入门教程3React-Redux的用法.html","title":"Redux入门教程3React-Redux的用法","keywords":"","body":"1. Redux 入门教程（三）：React-Redux 的用法1.1. 一、UI 组件1.2. 二、容器组件1.3. 三、connect()1.3.1. 四、mapStateToProps()1.4. 五、mapDispatchToProps()1.5. 六、Provider 组件1.6. 七、实例：计数器1.7. 八、React-Router 路由库1. Redux 入门教程（三）：React-Redux 的用法 1.1. 一、UI 组件 React-Redux 将所有组件分成两大类：UI 组件（presentational component）和容器组件（container component）。 UI 组件有以下几个特征。 只负责 UI 的呈现，不带有任何业务逻辑 没有状态（即不使用this.state这个变量） 所有数据都由参数（this.props）提供 不使用任何 Redux 的 API 下面就是一个 UI 组件的例子。 const Title = value => {value}; 因为不含有状态，UI 组件又称为\"纯组件\"，即它纯函数一样，纯粹由参数决定它的值。 1.2. 二、容器组件 容器组件的特征恰恰相反。 负责管理数据和业务逻辑，不负责 UI 的呈现 带有内部状态 使用 Redux 的 API 总之，只要记住一句话就可以了：UI 组件负责 UI 的呈现，容器组件负责管理数据和逻辑。 你可能会问，如果一个组件既有 UI 又有业务逻辑，那怎么办？回答是，将它拆分成下面的结构：外面是一个容器组件，里面包了一个UI 组件。前者负责与外部的通信，将数据传给后者，由后者渲染出视图。 React-Redux 规定，所有的 UI 组件都由用户提供，容器组件则是由 React-Redux 自动生成。也就是说，用户负责视觉层，状态管理则是全部交给它。 1.3. 三、connect() React-Redux 提供connect方法，用于从 UI 组件生成容器组件。connect的意思，就是将这两种组件连起来。 import { connect } from 'react-redux' const VisibleTodoList = connect()(TodoList); 上面代码中，TodoList是 UI 组件，VisibleTodoList就是由 React-Redux 通过connect方法自动生成的容器组件。 但是，因为没有定义业务逻辑，上面这个容器组件毫无意义，只是 UI 组件的一个单纯的包装层。为了定义业务逻辑，需要给出下面两方面的信息。 输入逻辑：外部的数据（即state对象）如何转换为 UI 组件的参数 输出逻辑：用户发出的动作如何变为 Action 对象，从 UI 组件传出去。 因此，connect方法的完整 API 如下。 import { connect } from 'react-redux' const VisibleTodoList = connect( mapStateToProps, mapDispatchToProps )(TodoList) 上面代码中，connect方法接受两个参数：mapStateToProps和mapDispatchToProps。它们定义了 UI 组件的业务逻辑。前者负责输入逻辑，即将state映射到 UI 组件的参数（props），后者负责输出逻辑，即将用户对 UI 组件的操作映射成 Action。 1.3.1. 四、mapStateToProps() mapStateToProps是一个函数。它的作用就是像它的名字那样，建立一个从（外部的）state对象到（UI 组件的）props对象的映射关系。 作为函数，mapStateToProps执行后应该返回一个对象，里面的每一个键值对就是一个映射。请看下面的例子。 const mapStateToProps = (state) => { return { todos: getVisibleTodos(state.todos, state.visibilityFilter) } } 上面代码中，mapStateToProps是一个函数，它接受state作为参数，返回一个对象。这个对象有一个todos属性，代表 UI 组件的同名参数，后面的getVisibleTodos也是一个函数，可以从state算出 todos 的值。 下面就是getVisibleTodos的一个例子，用来算出todos。 const getVisibleTodos = (todos, filter) => { switch (filter) { case 'SHOW_ALL': return todos case 'SHOW_COMPLETED': return todos.filter(t => t.completed) case 'SHOW_ACTIVE': return todos.filter(t => !t.completed) default: throw new Error('Unknown filter: ' + filter) } } mapStateToProps会订阅 Store，每当state更新的时候，就会自动执行，重新计算 UI 组件的参数，从而触发 UI 组件的重新渲染。 mapStateToProps的第一个参数总是state对象，还可以使用第二个参数，代表容器组件的props对象。 // 容器组件的代码 // // All // const mapStateToProps = (state, ownProps) => { return { active: ownProps.filter === state.visibilityFilter } } 使用ownProps作为参数后，如果容器组件的参数发生变化，也会引发 UI 组件重新渲染。 connect方法可以省略mapStateToProps参数，那样的话，UI 组件就不会订阅Store，就是说 Store 的更新不会引起 UI 组件的更新。 1.4. 五、mapDispatchToProps() mapDispatchToProps是connect函数的第二个参数，用来建立 UI 组件的参数到store.dispatch方法的映射。也就是说，它定义了哪些用户的操作应该当作 Action，传给 Store。它可以是一个函数，也可以是一个对象。 如果mapDispatchToProps是一个函数，会得到dispatch和ownProps（容器组件的props对象）两个参数。 const mapDispatchToProps = (dispatch, ownProps) => { return { onClick: () => { dispatch({ type: 'SET_VISIBILITY_FILTER', filter: ownProps.filter }); } }; } 从上面代码可以看到，mapDispatchToProps作为函数，应该返回一个对象，该对象的每个键值对都是一个映射，定义了 UI 组件的参数怎样发出 Action。 如果mapDispatchToProps是一个对象，它的每个键名也是对应 UI 组件的同名参数，键值应该是一个函数，会被当作 Action creator ，返回的 Action 会由 Redux 自动发出。举例来说，上面的mapDispatchToProps写成对象就是下面这样。 const mapDispatchToProps = { onClick: (filter) => { type: 'SET_VISIBILITY_FILTER', filter: filter }; } 1.5. 六、Provider 组件 connect方法生成容器组件以后，需要让容器组件拿到state对象，才能生成 UI 组件的参数。 一种解决方法是将state对象作为参数，传入容器组件。但是，这样做比较麻烦，尤其是容器组件可能在很深的层级，一级级将state传下去就很麻烦。 React-Redux 提供Provider组件，可以让容器组件拿到state。 import { Provider } from 'react-redux' import { createStore } from 'redux' import todoApp from './reducers' import App from './components/App' let store = createStore(todoApp); render( , document.getElementById('root') ) 上面代码中，Provider在根组件外面包了一层，这样一来，App的所有子组件就默认都可以拿到state了。 它的原理是React组件的context属性，请看源码。 class Provider extends Component { getChildContext() { return { store: this.props.store }; } render() { return this.props.children; } } Provider.childContextTypes = { store: React.PropTypes.object } 上面代码中，store放在了上下文对象context上面。然后，子组件就可以从context拿到store，代码大致如下。 class VisibleTodoList extends Component { componentDidMount() { const { store } = this.context; this.unsubscribe = store.subscribe(() => this.forceUpdate() ); } render() { const props = this.props; const { store } = this.context; const state = store.getState(); // ... } } VisibleTodoList.contextTypes = { store: React.PropTypes.object } React-Redux自动生成的容器组件的代码，就类似上面这样，从而拿到store。 1.6. 七、实例：计数器 我们来看一个实例。下面是一个计数器组件，它是一个纯的 UI 组件。 class Counter extends Component { render() { const { value, onIncreaseClick } = this.props return ( {value} Increase ) } } 上面代码中，这个 UI 组件有两个参数：value和onIncreaseClick。前者需要从state计算得到，后者需要向外发出 Action。 接着，定义value到state的映射，以及onIncreaseClick到dispatch的映射。 function mapStateToProps(state) { return { value: state.count } } function mapDispatchToProps(dispatch) { return { onIncreaseClick: () => dispatch(increaseAction) } } // Action Creator const increaseAction = { type: 'increase' } 然后，使用connect方法生成容器组件。 const App = connect( mapStateToProps, mapDispatchToProps )(Counter) 然后，定义这个组件的 Reducer。 // Reducer function counter(state = { count: 0 }, action) { const count = state.count switch (action.type) { case 'increase': return { count: count + 1 } default: return state } } 最后，生成store对象，并使用Provider在根组件外面包一层。 const store = createStore(counter); ReactDOM.render( , document.getElementById('root') ); 完整的代码看这里。 import React, { Component } from 'react' import PropTypes from 'prop-types' import ReactDOM from 'react-dom' import { createStore } from 'redux' import { Provider, connect } from 'react-redux' // React component class Counter extends Component { render() { const { value, onIncreaseClick } = this.props return ( {value} Increase ) } } Counter.propTypes = { value: PropTypes.number.isRequired, onIncreaseClick: PropTypes.func.isRequired } // Action const increaseAction = { type: 'increase' } // Reducer function counter(state = { count: 0 }, action) { const count = state.count switch (action.type) { case 'increase': return { count: count + 1 } default: return state } } // Store const store = createStore(counter) // Map Redux state to component props function mapStateToProps(state) { return { value: state.count } } // Map Redux actions to component props function mapDispatchToProps(dispatch) { return { onIncreaseClick: () => dispatch(increaseAction) } } // Connected Component const App = connect( mapStateToProps, mapDispatchToProps )(Counter) ReactDOM.render( , document.getElementById('root') ) 1.7. 八、React-Router 路由库 使用React-Router的项目，与其他项目没有不同之处，也是使用 Provider 在 BrowserRouter 外面包一层，毕竟 Provider 的唯一功能就是传入 store 对象。 const Root = ({ store }) => ( ); Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Redux/数字加1.html":{"url":"Redux/数字加1.html","title":"数字加1","keywords":"","body":"1. Click button to add 11. Click button to add 1 \"prop-types\": \"^15.5.10\", \"react\": \"^15.0.2\", \"react-dom\": \"^15.0.2\", \"react-redux\": \"^4.4.5\", \"redux\": \"^3.5.2\" import React, { Component } from 'react' import PropTypes from 'prop-types' import ReactDOM from 'react-dom' import { createStore } from 'redux' import { Provider, connect } from 'react-redux' // React UI component function Counter(props) { const { value, onIncreaseClick } = props return ( {value} Increase ) } Counter.propTypes = { value: PropTypes.number.isRequired, onIncreaseClick: PropTypes.func.isRequired } // Action const increaseAction = { type: 'increase' } // Reducer function counter(state = { count: 0 }, action) { const count = state.count switch (action.type) { case 'increase': return { count: count + 1 } default: return state } } // Store const store = createStore(counter) // Map Redux state to component props function mapStateToProps(state) { return { value: state.count } } // Map Redux actions to component props function mapDispatchToProps(dispatch) { return { onIncreaseClick: () => dispatch(increaseAction) } } // Connected Component, Container of Counter const App = connect( mapStateToProps, mapDispatchToProps )(Counter) ReactDOM.render( , document.getElementById('root') ) Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Terminal/":{"url":"Terminal/","title":"Terminal","keywords":"","body":"1. TOC1. TOC commands mac_curl_request Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"Terminal/commands.html":{"url":"Terminal/commands.html","title":"commands","keywords":"","body":"1. Mac useful commands1.1. kill port1.2. npm commands1.2.1. npm-check-updates1. Mac useful commands ls # list files ls -a # list files including .gitignore, _book, etc 1.1. kill port lsof -i:3000 kill -9 1.2. npm commands npm install -g packagename --save-dev npm start npm t/test/tst npm version major/minor/patch 1.2.1. npm-check-updates npm install -g npm-check-updates ncu # list ncu -u # update package version Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"Terminal/mac_curl_request.html":{"url":"Terminal/mac_curl_request.html","title":"mac_curl_request","keywords":"","body":"1. curl request1. curl request Using postman is a good option. POST: $ curl -X POST -H \"Content-Type: application/json\" -d '{\"firstName\":\"First\", \"lastName\":\"Last\",\"email\":\"user@example.com\",\"username\":\"username\",\"password\":\"password\"}' localhost:3000/users PUT: $ curl -X PUT -H \"Content-Type: application/json\" -d '{\"lastName\": \"Updated\"}' localhost:3000/users/[id] DELETE: $ curl -X DELETE localhost:3000/users/[id] Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"移动端/":{"url":"移动端/","title":"移动端","keywords":"","body":"1. TOC1. TOC Android viewport Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:38:56 "},"移动端/Android.html":{"url":"移动端/Android.html","title":"Android","keywords":"","body":"1. 疑难杂症1.1. Android1.1.1. Android WebView :active 失效1. 疑难杂症 1.1. Android 1.1.1. Android WebView :active 失效 Android WebView :active 失效，即点击瞬间的效果无法被触发。最简单的解决办法是，添加： 详情讨论见：http://stackoverflow.com/questions/4940429/how-to-simulate-active-css-pseudo-class-in-android-on-non-link-elements Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "},"移动端/viewport.html":{"url":"移动端/viewport.html","title":"viewport","keywords":"","body":"1. Viewport1. Viewport width [pixel_value | device-width] width 直接去设置具体数值大部分的安卓手机不支持的 但是IOS支持 user-scalable 是否允许缩放 （no||yes） initial-scale 初始比例 minimum-scale 允许缩放的最小比例 maximum-scale 允许缩放的最大比例 target-densitydpi dpi_value 70–400 //每英寸像素点的个数 device-dpi 设备默认像素密度 high-dpi 高像素密度 medium-dpi 中等像素密度 low-dpi 低像素密度 webkit内核已不准备再支持 Copyright © Guanghui Wang all right reserved，powered by GitbookFile Modified： 2017-10-18 00:28:37 "}}