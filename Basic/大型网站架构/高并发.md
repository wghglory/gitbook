# 如何处理并发和同步

一种我觉得有点老的方式是通过锁机制。

锁机制有两个层面。一种是代码层次上的，如 java 中的同步锁，典型的就是同步关键字 `synchronized`。.net `lock`

另外一种是数据库层次上的，比较典型的就是悲观锁和乐观锁。

## 悲观锁(Pessimistic Locking)

对数据被外界（包括本系统当前的其他事务，以及来自 外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能 真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。

一个典型的倚赖数据库的悲观锁调用：

```sql
select * from account where name="Erica" for update
```

这条 sql 语句锁定了 account 表中所有符合检索条件（ name="Erica" ）的记录。本次事务提交之前（事务提交时会释放事务过程中的锁），外界无法修改这些记录。

Hibernate 的悲观锁，也是基于数据库的锁机制实现。

下面的代码实现了对查询记录的加锁：

```java
String hqlStr = "from TUser as user where user.name='Erica'";
Query query = session.createQuery(hqlStr);
query.setLockMode("user", LockMode.UPGRADE); // 加锁
List userList = query.list();// 执行查询，获取数据
```

`query.setLockMode` 对查询语句中，特定别名所对应的记录进行加锁（我们为 TUser 类指定了一个别名 “user" ），这里也就是对返回的所有 user 记录进行加锁。

Hibernate 的加锁模式有：

- LockMode.NONE ： 无锁机制。
- LockMode.WRITE ： Hibernate 在 Insert 和 Update 记录的时候会自动获取
- LockMode.READ ： Hibernate 在读取记录的时候会自动获取。

以上这三种锁机制一般由 Hibernate 内部使用，如 Hibernate 为了保证 Update 过程中对象不会被外界修改，会在 save 方法实现中自动为目标对象加上 WRITE 锁。

- LockMode.UPGRADE ：利用数据库的 for update 子句加锁。
- LockMode. UPGRADE_NOWAIT ： Oracle 的特定实现，利用 Oracle 的 for update nowait 子句实现加锁。

上面这两种锁机制是我们在应用层较为常用的，加锁一般通过以下方法实现：

- Criteria.setLockMode
- Query.setLockMode
- Session.lock

> 只有在查询开始之前（也就是 Hibernate 生成 SQL 之前）设定加锁，才会真正通过数据库的锁机制进行加锁处理，否则，数据已经通过不包含 for update 子句的 Select SQL 加载进来，所谓数据库加锁也就无从谈起。

## 乐观锁(Optimistic Locking)

相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依 靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库 性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。 如一个金融系统，当某个操作员读取用户的数据，并在读出的用户数据的基础上进 行修改时（如更改用户帐户余额），如果采用悲观锁机制，也就意味着整个操作过程中（从操作员读出数据、开始修改直至提交修改结果的全过程，甚至还包括操作员中途去煮咖啡的时间），数据库记录始终处于加锁状态，可以想见，如果面对几百上千个并发，这样的情况将导致怎样的后果。 乐观锁机制在一定程度上解决了这个问题。

乐观锁，大多是基于数据版本 Version 记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version" 字段来实现。 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。

对于上面修改用户帐户信息的例子而言，假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 \$100 。

1.  操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-\$50 ）。
1.  在操作员 A 操作的过程中，操作员 B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-\$20 ）。
1.  操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣 除后余额（ balance=\$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
1.  操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数 据（ balance=\$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的 数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 **提交版本必须大于记录当前版本才能执行更新** 的乐观锁策略，因此，操作员 B 的提交被驳回。

这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员 A 的操作结果的可能。 从上面的例子可以看出，乐观锁机制避免了长事务中的数据库加锁开销（操作员 A 和操作员 B 操作过程中，都没有对数据库数据加锁），大大提升了大并发量下的系 统整体性能表现。

> 乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如 将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。

Hibernate 在其数据访问引擎中内置了乐观锁实现。如果不用考虑外部系统对数据库的更新操作，利用 Hibernate 提供的透明化乐观锁实现，将大大提升我们的生产力。Hibernate 中可以通过 class 描述符的 optimistic-lock 属性结合 version 描述符指定。

## 常见并发同步案例分析

### 案例一：订票系统案例，某航班只有一张机票，假定有 1w 个人打开你的网站来订票，问你如何解决并发问题(可扩展到任何高并发网站要考虑的并发读写问题)

首先，1w 个人来访问，票没出去前要保证大家都能看到有票，不可能一个人在看到票的时候别人就不能看了。到底谁能抢到，那得看这个人的“运气"（网络快慢等）。其次考虑的问题，并发，1w 个人同时点击购买，到底谁能成交？总共只有一张票。

我们容易想到和并发相关的几个方案 ：

锁同步同步更多指的是应用程序的层面，多个线程进来，只能一个一个的访问，java 中指的是 synchronized 关键字。锁也有 2 个层面，一个是 java 中谈到的对象锁，用于线程同步；另外一个层面是数据库的锁；如果是分布式的系统，显然只能利用数据库端的锁来实现。

假定我们采用了同步机制或者数据库物理锁机制，如何保证 1w 个人还能同时看到有票，显然会牺牲性能，在高并发网站中是不可取的。使用 hibernate 后我们提出了另外一个概念：乐观锁、悲观锁（即传统的物理锁）；

**采用乐观锁即可解决此问题。乐观锁意思是不锁定表的情况下，利用业务的控制来解决并发问题，这样即保证数据的并发可读性又保证保存数据的排他性，保证性能的同时解决了并发带来的脏数据问题。**

hibernate 中如何实现乐观锁：

前提：在现有表当中增加一个冗余字段，version 版本号, long 类型

原理：

1.  只有当前版本号》=数据库表版本号，才能提交
1.  提交成功后，版本号 version ++

实现很简单：在 ormapping 增加一属性 optimistic-lock="version" 即可，以下是样例片段

```xml
<hibernate-mapping>
<class name="com.insigma.stock.ABC" optimistic-lock="version" table="T_Stock" schema="STOCK">
```

### 案例二、股票交易系统、银行系统，大数据量你是如何考虑的

首先，股票交易系统的行情表，每几秒钟就有一个行情记录产生，一天下来就有（假定行情 3 秒一个） 股票数量 ×20×60\*6 条记录，一月下来这个表记录数量多大？ oracle 中一张表的记录数超过 100w 后 查询性能就很差了，如何保证系统性能？再比如，中国移动有上亿的用户量，表如何设计？把所有用于存在于一个表么？

所以，大数量的系统，必须考虑表拆分（表名字不一样，但是结构完全一样），通用的几种方式：

1.  按业务分，比如 手机号的表，我们可以考虑 130 开头的作为一个表，131 开头的另外一张表 以此类推
1.  利用 oracle 的表拆分机制做分表
1.  如果是交易系统，我们可以考虑按时间轴拆分，当日数据一个表，历史数据弄到其它表。这里历史数据的报表和查询不会影响当日交易。

当然，表拆分后我们的应用得做相应的适配。单纯的 ORM Mapping 也许就得改动了。比如部分业务得通过存储过程等

此外，我们还得考虑**缓存**。这里的缓存，指的不仅仅是 hibernate，hibernate 本身提供了一级二级缓存。这里的缓存独立于应用，依然是内存的读取，假如我们能减少数据库频繁的访问，那对系统肯定大大有利的。比如一个电子商务系统的商品搜索，如果某个关键字的商品经常被搜，那就可以考虑这部分商品列表存放到缓存（内存中去），这样不用每次访问数据库，性能大大增加。

简单的缓存大家可以理解为自己做一个 hashmap，把常访问的数据做一个 key，value 是第一次从数据库搜索出来的值，下次访问就可以从 map 里读取，而不读数据库；专业些的目前有独立的缓存框架比如 memcached 等，可独立部署成一个缓存服务器。

## 常见的提高高并发下访问的效率的手段

首先要了解高并发的的瓶颈在哪里？

1.  可能是服务器网络带宽不够
1.  可能 web 线程连接数不够
1.  可能数据库连接查询上不去。

根据不同的情况，解决思路也不同。

第一种情况可以增加网络带宽，DNS 域名解析分发多台服务器。第二种情况：负载均衡，前置代理服务器 nginx、apache 等等第三种：数据库查询优化，读写分离，分表等等

## 总结

- 尽量使用缓存，包括用户缓存，信息缓存等，多花点内存来做缓存，可以大量减少与数据库的交互，提高性能。
- 用 jprofiler 等工具找出性能瓶颈，减少额外的开销。
- 优化数据库查询语句，减少直接使用 hibernate 等工具的直接生成语句（仅耗时较长的查询做优化）。
- 优化数据库结构，多做索引，提高查询效率。
- 统计的功能尽量做缓存，或按每天一统计或定时统计相关报表，避免需要时进行统计的功能。
- 能使用静态页面的地方尽量使用，减少容器的解析（尽量将动态内容生成静态 html 来显示）。
- 解决以上问题后，使用服务器集群来解决单台的瓶颈问题。

## 参考

<http://betakoli.iteye.com/blog/2257095>

---

## .net 高并发

先还原一下 nuget 包，需要改一下 redis 的配置，rabbitmq 的配置以及 Ef 的连接字符串。另外使用的是 CodeFirst，先 update-database 生成数据库后再进行操作。

大量的请求，如果仅仅只有一台服务器肯定是吃不消的，通常一些公司都是一台服务器上部署了很多个网站也充当了数据库服务器、redis 服务器。如果要应用高并发没有足够的硬件支持是不行的。我们需要进行 **分布式集群** 以及 **负载均衡**

这时我们还需要提高网站的吞吐量，怎么提高呢？首先我们需要针对 IO 密集型做异步化操作,抢单的页面不只是有抢单按钮，还有商品的介绍，图片，文字描述等。对于这些数据我们要进行**缓存**，一万个用户一万次请求都从数据库中取数据与只取一次剩下 9999 次从缓存中取效率自然是不一样的

上面说的都是为了解决一个 高 字，而并发才是我们真正需要准备的，假如两个用户同时请求，这时库存还有 1，程序里先判断库存是不是 1，现在都符合条件，然后进行生成订单等操作。就发生了资源共享的问题，明明只有一个订单，但是两个用户都完成了订单，那么这个商品应该给谁呢？假设现在是一个电商网站，今天要举办活动，有 10 个商品低价销售，但是会来抢购的人会特别多，最后只有十个人可以成功的买到商品。

假设的逻辑，我们用户进行了请求，我们把他们的信息放到库里，但是只有前十个人是可以购买商品的，因为库存只有 10 个也许我们可以用锁来解决并发的问题，但是锁无疑带来的是效率的低下，用户体验也极低。我们想要的是快速返回，但是后面那一堆的逻辑怎么办呢？_我们可以使用 RabbitMq 队列，用户的请求到达了抢单接口，我们只向队列中丢一条数据后就立即返回_ 这时又来了一个问题，会有同一个用户多次进行请求的情况，如果像之前的逻辑，前 10 条信息有二条是属于一个人的呢，（这里假设每个人只可以购买一次）我们就需要进行判断了，同一个账户发送的多次请求，我们只认为第一次请求是有效的，剩下的都请都直接返回。因为是并发，_我们又怎么做到第一次请求有效呢？这时我们可以使用 Redis incr 存储用户的标识，Redis 是单线程的，不存在并发的问题。incr 返回为 1 那么是第一次请求，为 N 则是第 N 请求那么它就是无效的_。这是请求标识。请求标识我们可以在抢单接口就进行判断，也就是先拿用户的标识去 Incr，返回为 1 则丢到队列，不为 1 则不丢到队列。也可以在 rabbitmq 的消费端进行处理，从 rabbitmq 消息队列中拿到用户信息后，进行 incr。再进行下一步操作。丢到了消息队列中，我们还需要去处理，consumer 我们肯定是要有多个的，我们可以使用平分分发与手动交付。在这里我们把用户的信息进行入库，当然入库后我们再向 Redis 中存入一条入库标识上面都是在后端，客户端这里点击了抢单按钮后可以立即导向排队界面（是不是很熟悉，某米。。。）在这个界面进行轮询五秒一次，判断当前用户在库中的位置，如果是前十，那么就进行订单操作，不是。。。那就再等，看看会不会有其他用户放弃购买资格。其实讲到这里，已经差不多了，成功的把并行变成了串行。剩下的就是业务处理，怎么做都可以。

其实对于并发还可以有其它的处理方式，比如**乐观锁**也可以有效的控制并发
